{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c730ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28cbbbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>lang_abv</th>\n",
       "      <th>language</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5130fd2cb5</td>\n",
       "      <td>and these comments were considered in formulat...</td>\n",
       "      <td>The rules developed in the interim were put to...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b72532a0b</td>\n",
       "      <td>These are issues that we wrestle with in pract...</td>\n",
       "      <td>Practice groups are not permitted to work on t...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5622f0c60b</td>\n",
       "      <td>you know they can't really defend themselves l...</td>\n",
       "      <td>They can't defend themselves because of their ...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fdcd1bd867</td>\n",
       "      <td>From Cockpit Country to St. Ann's Bay</td>\n",
       "      <td>From St. Ann's Bay to Cockpit Country.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7cfb3d272c</td>\n",
       "      <td>Look, it's your skin, but you're going to be i...</td>\n",
       "      <td>The boss will fire you if he sees you slacking...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                            premise  \\\n",
       "0  5130fd2cb5  and these comments were considered in formulat...   \n",
       "1  5b72532a0b  These are issues that we wrestle with in pract...   \n",
       "2  5622f0c60b  you know they can't really defend themselves l...   \n",
       "3  fdcd1bd867              From Cockpit Country to St. Ann's Bay   \n",
       "4  7cfb3d272c  Look, it's your skin, but you're going to be i...   \n",
       "\n",
       "                                          hypothesis lang_abv language  label  \n",
       "0  The rules developed in the interim were put to...       en  English      0  \n",
       "1  Practice groups are not permitted to work on t...       en  English      2  \n",
       "2  They can't defend themselves because of their ...       en  English      0  \n",
       "3             From St. Ann's Bay to Cockpit Country.       en  English      2  \n",
       "4  The boss will fire you if he sees you slacking...       en  English      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('augmented_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9c7b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101367, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18d306fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English       6870\n",
       "Chinese       6822\n",
       "Arabic        6802\n",
       "French        6780\n",
       "Swahili       6770\n",
       "Urdu          6760\n",
       "Vietnamese    6758\n",
       "Russian       6752\n",
       "Hindi         6747\n",
       "Greek         6744\n",
       "Thai          6742\n",
       "Spanish       6732\n",
       "Turkish       6702\n",
       "German        6702\n",
       "Bulgarian     6684\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e805f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['premise'] = df['premise'].str.replace('.', '',regex=True)\n",
    "df['premise'] = df['premise'].str.replace('http\\S+|www.\\S+', '',regex=True)\n",
    "\n",
    "df['hypothesis'] = df['hypothesis'].str.replace('.', '',regex=True)\n",
    "df['hypothesis'] = df['hypothesis'].str.replace('http\\S+|www.\\S+', '',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba39616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "shuffled_df = shuffle(df)\n",
    "\n",
    "train, test = train_test_split(\n",
    "                    shuffled_df, train_size = 0.8, test_size = 0.2, shuffle=True, \n",
    "                    stratify = shuffled_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe88a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, shuffled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aea64d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(['label', 'id'], axis = 1)\n",
    "y_train = train['label']\n",
    "\n",
    "x_test = test.drop(['label', 'id'], axis = 1)\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "999609a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81093, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab0c93dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81093,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4064521",
   "metadata": {},
   "source": [
    "#### For CLS and word level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de28c971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
    "# tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "# model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n",
    "# from tqdm import tqdm\n",
    "# def extract_xlm_r(list_of_sentences=[],batch_size=16):\n",
    "#     cls_hidden_states = []\n",
    "#     train_word_vectors = []\n",
    "#     if len(list_of_sentences)<batch_size: #go longer ones we should batch\n",
    "#         tknzed= tokenizer(list_of_sentences, return_tensors=\"pt\",max_length=max_length, padding = \"max_length\", truncation = True)\n",
    "#         b=model(**tknzed)\n",
    "#         cls_hidden_states = torch.squeeze(b.last_hidden_state[:,0,:])\n",
    "#         train_word_vectors = b.last_hidden_state[:, 1:, :]\n",
    "#     else:\n",
    "#         for i in tqdm(range(0,len(list_of_sentences),batch_size)):    \n",
    "#             tknzed= tokenizer(list_of_sentences[i:min(len(list_of_sentences),i+batch_size)],  max_length = max_length, return_tensors=\"pt\", padding=\"max_length\", truncation = True)\n",
    "#             b=model(**tknzed)\n",
    "#             cls_hidden_states.append(torch.squeeze(b.last_hidden_state[:,0,:]))\n",
    "#             train_word_vectors.append(b.last_hidden_state[:, 1:, :])\n",
    "# #             print(b.last_hidden_state[:,0,:].shape)\n",
    "# #             print(b.last_hidden_state[:,1:,:].shape)\n",
    "#     return cls_hidden_states, train_word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0b7bea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(0, len(x_train1), 400):\n",
    "#     reduced_x_train = x_train1[i: i + 400]\n",
    "#     cls_reduced_x_train_xlm, word_reduced_x_train_xlm = extract_xlm_r(list(reduced_x_train))\n",
    "#     cls_reduced_x_train_torch = torch.cat(cls_reduced_x_train_xlm)\n",
    "#     word_reduced_x_train_torch = torch.cat(word_reduced_x_train_xlm)\n",
    "#     word_reduced_x_train_features = word_reduced_x_train_torch.cpu().detach().numpy()\n",
    "#     cls_reduced_x_train_features = cls_reduced_x_train_torch.cpu().detach().numpy()\n",
    "#     print(i)\n",
    "#     if i != 0:\n",
    "#         cls_x_train_features = np.concatenate((cls_x_train_features, cls_reduced_x_train_features), axis = 0)\n",
    "#         word_x_train_features = np.concatenate((word_x_train_features, word_reduced_x_train_features), axis = 0)\n",
    "#     else:\n",
    "#         cls_x_train_features = cls_reduced_x_train_features\n",
    "#         word_x_train_features = word_reduced_x_train_features\n",
    "# #     reduced_y_train = np.asarray(reduced_y_train)\n",
    "#     print(cls_x_train_features.shape)\n",
    "#     print(word_x_train_features.shape)\n",
    "#     del reduced_x_train, cls_reduced_x_train_xlm, cls_reduced_x_train_torch, cls_reduced_x_train_features, word_reduced_x_train_xlm, word_reduced_x_train_features, word_reduced_x_train_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ec04a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('train1_word_features_xlm.npy', 'wb') as f:\n",
    "#     np.save(f, word_x_train_features)\n",
    "    \n",
    "# with open('train1_cls_features_xlm.npy', 'wb') as f:\n",
    "#     np.save(f, cls_x_train_features)\n",
    "    \n",
    "# with open('train1_labels_xlm.npy', 'wb') as f:\n",
    "#     np.save(f, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91024f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del word_x_train_features, cls_x_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "789a44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, len(x_train2), 400):\n",
    "#     reduced_x_train = x_train2[i: i + 400]\n",
    "#     cls_reduced_x_train_xlm, word_reduced_x_train_xlm = extract_xlm_r(list(reduced_x_train))\n",
    "#     cls_reduced_x_train_torch = torch.cat(cls_reduced_x_train_xlm)\n",
    "#     word_reduced_x_train_torch = torch.cat(word_reduced_x_train_xlm)\n",
    "#     word_reduced_x_train_features = word_reduced_x_train_torch.cpu().detach().numpy()\n",
    "#     cls_reduced_x_train_features = cls_reduced_x_train_torch.cpu().detach().numpy()\n",
    "#     print(i)\n",
    "#     if i != 0:\n",
    "#         cls_x_train_features = np.concatenate((cls_x_train_features, cls_reduced_x_train_features), axis = 0)\n",
    "#         word_x_train_features = np.concatenate((word_x_train_features, word_reduced_x_train_features), axis = 0)\n",
    "#     else:\n",
    "#         cls_x_train_features = cls_reduced_x_train_features\n",
    "#         word_x_train_features = word_reduced_x_train_features\n",
    "# #     reduced_y_train = np.asarray(reduced_y_train)\n",
    "#     print(cls_x_train_features.shape)\n",
    "#     print(word_x_train_features.shape)\n",
    "#     del reduced_x_train, cls_reduced_x_train_xlm, cls_reduced_x_train_torch, cls_reduced_x_train_features, word_reduced_x_train_xlm, word_reduced_x_train_features, word_reduced_x_train_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653d085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('train2_word_features_xlm.npy', 'wb') as f:\n",
    "#     np.save(f, word_x_train_features)\n",
    "    \n",
    "# with open('train2_cls_features_xlm.npy', 'wb') as f:\n",
    "#     np.save(f, cls_x_train_features)\n",
    "    \n",
    "# with open('train2_labels_xlm.npy', 'wb') as f:\n",
    "#     np.save(f, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c60421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del word_x_train_features, cls_x_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333aa5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, len(x_test), 400):\n",
    "#     reduced_x_test = x_test[i: i + 400]\n",
    "#     cls_reduced_x_test_xlm, word_reduced_x_test_xlm = extract_xlm_r(list(reduced_x_test))\n",
    "#     cls_reduced_x_test_torch = torch.cat(cls_reduced_x_test_xlm)\n",
    "#     word_reduced_x_test_torch = torch.cat(word_reduced_x_test_xlm)\n",
    "#     word_reduced_x_test_features = word_reduced_x_test_torch.cpu().detach().numpy()\n",
    "#     cls_reduced_x_test_features = cls_reduced_x_test_torch.cpu().detach().numpy()\n",
    "#     print(i)\n",
    "#     if i != 0:\n",
    "#         cls_x_test_features = np.concatenate((cls_x_test_features, cls_reduced_x_test_features), axis = 0)\n",
    "#         word_x_test_features = np.concatenate((word_x_test_features, word_reduced_x_test_features), axis = 0)\n",
    "#     else:\n",
    "#         cls_x_test_features = cls_reduced_x_test_features\n",
    "#         word_x_test_features = word_reduced_x_test_features\n",
    "# #     reduced_y_train = np.asarray(reduced_y_train)\n",
    "#     print(cls_x_test_features.shape)\n",
    "#     print(word_x_test_features.shape)\n",
    "#     del reduced_x_test, cls_reduced_x_test_xlm, cls_reduced_x_test_torch, cls_reduced_x_test_features, word_reduced_x_test_xlm, word_reduced_x_test_features, word_reduced_x_test_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc8c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('test_cls_features_xlm.npy', 'wb') as f:\n",
    "#     np.save(f, cls_x_test_features)\n",
    "    \n",
    "# with open('test_word_features_xlm.npy', 'wb') as f:\n",
    "#     np.save(f, word_x_test_features)\n",
    "    \n",
    "# with open('test_labels_xlm.npy', 'wb') as f:\n",
    "#     np.save(f, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222f4fb5",
   "metadata": {},
   "source": [
    "### For only CLS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cce9c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n",
    "from tqdm import tqdm\n",
    "def extract_xlm_r_cls_only(list_of_premises=[], list_of_hypothesis=[], batch_size=16):\n",
    "    cls_hidden_states = []\n",
    "    if len(list_of_premises)<batch_size: #go longer ones we should batch\n",
    "        tknzed= tokenizer(list_of_premises, list_of_hypothesis, return_tensors=\"pt\", padding=True)\n",
    "        b=model(**tknzed)\n",
    "        cls_hidden_states = torch.squeeze(b.last_hidden_state[:,0,:])\n",
    "    else:\n",
    "        for i in tqdm(range(0,len(list_of_premises),batch_size)):    \n",
    "            tknzed= tokenizer(list_of_premises[i:min(len(list_of_premises),i+batch_size)], list_of_hypothesis[i:min(len(list_of_hypothesis),i+batch_size)], return_tensors=\"pt\", padding=True)\n",
    "            b=model(**tknzed)\n",
    "            cls_hidden_states.append(torch.squeeze(b.last_hidden_state[:,0,:]))\n",
    "#             print(b.last_hidden_state[:,0,:].shape)\n",
    "#             print(b.last_hidden_state[:,1:,:].shape)\n",
    "    return cls_hidden_states\n",
    "    return cls_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53d91f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [01:28<00:00,  3.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "(800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:19<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "(1200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "(1600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "(2000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:19<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "(2400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "(2800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800\n",
      "(3200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "(3600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:16<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600\n",
      "(4000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "(4400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400\n",
      "(4800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:19<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n",
      "(5200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200\n",
      "(5600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600\n",
      "(6000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "(6400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:20<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400\n",
      "(6800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6800\n",
      "(7200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:23<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200\n",
      "(7600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7600\n",
      "(8000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:22<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "(8400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:22<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400\n",
      "(8800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:25<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8800\n",
      "(9200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:30<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200\n",
      "(9600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600\n",
      "(10000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:24<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "(10400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:23<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10400\n",
      "(10800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:29<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10800\n",
      "(11200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:28<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11200\n",
      "(11600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:25<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11600\n",
      "(12000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:23<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "(12400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:23<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12400\n",
      "(12800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:22<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800\n",
      "(13200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:24<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13200\n",
      "(13600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13600\n",
      "(14000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:22<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "(14400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:22<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14400\n",
      "(14800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:24<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14800\n",
      "(15200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:23<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15200\n",
      "(15600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:20<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15600\n",
      "(16000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:24<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "(16400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:26<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16400\n",
      "(16800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16800\n",
      "(17200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:22<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17200\n",
      "(17600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:26<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17600\n",
      "(18000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:25<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n",
      "(18400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:22<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18400\n",
      "(18800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:24<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18800\n",
      "(19200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:22<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19200\n",
      "(19600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19600\n",
      "(20000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "(20400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400\n",
      "(20800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:20<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20800\n",
      "(21200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21200\n",
      "(21600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21600\n",
      "(22000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000\n",
      "(22400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:22<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22400\n",
      "(22800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22800\n",
      "(23200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:20<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23200\n",
      "(23600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23600\n",
      "(24000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:20<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n",
      "(24400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:20<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24400\n",
      "(24800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:19<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24800\n",
      "(25200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25200\n",
      "(25600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:19<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25600\n",
      "(26000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26000\n",
      "(26400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26400\n",
      "(26800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:16<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26800\n",
      "(27200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27200\n",
      "(27600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:20<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27600\n",
      "(28000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:19<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000\n",
      "(28400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:20<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28400\n",
      "(28800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:23<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28800\n",
      "(29200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29200\n",
      "(29600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29600\n",
      "(30000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "(30400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30400\n",
      "(30800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30800\n",
      "(31200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:19<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31200\n",
      "(31600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31600\n",
      "(32000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000\n",
      "(32400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:16<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32400\n",
      "(32800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32800\n",
      "(33200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33200\n",
      "(33600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:23<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600\n",
      "(34000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:25<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34000\n",
      "(34400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34400\n",
      "(34800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34800\n",
      "(35200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:20<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35200\n",
      "(35600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35600\n",
      "(36000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000\n",
      "(36400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:20<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36400\n",
      "(36800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800\n",
      "(37200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37200\n",
      "(37600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37600\n",
      "(38000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:20<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38000\n",
      "(38400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:16<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38400\n",
      "(38800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:19<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38800\n",
      "(39200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:20<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39200\n",
      "(39600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:23<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39600\n",
      "(40000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:28<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "(40400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:22<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40400\n",
      "(40800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40800\n",
      "(41200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41200\n",
      "(41600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41600\n",
      "(42000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n",
      "(42400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:20<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42400\n",
      "(42800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:18<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42800\n",
      "(43200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200\n",
      "(43600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:16<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43600\n",
      "(44000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44000\n",
      "(44400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44400\n",
      "(44800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44800\n",
      "(45200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45200\n",
      "(45600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45600\n",
      "(46000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:16<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46000\n",
      "(46400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:16<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46400\n",
      "(46800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46800\n",
      "(47200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:19<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47200\n",
      "(47600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47600\n",
      "(48000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n",
      "(48400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48400\n",
      "(48800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48800\n",
      "(49200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49200\n",
      "(49600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:16<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49600\n",
      "(50000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "(50400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50400\n",
      "(50800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:16<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50800\n",
      "(51200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51200\n",
      "(51600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51600\n",
      "(52000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52000\n",
      "(52400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52400\n",
      "(52800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52800\n",
      "(53200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:16<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53200\n",
      "(53600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53600\n",
      "(54000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000\n",
      "(54400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54400\n",
      "(54800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54800\n",
      "(55200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55200\n",
      "(55600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55600\n",
      "(56000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56000\n",
      "(56400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:17<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56400\n",
      "(56800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56800\n",
      "(57200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [17:19<00:00, 41.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57200\n",
      "(57600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [02:27<00:00,  5.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57600\n",
      "(58000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [02:45<00:00,  6.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58000\n",
      "(58400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [01:51<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58400\n",
      "(58800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58800\n",
      "(59200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [02:47<00:00,  6.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59200\n",
      "(59600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:24<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59600\n",
      "(60000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:36<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "(60400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60400\n",
      "(60800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60800\n",
      "(61200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61200\n",
      "(61600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [05:06<00:00, 12.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61600\n",
      "(62000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [01:40<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62000\n",
      "(62400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [06:48<00:00, 16.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62400\n",
      "(62800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [02:02<00:00,  4.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62800\n",
      "(63200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:32<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63200\n",
      "(63600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:36<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63600\n",
      "(64000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:21<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64000\n",
      "(64400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:11<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64400\n",
      "(64800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64800\n",
      "(65200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65200\n",
      "(65600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65600\n",
      "(66000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:11<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66000\n",
      "(66400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66400\n",
      "(66800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66800\n",
      "(67200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:11<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67200\n",
      "(67600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:11<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67600\n",
      "(68000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:10<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68000\n",
      "(68400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68400\n",
      "(68800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68800\n",
      "(69200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69200\n",
      "(69600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69600\n",
      "(70000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:11<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "(70400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70400\n",
      "(70800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70800\n",
      "(71200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71200\n",
      "(71600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71600\n",
      "(72000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72000\n",
      "(72400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:11<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72400\n",
      "(72800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72800\n",
      "(73200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:11<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73200\n",
      "(73600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73600\n",
      "(74000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:11<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74000\n",
      "(74400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74400\n",
      "(74800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74800\n",
      "(75200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:11<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75200\n",
      "(75600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75600\n",
      "(76000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76000\n",
      "(76400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76400\n",
      "(76800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76800\n",
      "(77200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77200\n",
      "(77600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77600\n",
      "(78000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:11<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78000\n",
      "(78400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78400\n",
      "(78800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78800\n",
      "(79200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79200\n",
      "(79600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:11<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79600\n",
      "(80000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "(80400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80400\n",
      "(80800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 19/19 [00:09<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80800\n",
      "(81093, 768)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(x_train), 400):\n",
    "    reduced_x_train = x_train[i: i + 400]\n",
    "    cls_reduced_x_train = extract_xlm_r_cls_only(list(reduced_x_train['premise']), list(reduced_x_train['hypothesis']))\n",
    "    cls_reduced_x_train_torch = torch.cat(cls_reduced_x_train)\n",
    "    cls_reduced_x_train_features = cls_reduced_x_train_torch.cpu().detach().numpy()\n",
    "    print(i)\n",
    "    if i != 0:\n",
    "        cls_x_train_features = np.concatenate((cls_x_train_features, cls_reduced_x_train_features), axis = 0)\n",
    "    else:\n",
    "        cls_x_train_features = cls_reduced_x_train_features\n",
    "#     reduced_y_train = np.asarray(reduced_y_train)\n",
    "    print(cls_x_train_features.shape)\n",
    "    del reduced_x_train, cls_reduced_x_train, cls_reduced_x_train_torch, cls_reduced_x_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0559f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_cls_features_xlm_v3.npy', 'wb') as f:\n",
    "    np.save(f, cls_x_train_features)\n",
    "    \n",
    "with open('train_labels_xlm_v3.npy', 'wb') as f:\n",
    "    np.save(f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a24eafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "(800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "(1200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "(1600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "(2000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "(2400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "(2800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800\n",
      "(3200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:11<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "(3600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600\n",
      "(4000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "(4400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400\n",
      "(4800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n",
      "(5200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200\n",
      "(5600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600\n",
      "(6000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "(6400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400\n",
      "(6800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:11<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6800\n",
      "(7200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200\n",
      "(7600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7600\n",
      "(8000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "(8400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400\n",
      "(8800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8800\n",
      "(9200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200\n",
      "(9600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600\n",
      "(10000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "(10400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10400\n",
      "(10800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10800\n",
      "(11200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11200\n",
      "(11600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11600\n",
      "(12000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "(12400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12400\n",
      "(12800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800\n",
      "(13200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13200\n",
      "(13600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13600\n",
      "(14000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:14<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "(14400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14400\n",
      "(14800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:11<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14800\n",
      "(15200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15200\n",
      "(15600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15600\n",
      "(16000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "(16400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16400\n",
      "(16800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16800\n",
      "(17200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17200\n",
      "(17600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:13<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17600\n",
      "(18000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n",
      "(18400, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18400\n",
      "(18800, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:11<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18800\n",
      "(19200, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19200\n",
      "(19600, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:12<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19600\n",
      "(20000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 18/18 [00:08<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "(20274, 768)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(x_test), 400):\n",
    "    reduced_x_test = x_test[i: i + 400]\n",
    "    cls_reduced_x_test = extract_xlm_r_cls_only(list(reduced_x_test['premise']), list(reduced_x_test['hypothesis']))\n",
    "    cls_reduced_x_test_torch = torch.cat(cls_reduced_x_test)\n",
    "    cls_reduced_x_test_features = cls_reduced_x_test_torch.cpu().detach().numpy()\n",
    "    print(i)\n",
    "    if i != 0:\n",
    "        cls_x_test_features = np.concatenate((cls_x_test_features, cls_reduced_x_test_features), axis = 0)\n",
    "    else:\n",
    "        cls_x_test_features = cls_reduced_x_test_features\n",
    "#     reduced_y_train = np.asarray(reduced_y_train)\n",
    "    print(cls_x_test_features.shape)\n",
    "    del reduced_x_test, cls_reduced_x_test, cls_reduced_x_test_torch, cls_reduced_x_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cef0e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_cls_features_xlm_v3.npy', 'wb') as f:\n",
    "    np.save(f, cls_x_test_features)\n",
    "    \n",
    "with open('test_labels_xlm_v3.npy', 'wb') as f:\n",
    "    np.save(f, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1f302d",
   "metadata": {},
   "source": [
    "## Loading features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63f42d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_x_train = np.load('train_cls_features_xlm_v3.npy', allow_pickle=True)\n",
    "y_train = np.load('train_labels_xlm_v3.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c1a90d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81093, 768)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94302bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81093,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "569349ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_x_test = np.load('test_cls_features_xlm_v3.npy', allow_pickle=True)\n",
    "y_test = np.load('test_labels_xlm_v3.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e36a7dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(cls_x_train)\n",
    "simple_x_train = scaler.transform(cls_x_train)\n",
    "\n",
    "simple_x_test =scaler.transform(cls_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31199f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81093, 768)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ae701f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.52      0.52      6785\n",
      "           1       0.47      0.47      0.47      6719\n",
      "           2       0.49      0.48      0.49      6770\n",
      "\n",
      "    accuracy                           0.49     20274\n",
      "   macro avg       0.49      0.49      0.49     20274\n",
      "weighted avg       0.49      0.49      0.49     20274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver = \"liblinear\")\n",
    "clf.fit(simple_x_train, y_train)\n",
    "pred = clf.predict(simple_x_test)\n",
    "pred = classification_report(y_test, pred)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e40a32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.44      0.45      6785\n",
      "           1       0.43      0.45      0.44      6719\n",
      "           2       0.44      0.46      0.45      6770\n",
      "\n",
      "    accuracy                           0.45     20274\n",
      "   macro avg       0.45      0.45      0.45     20274\n",
      "weighted avg       0.45      0.45      0.45     20274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geetshingi/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC()\n",
    "\n",
    "model.fit(simple_x_train, y_train)\n",
    "pred = model.predict(simple_x_test)\n",
    "pred = classification_report(y_test, pred)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1edc5882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.42      0.43      6785\n",
      "           1       0.41      0.38      0.39      6719\n",
      "           2       0.40      0.43      0.42      6770\n",
      "\n",
      "    accuracy                           0.41     20274\n",
      "   macro avg       0.41      0.41      0.41     20274\n",
      "weighted avg       0.41      0.41      0.41     20274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Perceptron()\n",
    "\n",
    "model.fit(simple_x_train, y_train)\n",
    "pred = model.predict(simple_x_test)\n",
    "pred = classification_report(y_test, pred)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44fb7845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(simple_x_train, y_train)\n",
    "pred = model.predict(simple_x_test)\n",
    "pred = classification_report(y_test, pred)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31b64dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x_train_torch = torch.from_numpy(cls_x_train)\n",
    "x_test_torch = torch.from_numpy(cls_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d60de158",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipper = lambda x,y : list(zip(x,list(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab7fe796",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_torch = zipper(x_train_torch, y_train)\n",
    "test_torch = zipper(x_test_torch, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_torch, batch_size=16)\n",
    "test_loader = torch.utils.data.DataLoader(test_torch, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b43787d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module): \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() \n",
    "#         self.gru = nn.GRU(input_size=768, hidden_size=32, batch_first=True) \n",
    "        self.fc1 = nn.Linear(768,3)\n",
    "#         self.fc2 = nn.Linear(256, 64)\n",
    "#         self.fc3 = nn.Linear(128, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "#         self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         out, hn = self.gru(x, torch.randn(1, len(x), 32))\n",
    "#         out = self.fc1(self.relu(x))\n",
    "#         out = self.fc2(self.relu(out))\n",
    "        out = self.fc1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d967119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "linear_model = Net()\n",
    "print(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdfa8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# specify optimizer (stochastic gradient descent) and learning rate = 0.01\n",
    "optimizer = torch.optim.SGD(linear_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4625a41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.185740 \tValidation Loss: 1.783295\n",
      "Validation loss decreased (inf --> 1.783295).         Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 1.182679 \tValidation Loss: 1.769638\n",
      "Validation loss decreased (1.783295 --> 1.769638).         Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 1.179867 \tValidation Loss: 1.757969\n",
      "Validation loss decreased (1.769638 --> 1.757969).         Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 1.177343 \tValidation Loss: 1.747956\n",
      "Validation loss decreased (1.757969 --> 1.747956).         Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 1.175050 \tValidation Loss: 1.739328\n",
      "Validation loss decreased (1.747956 --> 1.739328).         Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 1.172947 \tValidation Loss: 1.731865\n",
      "Validation loss decreased (1.739328 --> 1.731865).         Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.171004 \tValidation Loss: 1.725382\n",
      "Validation loss decreased (1.731865 --> 1.725382).         Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.169197 \tValidation Loss: 1.719731\n",
      "Validation loss decreased (1.725382 --> 1.719731).         Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.167507 \tValidation Loss: 1.714788\n",
      "Validation loss decreased (1.719731 --> 1.714788).         Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.165921 \tValidation Loss: 1.710449\n",
      "Validation loss decreased (1.714788 --> 1.710449).         Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.164427 \tValidation Loss: 1.706628\n",
      "Validation loss decreased (1.710449 --> 1.706628).         Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.163014 \tValidation Loss: 1.703253\n",
      "Validation loss decreased (1.706628 --> 1.703253).         Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.161675 \tValidation Loss: 1.700263\n",
      "Validation loss decreased (1.703253 --> 1.700263).         Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.160402 \tValidation Loss: 1.697606\n",
      "Validation loss decreased (1.700263 --> 1.697606).         Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.159190 \tValidation Loss: 1.695238\n",
      "Validation loss decreased (1.697606 --> 1.695238).         Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 1.158034 \tValidation Loss: 1.693122\n",
      "Validation loss decreased (1.695238 --> 1.693122).         Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 1.156929 \tValidation Loss: 1.691225\n",
      "Validation loss decreased (1.693122 --> 1.691225).         Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 1.155870 \tValidation Loss: 1.689520\n",
      "Validation loss decreased (1.691225 --> 1.689520).         Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 1.154856 \tValidation Loss: 1.687983\n",
      "Validation loss decreased (1.689520 --> 1.687983).         Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 1.153882 \tValidation Loss: 1.686593\n",
      "Validation loss decreased (1.687983 --> 1.686593).         Saving model ...\n",
      "Epoch: 21 \tTraining Loss: 1.152945 \tValidation Loss: 1.685332\n",
      "Validation loss decreased (1.686593 --> 1.685332).         Saving model ...\n",
      "Epoch: 22 \tTraining Loss: 1.152044 \tValidation Loss: 1.684186\n",
      "Validation loss decreased (1.685332 --> 1.684186).         Saving model ...\n",
      "Epoch: 23 \tTraining Loss: 1.151176 \tValidation Loss: 1.683139\n",
      "Validation loss decreased (1.684186 --> 1.683139).         Saving model ...\n",
      "Epoch: 24 \tTraining Loss: 1.150338 \tValidation Loss: 1.682180\n",
      "Validation loss decreased (1.683139 --> 1.682180).         Saving model ...\n",
      "Epoch: 25 \tTraining Loss: 1.149530 \tValidation Loss: 1.681299\n",
      "Validation loss decreased (1.682180 --> 1.681299).         Saving model ...\n",
      "Epoch: 26 \tTraining Loss: 1.148748 \tValidation Loss: 1.680486\n",
      "Validation loss decreased (1.681299 --> 1.680486).         Saving model ...\n",
      "Epoch: 27 \tTraining Loss: 1.147993 \tValidation Loss: 1.679733\n",
      "Validation loss decreased (1.680486 --> 1.679733).         Saving model ...\n",
      "Epoch: 28 \tTraining Loss: 1.147261 \tValidation Loss: 1.679034\n",
      "Validation loss decreased (1.679733 --> 1.679034).         Saving model ...\n",
      "Epoch: 29 \tTraining Loss: 1.146553 \tValidation Loss: 1.678381\n",
      "Validation loss decreased (1.679034 --> 1.678381).         Saving model ...\n",
      "Epoch: 30 \tTraining Loss: 1.145866 \tValidation Loss: 1.677770\n",
      "Validation loss decreased (1.678381 --> 1.677770).         Saving model ...\n",
      "Epoch: 31 \tTraining Loss: 1.145200 \tValidation Loss: 1.677195\n",
      "Validation loss decreased (1.677770 --> 1.677195).         Saving model ...\n",
      "Epoch: 32 \tTraining Loss: 1.144553 \tValidation Loss: 1.676652\n",
      "Validation loss decreased (1.677195 --> 1.676652).         Saving model ...\n",
      "Epoch: 33 \tTraining Loss: 1.143925 \tValidation Loss: 1.676138\n",
      "Validation loss decreased (1.676652 --> 1.676138).         Saving model ...\n",
      "Epoch: 34 \tTraining Loss: 1.143315 \tValidation Loss: 1.675648\n",
      "Validation loss decreased (1.676138 --> 1.675648).         Saving model ...\n",
      "Epoch: 35 \tTraining Loss: 1.142721 \tValidation Loss: 1.675180\n",
      "Validation loss decreased (1.675648 --> 1.675180).         Saving model ...\n",
      "Epoch: 36 \tTraining Loss: 1.142143 \tValidation Loss: 1.674730\n",
      "Validation loss decreased (1.675180 --> 1.674730).         Saving model ...\n",
      "Epoch: 37 \tTraining Loss: 1.141581 \tValidation Loss: 1.674298\n",
      "Validation loss decreased (1.674730 --> 1.674298).         Saving model ...\n",
      "Epoch: 38 \tTraining Loss: 1.141034 \tValidation Loss: 1.673880\n",
      "Validation loss decreased (1.674298 --> 1.673880).         Saving model ...\n",
      "Epoch: 39 \tTraining Loss: 1.140500 \tValidation Loss: 1.673475\n",
      "Validation loss decreased (1.673880 --> 1.673475).         Saving model ...\n",
      "Epoch: 40 \tTraining Loss: 1.139980 \tValidation Loss: 1.673081\n",
      "Validation loss decreased (1.673475 --> 1.673081).         Saving model ...\n",
      "Epoch: 41 \tTraining Loss: 1.139472 \tValidation Loss: 1.672696\n",
      "Validation loss decreased (1.673081 --> 1.672696).         Saving model ...\n",
      "Epoch: 42 \tTraining Loss: 1.138977 \tValidation Loss: 1.672319\n",
      "Validation loss decreased (1.672696 --> 1.672319).         Saving model ...\n",
      "Epoch: 43 \tTraining Loss: 1.138493 \tValidation Loss: 1.671950\n",
      "Validation loss decreased (1.672319 --> 1.671950).         Saving model ...\n",
      "Epoch: 44 \tTraining Loss: 1.138021 \tValidation Loss: 1.671586\n",
      "Validation loss decreased (1.671950 --> 1.671586).         Saving model ...\n",
      "Epoch: 45 \tTraining Loss: 1.137560 \tValidation Loss: 1.671228\n",
      "Validation loss decreased (1.671586 --> 1.671228).         Saving model ...\n",
      "Epoch: 46 \tTraining Loss: 1.137109 \tValidation Loss: 1.670873\n",
      "Validation loss decreased (1.671228 --> 1.670873).         Saving model ...\n",
      "Epoch: 47 \tTraining Loss: 1.136668 \tValidation Loss: 1.670523\n",
      "Validation loss decreased (1.670873 --> 1.670523).         Saving model ...\n",
      "Epoch: 48 \tTraining Loss: 1.136237 \tValidation Loss: 1.670175\n",
      "Validation loss decreased (1.670523 --> 1.670175).         Saving model ...\n",
      "Epoch: 49 \tTraining Loss: 1.135815 \tValidation Loss: 1.669830\n",
      "Validation loss decreased (1.670175 --> 1.669830).         Saving model ...\n",
      "Epoch: 50 \tTraining Loss: 1.135402 \tValidation Loss: 1.669487\n",
      "Validation loss decreased (1.669830 --> 1.669487).         Saving model ...\n",
      "Epoch: 51 \tTraining Loss: 1.134998 \tValidation Loss: 1.669145\n",
      "Validation loss decreased (1.669487 --> 1.669145).         Saving model ...\n",
      "Epoch: 52 \tTraining Loss: 1.134602 \tValidation Loss: 1.668804\n",
      "Validation loss decreased (1.669145 --> 1.668804).         Saving model ...\n",
      "Epoch: 53 \tTraining Loss: 1.134214 \tValidation Loss: 1.668464\n",
      "Validation loss decreased (1.668804 --> 1.668464).         Saving model ...\n",
      "Epoch: 54 \tTraining Loss: 1.133833 \tValidation Loss: 1.668125\n",
      "Validation loss decreased (1.668464 --> 1.668125).         Saving model ...\n",
      "Epoch: 55 \tTraining Loss: 1.133461 \tValidation Loss: 1.667786\n",
      "Validation loss decreased (1.668125 --> 1.667786).         Saving model ...\n",
      "Epoch: 56 \tTraining Loss: 1.133095 \tValidation Loss: 1.667447\n",
      "Validation loss decreased (1.667786 --> 1.667447).         Saving model ...\n",
      "Epoch: 57 \tTraining Loss: 1.132737 \tValidation Loss: 1.667107\n",
      "Validation loss decreased (1.667447 --> 1.667107).         Saving model ...\n",
      "Epoch: 58 \tTraining Loss: 1.132385 \tValidation Loss: 1.666767\n",
      "Validation loss decreased (1.667107 --> 1.666767).         Saving model ...\n",
      "Epoch: 59 \tTraining Loss: 1.132040 \tValidation Loss: 1.666427\n",
      "Validation loss decreased (1.666767 --> 1.666427).         Saving model ...\n",
      "Epoch: 60 \tTraining Loss: 1.131701 \tValidation Loss: 1.666087\n",
      "Validation loss decreased (1.666427 --> 1.666087).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61 \tTraining Loss: 1.131368 \tValidation Loss: 1.665745\n",
      "Validation loss decreased (1.666087 --> 1.665745).         Saving model ...\n",
      "Epoch: 62 \tTraining Loss: 1.131042 \tValidation Loss: 1.665403\n",
      "Validation loss decreased (1.665745 --> 1.665403).         Saving model ...\n",
      "Epoch: 63 \tTraining Loss: 1.130721 \tValidation Loss: 1.665060\n",
      "Validation loss decreased (1.665403 --> 1.665060).         Saving model ...\n",
      "Epoch: 64 \tTraining Loss: 1.130405 \tValidation Loss: 1.664716\n",
      "Validation loss decreased (1.665060 --> 1.664716).         Saving model ...\n",
      "Epoch: 65 \tTraining Loss: 1.130096 \tValidation Loss: 1.664371\n",
      "Validation loss decreased (1.664716 --> 1.664371).         Saving model ...\n",
      "Epoch: 66 \tTraining Loss: 1.129791 \tValidation Loss: 1.664026\n",
      "Validation loss decreased (1.664371 --> 1.664026).         Saving model ...\n",
      "Epoch: 67 \tTraining Loss: 1.129491 \tValidation Loss: 1.663679\n",
      "Validation loss decreased (1.664026 --> 1.663679).         Saving model ...\n",
      "Epoch: 68 \tTraining Loss: 1.129197 \tValidation Loss: 1.663331\n",
      "Validation loss decreased (1.663679 --> 1.663331).         Saving model ...\n",
      "Epoch: 69 \tTraining Loss: 1.128907 \tValidation Loss: 1.662983\n",
      "Validation loss decreased (1.663331 --> 1.662983).         Saving model ...\n",
      "Epoch: 70 \tTraining Loss: 1.128622 \tValidation Loss: 1.662633\n",
      "Validation loss decreased (1.662983 --> 1.662633).         Saving model ...\n",
      "Epoch: 71 \tTraining Loss: 1.128342 \tValidation Loss: 1.662282\n",
      "Validation loss decreased (1.662633 --> 1.662282).         Saving model ...\n",
      "Epoch: 72 \tTraining Loss: 1.128066 \tValidation Loss: 1.661931\n",
      "Validation loss decreased (1.662282 --> 1.661931).         Saving model ...\n",
      "Epoch: 73 \tTraining Loss: 1.127794 \tValidation Loss: 1.661578\n",
      "Validation loss decreased (1.661931 --> 1.661578).         Saving model ...\n",
      "Epoch: 74 \tTraining Loss: 1.127527 \tValidation Loss: 1.661224\n",
      "Validation loss decreased (1.661578 --> 1.661224).         Saving model ...\n",
      "Epoch: 75 \tTraining Loss: 1.127263 \tValidation Loss: 1.660870\n",
      "Validation loss decreased (1.661224 --> 1.660870).         Saving model ...\n",
      "Epoch: 76 \tTraining Loss: 1.127004 \tValidation Loss: 1.660514\n",
      "Validation loss decreased (1.660870 --> 1.660514).         Saving model ...\n",
      "Epoch: 77 \tTraining Loss: 1.126748 \tValidation Loss: 1.660158\n",
      "Validation loss decreased (1.660514 --> 1.660158).         Saving model ...\n",
      "Epoch: 78 \tTraining Loss: 1.126497 \tValidation Loss: 1.659800\n",
      "Validation loss decreased (1.660158 --> 1.659800).         Saving model ...\n",
      "Epoch: 79 \tTraining Loss: 1.126248 \tValidation Loss: 1.659442\n",
      "Validation loss decreased (1.659800 --> 1.659442).         Saving model ...\n",
      "Epoch: 80 \tTraining Loss: 1.126004 \tValidation Loss: 1.659083\n",
      "Validation loss decreased (1.659442 --> 1.659083).         Saving model ...\n",
      "Epoch: 81 \tTraining Loss: 1.125763 \tValidation Loss: 1.658724\n",
      "Validation loss decreased (1.659083 --> 1.658724).         Saving model ...\n",
      "Epoch: 82 \tTraining Loss: 1.125525 \tValidation Loss: 1.658363\n",
      "Validation loss decreased (1.658724 --> 1.658363).         Saving model ...\n",
      "Epoch: 83 \tTraining Loss: 1.125291 \tValidation Loss: 1.658001\n",
      "Validation loss decreased (1.658363 --> 1.658001).         Saving model ...\n",
      "Epoch: 84 \tTraining Loss: 1.125060 \tValidation Loss: 1.657639\n",
      "Validation loss decreased (1.658001 --> 1.657639).         Saving model ...\n",
      "Epoch: 85 \tTraining Loss: 1.124832 \tValidation Loss: 1.657276\n",
      "Validation loss decreased (1.657639 --> 1.657276).         Saving model ...\n",
      "Epoch: 86 \tTraining Loss: 1.124608 \tValidation Loss: 1.656912\n",
      "Validation loss decreased (1.657276 --> 1.656912).         Saving model ...\n",
      "Epoch: 87 \tTraining Loss: 1.124386 \tValidation Loss: 1.656548\n",
      "Validation loss decreased (1.656912 --> 1.656548).         Saving model ...\n",
      "Epoch: 88 \tTraining Loss: 1.124167 \tValidation Loss: 1.656184\n",
      "Validation loss decreased (1.656548 --> 1.656184).         Saving model ...\n",
      "Epoch: 89 \tTraining Loss: 1.123951 \tValidation Loss: 1.655818\n",
      "Validation loss decreased (1.656184 --> 1.655818).         Saving model ...\n",
      "Epoch: 90 \tTraining Loss: 1.123738 \tValidation Loss: 1.655452\n",
      "Validation loss decreased (1.655818 --> 1.655452).         Saving model ...\n",
      "Epoch: 91 \tTraining Loss: 1.123528 \tValidation Loss: 1.655086\n",
      "Validation loss decreased (1.655452 --> 1.655086).         Saving model ...\n",
      "Epoch: 92 \tTraining Loss: 1.123320 \tValidation Loss: 1.654719\n",
      "Validation loss decreased (1.655086 --> 1.654719).         Saving model ...\n",
      "Epoch: 93 \tTraining Loss: 1.123115 \tValidation Loss: 1.654351\n",
      "Validation loss decreased (1.654719 --> 1.654351).         Saving model ...\n",
      "Epoch: 94 \tTraining Loss: 1.122913 \tValidation Loss: 1.653983\n",
      "Validation loss decreased (1.654351 --> 1.653983).         Saving model ...\n",
      "Epoch: 95 \tTraining Loss: 1.122713 \tValidation Loss: 1.653614\n",
      "Validation loss decreased (1.653983 --> 1.653614).         Saving model ...\n",
      "Epoch: 96 \tTraining Loss: 1.122515 \tValidation Loss: 1.653245\n",
      "Validation loss decreased (1.653614 --> 1.653245).         Saving model ...\n",
      "Epoch: 97 \tTraining Loss: 1.122320 \tValidation Loss: 1.652876\n",
      "Validation loss decreased (1.653245 --> 1.652876).         Saving model ...\n",
      "Epoch: 98 \tTraining Loss: 1.122128 \tValidation Loss: 1.652506\n",
      "Validation loss decreased (1.652876 --> 1.652506).         Saving model ...\n",
      "Epoch: 99 \tTraining Loss: 1.121937 \tValidation Loss: 1.652136\n",
      "Validation loss decreased (1.652506 --> 1.652136).         Saving model ...\n",
      "Epoch: 100 \tTraining Loss: 1.121749 \tValidation Loss: 1.651766\n",
      "Validation loss decreased (1.652136 --> 1.651766).         Saving model ...\n",
      "Epoch: 101 \tTraining Loss: 1.121563 \tValidation Loss: 1.651395\n",
      "Validation loss decreased (1.651766 --> 1.651395).         Saving model ...\n",
      "Epoch: 102 \tTraining Loss: 1.121380 \tValidation Loss: 1.651024\n",
      "Validation loss decreased (1.651395 --> 1.651024).         Saving model ...\n",
      "Epoch: 103 \tTraining Loss: 1.121198 \tValidation Loss: 1.650653\n",
      "Validation loss decreased (1.651024 --> 1.650653).         Saving model ...\n",
      "Epoch: 104 \tTraining Loss: 1.121018 \tValidation Loss: 1.650281\n",
      "Validation loss decreased (1.650653 --> 1.650281).         Saving model ...\n",
      "Epoch: 105 \tTraining Loss: 1.120841 \tValidation Loss: 1.649910\n",
      "Validation loss decreased (1.650281 --> 1.649910).         Saving model ...\n",
      "Epoch: 106 \tTraining Loss: 1.120665 \tValidation Loss: 1.649538\n",
      "Validation loss decreased (1.649910 --> 1.649538).         Saving model ...\n",
      "Epoch: 107 \tTraining Loss: 1.120492 \tValidation Loss: 1.649166\n",
      "Validation loss decreased (1.649538 --> 1.649166).         Saving model ...\n",
      "Epoch: 108 \tTraining Loss: 1.120320 \tValidation Loss: 1.648794\n",
      "Validation loss decreased (1.649166 --> 1.648794).         Saving model ...\n",
      "Epoch: 109 \tTraining Loss: 1.120151 \tValidation Loss: 1.648421\n",
      "Validation loss decreased (1.648794 --> 1.648421).         Saving model ...\n",
      "Epoch: 110 \tTraining Loss: 1.119983 \tValidation Loss: 1.648049\n",
      "Validation loss decreased (1.648421 --> 1.648049).         Saving model ...\n",
      "Epoch: 111 \tTraining Loss: 1.119817 \tValidation Loss: 1.647676\n",
      "Validation loss decreased (1.648049 --> 1.647676).         Saving model ...\n",
      "Epoch: 112 \tTraining Loss: 1.119652 \tValidation Loss: 1.647304\n",
      "Validation loss decreased (1.647676 --> 1.647304).         Saving model ...\n",
      "Epoch: 113 \tTraining Loss: 1.119490 \tValidation Loss: 1.646931\n",
      "Validation loss decreased (1.647304 --> 1.646931).         Saving model ...\n",
      "Epoch: 114 \tTraining Loss: 1.119329 \tValidation Loss: 1.646558\n",
      "Validation loss decreased (1.646931 --> 1.646558).         Saving model ...\n",
      "Epoch: 115 \tTraining Loss: 1.119170 \tValidation Loss: 1.646185\n",
      "Validation loss decreased (1.646558 --> 1.646185).         Saving model ...\n",
      "Epoch: 116 \tTraining Loss: 1.119012 \tValidation Loss: 1.645812\n",
      "Validation loss decreased (1.646185 --> 1.645812).         Saving model ...\n",
      "Epoch: 117 \tTraining Loss: 1.118856 \tValidation Loss: 1.645439\n",
      "Validation loss decreased (1.645812 --> 1.645439).         Saving model ...\n",
      "Epoch: 118 \tTraining Loss: 1.118702 \tValidation Loss: 1.645066\n",
      "Validation loss decreased (1.645439 --> 1.645066).         Saving model ...\n",
      "Epoch: 119 \tTraining Loss: 1.118549 \tValidation Loss: 1.644693\n",
      "Validation loss decreased (1.645066 --> 1.644693).         Saving model ...\n",
      "Epoch: 120 \tTraining Loss: 1.118398 \tValidation Loss: 1.644321\n",
      "Validation loss decreased (1.644693 --> 1.644321).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 121 \tTraining Loss: 1.118249 \tValidation Loss: 1.643949\n",
      "Validation loss decreased (1.644321 --> 1.643949).         Saving model ...\n",
      "Epoch: 122 \tTraining Loss: 1.118100 \tValidation Loss: 1.643576\n",
      "Validation loss decreased (1.643949 --> 1.643576).         Saving model ...\n",
      "Epoch: 123 \tTraining Loss: 1.117954 \tValidation Loss: 1.643204\n",
      "Validation loss decreased (1.643576 --> 1.643204).         Saving model ...\n",
      "Epoch: 124 \tTraining Loss: 1.117808 \tValidation Loss: 1.642832\n",
      "Validation loss decreased (1.643204 --> 1.642832).         Saving model ...\n",
      "Epoch: 125 \tTraining Loss: 1.117664 \tValidation Loss: 1.642460\n",
      "Validation loss decreased (1.642832 --> 1.642460).         Saving model ...\n",
      "Epoch: 126 \tTraining Loss: 1.117522 \tValidation Loss: 1.642088\n",
      "Validation loss decreased (1.642460 --> 1.642088).         Saving model ...\n",
      "Epoch: 127 \tTraining Loss: 1.117381 \tValidation Loss: 1.641716\n",
      "Validation loss decreased (1.642088 --> 1.641716).         Saving model ...\n",
      "Epoch: 128 \tTraining Loss: 1.117241 \tValidation Loss: 1.641344\n",
      "Validation loss decreased (1.641716 --> 1.641344).         Saving model ...\n",
      "Epoch: 129 \tTraining Loss: 1.117102 \tValidation Loss: 1.640973\n",
      "Validation loss decreased (1.641344 --> 1.640973).         Saving model ...\n",
      "Epoch: 130 \tTraining Loss: 1.116965 \tValidation Loss: 1.640601\n",
      "Validation loss decreased (1.640973 --> 1.640601).         Saving model ...\n",
      "Epoch: 131 \tTraining Loss: 1.116829 \tValidation Loss: 1.640231\n",
      "Validation loss decreased (1.640601 --> 1.640231).         Saving model ...\n",
      "Epoch: 132 \tTraining Loss: 1.116694 \tValidation Loss: 1.639860\n",
      "Validation loss decreased (1.640231 --> 1.639860).         Saving model ...\n",
      "Epoch: 133 \tTraining Loss: 1.116561 \tValidation Loss: 1.639489\n",
      "Validation loss decreased (1.639860 --> 1.639489).         Saving model ...\n",
      "Epoch: 134 \tTraining Loss: 1.116429 \tValidation Loss: 1.639119\n",
      "Validation loss decreased (1.639489 --> 1.639119).         Saving model ...\n",
      "Epoch: 135 \tTraining Loss: 1.116298 \tValidation Loss: 1.638749\n",
      "Validation loss decreased (1.639119 --> 1.638749).         Saving model ...\n",
      "Epoch: 136 \tTraining Loss: 1.116168 \tValidation Loss: 1.638378\n",
      "Validation loss decreased (1.638749 --> 1.638378).         Saving model ...\n",
      "Epoch: 137 \tTraining Loss: 1.116039 \tValidation Loss: 1.638009\n",
      "Validation loss decreased (1.638378 --> 1.638009).         Saving model ...\n",
      "Epoch: 138 \tTraining Loss: 1.115911 \tValidation Loss: 1.637640\n",
      "Validation loss decreased (1.638009 --> 1.637640).         Saving model ...\n",
      "Epoch: 139 \tTraining Loss: 1.115785 \tValidation Loss: 1.637271\n",
      "Validation loss decreased (1.637640 --> 1.637271).         Saving model ...\n",
      "Epoch: 140 \tTraining Loss: 1.115659 \tValidation Loss: 1.636903\n",
      "Validation loss decreased (1.637271 --> 1.636903).         Saving model ...\n",
      "Epoch: 141 \tTraining Loss: 1.115535 \tValidation Loss: 1.636534\n",
      "Validation loss decreased (1.636903 --> 1.636534).         Saving model ...\n",
      "Epoch: 142 \tTraining Loss: 1.115412 \tValidation Loss: 1.636166\n",
      "Validation loss decreased (1.636534 --> 1.636166).         Saving model ...\n",
      "Epoch: 143 \tTraining Loss: 1.115290 \tValidation Loss: 1.635799\n",
      "Validation loss decreased (1.636166 --> 1.635799).         Saving model ...\n",
      "Epoch: 144 \tTraining Loss: 1.115168 \tValidation Loss: 1.635431\n",
      "Validation loss decreased (1.635799 --> 1.635431).         Saving model ...\n",
      "Epoch: 145 \tTraining Loss: 1.115048 \tValidation Loss: 1.635064\n",
      "Validation loss decreased (1.635431 --> 1.635064).         Saving model ...\n",
      "Epoch: 146 \tTraining Loss: 1.114929 \tValidation Loss: 1.634698\n",
      "Validation loss decreased (1.635064 --> 1.634698).         Saving model ...\n",
      "Epoch: 147 \tTraining Loss: 1.114811 \tValidation Loss: 1.634332\n",
      "Validation loss decreased (1.634698 --> 1.634332).         Saving model ...\n",
      "Epoch: 148 \tTraining Loss: 1.114694 \tValidation Loss: 1.633966\n",
      "Validation loss decreased (1.634332 --> 1.633966).         Saving model ...\n",
      "Epoch: 149 \tTraining Loss: 1.114578 \tValidation Loss: 1.633600\n",
      "Validation loss decreased (1.633966 --> 1.633600).         Saving model ...\n",
      "Epoch: 150 \tTraining Loss: 1.114462 \tValidation Loss: 1.633235\n",
      "Validation loss decreased (1.633600 --> 1.633235).         Saving model ...\n",
      "Epoch: 151 \tTraining Loss: 1.114348 \tValidation Loss: 1.632871\n",
      "Validation loss decreased (1.633235 --> 1.632871).         Saving model ...\n",
      "Epoch: 152 \tTraining Loss: 1.114235 \tValidation Loss: 1.632506\n",
      "Validation loss decreased (1.632871 --> 1.632506).         Saving model ...\n",
      "Epoch: 153 \tTraining Loss: 1.114122 \tValidation Loss: 1.632143\n",
      "Validation loss decreased (1.632506 --> 1.632143).         Saving model ...\n",
      "Epoch: 154 \tTraining Loss: 1.114010 \tValidation Loss: 1.631779\n",
      "Validation loss decreased (1.632143 --> 1.631779).         Saving model ...\n",
      "Epoch: 155 \tTraining Loss: 1.113900 \tValidation Loss: 1.631416\n",
      "Validation loss decreased (1.631779 --> 1.631416).         Saving model ...\n",
      "Epoch: 156 \tTraining Loss: 1.113790 \tValidation Loss: 1.631054\n",
      "Validation loss decreased (1.631416 --> 1.631054).         Saving model ...\n",
      "Epoch: 157 \tTraining Loss: 1.113681 \tValidation Loss: 1.630692\n",
      "Validation loss decreased (1.631054 --> 1.630692).         Saving model ...\n",
      "Epoch: 158 \tTraining Loss: 1.113573 \tValidation Loss: 1.630330\n",
      "Validation loss decreased (1.630692 --> 1.630330).         Saving model ...\n",
      "Epoch: 159 \tTraining Loss: 1.113465 \tValidation Loss: 1.629970\n",
      "Validation loss decreased (1.630330 --> 1.629970).         Saving model ...\n",
      "Epoch: 160 \tTraining Loss: 1.113359 \tValidation Loss: 1.629609\n",
      "Validation loss decreased (1.629970 --> 1.629609).         Saving model ...\n",
      "Epoch: 161 \tTraining Loss: 1.113253 \tValidation Loss: 1.629249\n",
      "Validation loss decreased (1.629609 --> 1.629249).         Saving model ...\n",
      "Epoch: 162 \tTraining Loss: 1.113148 \tValidation Loss: 1.628890\n",
      "Validation loss decreased (1.629249 --> 1.628890).         Saving model ...\n",
      "Epoch: 163 \tTraining Loss: 1.113044 \tValidation Loss: 1.628531\n",
      "Validation loss decreased (1.628890 --> 1.628531).         Saving model ...\n",
      "Epoch: 164 \tTraining Loss: 1.112941 \tValidation Loss: 1.628172\n",
      "Validation loss decreased (1.628531 --> 1.628172).         Saving model ...\n",
      "Epoch: 165 \tTraining Loss: 1.112838 \tValidation Loss: 1.627814\n",
      "Validation loss decreased (1.628172 --> 1.627814).         Saving model ...\n",
      "Epoch: 166 \tTraining Loss: 1.112736 \tValidation Loss: 1.627457\n",
      "Validation loss decreased (1.627814 --> 1.627457).         Saving model ...\n",
      "Epoch: 167 \tTraining Loss: 1.112635 \tValidation Loss: 1.627100\n",
      "Validation loss decreased (1.627457 --> 1.627100).         Saving model ...\n",
      "Epoch: 168 \tTraining Loss: 1.112535 \tValidation Loss: 1.626743\n",
      "Validation loss decreased (1.627100 --> 1.626743).         Saving model ...\n",
      "Epoch: 169 \tTraining Loss: 1.112435 \tValidation Loss: 1.626387\n",
      "Validation loss decreased (1.626743 --> 1.626387).         Saving model ...\n",
      "Epoch: 170 \tTraining Loss: 1.112337 \tValidation Loss: 1.626032\n",
      "Validation loss decreased (1.626387 --> 1.626032).         Saving model ...\n",
      "Epoch: 171 \tTraining Loss: 1.112238 \tValidation Loss: 1.625678\n",
      "Validation loss decreased (1.626032 --> 1.625678).         Saving model ...\n",
      "Epoch: 172 \tTraining Loss: 1.112141 \tValidation Loss: 1.625323\n",
      "Validation loss decreased (1.625678 --> 1.625323).         Saving model ...\n",
      "Epoch: 173 \tTraining Loss: 1.112044 \tValidation Loss: 1.624970\n",
      "Validation loss decreased (1.625323 --> 1.624970).         Saving model ...\n",
      "Epoch: 174 \tTraining Loss: 1.111948 \tValidation Loss: 1.624617\n",
      "Validation loss decreased (1.624970 --> 1.624617).         Saving model ...\n",
      "Epoch: 175 \tTraining Loss: 1.111853 \tValidation Loss: 1.624265\n",
      "Validation loss decreased (1.624617 --> 1.624265).         Saving model ...\n",
      "Epoch: 176 \tTraining Loss: 1.111758 \tValidation Loss: 1.623912\n",
      "Validation loss decreased (1.624265 --> 1.623912).         Saving model ...\n",
      "Epoch: 177 \tTraining Loss: 1.111664 \tValidation Loss: 1.623561\n",
      "Validation loss decreased (1.623912 --> 1.623561).         Saving model ...\n",
      "Epoch: 178 \tTraining Loss: 1.111570 \tValidation Loss: 1.623210\n",
      "Validation loss decreased (1.623561 --> 1.623210).         Saving model ...\n",
      "Epoch: 179 \tTraining Loss: 1.111478 \tValidation Loss: 1.622860\n",
      "Validation loss decreased (1.623210 --> 1.622860).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180 \tTraining Loss: 1.111385 \tValidation Loss: 1.622511\n",
      "Validation loss decreased (1.622860 --> 1.622511).         Saving model ...\n",
      "Epoch: 181 \tTraining Loss: 1.111294 \tValidation Loss: 1.622162\n",
      "Validation loss decreased (1.622511 --> 1.622162).         Saving model ...\n",
      "Epoch: 182 \tTraining Loss: 1.111203 \tValidation Loss: 1.621814\n",
      "Validation loss decreased (1.622162 --> 1.621814).         Saving model ...\n",
      "Epoch: 183 \tTraining Loss: 1.111113 \tValidation Loss: 1.621467\n",
      "Validation loss decreased (1.621814 --> 1.621467).         Saving model ...\n",
      "Epoch: 184 \tTraining Loss: 1.111023 \tValidation Loss: 1.621120\n",
      "Validation loss decreased (1.621467 --> 1.621120).         Saving model ...\n",
      "Epoch: 185 \tTraining Loss: 1.110934 \tValidation Loss: 1.620774\n",
      "Validation loss decreased (1.621120 --> 1.620774).         Saving model ...\n",
      "Epoch: 186 \tTraining Loss: 1.110845 \tValidation Loss: 1.620428\n",
      "Validation loss decreased (1.620774 --> 1.620428).         Saving model ...\n",
      "Epoch: 187 \tTraining Loss: 1.110758 \tValidation Loss: 1.620083\n",
      "Validation loss decreased (1.620428 --> 1.620083).         Saving model ...\n",
      "Epoch: 188 \tTraining Loss: 1.110670 \tValidation Loss: 1.619738\n",
      "Validation loss decreased (1.620083 --> 1.619738).         Saving model ...\n",
      "Epoch: 189 \tTraining Loss: 1.110583 \tValidation Loss: 1.619395\n",
      "Validation loss decreased (1.619738 --> 1.619395).         Saving model ...\n",
      "Epoch: 190 \tTraining Loss: 1.110497 \tValidation Loss: 1.619051\n",
      "Validation loss decreased (1.619395 --> 1.619051).         Saving model ...\n",
      "Epoch: 191 \tTraining Loss: 1.110412 \tValidation Loss: 1.618709\n",
      "Validation loss decreased (1.619051 --> 1.618709).         Saving model ...\n",
      "Epoch: 192 \tTraining Loss: 1.110326 \tValidation Loss: 1.618367\n",
      "Validation loss decreased (1.618709 --> 1.618367).         Saving model ...\n",
      "Epoch: 193 \tTraining Loss: 1.110242 \tValidation Loss: 1.618026\n",
      "Validation loss decreased (1.618367 --> 1.618026).         Saving model ...\n",
      "Epoch: 194 \tTraining Loss: 1.110158 \tValidation Loss: 1.617686\n",
      "Validation loss decreased (1.618026 --> 1.617686).         Saving model ...\n",
      "Epoch: 195 \tTraining Loss: 1.110074 \tValidation Loss: 1.617346\n",
      "Validation loss decreased (1.617686 --> 1.617346).         Saving model ...\n",
      "Epoch: 196 \tTraining Loss: 1.109991 \tValidation Loss: 1.617007\n",
      "Validation loss decreased (1.617346 --> 1.617007).         Saving model ...\n",
      "Epoch: 197 \tTraining Loss: 1.109909 \tValidation Loss: 1.616669\n",
      "Validation loss decreased (1.617007 --> 1.616669).         Saving model ...\n",
      "Epoch: 198 \tTraining Loss: 1.109827 \tValidation Loss: 1.616331\n",
      "Validation loss decreased (1.616669 --> 1.616331).         Saving model ...\n",
      "Epoch: 199 \tTraining Loss: 1.109746 \tValidation Loss: 1.615993\n",
      "Validation loss decreased (1.616331 --> 1.615993).         Saving model ...\n",
      "Epoch: 200 \tTraining Loss: 1.109665 \tValidation Loss: 1.615657\n",
      "Validation loss decreased (1.615993 --> 1.615657).         Saving model ...\n",
      "Epoch: 201 \tTraining Loss: 1.109584 \tValidation Loss: 1.615321\n",
      "Validation loss decreased (1.615657 --> 1.615321).         Saving model ...\n",
      "Epoch: 202 \tTraining Loss: 1.109504 \tValidation Loss: 1.614986\n",
      "Validation loss decreased (1.615321 --> 1.614986).         Saving model ...\n",
      "Epoch: 203 \tTraining Loss: 1.109425 \tValidation Loss: 1.614652\n",
      "Validation loss decreased (1.614986 --> 1.614652).         Saving model ...\n",
      "Epoch: 204 \tTraining Loss: 1.109346 \tValidation Loss: 1.614318\n",
      "Validation loss decreased (1.614652 --> 1.614318).         Saving model ...\n",
      "Epoch: 205 \tTraining Loss: 1.109267 \tValidation Loss: 1.613985\n",
      "Validation loss decreased (1.614318 --> 1.613985).         Saving model ...\n",
      "Epoch: 206 \tTraining Loss: 1.109189 \tValidation Loss: 1.613653\n",
      "Validation loss decreased (1.613985 --> 1.613653).         Saving model ...\n",
      "Epoch: 207 \tTraining Loss: 1.109112 \tValidation Loss: 1.613321\n",
      "Validation loss decreased (1.613653 --> 1.613321).         Saving model ...\n",
      "Epoch: 208 \tTraining Loss: 1.109035 \tValidation Loss: 1.612991\n",
      "Validation loss decreased (1.613321 --> 1.612991).         Saving model ...\n",
      "Epoch: 209 \tTraining Loss: 1.108958 \tValidation Loss: 1.612660\n",
      "Validation loss decreased (1.612991 --> 1.612660).         Saving model ...\n",
      "Epoch: 210 \tTraining Loss: 1.108882 \tValidation Loss: 1.612331\n",
      "Validation loss decreased (1.612660 --> 1.612331).         Saving model ...\n",
      "Epoch: 211 \tTraining Loss: 1.108806 \tValidation Loss: 1.612002\n",
      "Validation loss decreased (1.612331 --> 1.612002).         Saving model ...\n",
      "Epoch: 212 \tTraining Loss: 1.108731 \tValidation Loss: 1.611675\n",
      "Validation loss decreased (1.612002 --> 1.611675).         Saving model ...\n",
      "Epoch: 213 \tTraining Loss: 1.108656 \tValidation Loss: 1.611348\n",
      "Validation loss decreased (1.611675 --> 1.611348).         Saving model ...\n",
      "Epoch: 214 \tTraining Loss: 1.108582 \tValidation Loss: 1.611020\n",
      "Validation loss decreased (1.611348 --> 1.611020).         Saving model ...\n",
      "Epoch: 215 \tTraining Loss: 1.108508 \tValidation Loss: 1.610695\n",
      "Validation loss decreased (1.611020 --> 1.610695).         Saving model ...\n",
      "Epoch: 216 \tTraining Loss: 1.108434 \tValidation Loss: 1.610370\n",
      "Validation loss decreased (1.610695 --> 1.610370).         Saving model ...\n",
      "Epoch: 217 \tTraining Loss: 1.108361 \tValidation Loss: 1.610045\n",
      "Validation loss decreased (1.610370 --> 1.610045).         Saving model ...\n",
      "Epoch: 218 \tTraining Loss: 1.108288 \tValidation Loss: 1.609722\n",
      "Validation loss decreased (1.610045 --> 1.609722).         Saving model ...\n",
      "Epoch: 219 \tTraining Loss: 1.108216 \tValidation Loss: 1.609398\n",
      "Validation loss decreased (1.609722 --> 1.609398).         Saving model ...\n",
      "Epoch: 220 \tTraining Loss: 1.108144 \tValidation Loss: 1.609076\n",
      "Validation loss decreased (1.609398 --> 1.609076).         Saving model ...\n",
      "Epoch: 221 \tTraining Loss: 1.108072 \tValidation Loss: 1.608755\n",
      "Validation loss decreased (1.609076 --> 1.608755).         Saving model ...\n",
      "Epoch: 222 \tTraining Loss: 1.108001 \tValidation Loss: 1.608434\n",
      "Validation loss decreased (1.608755 --> 1.608434).         Saving model ...\n",
      "Epoch: 223 \tTraining Loss: 1.107931 \tValidation Loss: 1.608114\n",
      "Validation loss decreased (1.608434 --> 1.608114).         Saving model ...\n",
      "Epoch: 224 \tTraining Loss: 1.107860 \tValidation Loss: 1.607795\n",
      "Validation loss decreased (1.608114 --> 1.607795).         Saving model ...\n",
      "Epoch: 225 \tTraining Loss: 1.107790 \tValidation Loss: 1.607476\n",
      "Validation loss decreased (1.607795 --> 1.607476).         Saving model ...\n",
      "Epoch: 226 \tTraining Loss: 1.107721 \tValidation Loss: 1.607158\n",
      "Validation loss decreased (1.607476 --> 1.607158).         Saving model ...\n",
      "Epoch: 227 \tTraining Loss: 1.107652 \tValidation Loss: 1.606841\n",
      "Validation loss decreased (1.607158 --> 1.606841).         Saving model ...\n",
      "Epoch: 228 \tTraining Loss: 1.107583 \tValidation Loss: 1.606525\n",
      "Validation loss decreased (1.606841 --> 1.606525).         Saving model ...\n",
      "Epoch: 229 \tTraining Loss: 1.107514 \tValidation Loss: 1.606210\n",
      "Validation loss decreased (1.606525 --> 1.606210).         Saving model ...\n",
      "Epoch: 230 \tTraining Loss: 1.107446 \tValidation Loss: 1.605895\n",
      "Validation loss decreased (1.606210 --> 1.605895).         Saving model ...\n",
      "Epoch: 231 \tTraining Loss: 1.107378 \tValidation Loss: 1.605581\n",
      "Validation loss decreased (1.605895 --> 1.605581).         Saving model ...\n",
      "Epoch: 232 \tTraining Loss: 1.107311 \tValidation Loss: 1.605269\n",
      "Validation loss decreased (1.605581 --> 1.605269).         Saving model ...\n",
      "Epoch: 233 \tTraining Loss: 1.107244 \tValidation Loss: 1.604956\n",
      "Validation loss decreased (1.605269 --> 1.604956).         Saving model ...\n",
      "Epoch: 234 \tTraining Loss: 1.107178 \tValidation Loss: 1.604645\n",
      "Validation loss decreased (1.604956 --> 1.604645).         Saving model ...\n",
      "Epoch: 235 \tTraining Loss: 1.107111 \tValidation Loss: 1.604333\n",
      "Validation loss decreased (1.604645 --> 1.604333).         Saving model ...\n",
      "Epoch: 236 \tTraining Loss: 1.107045 \tValidation Loss: 1.604023\n",
      "Validation loss decreased (1.604333 --> 1.604023).         Saving model ...\n",
      "Epoch: 237 \tTraining Loss: 1.106980 \tValidation Loss: 1.603713\n",
      "Validation loss decreased (1.604023 --> 1.603713).         Saving model ...\n",
      "Epoch: 238 \tTraining Loss: 1.106915 \tValidation Loss: 1.603405\n",
      "Validation loss decreased (1.603713 --> 1.603405).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 239 \tTraining Loss: 1.106850 \tValidation Loss: 1.603097\n",
      "Validation loss decreased (1.603405 --> 1.603097).         Saving model ...\n",
      "Epoch: 240 \tTraining Loss: 1.106785 \tValidation Loss: 1.602790\n",
      "Validation loss decreased (1.603097 --> 1.602790).         Saving model ...\n",
      "Epoch: 241 \tTraining Loss: 1.106721 \tValidation Loss: 1.602483\n",
      "Validation loss decreased (1.602790 --> 1.602483).         Saving model ...\n",
      "Epoch: 242 \tTraining Loss: 1.106657 \tValidation Loss: 1.602178\n",
      "Validation loss decreased (1.602483 --> 1.602178).         Saving model ...\n",
      "Epoch: 243 \tTraining Loss: 1.106593 \tValidation Loss: 1.601873\n",
      "Validation loss decreased (1.602178 --> 1.601873).         Saving model ...\n",
      "Epoch: 244 \tTraining Loss: 1.106530 \tValidation Loss: 1.601569\n",
      "Validation loss decreased (1.601873 --> 1.601569).         Saving model ...\n",
      "Epoch: 245 \tTraining Loss: 1.106467 \tValidation Loss: 1.601265\n",
      "Validation loss decreased (1.601569 --> 1.601265).         Saving model ...\n",
      "Epoch: 246 \tTraining Loss: 1.106405 \tValidation Loss: 1.600963\n",
      "Validation loss decreased (1.601265 --> 1.600963).         Saving model ...\n",
      "Epoch: 247 \tTraining Loss: 1.106342 \tValidation Loss: 1.600661\n",
      "Validation loss decreased (1.600963 --> 1.600661).         Saving model ...\n",
      "Epoch: 248 \tTraining Loss: 1.106280 \tValidation Loss: 1.600360\n",
      "Validation loss decreased (1.600661 --> 1.600360).         Saving model ...\n",
      "Epoch: 249 \tTraining Loss: 1.106219 \tValidation Loss: 1.600060\n",
      "Validation loss decreased (1.600360 --> 1.600060).         Saving model ...\n",
      "Epoch: 250 \tTraining Loss: 1.106157 \tValidation Loss: 1.599760\n",
      "Validation loss decreased (1.600060 --> 1.599760).         Saving model ...\n",
      "Epoch: 251 \tTraining Loss: 1.106096 \tValidation Loss: 1.599461\n",
      "Validation loss decreased (1.599760 --> 1.599461).         Saving model ...\n",
      "Epoch: 252 \tTraining Loss: 1.106035 \tValidation Loss: 1.599163\n",
      "Validation loss decreased (1.599461 --> 1.599163).         Saving model ...\n",
      "Epoch: 253 \tTraining Loss: 1.105975 \tValidation Loss: 1.598866\n",
      "Validation loss decreased (1.599163 --> 1.598866).         Saving model ...\n",
      "Epoch: 254 \tTraining Loss: 1.105915 \tValidation Loss: 1.598570\n",
      "Validation loss decreased (1.598866 --> 1.598570).         Saving model ...\n",
      "Epoch: 255 \tTraining Loss: 1.105855 \tValidation Loss: 1.598274\n",
      "Validation loss decreased (1.598570 --> 1.598274).         Saving model ...\n",
      "Epoch: 256 \tTraining Loss: 1.105795 \tValidation Loss: 1.597979\n",
      "Validation loss decreased (1.598274 --> 1.597979).         Saving model ...\n",
      "Epoch: 257 \tTraining Loss: 1.105736 \tValidation Loss: 1.597685\n",
      "Validation loss decreased (1.597979 --> 1.597685).         Saving model ...\n",
      "Epoch: 258 \tTraining Loss: 1.105677 \tValidation Loss: 1.597392\n",
      "Validation loss decreased (1.597685 --> 1.597392).         Saving model ...\n",
      "Epoch: 259 \tTraining Loss: 1.105618 \tValidation Loss: 1.597099\n",
      "Validation loss decreased (1.597392 --> 1.597099).         Saving model ...\n",
      "Epoch: 260 \tTraining Loss: 1.105560 \tValidation Loss: 1.596807\n",
      "Validation loss decreased (1.597099 --> 1.596807).         Saving model ...\n",
      "Epoch: 261 \tTraining Loss: 1.105501 \tValidation Loss: 1.596515\n",
      "Validation loss decreased (1.596807 --> 1.596515).         Saving model ...\n",
      "Epoch: 262 \tTraining Loss: 1.105444 \tValidation Loss: 1.596225\n",
      "Validation loss decreased (1.596515 --> 1.596225).         Saving model ...\n",
      "Epoch: 263 \tTraining Loss: 1.105386 \tValidation Loss: 1.595936\n",
      "Validation loss decreased (1.596225 --> 1.595936).         Saving model ...\n",
      "Epoch: 264 \tTraining Loss: 1.105329 \tValidation Loss: 1.595647\n",
      "Validation loss decreased (1.595936 --> 1.595647).         Saving model ...\n",
      "Epoch: 265 \tTraining Loss: 1.105271 \tValidation Loss: 1.595359\n",
      "Validation loss decreased (1.595647 --> 1.595359).         Saving model ...\n",
      "Epoch: 266 \tTraining Loss: 1.105215 \tValidation Loss: 1.595071\n",
      "Validation loss decreased (1.595359 --> 1.595071).         Saving model ...\n",
      "Epoch: 267 \tTraining Loss: 1.105158 \tValidation Loss: 1.594785\n",
      "Validation loss decreased (1.595071 --> 1.594785).         Saving model ...\n",
      "Epoch: 268 \tTraining Loss: 1.105102 \tValidation Loss: 1.594498\n",
      "Validation loss decreased (1.594785 --> 1.594498).         Saving model ...\n",
      "Epoch: 269 \tTraining Loss: 1.105046 \tValidation Loss: 1.594213\n",
      "Validation loss decreased (1.594498 --> 1.594213).         Saving model ...\n",
      "Epoch: 270 \tTraining Loss: 1.104990 \tValidation Loss: 1.593928\n",
      "Validation loss decreased (1.594213 --> 1.593928).         Saving model ...\n",
      "Epoch: 271 \tTraining Loss: 1.104934 \tValidation Loss: 1.593645\n",
      "Validation loss decreased (1.593928 --> 1.593645).         Saving model ...\n",
      "Epoch: 272 \tTraining Loss: 1.104879 \tValidation Loss: 1.593362\n",
      "Validation loss decreased (1.593645 --> 1.593362).         Saving model ...\n",
      "Epoch: 273 \tTraining Loss: 1.104824 \tValidation Loss: 1.593079\n",
      "Validation loss decreased (1.593362 --> 1.593079).         Saving model ...\n",
      "Epoch: 274 \tTraining Loss: 1.104769 \tValidation Loss: 1.592798\n",
      "Validation loss decreased (1.593079 --> 1.592798).         Saving model ...\n",
      "Epoch: 275 \tTraining Loss: 1.104715 \tValidation Loss: 1.592517\n",
      "Validation loss decreased (1.592798 --> 1.592517).         Saving model ...\n",
      "Epoch: 276 \tTraining Loss: 1.104661 \tValidation Loss: 1.592237\n",
      "Validation loss decreased (1.592517 --> 1.592237).         Saving model ...\n",
      "Epoch: 277 \tTraining Loss: 1.104607 \tValidation Loss: 1.591958\n",
      "Validation loss decreased (1.592237 --> 1.591958).         Saving model ...\n",
      "Epoch: 278 \tTraining Loss: 1.104553 \tValidation Loss: 1.591680\n",
      "Validation loss decreased (1.591958 --> 1.591680).         Saving model ...\n",
      "Epoch: 279 \tTraining Loss: 1.104499 \tValidation Loss: 1.591402\n",
      "Validation loss decreased (1.591680 --> 1.591402).         Saving model ...\n",
      "Epoch: 280 \tTraining Loss: 1.104446 \tValidation Loss: 1.591125\n",
      "Validation loss decreased (1.591402 --> 1.591125).         Saving model ...\n",
      "Epoch: 281 \tTraining Loss: 1.104393 \tValidation Loss: 1.590849\n",
      "Validation loss decreased (1.591125 --> 1.590849).         Saving model ...\n",
      "Epoch: 282 \tTraining Loss: 1.104340 \tValidation Loss: 1.590573\n",
      "Validation loss decreased (1.590849 --> 1.590573).         Saving model ...\n",
      "Epoch: 283 \tTraining Loss: 1.104287 \tValidation Loss: 1.590298\n",
      "Validation loss decreased (1.590573 --> 1.590298).         Saving model ...\n",
      "Epoch: 284 \tTraining Loss: 1.104235 \tValidation Loss: 1.590024\n",
      "Validation loss decreased (1.590298 --> 1.590024).         Saving model ...\n",
      "Epoch: 285 \tTraining Loss: 1.104183 \tValidation Loss: 1.589750\n",
      "Validation loss decreased (1.590024 --> 1.589750).         Saving model ...\n",
      "Epoch: 286 \tTraining Loss: 1.104131 \tValidation Loss: 1.589478\n",
      "Validation loss decreased (1.589750 --> 1.589478).         Saving model ...\n",
      "Epoch: 287 \tTraining Loss: 1.104079 \tValidation Loss: 1.589206\n",
      "Validation loss decreased (1.589478 --> 1.589206).         Saving model ...\n",
      "Epoch: 288 \tTraining Loss: 1.104028 \tValidation Loss: 1.588935\n",
      "Validation loss decreased (1.589206 --> 1.588935).         Saving model ...\n",
      "Epoch: 289 \tTraining Loss: 1.103976 \tValidation Loss: 1.588665\n",
      "Validation loss decreased (1.588935 --> 1.588665).         Saving model ...\n",
      "Epoch: 290 \tTraining Loss: 1.103925 \tValidation Loss: 1.588396\n",
      "Validation loss decreased (1.588665 --> 1.588396).         Saving model ...\n",
      "Epoch: 291 \tTraining Loss: 1.103875 \tValidation Loss: 1.588128\n",
      "Validation loss decreased (1.588396 --> 1.588128).         Saving model ...\n",
      "Epoch: 292 \tTraining Loss: 1.103824 \tValidation Loss: 1.587860\n",
      "Validation loss decreased (1.588128 --> 1.587860).         Saving model ...\n",
      "Epoch: 293 \tTraining Loss: 1.103774 \tValidation Loss: 1.587592\n",
      "Validation loss decreased (1.587860 --> 1.587592).         Saving model ...\n",
      "Epoch: 294 \tTraining Loss: 1.103723 \tValidation Loss: 1.587326\n",
      "Validation loss decreased (1.587592 --> 1.587326).         Saving model ...\n",
      "Epoch: 295 \tTraining Loss: 1.103673 \tValidation Loss: 1.587061\n",
      "Validation loss decreased (1.587326 --> 1.587061).         Saving model ...\n",
      "Epoch: 296 \tTraining Loss: 1.103624 \tValidation Loss: 1.586795\n",
      "Validation loss decreased (1.587061 --> 1.586795).         Saving model ...\n",
      "Epoch: 297 \tTraining Loss: 1.103574 \tValidation Loss: 1.586531\n",
      "Validation loss decreased (1.586795 --> 1.586531).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 298 \tTraining Loss: 1.103525 \tValidation Loss: 1.586268\n",
      "Validation loss decreased (1.586531 --> 1.586268).         Saving model ...\n",
      "Epoch: 299 \tTraining Loss: 1.103476 \tValidation Loss: 1.586005\n",
      "Validation loss decreased (1.586268 --> 1.586005).         Saving model ...\n",
      "Epoch: 300 \tTraining Loss: 1.103427 \tValidation Loss: 1.585743\n",
      "Validation loss decreased (1.586005 --> 1.585743).         Saving model ...\n",
      "Epoch: 301 \tTraining Loss: 1.103378 \tValidation Loss: 1.585481\n",
      "Validation loss decreased (1.585743 --> 1.585481).         Saving model ...\n",
      "Epoch: 302 \tTraining Loss: 1.103329 \tValidation Loss: 1.585220\n",
      "Validation loss decreased (1.585481 --> 1.585220).         Saving model ...\n",
      "Epoch: 303 \tTraining Loss: 1.103281 \tValidation Loss: 1.584960\n",
      "Validation loss decreased (1.585220 --> 1.584960).         Saving model ...\n",
      "Epoch: 304 \tTraining Loss: 1.103233 \tValidation Loss: 1.584701\n",
      "Validation loss decreased (1.584960 --> 1.584701).         Saving model ...\n",
      "Epoch: 305 \tTraining Loss: 1.103185 \tValidation Loss: 1.584442\n",
      "Validation loss decreased (1.584701 --> 1.584442).         Saving model ...\n",
      "Epoch: 306 \tTraining Loss: 1.103137 \tValidation Loss: 1.584185\n",
      "Validation loss decreased (1.584442 --> 1.584185).         Saving model ...\n",
      "Epoch: 307 \tTraining Loss: 1.103090 \tValidation Loss: 1.583928\n",
      "Validation loss decreased (1.584185 --> 1.583928).         Saving model ...\n",
      "Epoch: 308 \tTraining Loss: 1.103042 \tValidation Loss: 1.583671\n",
      "Validation loss decreased (1.583928 --> 1.583671).         Saving model ...\n",
      "Epoch: 309 \tTraining Loss: 1.102995 \tValidation Loss: 1.583415\n",
      "Validation loss decreased (1.583671 --> 1.583415).         Saving model ...\n",
      "Epoch: 310 \tTraining Loss: 1.102948 \tValidation Loss: 1.583160\n",
      "Validation loss decreased (1.583415 --> 1.583160).         Saving model ...\n",
      "Epoch: 311 \tTraining Loss: 1.102901 \tValidation Loss: 1.582905\n",
      "Validation loss decreased (1.583160 --> 1.582905).         Saving model ...\n",
      "Epoch: 312 \tTraining Loss: 1.102855 \tValidation Loss: 1.582652\n",
      "Validation loss decreased (1.582905 --> 1.582652).         Saving model ...\n",
      "Epoch: 313 \tTraining Loss: 1.102808 \tValidation Loss: 1.582399\n",
      "Validation loss decreased (1.582652 --> 1.582399).         Saving model ...\n",
      "Epoch: 314 \tTraining Loss: 1.102762 \tValidation Loss: 1.582147\n",
      "Validation loss decreased (1.582399 --> 1.582147).         Saving model ...\n",
      "Epoch: 315 \tTraining Loss: 1.102716 \tValidation Loss: 1.581896\n",
      "Validation loss decreased (1.582147 --> 1.581896).         Saving model ...\n",
      "Epoch: 316 \tTraining Loss: 1.102670 \tValidation Loss: 1.581645\n",
      "Validation loss decreased (1.581896 --> 1.581645).         Saving model ...\n",
      "Epoch: 317 \tTraining Loss: 1.102625 \tValidation Loss: 1.581395\n",
      "Validation loss decreased (1.581645 --> 1.581395).         Saving model ...\n",
      "Epoch: 318 \tTraining Loss: 1.102579 \tValidation Loss: 1.581145\n",
      "Validation loss decreased (1.581395 --> 1.581145).         Saving model ...\n",
      "Epoch: 319 \tTraining Loss: 1.102534 \tValidation Loss: 1.580897\n",
      "Validation loss decreased (1.581145 --> 1.580897).         Saving model ...\n",
      "Epoch: 320 \tTraining Loss: 1.102489 \tValidation Loss: 1.580649\n",
      "Validation loss decreased (1.580897 --> 1.580649).         Saving model ...\n",
      "Epoch: 321 \tTraining Loss: 1.102444 \tValidation Loss: 1.580402\n",
      "Validation loss decreased (1.580649 --> 1.580402).         Saving model ...\n",
      "Epoch: 322 \tTraining Loss: 1.102399 \tValidation Loss: 1.580155\n",
      "Validation loss decreased (1.580402 --> 1.580155).         Saving model ...\n",
      "Epoch: 323 \tTraining Loss: 1.102354 \tValidation Loss: 1.579910\n",
      "Validation loss decreased (1.580155 --> 1.579910).         Saving model ...\n",
      "Epoch: 324 \tTraining Loss: 1.102310 \tValidation Loss: 1.579665\n",
      "Validation loss decreased (1.579910 --> 1.579665).         Saving model ...\n",
      "Epoch: 325 \tTraining Loss: 1.102265 \tValidation Loss: 1.579421\n",
      "Validation loss decreased (1.579665 --> 1.579421).         Saving model ...\n",
      "Epoch: 326 \tTraining Loss: 1.102221 \tValidation Loss: 1.579177\n",
      "Validation loss decreased (1.579421 --> 1.579177).         Saving model ...\n",
      "Epoch: 327 \tTraining Loss: 1.102177 \tValidation Loss: 1.578934\n",
      "Validation loss decreased (1.579177 --> 1.578934).         Saving model ...\n",
      "Epoch: 328 \tTraining Loss: 1.102134 \tValidation Loss: 1.578692\n",
      "Validation loss decreased (1.578934 --> 1.578692).         Saving model ...\n",
      "Epoch: 329 \tTraining Loss: 1.102090 \tValidation Loss: 1.578449\n",
      "Validation loss decreased (1.578692 --> 1.578449).         Saving model ...\n",
      "Epoch: 330 \tTraining Loss: 1.102047 \tValidation Loss: 1.578208\n",
      "Validation loss decreased (1.578449 --> 1.578208).         Saving model ...\n",
      "Epoch: 331 \tTraining Loss: 1.102003 \tValidation Loss: 1.577968\n",
      "Validation loss decreased (1.578208 --> 1.577968).         Saving model ...\n",
      "Epoch: 332 \tTraining Loss: 1.101960 \tValidation Loss: 1.577728\n",
      "Validation loss decreased (1.577968 --> 1.577728).         Saving model ...\n",
      "Epoch: 333 \tTraining Loss: 1.101917 \tValidation Loss: 1.577489\n",
      "Validation loss decreased (1.577728 --> 1.577489).         Saving model ...\n",
      "Epoch: 334 \tTraining Loss: 1.101874 \tValidation Loss: 1.577251\n",
      "Validation loss decreased (1.577489 --> 1.577251).         Saving model ...\n",
      "Epoch: 335 \tTraining Loss: 1.101832 \tValidation Loss: 1.577013\n",
      "Validation loss decreased (1.577251 --> 1.577013).         Saving model ...\n",
      "Epoch: 336 \tTraining Loss: 1.101789 \tValidation Loss: 1.576776\n",
      "Validation loss decreased (1.577013 --> 1.576776).         Saving model ...\n",
      "Epoch: 337 \tTraining Loss: 1.101747 \tValidation Loss: 1.576540\n",
      "Validation loss decreased (1.576776 --> 1.576540).         Saving model ...\n",
      "Epoch: 338 \tTraining Loss: 1.101705 \tValidation Loss: 1.576304\n",
      "Validation loss decreased (1.576540 --> 1.576304).         Saving model ...\n",
      "Epoch: 339 \tTraining Loss: 1.101663 \tValidation Loss: 1.576069\n",
      "Validation loss decreased (1.576304 --> 1.576069).         Saving model ...\n",
      "Epoch: 340 \tTraining Loss: 1.101621 \tValidation Loss: 1.575835\n",
      "Validation loss decreased (1.576069 --> 1.575835).         Saving model ...\n",
      "Epoch: 341 \tTraining Loss: 1.101579 \tValidation Loss: 1.575601\n",
      "Validation loss decreased (1.575835 --> 1.575601).         Saving model ...\n",
      "Epoch: 342 \tTraining Loss: 1.101538 \tValidation Loss: 1.575368\n",
      "Validation loss decreased (1.575601 --> 1.575368).         Saving model ...\n",
      "Epoch: 343 \tTraining Loss: 1.101496 \tValidation Loss: 1.575136\n",
      "Validation loss decreased (1.575368 --> 1.575136).         Saving model ...\n",
      "Epoch: 344 \tTraining Loss: 1.101455 \tValidation Loss: 1.574904\n",
      "Validation loss decreased (1.575136 --> 1.574904).         Saving model ...\n",
      "Epoch: 345 \tTraining Loss: 1.101414 \tValidation Loss: 1.574673\n",
      "Validation loss decreased (1.574904 --> 1.574673).         Saving model ...\n",
      "Epoch: 346 \tTraining Loss: 1.101373 \tValidation Loss: 1.574443\n",
      "Validation loss decreased (1.574673 --> 1.574443).         Saving model ...\n",
      "Epoch: 347 \tTraining Loss: 1.101332 \tValidation Loss: 1.574213\n",
      "Validation loss decreased (1.574443 --> 1.574213).         Saving model ...\n",
      "Epoch: 348 \tTraining Loss: 1.101291 \tValidation Loss: 1.573984\n",
      "Validation loss decreased (1.574213 --> 1.573984).         Saving model ...\n",
      "Epoch: 349 \tTraining Loss: 1.101251 \tValidation Loss: 1.573756\n",
      "Validation loss decreased (1.573984 --> 1.573756).         Saving model ...\n",
      "Epoch: 350 \tTraining Loss: 1.101211 \tValidation Loss: 1.573528\n",
      "Validation loss decreased (1.573756 --> 1.573528).         Saving model ...\n",
      "Epoch: 351 \tTraining Loss: 1.101170 \tValidation Loss: 1.573301\n",
      "Validation loss decreased (1.573528 --> 1.573301).         Saving model ...\n",
      "Epoch: 352 \tTraining Loss: 1.101130 \tValidation Loss: 1.573074\n",
      "Validation loss decreased (1.573301 --> 1.573074).         Saving model ...\n",
      "Epoch: 353 \tTraining Loss: 1.101090 \tValidation Loss: 1.572848\n",
      "Validation loss decreased (1.573074 --> 1.572848).         Saving model ...\n",
      "Epoch: 354 \tTraining Loss: 1.101050 \tValidation Loss: 1.572623\n",
      "Validation loss decreased (1.572848 --> 1.572623).         Saving model ...\n",
      "Epoch: 355 \tTraining Loss: 1.101011 \tValidation Loss: 1.572398\n",
      "Validation loss decreased (1.572623 --> 1.572398).         Saving model ...\n",
      "Epoch: 356 \tTraining Loss: 1.100971 \tValidation Loss: 1.572173\n",
      "Validation loss decreased (1.572398 --> 1.572173).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 357 \tTraining Loss: 1.100932 \tValidation Loss: 1.571950\n",
      "Validation loss decreased (1.572173 --> 1.571950).         Saving model ...\n",
      "Epoch: 358 \tTraining Loss: 1.100893 \tValidation Loss: 1.571727\n",
      "Validation loss decreased (1.571950 --> 1.571727).         Saving model ...\n",
      "Epoch: 359 \tTraining Loss: 1.100854 \tValidation Loss: 1.571505\n",
      "Validation loss decreased (1.571727 --> 1.571505).         Saving model ...\n",
      "Epoch: 360 \tTraining Loss: 1.100815 \tValidation Loss: 1.571283\n",
      "Validation loss decreased (1.571505 --> 1.571283).         Saving model ...\n",
      "Epoch: 361 \tTraining Loss: 1.100776 \tValidation Loss: 1.571063\n",
      "Validation loss decreased (1.571283 --> 1.571063).         Saving model ...\n",
      "Epoch: 362 \tTraining Loss: 1.100737 \tValidation Loss: 1.570843\n",
      "Validation loss decreased (1.571063 --> 1.570843).         Saving model ...\n",
      "Epoch: 363 \tTraining Loss: 1.100698 \tValidation Loss: 1.570623\n",
      "Validation loss decreased (1.570843 --> 1.570623).         Saving model ...\n",
      "Epoch: 364 \tTraining Loss: 1.100660 \tValidation Loss: 1.570404\n",
      "Validation loss decreased (1.570623 --> 1.570404).         Saving model ...\n",
      "Epoch: 365 \tTraining Loss: 1.100622 \tValidation Loss: 1.570186\n",
      "Validation loss decreased (1.570404 --> 1.570186).         Saving model ...\n",
      "Epoch: 366 \tTraining Loss: 1.100584 \tValidation Loss: 1.569968\n",
      "Validation loss decreased (1.570186 --> 1.569968).         Saving model ...\n",
      "Epoch: 367 \tTraining Loss: 1.100545 \tValidation Loss: 1.569751\n",
      "Validation loss decreased (1.569968 --> 1.569751).         Saving model ...\n",
      "Epoch: 368 \tTraining Loss: 1.100508 \tValidation Loss: 1.569535\n",
      "Validation loss decreased (1.569751 --> 1.569535).         Saving model ...\n",
      "Epoch: 369 \tTraining Loss: 1.100470 \tValidation Loss: 1.569319\n",
      "Validation loss decreased (1.569535 --> 1.569319).         Saving model ...\n",
      "Epoch: 370 \tTraining Loss: 1.100432 \tValidation Loss: 1.569105\n",
      "Validation loss decreased (1.569319 --> 1.569105).         Saving model ...\n",
      "Epoch: 371 \tTraining Loss: 1.100395 \tValidation Loss: 1.568889\n",
      "Validation loss decreased (1.569105 --> 1.568889).         Saving model ...\n",
      "Epoch: 372 \tTraining Loss: 1.100357 \tValidation Loss: 1.568676\n",
      "Validation loss decreased (1.568889 --> 1.568676).         Saving model ...\n",
      "Epoch: 373 \tTraining Loss: 1.100320 \tValidation Loss: 1.568462\n",
      "Validation loss decreased (1.568676 --> 1.568462).         Saving model ...\n",
      "Epoch: 374 \tTraining Loss: 1.100283 \tValidation Loss: 1.568250\n",
      "Validation loss decreased (1.568462 --> 1.568250).         Saving model ...\n",
      "Epoch: 375 \tTraining Loss: 1.100246 \tValidation Loss: 1.568037\n",
      "Validation loss decreased (1.568250 --> 1.568037).         Saving model ...\n",
      "Epoch: 376 \tTraining Loss: 1.100209 \tValidation Loss: 1.567826\n",
      "Validation loss decreased (1.568037 --> 1.567826).         Saving model ...\n",
      "Epoch: 377 \tTraining Loss: 1.100172 \tValidation Loss: 1.567616\n",
      "Validation loss decreased (1.567826 --> 1.567616).         Saving model ...\n",
      "Epoch: 378 \tTraining Loss: 1.100135 \tValidation Loss: 1.567406\n",
      "Validation loss decreased (1.567616 --> 1.567406).         Saving model ...\n",
      "Epoch: 379 \tTraining Loss: 1.100099 \tValidation Loss: 1.567196\n",
      "Validation loss decreased (1.567406 --> 1.567196).         Saving model ...\n",
      "Epoch: 380 \tTraining Loss: 1.100062 \tValidation Loss: 1.566987\n",
      "Validation loss decreased (1.567196 --> 1.566987).         Saving model ...\n",
      "Epoch: 381 \tTraining Loss: 1.100026 \tValidation Loss: 1.566779\n",
      "Validation loss decreased (1.566987 --> 1.566779).         Saving model ...\n",
      "Epoch: 382 \tTraining Loss: 1.099990 \tValidation Loss: 1.566570\n",
      "Validation loss decreased (1.566779 --> 1.566570).         Saving model ...\n",
      "Epoch: 383 \tTraining Loss: 1.099954 \tValidation Loss: 1.566363\n",
      "Validation loss decreased (1.566570 --> 1.566363).         Saving model ...\n",
      "Epoch: 384 \tTraining Loss: 1.099918 \tValidation Loss: 1.566157\n",
      "Validation loss decreased (1.566363 --> 1.566157).         Saving model ...\n",
      "Epoch: 385 \tTraining Loss: 1.099882 \tValidation Loss: 1.565951\n",
      "Validation loss decreased (1.566157 --> 1.565951).         Saving model ...\n",
      "Epoch: 386 \tTraining Loss: 1.099846 \tValidation Loss: 1.565745\n",
      "Validation loss decreased (1.565951 --> 1.565745).         Saving model ...\n",
      "Epoch: 387 \tTraining Loss: 1.099811 \tValidation Loss: 1.565540\n",
      "Validation loss decreased (1.565745 --> 1.565540).         Saving model ...\n",
      "Epoch: 388 \tTraining Loss: 1.099775 \tValidation Loss: 1.565336\n",
      "Validation loss decreased (1.565540 --> 1.565336).         Saving model ...\n",
      "Epoch: 389 \tTraining Loss: 1.099740 \tValidation Loss: 1.565132\n",
      "Validation loss decreased (1.565336 --> 1.565132).         Saving model ...\n",
      "Epoch: 390 \tTraining Loss: 1.099705 \tValidation Loss: 1.564929\n",
      "Validation loss decreased (1.565132 --> 1.564929).         Saving model ...\n",
      "Epoch: 391 \tTraining Loss: 1.099669 \tValidation Loss: 1.564726\n",
      "Validation loss decreased (1.564929 --> 1.564726).         Saving model ...\n",
      "Epoch: 392 \tTraining Loss: 1.099634 \tValidation Loss: 1.564523\n",
      "Validation loss decreased (1.564726 --> 1.564523).         Saving model ...\n",
      "Epoch: 393 \tTraining Loss: 1.099599 \tValidation Loss: 1.564322\n",
      "Validation loss decreased (1.564523 --> 1.564322).         Saving model ...\n",
      "Epoch: 394 \tTraining Loss: 1.099565 \tValidation Loss: 1.564121\n",
      "Validation loss decreased (1.564322 --> 1.564121).         Saving model ...\n",
      "Epoch: 395 \tTraining Loss: 1.099530 \tValidation Loss: 1.563921\n",
      "Validation loss decreased (1.564121 --> 1.563921).         Saving model ...\n",
      "Epoch: 396 \tTraining Loss: 1.099495 \tValidation Loss: 1.563721\n",
      "Validation loss decreased (1.563921 --> 1.563721).         Saving model ...\n",
      "Epoch: 397 \tTraining Loss: 1.099461 \tValidation Loss: 1.563522\n",
      "Validation loss decreased (1.563721 --> 1.563522).         Saving model ...\n",
      "Epoch: 398 \tTraining Loss: 1.099426 \tValidation Loss: 1.563323\n",
      "Validation loss decreased (1.563522 --> 1.563323).         Saving model ...\n",
      "Epoch: 399 \tTraining Loss: 1.099392 \tValidation Loss: 1.563125\n",
      "Validation loss decreased (1.563323 --> 1.563125).         Saving model ...\n",
      "Epoch: 400 \tTraining Loss: 1.099358 \tValidation Loss: 1.562927\n",
      "Validation loss decreased (1.563125 --> 1.562927).         Saving model ...\n",
      "Epoch: 401 \tTraining Loss: 1.099324 \tValidation Loss: 1.562731\n",
      "Validation loss decreased (1.562927 --> 1.562731).         Saving model ...\n",
      "Epoch: 402 \tTraining Loss: 1.099290 \tValidation Loss: 1.562534\n",
      "Validation loss decreased (1.562731 --> 1.562534).         Saving model ...\n",
      "Epoch: 403 \tTraining Loss: 1.099256 \tValidation Loss: 1.562338\n",
      "Validation loss decreased (1.562534 --> 1.562338).         Saving model ...\n",
      "Epoch: 404 \tTraining Loss: 1.099223 \tValidation Loss: 1.562143\n",
      "Validation loss decreased (1.562338 --> 1.562143).         Saving model ...\n",
      "Epoch: 405 \tTraining Loss: 1.099189 \tValidation Loss: 1.561949\n",
      "Validation loss decreased (1.562143 --> 1.561949).         Saving model ...\n",
      "Epoch: 406 \tTraining Loss: 1.099155 \tValidation Loss: 1.561754\n",
      "Validation loss decreased (1.561949 --> 1.561754).         Saving model ...\n",
      "Epoch: 407 \tTraining Loss: 1.099122 \tValidation Loss: 1.561561\n",
      "Validation loss decreased (1.561754 --> 1.561561).         Saving model ...\n",
      "Epoch: 408 \tTraining Loss: 1.099089 \tValidation Loss: 1.561367\n",
      "Validation loss decreased (1.561561 --> 1.561367).         Saving model ...\n",
      "Epoch: 409 \tTraining Loss: 1.099055 \tValidation Loss: 1.561175\n",
      "Validation loss decreased (1.561367 --> 1.561175).         Saving model ...\n",
      "Epoch: 410 \tTraining Loss: 1.099022 \tValidation Loss: 1.560983\n",
      "Validation loss decreased (1.561175 --> 1.560983).         Saving model ...\n",
      "Epoch: 411 \tTraining Loss: 1.098989 \tValidation Loss: 1.560792\n",
      "Validation loss decreased (1.560983 --> 1.560792).         Saving model ...\n",
      "Epoch: 412 \tTraining Loss: 1.098956 \tValidation Loss: 1.560601\n",
      "Validation loss decreased (1.560792 --> 1.560601).         Saving model ...\n",
      "Epoch: 413 \tTraining Loss: 1.098924 \tValidation Loss: 1.560410\n",
      "Validation loss decreased (1.560601 --> 1.560410).         Saving model ...\n",
      "Epoch: 414 \tTraining Loss: 1.098891 \tValidation Loss: 1.560219\n",
      "Validation loss decreased (1.560410 --> 1.560219).         Saving model ...\n",
      "Epoch: 415 \tTraining Loss: 1.098858 \tValidation Loss: 1.560031\n",
      "Validation loss decreased (1.560219 --> 1.560031).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 416 \tTraining Loss: 1.098826 \tValidation Loss: 1.559842\n",
      "Validation loss decreased (1.560031 --> 1.559842).         Saving model ...\n",
      "Epoch: 417 \tTraining Loss: 1.098793 \tValidation Loss: 1.559654\n",
      "Validation loss decreased (1.559842 --> 1.559654).         Saving model ...\n",
      "Epoch: 418 \tTraining Loss: 1.098761 \tValidation Loss: 1.559467\n",
      "Validation loss decreased (1.559654 --> 1.559467).         Saving model ...\n",
      "Epoch: 419 \tTraining Loss: 1.098729 \tValidation Loss: 1.559279\n",
      "Validation loss decreased (1.559467 --> 1.559279).         Saving model ...\n",
      "Epoch: 420 \tTraining Loss: 1.098697 \tValidation Loss: 1.559093\n",
      "Validation loss decreased (1.559279 --> 1.559093).         Saving model ...\n",
      "Epoch: 421 \tTraining Loss: 1.098665 \tValidation Loss: 1.558907\n",
      "Validation loss decreased (1.559093 --> 1.558907).         Saving model ...\n",
      "Epoch: 422 \tTraining Loss: 1.098633 \tValidation Loss: 1.558721\n",
      "Validation loss decreased (1.558907 --> 1.558721).         Saving model ...\n",
      "Epoch: 423 \tTraining Loss: 1.098601 \tValidation Loss: 1.558536\n",
      "Validation loss decreased (1.558721 --> 1.558536).         Saving model ...\n",
      "Epoch: 424 \tTraining Loss: 1.098569 \tValidation Loss: 1.558352\n",
      "Validation loss decreased (1.558536 --> 1.558352).         Saving model ...\n",
      "Epoch: 425 \tTraining Loss: 1.098537 \tValidation Loss: 1.558167\n",
      "Validation loss decreased (1.558352 --> 1.558167).         Saving model ...\n",
      "Epoch: 426 \tTraining Loss: 1.098506 \tValidation Loss: 1.557985\n",
      "Validation loss decreased (1.558167 --> 1.557985).         Saving model ...\n",
      "Epoch: 427 \tTraining Loss: 1.098474 \tValidation Loss: 1.557801\n",
      "Validation loss decreased (1.557985 --> 1.557801).         Saving model ...\n",
      "Epoch: 428 \tTraining Loss: 1.098443 \tValidation Loss: 1.557619\n",
      "Validation loss decreased (1.557801 --> 1.557619).         Saving model ...\n",
      "Epoch: 429 \tTraining Loss: 1.098412 \tValidation Loss: 1.557437\n",
      "Validation loss decreased (1.557619 --> 1.557437).         Saving model ...\n",
      "Epoch: 430 \tTraining Loss: 1.098380 \tValidation Loss: 1.557255\n",
      "Validation loss decreased (1.557437 --> 1.557255).         Saving model ...\n",
      "Epoch: 431 \tTraining Loss: 1.098349 \tValidation Loss: 1.557074\n",
      "Validation loss decreased (1.557255 --> 1.557074).         Saving model ...\n",
      "Epoch: 432 \tTraining Loss: 1.098318 \tValidation Loss: 1.556894\n",
      "Validation loss decreased (1.557074 --> 1.556894).         Saving model ...\n",
      "Epoch: 433 \tTraining Loss: 1.098287 \tValidation Loss: 1.556714\n",
      "Validation loss decreased (1.556894 --> 1.556714).         Saving model ...\n",
      "Epoch: 434 \tTraining Loss: 1.098257 \tValidation Loss: 1.556535\n",
      "Validation loss decreased (1.556714 --> 1.556535).         Saving model ...\n",
      "Epoch: 435 \tTraining Loss: 1.098226 \tValidation Loss: 1.556356\n",
      "Validation loss decreased (1.556535 --> 1.556356).         Saving model ...\n",
      "Epoch: 436 \tTraining Loss: 1.098195 \tValidation Loss: 1.556177\n",
      "Validation loss decreased (1.556356 --> 1.556177).         Saving model ...\n",
      "Epoch: 437 \tTraining Loss: 1.098165 \tValidation Loss: 1.555999\n",
      "Validation loss decreased (1.556177 --> 1.555999).         Saving model ...\n",
      "Epoch: 438 \tTraining Loss: 1.098134 \tValidation Loss: 1.555822\n",
      "Validation loss decreased (1.555999 --> 1.555822).         Saving model ...\n",
      "Epoch: 439 \tTraining Loss: 1.098104 \tValidation Loss: 1.555645\n",
      "Validation loss decreased (1.555822 --> 1.555645).         Saving model ...\n",
      "Epoch: 440 \tTraining Loss: 1.098073 \tValidation Loss: 1.555468\n",
      "Validation loss decreased (1.555645 --> 1.555468).         Saving model ...\n",
      "Epoch: 441 \tTraining Loss: 1.098043 \tValidation Loss: 1.555292\n",
      "Validation loss decreased (1.555468 --> 1.555292).         Saving model ...\n",
      "Epoch: 442 \tTraining Loss: 1.098013 \tValidation Loss: 1.555116\n",
      "Validation loss decreased (1.555292 --> 1.555116).         Saving model ...\n",
      "Epoch: 443 \tTraining Loss: 1.097983 \tValidation Loss: 1.554941\n",
      "Validation loss decreased (1.555116 --> 1.554941).         Saving model ...\n",
      "Epoch: 444 \tTraining Loss: 1.097953 \tValidation Loss: 1.554766\n",
      "Validation loss decreased (1.554941 --> 1.554766).         Saving model ...\n",
      "Epoch: 445 \tTraining Loss: 1.097923 \tValidation Loss: 1.554592\n",
      "Validation loss decreased (1.554766 --> 1.554592).         Saving model ...\n",
      "Epoch: 446 \tTraining Loss: 1.097893 \tValidation Loss: 1.554419\n",
      "Validation loss decreased (1.554592 --> 1.554419).         Saving model ...\n",
      "Epoch: 447 \tTraining Loss: 1.097864 \tValidation Loss: 1.554246\n",
      "Validation loss decreased (1.554419 --> 1.554246).         Saving model ...\n",
      "Epoch: 448 \tTraining Loss: 1.097834 \tValidation Loss: 1.554073\n",
      "Validation loss decreased (1.554246 --> 1.554073).         Saving model ...\n",
      "Epoch: 449 \tTraining Loss: 1.097805 \tValidation Loss: 1.553901\n",
      "Validation loss decreased (1.554073 --> 1.553901).         Saving model ...\n",
      "Epoch: 450 \tTraining Loss: 1.097775 \tValidation Loss: 1.553730\n",
      "Validation loss decreased (1.553901 --> 1.553730).         Saving model ...\n",
      "Epoch: 451 \tTraining Loss: 1.097746 \tValidation Loss: 1.553558\n",
      "Validation loss decreased (1.553730 --> 1.553558).         Saving model ...\n",
      "Epoch: 452 \tTraining Loss: 1.097716 \tValidation Loss: 1.553387\n",
      "Validation loss decreased (1.553558 --> 1.553387).         Saving model ...\n",
      "Epoch: 453 \tTraining Loss: 1.097687 \tValidation Loss: 1.553217\n",
      "Validation loss decreased (1.553387 --> 1.553217).         Saving model ...\n",
      "Epoch: 454 \tTraining Loss: 1.097658 \tValidation Loss: 1.553048\n",
      "Validation loss decreased (1.553217 --> 1.553048).         Saving model ...\n",
      "Epoch: 455 \tTraining Loss: 1.097629 \tValidation Loss: 1.552879\n",
      "Validation loss decreased (1.553048 --> 1.552879).         Saving model ...\n",
      "Epoch: 456 \tTraining Loss: 1.097600 \tValidation Loss: 1.552710\n",
      "Validation loss decreased (1.552879 --> 1.552710).         Saving model ...\n",
      "Epoch: 457 \tTraining Loss: 1.097571 \tValidation Loss: 1.552542\n",
      "Validation loss decreased (1.552710 --> 1.552542).         Saving model ...\n",
      "Epoch: 458 \tTraining Loss: 1.097542 \tValidation Loss: 1.552375\n",
      "Validation loss decreased (1.552542 --> 1.552375).         Saving model ...\n",
      "Epoch: 459 \tTraining Loss: 1.097514 \tValidation Loss: 1.552208\n",
      "Validation loss decreased (1.552375 --> 1.552208).         Saving model ...\n",
      "Epoch: 460 \tTraining Loss: 1.097485 \tValidation Loss: 1.552041\n",
      "Validation loss decreased (1.552208 --> 1.552041).         Saving model ...\n",
      "Epoch: 461 \tTraining Loss: 1.097456 \tValidation Loss: 1.551875\n",
      "Validation loss decreased (1.552041 --> 1.551875).         Saving model ...\n",
      "Epoch: 462 \tTraining Loss: 1.097428 \tValidation Loss: 1.551709\n",
      "Validation loss decreased (1.551875 --> 1.551709).         Saving model ...\n",
      "Epoch: 463 \tTraining Loss: 1.097400 \tValidation Loss: 1.551543\n",
      "Validation loss decreased (1.551709 --> 1.551543).         Saving model ...\n",
      "Epoch: 464 \tTraining Loss: 1.097371 \tValidation Loss: 1.551378\n",
      "Validation loss decreased (1.551543 --> 1.551378).         Saving model ...\n",
      "Epoch: 465 \tTraining Loss: 1.097343 \tValidation Loss: 1.551213\n",
      "Validation loss decreased (1.551378 --> 1.551213).         Saving model ...\n",
      "Epoch: 466 \tTraining Loss: 1.097315 \tValidation Loss: 1.551049\n",
      "Validation loss decreased (1.551213 --> 1.551049).         Saving model ...\n",
      "Epoch: 467 \tTraining Loss: 1.097287 \tValidation Loss: 1.550885\n",
      "Validation loss decreased (1.551049 --> 1.550885).         Saving model ...\n",
      "Epoch: 468 \tTraining Loss: 1.097259 \tValidation Loss: 1.550722\n",
      "Validation loss decreased (1.550885 --> 1.550722).         Saving model ...\n",
      "Epoch: 469 \tTraining Loss: 1.097231 \tValidation Loss: 1.550560\n",
      "Validation loss decreased (1.550722 --> 1.550560).         Saving model ...\n",
      "Epoch: 470 \tTraining Loss: 1.097203 \tValidation Loss: 1.550397\n",
      "Validation loss decreased (1.550560 --> 1.550397).         Saving model ...\n",
      "Epoch: 471 \tTraining Loss: 1.097175 \tValidation Loss: 1.550235\n",
      "Validation loss decreased (1.550397 --> 1.550235).         Saving model ...\n",
      "Epoch: 472 \tTraining Loss: 1.097147 \tValidation Loss: 1.550074\n",
      "Validation loss decreased (1.550235 --> 1.550074).         Saving model ...\n",
      "Epoch: 473 \tTraining Loss: 1.097120 \tValidation Loss: 1.549912\n",
      "Validation loss decreased (1.550074 --> 1.549912).         Saving model ...\n",
      "Epoch: 474 \tTraining Loss: 1.097092 \tValidation Loss: 1.549752\n",
      "Validation loss decreased (1.549912 --> 1.549752).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 475 \tTraining Loss: 1.097064 \tValidation Loss: 1.549592\n",
      "Validation loss decreased (1.549752 --> 1.549592).         Saving model ...\n",
      "Epoch: 476 \tTraining Loss: 1.097037 \tValidation Loss: 1.549433\n",
      "Validation loss decreased (1.549592 --> 1.549433).         Saving model ...\n",
      "Epoch: 477 \tTraining Loss: 1.097010 \tValidation Loss: 1.549273\n",
      "Validation loss decreased (1.549433 --> 1.549273).         Saving model ...\n",
      "Epoch: 478 \tTraining Loss: 1.096982 \tValidation Loss: 1.549115\n",
      "Validation loss decreased (1.549273 --> 1.549115).         Saving model ...\n",
      "Epoch: 479 \tTraining Loss: 1.096955 \tValidation Loss: 1.548956\n",
      "Validation loss decreased (1.549115 --> 1.548956).         Saving model ...\n",
      "Epoch: 480 \tTraining Loss: 1.096928 \tValidation Loss: 1.548799\n",
      "Validation loss decreased (1.548956 --> 1.548799).         Saving model ...\n",
      "Epoch: 481 \tTraining Loss: 1.096901 \tValidation Loss: 1.548642\n",
      "Validation loss decreased (1.548799 --> 1.548642).         Saving model ...\n",
      "Epoch: 482 \tTraining Loss: 1.096874 \tValidation Loss: 1.548484\n",
      "Validation loss decreased (1.548642 --> 1.548484).         Saving model ...\n",
      "Epoch: 483 \tTraining Loss: 1.096847 \tValidation Loss: 1.548327\n",
      "Validation loss decreased (1.548484 --> 1.548327).         Saving model ...\n",
      "Epoch: 484 \tTraining Loss: 1.096820 \tValidation Loss: 1.548172\n",
      "Validation loss decreased (1.548327 --> 1.548172).         Saving model ...\n",
      "Epoch: 485 \tTraining Loss: 1.096793 \tValidation Loss: 1.548015\n",
      "Validation loss decreased (1.548172 --> 1.548015).         Saving model ...\n",
      "Epoch: 486 \tTraining Loss: 1.096767 \tValidation Loss: 1.547859\n",
      "Validation loss decreased (1.548015 --> 1.547859).         Saving model ...\n",
      "Epoch: 487 \tTraining Loss: 1.096740 \tValidation Loss: 1.547705\n",
      "Validation loss decreased (1.547859 --> 1.547705).         Saving model ...\n",
      "Epoch: 488 \tTraining Loss: 1.096713 \tValidation Loss: 1.547551\n",
      "Validation loss decreased (1.547705 --> 1.547551).         Saving model ...\n",
      "Epoch: 489 \tTraining Loss: 1.096687 \tValidation Loss: 1.547397\n",
      "Validation loss decreased (1.547551 --> 1.547397).         Saving model ...\n",
      "Epoch: 490 \tTraining Loss: 1.096660 \tValidation Loss: 1.547243\n",
      "Validation loss decreased (1.547397 --> 1.547243).         Saving model ...\n",
      "Epoch: 491 \tTraining Loss: 1.096634 \tValidation Loss: 1.547090\n",
      "Validation loss decreased (1.547243 --> 1.547090).         Saving model ...\n",
      "Epoch: 492 \tTraining Loss: 1.096608 \tValidation Loss: 1.546938\n",
      "Validation loss decreased (1.547090 --> 1.546938).         Saving model ...\n",
      "Epoch: 493 \tTraining Loss: 1.096581 \tValidation Loss: 1.546785\n",
      "Validation loss decreased (1.546938 --> 1.546785).         Saving model ...\n",
      "Epoch: 494 \tTraining Loss: 1.096555 \tValidation Loss: 1.546634\n",
      "Validation loss decreased (1.546785 --> 1.546634).         Saving model ...\n",
      "Epoch: 495 \tTraining Loss: 1.096529 \tValidation Loss: 1.546481\n",
      "Validation loss decreased (1.546634 --> 1.546481).         Saving model ...\n",
      "Epoch: 496 \tTraining Loss: 1.096503 \tValidation Loss: 1.546330\n",
      "Validation loss decreased (1.546481 --> 1.546330).         Saving model ...\n",
      "Epoch: 497 \tTraining Loss: 1.096477 \tValidation Loss: 1.546180\n",
      "Validation loss decreased (1.546330 --> 1.546180).         Saving model ...\n",
      "Epoch: 498 \tTraining Loss: 1.096451 \tValidation Loss: 1.546030\n",
      "Validation loss decreased (1.546180 --> 1.546030).         Saving model ...\n",
      "Epoch: 499 \tTraining Loss: 1.096425 \tValidation Loss: 1.545880\n",
      "Validation loss decreased (1.546030 --> 1.545880).         Saving model ...\n",
      "Epoch: 500 \tTraining Loss: 1.096399 \tValidation Loss: 1.545731\n",
      "Validation loss decreased (1.545880 --> 1.545731).         Saving model ...\n",
      "Epoch: 501 \tTraining Loss: 1.096374 \tValidation Loss: 1.545582\n",
      "Validation loss decreased (1.545731 --> 1.545582).         Saving model ...\n",
      "Epoch: 502 \tTraining Loss: 1.096348 \tValidation Loss: 1.545433\n",
      "Validation loss decreased (1.545582 --> 1.545433).         Saving model ...\n",
      "Epoch: 503 \tTraining Loss: 1.096322 \tValidation Loss: 1.545284\n",
      "Validation loss decreased (1.545433 --> 1.545284).         Saving model ...\n",
      "Epoch: 504 \tTraining Loss: 1.096297 \tValidation Loss: 1.545137\n",
      "Validation loss decreased (1.545284 --> 1.545137).         Saving model ...\n",
      "Epoch: 505 \tTraining Loss: 1.096272 \tValidation Loss: 1.544990\n",
      "Validation loss decreased (1.545137 --> 1.544990).         Saving model ...\n",
      "Epoch: 506 \tTraining Loss: 1.096246 \tValidation Loss: 1.544843\n",
      "Validation loss decreased (1.544990 --> 1.544843).         Saving model ...\n",
      "Epoch: 507 \tTraining Loss: 1.096221 \tValidation Loss: 1.544696\n",
      "Validation loss decreased (1.544843 --> 1.544696).         Saving model ...\n",
      "Epoch: 508 \tTraining Loss: 1.096196 \tValidation Loss: 1.544550\n",
      "Validation loss decreased (1.544696 --> 1.544550).         Saving model ...\n",
      "Epoch: 509 \tTraining Loss: 1.096170 \tValidation Loss: 1.544404\n",
      "Validation loss decreased (1.544550 --> 1.544404).         Saving model ...\n",
      "Epoch: 510 \tTraining Loss: 1.096145 \tValidation Loss: 1.544259\n",
      "Validation loss decreased (1.544404 --> 1.544259).         Saving model ...\n",
      "Epoch: 511 \tTraining Loss: 1.096120 \tValidation Loss: 1.544114\n",
      "Validation loss decreased (1.544259 --> 1.544114).         Saving model ...\n",
      "Epoch: 512 \tTraining Loss: 1.096095 \tValidation Loss: 1.543969\n",
      "Validation loss decreased (1.544114 --> 1.543969).         Saving model ...\n",
      "Epoch: 513 \tTraining Loss: 1.096070 \tValidation Loss: 1.543825\n",
      "Validation loss decreased (1.543969 --> 1.543825).         Saving model ...\n",
      "Epoch: 514 \tTraining Loss: 1.096045 \tValidation Loss: 1.543681\n",
      "Validation loss decreased (1.543825 --> 1.543681).         Saving model ...\n",
      "Epoch: 515 \tTraining Loss: 1.096020 \tValidation Loss: 1.543537\n",
      "Validation loss decreased (1.543681 --> 1.543537).         Saving model ...\n",
      "Epoch: 516 \tTraining Loss: 1.095996 \tValidation Loss: 1.543394\n",
      "Validation loss decreased (1.543537 --> 1.543394).         Saving model ...\n",
      "Epoch: 517 \tTraining Loss: 1.095971 \tValidation Loss: 1.543252\n",
      "Validation loss decreased (1.543394 --> 1.543252).         Saving model ...\n",
      "Epoch: 518 \tTraining Loss: 1.095946 \tValidation Loss: 1.543110\n",
      "Validation loss decreased (1.543252 --> 1.543110).         Saving model ...\n",
      "Epoch: 519 \tTraining Loss: 1.095922 \tValidation Loss: 1.542968\n",
      "Validation loss decreased (1.543110 --> 1.542968).         Saving model ...\n",
      "Epoch: 520 \tTraining Loss: 1.095897 \tValidation Loss: 1.542826\n",
      "Validation loss decreased (1.542968 --> 1.542826).         Saving model ...\n",
      "Epoch: 521 \tTraining Loss: 1.095873 \tValidation Loss: 1.542685\n",
      "Validation loss decreased (1.542826 --> 1.542685).         Saving model ...\n",
      "Epoch: 522 \tTraining Loss: 1.095848 \tValidation Loss: 1.542544\n",
      "Validation loss decreased (1.542685 --> 1.542544).         Saving model ...\n",
      "Epoch: 523 \tTraining Loss: 1.095824 \tValidation Loss: 1.542403\n",
      "Validation loss decreased (1.542544 --> 1.542403).         Saving model ...\n",
      "Epoch: 524 \tTraining Loss: 1.095800 \tValidation Loss: 1.542263\n",
      "Validation loss decreased (1.542403 --> 1.542263).         Saving model ...\n",
      "Epoch: 525 \tTraining Loss: 1.095775 \tValidation Loss: 1.542123\n",
      "Validation loss decreased (1.542263 --> 1.542123).         Saving model ...\n",
      "Epoch: 526 \tTraining Loss: 1.095751 \tValidation Loss: 1.541985\n",
      "Validation loss decreased (1.542123 --> 1.541985).         Saving model ...\n",
      "Epoch: 527 \tTraining Loss: 1.095727 \tValidation Loss: 1.541846\n",
      "Validation loss decreased (1.541985 --> 1.541846).         Saving model ...\n",
      "Epoch: 528 \tTraining Loss: 1.095703 \tValidation Loss: 1.541707\n",
      "Validation loss decreased (1.541846 --> 1.541707).         Saving model ...\n",
      "Epoch: 529 \tTraining Loss: 1.095679 \tValidation Loss: 1.541570\n",
      "Validation loss decreased (1.541707 --> 1.541570).         Saving model ...\n",
      "Epoch: 530 \tTraining Loss: 1.095655 \tValidation Loss: 1.541433\n",
      "Validation loss decreased (1.541570 --> 1.541433).         Saving model ...\n",
      "Epoch: 531 \tTraining Loss: 1.095631 \tValidation Loss: 1.541294\n",
      "Validation loss decreased (1.541433 --> 1.541294).         Saving model ...\n",
      "Epoch: 532 \tTraining Loss: 1.095607 \tValidation Loss: 1.541158\n",
      "Validation loss decreased (1.541294 --> 1.541158).         Saving model ...\n",
      "Epoch: 533 \tTraining Loss: 1.095583 \tValidation Loss: 1.541021\n",
      "Validation loss decreased (1.541158 --> 1.541021).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 534 \tTraining Loss: 1.095560 \tValidation Loss: 1.540885\n",
      "Validation loss decreased (1.541021 --> 1.540885).         Saving model ...\n",
      "Epoch: 535 \tTraining Loss: 1.095536 \tValidation Loss: 1.540749\n",
      "Validation loss decreased (1.540885 --> 1.540749).         Saving model ...\n",
      "Epoch: 536 \tTraining Loss: 1.095512 \tValidation Loss: 1.540613\n",
      "Validation loss decreased (1.540749 --> 1.540613).         Saving model ...\n",
      "Epoch: 537 \tTraining Loss: 1.095489 \tValidation Loss: 1.540478\n",
      "Validation loss decreased (1.540613 --> 1.540478).         Saving model ...\n",
      "Epoch: 538 \tTraining Loss: 1.095465 \tValidation Loss: 1.540343\n",
      "Validation loss decreased (1.540478 --> 1.540343).         Saving model ...\n",
      "Epoch: 539 \tTraining Loss: 1.095442 \tValidation Loss: 1.540209\n",
      "Validation loss decreased (1.540343 --> 1.540209).         Saving model ...\n",
      "Epoch: 540 \tTraining Loss: 1.095419 \tValidation Loss: 1.540074\n",
      "Validation loss decreased (1.540209 --> 1.540074).         Saving model ...\n",
      "Epoch: 541 \tTraining Loss: 1.095395 \tValidation Loss: 1.539941\n",
      "Validation loss decreased (1.540074 --> 1.539941).         Saving model ...\n",
      "Epoch: 542 \tTraining Loss: 1.095372 \tValidation Loss: 1.539808\n",
      "Validation loss decreased (1.539941 --> 1.539808).         Saving model ...\n",
      "Epoch: 543 \tTraining Loss: 1.095349 \tValidation Loss: 1.539674\n",
      "Validation loss decreased (1.539808 --> 1.539674).         Saving model ...\n",
      "Epoch: 544 \tTraining Loss: 1.095326 \tValidation Loss: 1.539542\n",
      "Validation loss decreased (1.539674 --> 1.539542).         Saving model ...\n",
      "Epoch: 545 \tTraining Loss: 1.095302 \tValidation Loss: 1.539409\n",
      "Validation loss decreased (1.539542 --> 1.539409).         Saving model ...\n",
      "Epoch: 546 \tTraining Loss: 1.095279 \tValidation Loss: 1.539278\n",
      "Validation loss decreased (1.539409 --> 1.539278).         Saving model ...\n",
      "Epoch: 547 \tTraining Loss: 1.095256 \tValidation Loss: 1.539146\n",
      "Validation loss decreased (1.539278 --> 1.539146).         Saving model ...\n",
      "Epoch: 548 \tTraining Loss: 1.095233 \tValidation Loss: 1.539014\n",
      "Validation loss decreased (1.539146 --> 1.539014).         Saving model ...\n",
      "Epoch: 549 \tTraining Loss: 1.095211 \tValidation Loss: 1.538884\n",
      "Validation loss decreased (1.539014 --> 1.538884).         Saving model ...\n",
      "Epoch: 550 \tTraining Loss: 1.095188 \tValidation Loss: 1.538753\n",
      "Validation loss decreased (1.538884 --> 1.538753).         Saving model ...\n",
      "Epoch: 551 \tTraining Loss: 1.095165 \tValidation Loss: 1.538623\n",
      "Validation loss decreased (1.538753 --> 1.538623).         Saving model ...\n",
      "Epoch: 552 \tTraining Loss: 1.095142 \tValidation Loss: 1.538493\n",
      "Validation loss decreased (1.538623 --> 1.538493).         Saving model ...\n",
      "Epoch: 553 \tTraining Loss: 1.095119 \tValidation Loss: 1.538363\n",
      "Validation loss decreased (1.538493 --> 1.538363).         Saving model ...\n",
      "Epoch: 554 \tTraining Loss: 1.095097 \tValidation Loss: 1.538234\n",
      "Validation loss decreased (1.538363 --> 1.538234).         Saving model ...\n",
      "Epoch: 555 \tTraining Loss: 1.095074 \tValidation Loss: 1.538105\n",
      "Validation loss decreased (1.538234 --> 1.538105).         Saving model ...\n",
      "Epoch: 556 \tTraining Loss: 1.095052 \tValidation Loss: 1.537976\n",
      "Validation loss decreased (1.538105 --> 1.537976).         Saving model ...\n",
      "Epoch: 557 \tTraining Loss: 1.095029 \tValidation Loss: 1.537848\n",
      "Validation loss decreased (1.537976 --> 1.537848).         Saving model ...\n",
      "Epoch: 558 \tTraining Loss: 1.095007 \tValidation Loss: 1.537720\n",
      "Validation loss decreased (1.537848 --> 1.537720).         Saving model ...\n",
      "Epoch: 559 \tTraining Loss: 1.094984 \tValidation Loss: 1.537593\n",
      "Validation loss decreased (1.537720 --> 1.537593).         Saving model ...\n",
      "Epoch: 560 \tTraining Loss: 1.094962 \tValidation Loss: 1.537465\n",
      "Validation loss decreased (1.537593 --> 1.537465).         Saving model ...\n",
      "Epoch: 561 \tTraining Loss: 1.094940 \tValidation Loss: 1.537338\n",
      "Validation loss decreased (1.537465 --> 1.537338).         Saving model ...\n",
      "Epoch: 562 \tTraining Loss: 1.094918 \tValidation Loss: 1.537212\n",
      "Validation loss decreased (1.537338 --> 1.537212).         Saving model ...\n",
      "Epoch: 563 \tTraining Loss: 1.094895 \tValidation Loss: 1.537086\n",
      "Validation loss decreased (1.537212 --> 1.537086).         Saving model ...\n",
      "Epoch: 564 \tTraining Loss: 1.094873 \tValidation Loss: 1.536960\n",
      "Validation loss decreased (1.537086 --> 1.536960).         Saving model ...\n",
      "Epoch: 565 \tTraining Loss: 1.094851 \tValidation Loss: 1.536835\n",
      "Validation loss decreased (1.536960 --> 1.536835).         Saving model ...\n",
      "Epoch: 566 \tTraining Loss: 1.094829 \tValidation Loss: 1.536709\n",
      "Validation loss decreased (1.536835 --> 1.536709).         Saving model ...\n",
      "Epoch: 567 \tTraining Loss: 1.094807 \tValidation Loss: 1.536585\n",
      "Validation loss decreased (1.536709 --> 1.536585).         Saving model ...\n",
      "Epoch: 568 \tTraining Loss: 1.094785 \tValidation Loss: 1.536460\n",
      "Validation loss decreased (1.536585 --> 1.536460).         Saving model ...\n",
      "Epoch: 569 \tTraining Loss: 1.094763 \tValidation Loss: 1.536336\n",
      "Validation loss decreased (1.536460 --> 1.536336).         Saving model ...\n",
      "Epoch: 570 \tTraining Loss: 1.094742 \tValidation Loss: 1.536211\n",
      "Validation loss decreased (1.536336 --> 1.536211).         Saving model ...\n",
      "Epoch: 571 \tTraining Loss: 1.094720 \tValidation Loss: 1.536088\n",
      "Validation loss decreased (1.536211 --> 1.536088).         Saving model ...\n",
      "Epoch: 572 \tTraining Loss: 1.094698 \tValidation Loss: 1.535964\n",
      "Validation loss decreased (1.536088 --> 1.535964).         Saving model ...\n",
      "Epoch: 573 \tTraining Loss: 1.094676 \tValidation Loss: 1.535842\n",
      "Validation loss decreased (1.535964 --> 1.535842).         Saving model ...\n",
      "Epoch: 574 \tTraining Loss: 1.094655 \tValidation Loss: 1.535719\n",
      "Validation loss decreased (1.535842 --> 1.535719).         Saving model ...\n",
      "Epoch: 575 \tTraining Loss: 1.094633 \tValidation Loss: 1.535596\n",
      "Validation loss decreased (1.535719 --> 1.535596).         Saving model ...\n",
      "Epoch: 576 \tTraining Loss: 1.094612 \tValidation Loss: 1.535475\n",
      "Validation loss decreased (1.535596 --> 1.535475).         Saving model ...\n",
      "Epoch: 577 \tTraining Loss: 1.094590 \tValidation Loss: 1.535354\n",
      "Validation loss decreased (1.535475 --> 1.535354).         Saving model ...\n",
      "Epoch: 578 \tTraining Loss: 1.094569 \tValidation Loss: 1.535233\n",
      "Validation loss decreased (1.535354 --> 1.535233).         Saving model ...\n",
      "Epoch: 579 \tTraining Loss: 1.094547 \tValidation Loss: 1.535111\n",
      "Validation loss decreased (1.535233 --> 1.535111).         Saving model ...\n",
      "Epoch: 580 \tTraining Loss: 1.094526 \tValidation Loss: 1.534991\n",
      "Validation loss decreased (1.535111 --> 1.534991).         Saving model ...\n",
      "Epoch: 581 \tTraining Loss: 1.094505 \tValidation Loss: 1.534870\n",
      "Validation loss decreased (1.534991 --> 1.534870).         Saving model ...\n",
      "Epoch: 582 \tTraining Loss: 1.094483 \tValidation Loss: 1.534751\n",
      "Validation loss decreased (1.534870 --> 1.534751).         Saving model ...\n",
      "Epoch: 583 \tTraining Loss: 1.094462 \tValidation Loss: 1.534631\n",
      "Validation loss decreased (1.534751 --> 1.534631).         Saving model ...\n",
      "Epoch: 584 \tTraining Loss: 1.094441 \tValidation Loss: 1.534511\n",
      "Validation loss decreased (1.534631 --> 1.534511).         Saving model ...\n",
      "Epoch: 585 \tTraining Loss: 1.094420 \tValidation Loss: 1.534392\n",
      "Validation loss decreased (1.534511 --> 1.534392).         Saving model ...\n",
      "Epoch: 586 \tTraining Loss: 1.094399 \tValidation Loss: 1.534273\n",
      "Validation loss decreased (1.534392 --> 1.534273).         Saving model ...\n",
      "Epoch: 587 \tTraining Loss: 1.094378 \tValidation Loss: 1.534155\n",
      "Validation loss decreased (1.534273 --> 1.534155).         Saving model ...\n",
      "Epoch: 588 \tTraining Loss: 1.094357 \tValidation Loss: 1.534036\n",
      "Validation loss decreased (1.534155 --> 1.534036).         Saving model ...\n",
      "Epoch: 589 \tTraining Loss: 1.094336 \tValidation Loss: 1.533918\n",
      "Validation loss decreased (1.534036 --> 1.533918).         Saving model ...\n",
      "Epoch: 590 \tTraining Loss: 1.094315 \tValidation Loss: 1.533801\n",
      "Validation loss decreased (1.533918 --> 1.533801).         Saving model ...\n",
      "Epoch: 591 \tTraining Loss: 1.094294 \tValidation Loss: 1.533683\n",
      "Validation loss decreased (1.533801 --> 1.533683).         Saving model ...\n",
      "Epoch: 592 \tTraining Loss: 1.094273 \tValidation Loss: 1.533566\n",
      "Validation loss decreased (1.533683 --> 1.533566).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 593 \tTraining Loss: 1.094252 \tValidation Loss: 1.533449\n",
      "Validation loss decreased (1.533566 --> 1.533449).         Saving model ...\n",
      "Epoch: 594 \tTraining Loss: 1.094232 \tValidation Loss: 1.533332\n",
      "Validation loss decreased (1.533449 --> 1.533332).         Saving model ...\n",
      "Epoch: 595 \tTraining Loss: 1.094211 \tValidation Loss: 1.533216\n",
      "Validation loss decreased (1.533332 --> 1.533216).         Saving model ...\n",
      "Epoch: 596 \tTraining Loss: 1.094190 \tValidation Loss: 1.533101\n",
      "Validation loss decreased (1.533216 --> 1.533101).         Saving model ...\n",
      "Epoch: 597 \tTraining Loss: 1.094170 \tValidation Loss: 1.532985\n",
      "Validation loss decreased (1.533101 --> 1.532985).         Saving model ...\n",
      "Epoch: 598 \tTraining Loss: 1.094149 \tValidation Loss: 1.532870\n",
      "Validation loss decreased (1.532985 --> 1.532870).         Saving model ...\n",
      "Epoch: 599 \tTraining Loss: 1.094129 \tValidation Loss: 1.532754\n",
      "Validation loss decreased (1.532870 --> 1.532754).         Saving model ...\n",
      "Epoch: 600 \tTraining Loss: 1.094108 \tValidation Loss: 1.532640\n",
      "Validation loss decreased (1.532754 --> 1.532640).         Saving model ...\n",
      "Epoch: 601 \tTraining Loss: 1.094088 \tValidation Loss: 1.532526\n",
      "Validation loss decreased (1.532640 --> 1.532526).         Saving model ...\n",
      "Epoch: 602 \tTraining Loss: 1.094068 \tValidation Loss: 1.532411\n",
      "Validation loss decreased (1.532526 --> 1.532411).         Saving model ...\n",
      "Epoch: 603 \tTraining Loss: 1.094047 \tValidation Loss: 1.532298\n",
      "Validation loss decreased (1.532411 --> 1.532298).         Saving model ...\n",
      "Epoch: 604 \tTraining Loss: 1.094027 \tValidation Loss: 1.532184\n",
      "Validation loss decreased (1.532298 --> 1.532184).         Saving model ...\n",
      "Epoch: 605 \tTraining Loss: 1.094007 \tValidation Loss: 1.532071\n",
      "Validation loss decreased (1.532184 --> 1.532071).         Saving model ...\n",
      "Epoch: 606 \tTraining Loss: 1.093987 \tValidation Loss: 1.531958\n",
      "Validation loss decreased (1.532071 --> 1.531958).         Saving model ...\n",
      "Epoch: 607 \tTraining Loss: 1.093966 \tValidation Loss: 1.531845\n",
      "Validation loss decreased (1.531958 --> 1.531845).         Saving model ...\n",
      "Epoch: 608 \tTraining Loss: 1.093946 \tValidation Loss: 1.531733\n",
      "Validation loss decreased (1.531845 --> 1.531733).         Saving model ...\n",
      "Epoch: 609 \tTraining Loss: 1.093926 \tValidation Loss: 1.531620\n",
      "Validation loss decreased (1.531733 --> 1.531620).         Saving model ...\n",
      "Epoch: 610 \tTraining Loss: 1.093906 \tValidation Loss: 1.531509\n",
      "Validation loss decreased (1.531620 --> 1.531509).         Saving model ...\n",
      "Epoch: 611 \tTraining Loss: 1.093886 \tValidation Loss: 1.531397\n",
      "Validation loss decreased (1.531509 --> 1.531397).         Saving model ...\n",
      "Epoch: 612 \tTraining Loss: 1.093866 \tValidation Loss: 1.531286\n",
      "Validation loss decreased (1.531397 --> 1.531286).         Saving model ...\n",
      "Epoch: 613 \tTraining Loss: 1.093846 \tValidation Loss: 1.531175\n",
      "Validation loss decreased (1.531286 --> 1.531175).         Saving model ...\n",
      "Epoch: 614 \tTraining Loss: 1.093827 \tValidation Loss: 1.531064\n",
      "Validation loss decreased (1.531175 --> 1.531064).         Saving model ...\n",
      "Epoch: 615 \tTraining Loss: 1.093807 \tValidation Loss: 1.530953\n",
      "Validation loss decreased (1.531064 --> 1.530953).         Saving model ...\n",
      "Epoch: 616 \tTraining Loss: 1.093787 \tValidation Loss: 1.530843\n",
      "Validation loss decreased (1.530953 --> 1.530843).         Saving model ...\n",
      "Epoch: 617 \tTraining Loss: 1.093767 \tValidation Loss: 1.530733\n",
      "Validation loss decreased (1.530843 --> 1.530733).         Saving model ...\n",
      "Epoch: 618 \tTraining Loss: 1.093748 \tValidation Loss: 1.530622\n",
      "Validation loss decreased (1.530733 --> 1.530622).         Saving model ...\n",
      "Epoch: 619 \tTraining Loss: 1.093728 \tValidation Loss: 1.530512\n",
      "Validation loss decreased (1.530622 --> 1.530512).         Saving model ...\n",
      "Epoch: 620 \tTraining Loss: 1.093708 \tValidation Loss: 1.530403\n",
      "Validation loss decreased (1.530512 --> 1.530403).         Saving model ...\n",
      "Epoch: 621 \tTraining Loss: 1.093689 \tValidation Loss: 1.530294\n",
      "Validation loss decreased (1.530403 --> 1.530294).         Saving model ...\n",
      "Epoch: 622 \tTraining Loss: 1.093669 \tValidation Loss: 1.530185\n",
      "Validation loss decreased (1.530294 --> 1.530185).         Saving model ...\n",
      "Epoch: 623 \tTraining Loss: 1.093650 \tValidation Loss: 1.530077\n",
      "Validation loss decreased (1.530185 --> 1.530077).         Saving model ...\n",
      "Epoch: 624 \tTraining Loss: 1.093630 \tValidation Loss: 1.529969\n",
      "Validation loss decreased (1.530077 --> 1.529969).         Saving model ...\n",
      "Epoch: 625 \tTraining Loss: 1.093611 \tValidation Loss: 1.529861\n",
      "Validation loss decreased (1.529969 --> 1.529861).         Saving model ...\n",
      "Epoch: 626 \tTraining Loss: 1.093591 \tValidation Loss: 1.529754\n",
      "Validation loss decreased (1.529861 --> 1.529754).         Saving model ...\n",
      "Epoch: 627 \tTraining Loss: 1.093572 \tValidation Loss: 1.529646\n",
      "Validation loss decreased (1.529754 --> 1.529646).         Saving model ...\n",
      "Epoch: 628 \tTraining Loss: 1.093553 \tValidation Loss: 1.529540\n",
      "Validation loss decreased (1.529646 --> 1.529540).         Saving model ...\n",
      "Epoch: 629 \tTraining Loss: 1.093534 \tValidation Loss: 1.529433\n",
      "Validation loss decreased (1.529540 --> 1.529433).         Saving model ...\n",
      "Epoch: 630 \tTraining Loss: 1.093514 \tValidation Loss: 1.529326\n",
      "Validation loss decreased (1.529433 --> 1.529326).         Saving model ...\n",
      "Epoch: 631 \tTraining Loss: 1.093495 \tValidation Loss: 1.529221\n",
      "Validation loss decreased (1.529326 --> 1.529221).         Saving model ...\n",
      "Epoch: 632 \tTraining Loss: 1.093476 \tValidation Loss: 1.529115\n",
      "Validation loss decreased (1.529221 --> 1.529115).         Saving model ...\n",
      "Epoch: 633 \tTraining Loss: 1.093457 \tValidation Loss: 1.529010\n",
      "Validation loss decreased (1.529115 --> 1.529010).         Saving model ...\n",
      "Epoch: 634 \tTraining Loss: 1.093438 \tValidation Loss: 1.528905\n",
      "Validation loss decreased (1.529010 --> 1.528905).         Saving model ...\n",
      "Epoch: 635 \tTraining Loss: 1.093419 \tValidation Loss: 1.528800\n",
      "Validation loss decreased (1.528905 --> 1.528800).         Saving model ...\n",
      "Epoch: 636 \tTraining Loss: 1.093400 \tValidation Loss: 1.528696\n",
      "Validation loss decreased (1.528800 --> 1.528696).         Saving model ...\n",
      "Epoch: 637 \tTraining Loss: 1.093381 \tValidation Loss: 1.528592\n",
      "Validation loss decreased (1.528696 --> 1.528592).         Saving model ...\n",
      "Epoch: 638 \tTraining Loss: 1.093362 \tValidation Loss: 1.528487\n",
      "Validation loss decreased (1.528592 --> 1.528487).         Saving model ...\n",
      "Epoch: 639 \tTraining Loss: 1.093343 \tValidation Loss: 1.528383\n",
      "Validation loss decreased (1.528487 --> 1.528383).         Saving model ...\n",
      "Epoch: 640 \tTraining Loss: 1.093324 \tValidation Loss: 1.528280\n",
      "Validation loss decreased (1.528383 --> 1.528280).         Saving model ...\n",
      "Epoch: 641 \tTraining Loss: 1.093306 \tValidation Loss: 1.528177\n",
      "Validation loss decreased (1.528280 --> 1.528177).         Saving model ...\n",
      "Epoch: 642 \tTraining Loss: 1.093287 \tValidation Loss: 1.528074\n",
      "Validation loss decreased (1.528177 --> 1.528074).         Saving model ...\n",
      "Epoch: 643 \tTraining Loss: 1.093268 \tValidation Loss: 1.527971\n",
      "Validation loss decreased (1.528074 --> 1.527971).         Saving model ...\n",
      "Epoch: 644 \tTraining Loss: 1.093249 \tValidation Loss: 1.527868\n",
      "Validation loss decreased (1.527971 --> 1.527868).         Saving model ...\n",
      "Epoch: 645 \tTraining Loss: 1.093231 \tValidation Loss: 1.527766\n",
      "Validation loss decreased (1.527868 --> 1.527766).         Saving model ...\n",
      "Epoch: 646 \tTraining Loss: 1.093212 \tValidation Loss: 1.527664\n",
      "Validation loss decreased (1.527766 --> 1.527664).         Saving model ...\n",
      "Epoch: 647 \tTraining Loss: 1.093194 \tValidation Loss: 1.527562\n",
      "Validation loss decreased (1.527664 --> 1.527562).         Saving model ...\n",
      "Epoch: 648 \tTraining Loss: 1.093175 \tValidation Loss: 1.527460\n",
      "Validation loss decreased (1.527562 --> 1.527460).         Saving model ...\n",
      "Epoch: 649 \tTraining Loss: 1.093157 \tValidation Loss: 1.527359\n",
      "Validation loss decreased (1.527460 --> 1.527359).         Saving model ...\n",
      "Epoch: 650 \tTraining Loss: 1.093138 \tValidation Loss: 1.527258\n",
      "Validation loss decreased (1.527359 --> 1.527258).         Saving model ...\n",
      "Epoch: 651 \tTraining Loss: 1.093120 \tValidation Loss: 1.527157\n",
      "Validation loss decreased (1.527258 --> 1.527157).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 652 \tTraining Loss: 1.093101 \tValidation Loss: 1.527057\n",
      "Validation loss decreased (1.527157 --> 1.527057).         Saving model ...\n",
      "Epoch: 653 \tTraining Loss: 1.093083 \tValidation Loss: 1.526956\n",
      "Validation loss decreased (1.527057 --> 1.526956).         Saving model ...\n",
      "Epoch: 654 \tTraining Loss: 1.093065 \tValidation Loss: 1.526857\n",
      "Validation loss decreased (1.526956 --> 1.526857).         Saving model ...\n",
      "Epoch: 655 \tTraining Loss: 1.093046 \tValidation Loss: 1.526756\n",
      "Validation loss decreased (1.526857 --> 1.526756).         Saving model ...\n",
      "Epoch: 656 \tTraining Loss: 1.093028 \tValidation Loss: 1.526658\n",
      "Validation loss decreased (1.526756 --> 1.526658).         Saving model ...\n",
      "Epoch: 657 \tTraining Loss: 1.093010 \tValidation Loss: 1.526558\n",
      "Validation loss decreased (1.526658 --> 1.526558).         Saving model ...\n",
      "Epoch: 658 \tTraining Loss: 1.092992 \tValidation Loss: 1.526459\n",
      "Validation loss decreased (1.526558 --> 1.526459).         Saving model ...\n",
      "Epoch: 659 \tTraining Loss: 1.092974 \tValidation Loss: 1.526361\n",
      "Validation loss decreased (1.526459 --> 1.526361).         Saving model ...\n",
      "Epoch: 660 \tTraining Loss: 1.092956 \tValidation Loss: 1.526262\n",
      "Validation loss decreased (1.526361 --> 1.526262).         Saving model ...\n",
      "Epoch: 661 \tTraining Loss: 1.092938 \tValidation Loss: 1.526164\n",
      "Validation loss decreased (1.526262 --> 1.526164).         Saving model ...\n",
      "Epoch: 662 \tTraining Loss: 1.092919 \tValidation Loss: 1.526065\n",
      "Validation loss decreased (1.526164 --> 1.526065).         Saving model ...\n",
      "Epoch: 663 \tTraining Loss: 1.092902 \tValidation Loss: 1.525968\n",
      "Validation loss decreased (1.526065 --> 1.525968).         Saving model ...\n",
      "Epoch: 664 \tTraining Loss: 1.092884 \tValidation Loss: 1.525870\n",
      "Validation loss decreased (1.525968 --> 1.525870).         Saving model ...\n",
      "Epoch: 665 \tTraining Loss: 1.092866 \tValidation Loss: 1.525772\n",
      "Validation loss decreased (1.525870 --> 1.525772).         Saving model ...\n",
      "Epoch: 666 \tTraining Loss: 1.092848 \tValidation Loss: 1.525676\n",
      "Validation loss decreased (1.525772 --> 1.525676).         Saving model ...\n",
      "Epoch: 667 \tTraining Loss: 1.092830 \tValidation Loss: 1.525578\n",
      "Validation loss decreased (1.525676 --> 1.525578).         Saving model ...\n",
      "Epoch: 668 \tTraining Loss: 1.092812 \tValidation Loss: 1.525482\n",
      "Validation loss decreased (1.525578 --> 1.525482).         Saving model ...\n",
      "Epoch: 669 \tTraining Loss: 1.092794 \tValidation Loss: 1.525385\n",
      "Validation loss decreased (1.525482 --> 1.525385).         Saving model ...\n",
      "Epoch: 670 \tTraining Loss: 1.092777 \tValidation Loss: 1.525289\n",
      "Validation loss decreased (1.525385 --> 1.525289).         Saving model ...\n",
      "Epoch: 671 \tTraining Loss: 1.092759 \tValidation Loss: 1.525192\n",
      "Validation loss decreased (1.525289 --> 1.525192).         Saving model ...\n",
      "Epoch: 672 \tTraining Loss: 1.092741 \tValidation Loss: 1.525096\n",
      "Validation loss decreased (1.525192 --> 1.525096).         Saving model ...\n",
      "Epoch: 673 \tTraining Loss: 1.092723 \tValidation Loss: 1.525001\n",
      "Validation loss decreased (1.525096 --> 1.525001).         Saving model ...\n",
      "Epoch: 674 \tTraining Loss: 1.092706 \tValidation Loss: 1.524905\n",
      "Validation loss decreased (1.525001 --> 1.524905).         Saving model ...\n",
      "Epoch: 675 \tTraining Loss: 1.092688 \tValidation Loss: 1.524810\n",
      "Validation loss decreased (1.524905 --> 1.524810).         Saving model ...\n",
      "Epoch: 676 \tTraining Loss: 1.092671 \tValidation Loss: 1.524715\n",
      "Validation loss decreased (1.524810 --> 1.524715).         Saving model ...\n",
      "Epoch: 677 \tTraining Loss: 1.092653 \tValidation Loss: 1.524621\n",
      "Validation loss decreased (1.524715 --> 1.524621).         Saving model ...\n",
      "Epoch: 678 \tTraining Loss: 1.092636 \tValidation Loss: 1.524526\n",
      "Validation loss decreased (1.524621 --> 1.524526).         Saving model ...\n",
      "Epoch: 679 \tTraining Loss: 1.092618 \tValidation Loss: 1.524432\n",
      "Validation loss decreased (1.524526 --> 1.524432).         Saving model ...\n",
      "Epoch: 680 \tTraining Loss: 1.092601 \tValidation Loss: 1.524339\n",
      "Validation loss decreased (1.524432 --> 1.524339).         Saving model ...\n",
      "Epoch: 681 \tTraining Loss: 1.092583 \tValidation Loss: 1.524246\n",
      "Validation loss decreased (1.524339 --> 1.524246).         Saving model ...\n",
      "Epoch: 682 \tTraining Loss: 1.092566 \tValidation Loss: 1.524152\n",
      "Validation loss decreased (1.524246 --> 1.524152).         Saving model ...\n",
      "Epoch: 683 \tTraining Loss: 1.092549 \tValidation Loss: 1.524059\n",
      "Validation loss decreased (1.524152 --> 1.524059).         Saving model ...\n",
      "Epoch: 684 \tTraining Loss: 1.092531 \tValidation Loss: 1.523966\n",
      "Validation loss decreased (1.524059 --> 1.523966).         Saving model ...\n",
      "Epoch: 685 \tTraining Loss: 1.092514 \tValidation Loss: 1.523874\n",
      "Validation loss decreased (1.523966 --> 1.523874).         Saving model ...\n",
      "Epoch: 686 \tTraining Loss: 1.092497 \tValidation Loss: 1.523781\n",
      "Validation loss decreased (1.523874 --> 1.523781).         Saving model ...\n",
      "Epoch: 687 \tTraining Loss: 1.092480 \tValidation Loss: 1.523689\n",
      "Validation loss decreased (1.523781 --> 1.523689).         Saving model ...\n",
      "Epoch: 688 \tTraining Loss: 1.092463 \tValidation Loss: 1.523598\n",
      "Validation loss decreased (1.523689 --> 1.523598).         Saving model ...\n",
      "Epoch: 689 \tTraining Loss: 1.092446 \tValidation Loss: 1.523505\n",
      "Validation loss decreased (1.523598 --> 1.523505).         Saving model ...\n",
      "Epoch: 690 \tTraining Loss: 1.092428 \tValidation Loss: 1.523413\n",
      "Validation loss decreased (1.523505 --> 1.523413).         Saving model ...\n",
      "Epoch: 691 \tTraining Loss: 1.092411 \tValidation Loss: 1.523322\n",
      "Validation loss decreased (1.523413 --> 1.523322).         Saving model ...\n",
      "Epoch: 692 \tTraining Loss: 1.092394 \tValidation Loss: 1.523231\n",
      "Validation loss decreased (1.523322 --> 1.523231).         Saving model ...\n",
      "Epoch: 693 \tTraining Loss: 1.092377 \tValidation Loss: 1.523139\n",
      "Validation loss decreased (1.523231 --> 1.523139).         Saving model ...\n",
      "Epoch: 694 \tTraining Loss: 1.092360 \tValidation Loss: 1.523048\n",
      "Validation loss decreased (1.523139 --> 1.523048).         Saving model ...\n",
      "Epoch: 695 \tTraining Loss: 1.092343 \tValidation Loss: 1.522958\n",
      "Validation loss decreased (1.523048 --> 1.522958).         Saving model ...\n",
      "Epoch: 696 \tTraining Loss: 1.092327 \tValidation Loss: 1.522867\n",
      "Validation loss decreased (1.522958 --> 1.522867).         Saving model ...\n",
      "Epoch: 697 \tTraining Loss: 1.092310 \tValidation Loss: 1.522777\n",
      "Validation loss decreased (1.522867 --> 1.522777).         Saving model ...\n",
      "Epoch: 698 \tTraining Loss: 1.092293 \tValidation Loss: 1.522686\n",
      "Validation loss decreased (1.522777 --> 1.522686).         Saving model ...\n",
      "Epoch: 699 \tTraining Loss: 1.092276 \tValidation Loss: 1.522596\n",
      "Validation loss decreased (1.522686 --> 1.522596).         Saving model ...\n",
      "Epoch: 700 \tTraining Loss: 1.092259 \tValidation Loss: 1.522508\n",
      "Validation loss decreased (1.522596 --> 1.522508).         Saving model ...\n",
      "Epoch: 701 \tTraining Loss: 1.092242 \tValidation Loss: 1.522418\n",
      "Validation loss decreased (1.522508 --> 1.522418).         Saving model ...\n",
      "Epoch: 702 \tTraining Loss: 1.092226 \tValidation Loss: 1.522328\n",
      "Validation loss decreased (1.522418 --> 1.522328).         Saving model ...\n",
      "Epoch: 703 \tTraining Loss: 1.092209 \tValidation Loss: 1.522240\n",
      "Validation loss decreased (1.522328 --> 1.522240).         Saving model ...\n",
      "Epoch: 704 \tTraining Loss: 1.092192 \tValidation Loss: 1.522152\n",
      "Validation loss decreased (1.522240 --> 1.522152).         Saving model ...\n",
      "Epoch: 705 \tTraining Loss: 1.092176 \tValidation Loss: 1.522063\n",
      "Validation loss decreased (1.522152 --> 1.522063).         Saving model ...\n",
      "Epoch: 706 \tTraining Loss: 1.092159 \tValidation Loss: 1.521974\n",
      "Validation loss decreased (1.522063 --> 1.521974).         Saving model ...\n",
      "Epoch: 707 \tTraining Loss: 1.092143 \tValidation Loss: 1.521887\n",
      "Validation loss decreased (1.521974 --> 1.521887).         Saving model ...\n",
      "Epoch: 708 \tTraining Loss: 1.092126 \tValidation Loss: 1.521798\n",
      "Validation loss decreased (1.521887 --> 1.521798).         Saving model ...\n",
      "Epoch: 709 \tTraining Loss: 1.092110 \tValidation Loss: 1.521711\n",
      "Validation loss decreased (1.521798 --> 1.521711).         Saving model ...\n",
      "Epoch: 710 \tTraining Loss: 1.092093 \tValidation Loss: 1.521623\n",
      "Validation loss decreased (1.521711 --> 1.521623).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 711 \tTraining Loss: 1.092077 \tValidation Loss: 1.521536\n",
      "Validation loss decreased (1.521623 --> 1.521536).         Saving model ...\n",
      "Epoch: 712 \tTraining Loss: 1.092060 \tValidation Loss: 1.521449\n",
      "Validation loss decreased (1.521536 --> 1.521449).         Saving model ...\n",
      "Epoch: 713 \tTraining Loss: 1.092044 \tValidation Loss: 1.521362\n",
      "Validation loss decreased (1.521449 --> 1.521362).         Saving model ...\n",
      "Epoch: 714 \tTraining Loss: 1.092028 \tValidation Loss: 1.521275\n",
      "Validation loss decreased (1.521362 --> 1.521275).         Saving model ...\n",
      "Epoch: 715 \tTraining Loss: 1.092011 \tValidation Loss: 1.521189\n",
      "Validation loss decreased (1.521275 --> 1.521189).         Saving model ...\n",
      "Epoch: 716 \tTraining Loss: 1.091995 \tValidation Loss: 1.521103\n",
      "Validation loss decreased (1.521189 --> 1.521103).         Saving model ...\n",
      "Epoch: 717 \tTraining Loss: 1.091979 \tValidation Loss: 1.521017\n",
      "Validation loss decreased (1.521103 --> 1.521017).         Saving model ...\n",
      "Epoch: 718 \tTraining Loss: 1.091962 \tValidation Loss: 1.520931\n",
      "Validation loss decreased (1.521017 --> 1.520931).         Saving model ...\n",
      "Epoch: 719 \tTraining Loss: 1.091946 \tValidation Loss: 1.520845\n",
      "Validation loss decreased (1.520931 --> 1.520845).         Saving model ...\n",
      "Epoch: 720 \tTraining Loss: 1.091930 \tValidation Loss: 1.520760\n",
      "Validation loss decreased (1.520845 --> 1.520760).         Saving model ...\n",
      "Epoch: 721 \tTraining Loss: 1.091914 \tValidation Loss: 1.520675\n",
      "Validation loss decreased (1.520760 --> 1.520675).         Saving model ...\n",
      "Epoch: 722 \tTraining Loss: 1.091898 \tValidation Loss: 1.520591\n",
      "Validation loss decreased (1.520675 --> 1.520591).         Saving model ...\n",
      "Epoch: 723 \tTraining Loss: 1.091882 \tValidation Loss: 1.520506\n",
      "Validation loss decreased (1.520591 --> 1.520506).         Saving model ...\n",
      "Epoch: 724 \tTraining Loss: 1.091866 \tValidation Loss: 1.520422\n",
      "Validation loss decreased (1.520506 --> 1.520422).         Saving model ...\n",
      "Epoch: 725 \tTraining Loss: 1.091850 \tValidation Loss: 1.520339\n",
      "Validation loss decreased (1.520422 --> 1.520339).         Saving model ...\n",
      "Epoch: 726 \tTraining Loss: 1.091834 \tValidation Loss: 1.520254\n",
      "Validation loss decreased (1.520339 --> 1.520254).         Saving model ...\n",
      "Epoch: 727 \tTraining Loss: 1.091818 \tValidation Loss: 1.520170\n",
      "Validation loss decreased (1.520254 --> 1.520170).         Saving model ...\n",
      "Epoch: 728 \tTraining Loss: 1.091802 \tValidation Loss: 1.520086\n",
      "Validation loss decreased (1.520170 --> 1.520086).         Saving model ...\n",
      "Epoch: 729 \tTraining Loss: 1.091786 \tValidation Loss: 1.520003\n",
      "Validation loss decreased (1.520086 --> 1.520003).         Saving model ...\n",
      "Epoch: 730 \tTraining Loss: 1.091770 \tValidation Loss: 1.519919\n",
      "Validation loss decreased (1.520003 --> 1.519919).         Saving model ...\n",
      "Epoch: 731 \tTraining Loss: 1.091754 \tValidation Loss: 1.519835\n",
      "Validation loss decreased (1.519919 --> 1.519835).         Saving model ...\n",
      "Epoch: 732 \tTraining Loss: 1.091738 \tValidation Loss: 1.519752\n",
      "Validation loss decreased (1.519835 --> 1.519752).         Saving model ...\n",
      "Epoch: 733 \tTraining Loss: 1.091722 \tValidation Loss: 1.519670\n",
      "Validation loss decreased (1.519752 --> 1.519670).         Saving model ...\n",
      "Epoch: 734 \tTraining Loss: 1.091707 \tValidation Loss: 1.519587\n",
      "Validation loss decreased (1.519670 --> 1.519587).         Saving model ...\n",
      "Epoch: 735 \tTraining Loss: 1.091691 \tValidation Loss: 1.519504\n",
      "Validation loss decreased (1.519587 --> 1.519504).         Saving model ...\n",
      "Epoch: 736 \tTraining Loss: 1.091675 \tValidation Loss: 1.519422\n",
      "Validation loss decreased (1.519504 --> 1.519422).         Saving model ...\n",
      "Epoch: 737 \tTraining Loss: 1.091659 \tValidation Loss: 1.519341\n",
      "Validation loss decreased (1.519422 --> 1.519341).         Saving model ...\n",
      "Epoch: 738 \tTraining Loss: 1.091644 \tValidation Loss: 1.519259\n",
      "Validation loss decreased (1.519341 --> 1.519259).         Saving model ...\n",
      "Epoch: 739 \tTraining Loss: 1.091628 \tValidation Loss: 1.519177\n",
      "Validation loss decreased (1.519259 --> 1.519177).         Saving model ...\n",
      "Epoch: 740 \tTraining Loss: 1.091612 \tValidation Loss: 1.519096\n",
      "Validation loss decreased (1.519177 --> 1.519096).         Saving model ...\n",
      "Epoch: 741 \tTraining Loss: 1.091597 \tValidation Loss: 1.519015\n",
      "Validation loss decreased (1.519096 --> 1.519015).         Saving model ...\n",
      "Epoch: 742 \tTraining Loss: 1.091581 \tValidation Loss: 1.518933\n",
      "Validation loss decreased (1.519015 --> 1.518933).         Saving model ...\n",
      "Epoch: 743 \tTraining Loss: 1.091566 \tValidation Loss: 1.518853\n",
      "Validation loss decreased (1.518933 --> 1.518853).         Saving model ...\n",
      "Epoch: 744 \tTraining Loss: 1.091550 \tValidation Loss: 1.518772\n",
      "Validation loss decreased (1.518853 --> 1.518772).         Saving model ...\n",
      "Epoch: 745 \tTraining Loss: 1.091535 \tValidation Loss: 1.518692\n",
      "Validation loss decreased (1.518772 --> 1.518692).         Saving model ...\n",
      "Epoch: 746 \tTraining Loss: 1.091519 \tValidation Loss: 1.518611\n",
      "Validation loss decreased (1.518692 --> 1.518611).         Saving model ...\n",
      "Epoch: 747 \tTraining Loss: 1.091504 \tValidation Loss: 1.518531\n",
      "Validation loss decreased (1.518611 --> 1.518531).         Saving model ...\n",
      "Epoch: 748 \tTraining Loss: 1.091488 \tValidation Loss: 1.518451\n",
      "Validation loss decreased (1.518531 --> 1.518451).         Saving model ...\n",
      "Epoch: 749 \tTraining Loss: 1.091473 \tValidation Loss: 1.518371\n",
      "Validation loss decreased (1.518451 --> 1.518371).         Saving model ...\n",
      "Epoch: 750 \tTraining Loss: 1.091458 \tValidation Loss: 1.518293\n",
      "Validation loss decreased (1.518371 --> 1.518293).         Saving model ...\n",
      "Epoch: 751 \tTraining Loss: 1.091442 \tValidation Loss: 1.518213\n",
      "Validation loss decreased (1.518293 --> 1.518213).         Saving model ...\n",
      "Epoch: 752 \tTraining Loss: 1.091427 \tValidation Loss: 1.518133\n",
      "Validation loss decreased (1.518213 --> 1.518133).         Saving model ...\n",
      "Epoch: 753 \tTraining Loss: 1.091412 \tValidation Loss: 1.518055\n",
      "Validation loss decreased (1.518133 --> 1.518055).         Saving model ...\n",
      "Epoch: 754 \tTraining Loss: 1.091397 \tValidation Loss: 1.517976\n",
      "Validation loss decreased (1.518055 --> 1.517976).         Saving model ...\n",
      "Epoch: 755 \tTraining Loss: 1.091381 \tValidation Loss: 1.517897\n",
      "Validation loss decreased (1.517976 --> 1.517897).         Saving model ...\n",
      "Epoch: 756 \tTraining Loss: 1.091366 \tValidation Loss: 1.517819\n",
      "Validation loss decreased (1.517897 --> 1.517819).         Saving model ...\n",
      "Epoch: 757 \tTraining Loss: 1.091351 \tValidation Loss: 1.517741\n",
      "Validation loss decreased (1.517819 --> 1.517741).         Saving model ...\n",
      "Epoch: 758 \tTraining Loss: 1.091336 \tValidation Loss: 1.517662\n",
      "Validation loss decreased (1.517741 --> 1.517662).         Saving model ...\n",
      "Epoch: 759 \tTraining Loss: 1.091321 \tValidation Loss: 1.517585\n",
      "Validation loss decreased (1.517662 --> 1.517585).         Saving model ...\n",
      "Epoch: 760 \tTraining Loss: 1.091306 \tValidation Loss: 1.517507\n",
      "Validation loss decreased (1.517585 --> 1.517507).         Saving model ...\n",
      "Epoch: 761 \tTraining Loss: 1.091291 \tValidation Loss: 1.517429\n",
      "Validation loss decreased (1.517507 --> 1.517429).         Saving model ...\n",
      "Epoch: 762 \tTraining Loss: 1.091276 \tValidation Loss: 1.517351\n",
      "Validation loss decreased (1.517429 --> 1.517351).         Saving model ...\n",
      "Epoch: 763 \tTraining Loss: 1.091261 \tValidation Loss: 1.517274\n",
      "Validation loss decreased (1.517351 --> 1.517274).         Saving model ...\n",
      "Epoch: 764 \tTraining Loss: 1.091246 \tValidation Loss: 1.517197\n",
      "Validation loss decreased (1.517274 --> 1.517197).         Saving model ...\n",
      "Epoch: 765 \tTraining Loss: 1.091231 \tValidation Loss: 1.517119\n",
      "Validation loss decreased (1.517197 --> 1.517119).         Saving model ...\n",
      "Epoch: 766 \tTraining Loss: 1.091216 \tValidation Loss: 1.517043\n",
      "Validation loss decreased (1.517119 --> 1.517043).         Saving model ...\n",
      "Epoch: 767 \tTraining Loss: 1.091201 \tValidation Loss: 1.516965\n",
      "Validation loss decreased (1.517043 --> 1.516965).         Saving model ...\n",
      "Epoch: 768 \tTraining Loss: 1.091186 \tValidation Loss: 1.516889\n",
      "Validation loss decreased (1.516965 --> 1.516889).         Saving model ...\n",
      "Epoch: 769 \tTraining Loss: 1.091171 \tValidation Loss: 1.516813\n",
      "Validation loss decreased (1.516889 --> 1.516813).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 770 \tTraining Loss: 1.091156 \tValidation Loss: 1.516737\n",
      "Validation loss decreased (1.516813 --> 1.516737).         Saving model ...\n",
      "Epoch: 771 \tTraining Loss: 1.091141 \tValidation Loss: 1.516661\n",
      "Validation loss decreased (1.516737 --> 1.516661).         Saving model ...\n",
      "Epoch: 772 \tTraining Loss: 1.091127 \tValidation Loss: 1.516586\n",
      "Validation loss decreased (1.516661 --> 1.516586).         Saving model ...\n",
      "Epoch: 773 \tTraining Loss: 1.091112 \tValidation Loss: 1.516511\n",
      "Validation loss decreased (1.516586 --> 1.516511).         Saving model ...\n",
      "Epoch: 774 \tTraining Loss: 1.091097 \tValidation Loss: 1.516436\n",
      "Validation loss decreased (1.516511 --> 1.516436).         Saving model ...\n",
      "Epoch: 775 \tTraining Loss: 1.091082 \tValidation Loss: 1.516360\n",
      "Validation loss decreased (1.516436 --> 1.516360).         Saving model ...\n",
      "Epoch: 776 \tTraining Loss: 1.091068 \tValidation Loss: 1.516286\n",
      "Validation loss decreased (1.516360 --> 1.516286).         Saving model ...\n",
      "Epoch: 777 \tTraining Loss: 1.091053 \tValidation Loss: 1.516211\n",
      "Validation loss decreased (1.516286 --> 1.516211).         Saving model ...\n",
      "Epoch: 778 \tTraining Loss: 1.091038 \tValidation Loss: 1.516136\n",
      "Validation loss decreased (1.516211 --> 1.516136).         Saving model ...\n",
      "Epoch: 779 \tTraining Loss: 1.091024 \tValidation Loss: 1.516061\n",
      "Validation loss decreased (1.516136 --> 1.516061).         Saving model ...\n",
      "Epoch: 780 \tTraining Loss: 1.091009 \tValidation Loss: 1.515987\n",
      "Validation loss decreased (1.516061 --> 1.515987).         Saving model ...\n",
      "Epoch: 781 \tTraining Loss: 1.090995 \tValidation Loss: 1.515914\n",
      "Validation loss decreased (1.515987 --> 1.515914).         Saving model ...\n",
      "Epoch: 782 \tTraining Loss: 1.090980 \tValidation Loss: 1.515840\n",
      "Validation loss decreased (1.515914 --> 1.515840).         Saving model ...\n",
      "Epoch: 783 \tTraining Loss: 1.090966 \tValidation Loss: 1.515766\n",
      "Validation loss decreased (1.515840 --> 1.515766).         Saving model ...\n",
      "Epoch: 784 \tTraining Loss: 1.090951 \tValidation Loss: 1.515693\n",
      "Validation loss decreased (1.515766 --> 1.515693).         Saving model ...\n",
      "Epoch: 785 \tTraining Loss: 1.090937 \tValidation Loss: 1.515619\n",
      "Validation loss decreased (1.515693 --> 1.515619).         Saving model ...\n",
      "Epoch: 786 \tTraining Loss: 1.090922 \tValidation Loss: 1.515546\n",
      "Validation loss decreased (1.515619 --> 1.515546).         Saving model ...\n",
      "Epoch: 787 \tTraining Loss: 1.090908 \tValidation Loss: 1.515474\n",
      "Validation loss decreased (1.515546 --> 1.515474).         Saving model ...\n",
      "Epoch: 788 \tTraining Loss: 1.090893 \tValidation Loss: 1.515401\n",
      "Validation loss decreased (1.515474 --> 1.515401).         Saving model ...\n",
      "Epoch: 789 \tTraining Loss: 1.090879 \tValidation Loss: 1.515328\n",
      "Validation loss decreased (1.515401 --> 1.515328).         Saving model ...\n",
      "Epoch: 790 \tTraining Loss: 1.090865 \tValidation Loss: 1.515257\n",
      "Validation loss decreased (1.515328 --> 1.515257).         Saving model ...\n",
      "Epoch: 791 \tTraining Loss: 1.090850 \tValidation Loss: 1.515184\n",
      "Validation loss decreased (1.515257 --> 1.515184).         Saving model ...\n",
      "Epoch: 792 \tTraining Loss: 1.090836 \tValidation Loss: 1.515112\n",
      "Validation loss decreased (1.515184 --> 1.515112).         Saving model ...\n",
      "Epoch: 793 \tTraining Loss: 1.090822 \tValidation Loss: 1.515040\n",
      "Validation loss decreased (1.515112 --> 1.515040).         Saving model ...\n",
      "Epoch: 794 \tTraining Loss: 1.090807 \tValidation Loss: 1.514969\n",
      "Validation loss decreased (1.515040 --> 1.514969).         Saving model ...\n",
      "Epoch: 795 \tTraining Loss: 1.090793 \tValidation Loss: 1.514898\n",
      "Validation loss decreased (1.514969 --> 1.514898).         Saving model ...\n",
      "Epoch: 796 \tTraining Loss: 1.090779 \tValidation Loss: 1.514826\n",
      "Validation loss decreased (1.514898 --> 1.514826).         Saving model ...\n",
      "Epoch: 797 \tTraining Loss: 1.090765 \tValidation Loss: 1.514754\n",
      "Validation loss decreased (1.514826 --> 1.514754).         Saving model ...\n",
      "Epoch: 798 \tTraining Loss: 1.090751 \tValidation Loss: 1.514683\n",
      "Validation loss decreased (1.514754 --> 1.514683).         Saving model ...\n",
      "Epoch: 799 \tTraining Loss: 1.090737 \tValidation Loss: 1.514612\n",
      "Validation loss decreased (1.514683 --> 1.514612).         Saving model ...\n",
      "Epoch: 800 \tTraining Loss: 1.090722 \tValidation Loss: 1.514542\n",
      "Validation loss decreased (1.514612 --> 1.514542).         Saving model ...\n",
      "Epoch: 801 \tTraining Loss: 1.090708 \tValidation Loss: 1.514472\n",
      "Validation loss decreased (1.514542 --> 1.514472).         Saving model ...\n",
      "Epoch: 802 \tTraining Loss: 1.090694 \tValidation Loss: 1.514402\n",
      "Validation loss decreased (1.514472 --> 1.514402).         Saving model ...\n",
      "Epoch: 803 \tTraining Loss: 1.090680 \tValidation Loss: 1.514330\n",
      "Validation loss decreased (1.514402 --> 1.514330).         Saving model ...\n",
      "Epoch: 804 \tTraining Loss: 1.090666 \tValidation Loss: 1.514259\n",
      "Validation loss decreased (1.514330 --> 1.514259).         Saving model ...\n",
      "Epoch: 805 \tTraining Loss: 1.090652 \tValidation Loss: 1.514189\n",
      "Validation loss decreased (1.514259 --> 1.514189).         Saving model ...\n",
      "Epoch: 806 \tTraining Loss: 1.090638 \tValidation Loss: 1.514118\n",
      "Validation loss decreased (1.514189 --> 1.514118).         Saving model ...\n",
      "Epoch: 807 \tTraining Loss: 1.090624 \tValidation Loss: 1.514049\n",
      "Validation loss decreased (1.514118 --> 1.514049).         Saving model ...\n",
      "Epoch: 808 \tTraining Loss: 1.090610 \tValidation Loss: 1.513980\n",
      "Validation loss decreased (1.514049 --> 1.513980).         Saving model ...\n",
      "Epoch: 809 \tTraining Loss: 1.090596 \tValidation Loss: 1.513909\n",
      "Validation loss decreased (1.513980 --> 1.513909).         Saving model ...\n",
      "Epoch: 810 \tTraining Loss: 1.090582 \tValidation Loss: 1.513839\n",
      "Validation loss decreased (1.513909 --> 1.513839).         Saving model ...\n",
      "Epoch: 811 \tTraining Loss: 1.090569 \tValidation Loss: 1.513770\n",
      "Validation loss decreased (1.513839 --> 1.513770).         Saving model ...\n",
      "Epoch: 812 \tTraining Loss: 1.090555 \tValidation Loss: 1.513701\n",
      "Validation loss decreased (1.513770 --> 1.513701).         Saving model ...\n",
      "Epoch: 813 \tTraining Loss: 1.090541 \tValidation Loss: 1.513631\n",
      "Validation loss decreased (1.513701 --> 1.513631).         Saving model ...\n",
      "Epoch: 814 \tTraining Loss: 1.090527 \tValidation Loss: 1.513563\n",
      "Validation loss decreased (1.513631 --> 1.513563).         Saving model ...\n",
      "Epoch: 815 \tTraining Loss: 1.090513 \tValidation Loss: 1.513495\n",
      "Validation loss decreased (1.513563 --> 1.513495).         Saving model ...\n",
      "Epoch: 816 \tTraining Loss: 1.090500 \tValidation Loss: 1.513426\n",
      "Validation loss decreased (1.513495 --> 1.513426).         Saving model ...\n",
      "Epoch: 817 \tTraining Loss: 1.090486 \tValidation Loss: 1.513357\n",
      "Validation loss decreased (1.513426 --> 1.513357).         Saving model ...\n",
      "Epoch: 818 \tTraining Loss: 1.090472 \tValidation Loss: 1.513290\n",
      "Validation loss decreased (1.513357 --> 1.513290).         Saving model ...\n",
      "Epoch: 819 \tTraining Loss: 1.090458 \tValidation Loss: 1.513223\n",
      "Validation loss decreased (1.513290 --> 1.513223).         Saving model ...\n",
      "Epoch: 820 \tTraining Loss: 1.090445 \tValidation Loss: 1.513156\n",
      "Validation loss decreased (1.513223 --> 1.513156).         Saving model ...\n",
      "Epoch: 821 \tTraining Loss: 1.090431 \tValidation Loss: 1.513087\n",
      "Validation loss decreased (1.513156 --> 1.513087).         Saving model ...\n",
      "Epoch: 822 \tTraining Loss: 1.090417 \tValidation Loss: 1.513020\n",
      "Validation loss decreased (1.513087 --> 1.513020).         Saving model ...\n",
      "Epoch: 823 \tTraining Loss: 1.090404 \tValidation Loss: 1.512952\n",
      "Validation loss decreased (1.513020 --> 1.512952).         Saving model ...\n",
      "Epoch: 824 \tTraining Loss: 1.090390 \tValidation Loss: 1.512886\n",
      "Validation loss decreased (1.512952 --> 1.512886).         Saving model ...\n",
      "Epoch: 825 \tTraining Loss: 1.090377 \tValidation Loss: 1.512819\n",
      "Validation loss decreased (1.512886 --> 1.512819).         Saving model ...\n",
      "Epoch: 826 \tTraining Loss: 1.090363 \tValidation Loss: 1.512752\n",
      "Validation loss decreased (1.512819 --> 1.512752).         Saving model ...\n",
      "Epoch: 827 \tTraining Loss: 1.090350 \tValidation Loss: 1.512686\n",
      "Validation loss decreased (1.512752 --> 1.512686).         Saving model ...\n",
      "Epoch: 828 \tTraining Loss: 1.090336 \tValidation Loss: 1.512620\n",
      "Validation loss decreased (1.512686 --> 1.512620).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 829 \tTraining Loss: 1.090323 \tValidation Loss: 1.512554\n",
      "Validation loss decreased (1.512620 --> 1.512554).         Saving model ...\n",
      "Epoch: 830 \tTraining Loss: 1.090309 \tValidation Loss: 1.512488\n",
      "Validation loss decreased (1.512554 --> 1.512488).         Saving model ...\n",
      "Epoch: 831 \tTraining Loss: 1.090296 \tValidation Loss: 1.512422\n",
      "Validation loss decreased (1.512488 --> 1.512422).         Saving model ...\n",
      "Epoch: 832 \tTraining Loss: 1.090282 \tValidation Loss: 1.512356\n",
      "Validation loss decreased (1.512422 --> 1.512356).         Saving model ...\n",
      "Epoch: 833 \tTraining Loss: 1.090269 \tValidation Loss: 1.512291\n",
      "Validation loss decreased (1.512356 --> 1.512291).         Saving model ...\n",
      "Epoch: 834 \tTraining Loss: 1.090256 \tValidation Loss: 1.512225\n",
      "Validation loss decreased (1.512291 --> 1.512225).         Saving model ...\n",
      "Epoch: 835 \tTraining Loss: 1.090242 \tValidation Loss: 1.512161\n",
      "Validation loss decreased (1.512225 --> 1.512161).         Saving model ...\n",
      "Epoch: 836 \tTraining Loss: 1.090229 \tValidation Loss: 1.512096\n",
      "Validation loss decreased (1.512161 --> 1.512096).         Saving model ...\n",
      "Epoch: 837 \tTraining Loss: 1.090216 \tValidation Loss: 1.512031\n",
      "Validation loss decreased (1.512096 --> 1.512031).         Saving model ...\n",
      "Epoch: 838 \tTraining Loss: 1.090202 \tValidation Loss: 1.511967\n",
      "Validation loss decreased (1.512031 --> 1.511967).         Saving model ...\n",
      "Epoch: 839 \tTraining Loss: 1.090189 \tValidation Loss: 1.511902\n",
      "Validation loss decreased (1.511967 --> 1.511902).         Saving model ...\n",
      "Epoch: 840 \tTraining Loss: 1.090176 \tValidation Loss: 1.511838\n",
      "Validation loss decreased (1.511902 --> 1.511838).         Saving model ...\n",
      "Epoch: 841 \tTraining Loss: 1.090163 \tValidation Loss: 1.511773\n",
      "Validation loss decreased (1.511838 --> 1.511773).         Saving model ...\n",
      "Epoch: 842 \tTraining Loss: 1.090149 \tValidation Loss: 1.511709\n",
      "Validation loss decreased (1.511773 --> 1.511709).         Saving model ...\n",
      "Epoch: 843 \tTraining Loss: 1.090136 \tValidation Loss: 1.511644\n",
      "Validation loss decreased (1.511709 --> 1.511644).         Saving model ...\n",
      "Epoch: 844 \tTraining Loss: 1.090123 \tValidation Loss: 1.511580\n",
      "Validation loss decreased (1.511644 --> 1.511580).         Saving model ...\n",
      "Epoch: 845 \tTraining Loss: 1.090110 \tValidation Loss: 1.511515\n",
      "Validation loss decreased (1.511580 --> 1.511515).         Saving model ...\n",
      "Epoch: 846 \tTraining Loss: 1.090097 \tValidation Loss: 1.511453\n",
      "Validation loss decreased (1.511515 --> 1.511453).         Saving model ...\n",
      "Epoch: 847 \tTraining Loss: 1.090084 \tValidation Loss: 1.511388\n",
      "Validation loss decreased (1.511453 --> 1.511388).         Saving model ...\n",
      "Epoch: 848 \tTraining Loss: 1.090070 \tValidation Loss: 1.511324\n",
      "Validation loss decreased (1.511388 --> 1.511324).         Saving model ...\n",
      "Epoch: 849 \tTraining Loss: 1.090057 \tValidation Loss: 1.511262\n",
      "Validation loss decreased (1.511324 --> 1.511262).         Saving model ...\n",
      "Epoch: 850 \tTraining Loss: 1.090044 \tValidation Loss: 1.511198\n",
      "Validation loss decreased (1.511262 --> 1.511198).         Saving model ...\n",
      "Epoch: 851 \tTraining Loss: 1.090031 \tValidation Loss: 1.511134\n",
      "Validation loss decreased (1.511198 --> 1.511134).         Saving model ...\n",
      "Epoch: 852 \tTraining Loss: 1.090018 \tValidation Loss: 1.511072\n",
      "Validation loss decreased (1.511134 --> 1.511072).         Saving model ...\n",
      "Epoch: 853 \tTraining Loss: 1.090005 \tValidation Loss: 1.511009\n",
      "Validation loss decreased (1.511072 --> 1.511009).         Saving model ...\n",
      "Epoch: 854 \tTraining Loss: 1.089992 \tValidation Loss: 1.510945\n",
      "Validation loss decreased (1.511009 --> 1.510945).         Saving model ...\n",
      "Epoch: 855 \tTraining Loss: 1.089979 \tValidation Loss: 1.510882\n",
      "Validation loss decreased (1.510945 --> 1.510882).         Saving model ...\n",
      "Epoch: 856 \tTraining Loss: 1.089966 \tValidation Loss: 1.510819\n",
      "Validation loss decreased (1.510882 --> 1.510819).         Saving model ...\n",
      "Epoch: 857 \tTraining Loss: 1.089954 \tValidation Loss: 1.510757\n",
      "Validation loss decreased (1.510819 --> 1.510757).         Saving model ...\n",
      "Epoch: 858 \tTraining Loss: 1.089941 \tValidation Loss: 1.510694\n",
      "Validation loss decreased (1.510757 --> 1.510694).         Saving model ...\n",
      "Epoch: 859 \tTraining Loss: 1.089928 \tValidation Loss: 1.510632\n",
      "Validation loss decreased (1.510694 --> 1.510632).         Saving model ...\n",
      "Epoch: 860 \tTraining Loss: 1.089915 \tValidation Loss: 1.510570\n",
      "Validation loss decreased (1.510632 --> 1.510570).         Saving model ...\n",
      "Epoch: 861 \tTraining Loss: 1.089902 \tValidation Loss: 1.510508\n",
      "Validation loss decreased (1.510570 --> 1.510508).         Saving model ...\n",
      "Epoch: 862 \tTraining Loss: 1.089889 \tValidation Loss: 1.510446\n",
      "Validation loss decreased (1.510508 --> 1.510446).         Saving model ...\n",
      "Epoch: 863 \tTraining Loss: 1.089877 \tValidation Loss: 1.510385\n",
      "Validation loss decreased (1.510446 --> 1.510385).         Saving model ...\n",
      "Epoch: 864 \tTraining Loss: 1.089864 \tValidation Loss: 1.510324\n",
      "Validation loss decreased (1.510385 --> 1.510324).         Saving model ...\n",
      "Epoch: 865 \tTraining Loss: 1.089851 \tValidation Loss: 1.510262\n",
      "Validation loss decreased (1.510324 --> 1.510262).         Saving model ...\n",
      "Epoch: 866 \tTraining Loss: 1.089838 \tValidation Loss: 1.510201\n",
      "Validation loss decreased (1.510262 --> 1.510201).         Saving model ...\n",
      "Epoch: 867 \tTraining Loss: 1.089826 \tValidation Loss: 1.510140\n",
      "Validation loss decreased (1.510201 --> 1.510140).         Saving model ...\n",
      "Epoch: 868 \tTraining Loss: 1.089813 \tValidation Loss: 1.510078\n",
      "Validation loss decreased (1.510140 --> 1.510078).         Saving model ...\n",
      "Epoch: 869 \tTraining Loss: 1.089800 \tValidation Loss: 1.510017\n",
      "Validation loss decreased (1.510078 --> 1.510017).         Saving model ...\n",
      "Epoch: 870 \tTraining Loss: 1.089788 \tValidation Loss: 1.509956\n",
      "Validation loss decreased (1.510017 --> 1.509956).         Saving model ...\n",
      "Epoch: 871 \tTraining Loss: 1.089775 \tValidation Loss: 1.509895\n",
      "Validation loss decreased (1.509956 --> 1.509895).         Saving model ...\n",
      "Epoch: 872 \tTraining Loss: 1.089762 \tValidation Loss: 1.509834\n",
      "Validation loss decreased (1.509895 --> 1.509834).         Saving model ...\n",
      "Epoch: 873 \tTraining Loss: 1.089750 \tValidation Loss: 1.509774\n",
      "Validation loss decreased (1.509834 --> 1.509774).         Saving model ...\n",
      "Epoch: 874 \tTraining Loss: 1.089737 \tValidation Loss: 1.509714\n",
      "Validation loss decreased (1.509774 --> 1.509714).         Saving model ...\n",
      "Epoch: 875 \tTraining Loss: 1.089724 \tValidation Loss: 1.509654\n",
      "Validation loss decreased (1.509714 --> 1.509654).         Saving model ...\n",
      "Epoch: 876 \tTraining Loss: 1.089712 \tValidation Loss: 1.509595\n",
      "Validation loss decreased (1.509654 --> 1.509595).         Saving model ...\n",
      "Epoch: 877 \tTraining Loss: 1.089699 \tValidation Loss: 1.509535\n",
      "Validation loss decreased (1.509595 --> 1.509535).         Saving model ...\n",
      "Epoch: 878 \tTraining Loss: 1.089687 \tValidation Loss: 1.509475\n",
      "Validation loss decreased (1.509535 --> 1.509475).         Saving model ...\n",
      "Epoch: 879 \tTraining Loss: 1.089674 \tValidation Loss: 1.509415\n",
      "Validation loss decreased (1.509475 --> 1.509415).         Saving model ...\n",
      "Epoch: 880 \tTraining Loss: 1.089662 \tValidation Loss: 1.509356\n",
      "Validation loss decreased (1.509415 --> 1.509356).         Saving model ...\n",
      "Epoch: 881 \tTraining Loss: 1.089649 \tValidation Loss: 1.509297\n",
      "Validation loss decreased (1.509356 --> 1.509297).         Saving model ...\n",
      "Epoch: 882 \tTraining Loss: 1.089637 \tValidation Loss: 1.509238\n",
      "Validation loss decreased (1.509297 --> 1.509238).         Saving model ...\n",
      "Epoch: 883 \tTraining Loss: 1.089625 \tValidation Loss: 1.509178\n",
      "Validation loss decreased (1.509238 --> 1.509178).         Saving model ...\n",
      "Epoch: 884 \tTraining Loss: 1.089612 \tValidation Loss: 1.509119\n",
      "Validation loss decreased (1.509178 --> 1.509119).         Saving model ...\n",
      "Epoch: 885 \tTraining Loss: 1.089600 \tValidation Loss: 1.509060\n",
      "Validation loss decreased (1.509119 --> 1.509060).         Saving model ...\n",
      "Epoch: 886 \tTraining Loss: 1.089588 \tValidation Loss: 1.509002\n",
      "Validation loss decreased (1.509060 --> 1.509002).         Saving model ...\n",
      "Epoch: 887 \tTraining Loss: 1.089575 \tValidation Loss: 1.508944\n",
      "Validation loss decreased (1.509002 --> 1.508944).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 888 \tTraining Loss: 1.089563 \tValidation Loss: 1.508885\n",
      "Validation loss decreased (1.508944 --> 1.508885).         Saving model ...\n",
      "Epoch: 889 \tTraining Loss: 1.089551 \tValidation Loss: 1.508827\n",
      "Validation loss decreased (1.508885 --> 1.508827).         Saving model ...\n",
      "Epoch: 890 \tTraining Loss: 1.089538 \tValidation Loss: 1.508769\n",
      "Validation loss decreased (1.508827 --> 1.508769).         Saving model ...\n",
      "Epoch: 891 \tTraining Loss: 1.089526 \tValidation Loss: 1.508711\n",
      "Validation loss decreased (1.508769 --> 1.508711).         Saving model ...\n",
      "Epoch: 892 \tTraining Loss: 1.089514 \tValidation Loss: 1.508653\n",
      "Validation loss decreased (1.508711 --> 1.508653).         Saving model ...\n",
      "Epoch: 893 \tTraining Loss: 1.089501 \tValidation Loss: 1.508595\n",
      "Validation loss decreased (1.508653 --> 1.508595).         Saving model ...\n",
      "Epoch: 894 \tTraining Loss: 1.089489 \tValidation Loss: 1.508537\n",
      "Validation loss decreased (1.508595 --> 1.508537).         Saving model ...\n",
      "Epoch: 895 \tTraining Loss: 1.089477 \tValidation Loss: 1.508480\n",
      "Validation loss decreased (1.508537 --> 1.508480).         Saving model ...\n",
      "Epoch: 896 \tTraining Loss: 1.089465 \tValidation Loss: 1.508422\n",
      "Validation loss decreased (1.508480 --> 1.508422).         Saving model ...\n",
      "Epoch: 897 \tTraining Loss: 1.089453 \tValidation Loss: 1.508366\n",
      "Validation loss decreased (1.508422 --> 1.508366).         Saving model ...\n",
      "Epoch: 898 \tTraining Loss: 1.089441 \tValidation Loss: 1.508309\n",
      "Validation loss decreased (1.508366 --> 1.508309).         Saving model ...\n",
      "Epoch: 899 \tTraining Loss: 1.089428 \tValidation Loss: 1.508251\n",
      "Validation loss decreased (1.508309 --> 1.508251).         Saving model ...\n",
      "Epoch: 900 \tTraining Loss: 1.089416 \tValidation Loss: 1.508195\n",
      "Validation loss decreased (1.508251 --> 1.508195).         Saving model ...\n",
      "Epoch: 901 \tTraining Loss: 1.089404 \tValidation Loss: 1.508138\n",
      "Validation loss decreased (1.508195 --> 1.508138).         Saving model ...\n",
      "Epoch: 902 \tTraining Loss: 1.089392 \tValidation Loss: 1.508081\n",
      "Validation loss decreased (1.508138 --> 1.508081).         Saving model ...\n",
      "Epoch: 903 \tTraining Loss: 1.089380 \tValidation Loss: 1.508024\n",
      "Validation loss decreased (1.508081 --> 1.508024).         Saving model ...\n",
      "Epoch: 904 \tTraining Loss: 1.089368 \tValidation Loss: 1.507968\n",
      "Validation loss decreased (1.508024 --> 1.507968).         Saving model ...\n",
      "Epoch: 905 \tTraining Loss: 1.089356 \tValidation Loss: 1.507911\n",
      "Validation loss decreased (1.507968 --> 1.507911).         Saving model ...\n",
      "Epoch: 906 \tTraining Loss: 1.089344 \tValidation Loss: 1.507855\n",
      "Validation loss decreased (1.507911 --> 1.507855).         Saving model ...\n",
      "Epoch: 907 \tTraining Loss: 1.089332 \tValidation Loss: 1.507798\n",
      "Validation loss decreased (1.507855 --> 1.507798).         Saving model ...\n",
      "Epoch: 908 \tTraining Loss: 1.089320 \tValidation Loss: 1.507742\n",
      "Validation loss decreased (1.507798 --> 1.507742).         Saving model ...\n",
      "Epoch: 909 \tTraining Loss: 1.089308 \tValidation Loss: 1.507685\n",
      "Validation loss decreased (1.507742 --> 1.507685).         Saving model ...\n",
      "Epoch: 910 \tTraining Loss: 1.089296 \tValidation Loss: 1.507630\n",
      "Validation loss decreased (1.507685 --> 1.507630).         Saving model ...\n",
      "Epoch: 911 \tTraining Loss: 1.089284 \tValidation Loss: 1.507575\n",
      "Validation loss decreased (1.507630 --> 1.507575).         Saving model ...\n",
      "Epoch: 912 \tTraining Loss: 1.089272 \tValidation Loss: 1.507519\n",
      "Validation loss decreased (1.507575 --> 1.507519).         Saving model ...\n",
      "Epoch: 913 \tTraining Loss: 1.089260 \tValidation Loss: 1.507463\n",
      "Validation loss decreased (1.507519 --> 1.507463).         Saving model ...\n",
      "Epoch: 914 \tTraining Loss: 1.089249 \tValidation Loss: 1.507407\n",
      "Validation loss decreased (1.507463 --> 1.507407).         Saving model ...\n",
      "Epoch: 915 \tTraining Loss: 1.089237 \tValidation Loss: 1.507353\n",
      "Validation loss decreased (1.507407 --> 1.507353).         Saving model ...\n",
      "Epoch: 916 \tTraining Loss: 1.089225 \tValidation Loss: 1.507297\n",
      "Validation loss decreased (1.507353 --> 1.507297).         Saving model ...\n",
      "Epoch: 917 \tTraining Loss: 1.089213 \tValidation Loss: 1.507243\n",
      "Validation loss decreased (1.507297 --> 1.507243).         Saving model ...\n",
      "Epoch: 918 \tTraining Loss: 1.089201 \tValidation Loss: 1.507188\n",
      "Validation loss decreased (1.507243 --> 1.507188).         Saving model ...\n",
      "Epoch: 919 \tTraining Loss: 1.089189 \tValidation Loss: 1.507133\n",
      "Validation loss decreased (1.507188 --> 1.507133).         Saving model ...\n",
      "Epoch: 920 \tTraining Loss: 1.089178 \tValidation Loss: 1.507077\n",
      "Validation loss decreased (1.507133 --> 1.507077).         Saving model ...\n",
      "Epoch: 921 \tTraining Loss: 1.089166 \tValidation Loss: 1.507024\n",
      "Validation loss decreased (1.507077 --> 1.507024).         Saving model ...\n",
      "Epoch: 922 \tTraining Loss: 1.089154 \tValidation Loss: 1.506970\n",
      "Validation loss decreased (1.507024 --> 1.506970).         Saving model ...\n",
      "Epoch: 923 \tTraining Loss: 1.089143 \tValidation Loss: 1.506915\n",
      "Validation loss decreased (1.506970 --> 1.506915).         Saving model ...\n",
      "Epoch: 924 \tTraining Loss: 1.089131 \tValidation Loss: 1.506861\n",
      "Validation loss decreased (1.506915 --> 1.506861).         Saving model ...\n",
      "Epoch: 925 \tTraining Loss: 1.089119 \tValidation Loss: 1.506808\n",
      "Validation loss decreased (1.506861 --> 1.506808).         Saving model ...\n",
      "Epoch: 926 \tTraining Loss: 1.089107 \tValidation Loss: 1.506754\n",
      "Validation loss decreased (1.506808 --> 1.506754).         Saving model ...\n",
      "Epoch: 927 \tTraining Loss: 1.089096 \tValidation Loss: 1.506700\n",
      "Validation loss decreased (1.506754 --> 1.506700).         Saving model ...\n",
      "Epoch: 928 \tTraining Loss: 1.089084 \tValidation Loss: 1.506646\n",
      "Validation loss decreased (1.506700 --> 1.506646).         Saving model ...\n",
      "Epoch: 929 \tTraining Loss: 1.089073 \tValidation Loss: 1.506593\n",
      "Validation loss decreased (1.506646 --> 1.506593).         Saving model ...\n",
      "Epoch: 930 \tTraining Loss: 1.089061 \tValidation Loss: 1.506539\n",
      "Validation loss decreased (1.506593 --> 1.506539).         Saving model ...\n",
      "Epoch: 931 \tTraining Loss: 1.089049 \tValidation Loss: 1.506485\n",
      "Validation loss decreased (1.506539 --> 1.506485).         Saving model ...\n",
      "Epoch: 932 \tTraining Loss: 1.089038 \tValidation Loss: 1.506432\n",
      "Validation loss decreased (1.506485 --> 1.506432).         Saving model ...\n",
      "Epoch: 933 \tTraining Loss: 1.089026 \tValidation Loss: 1.506378\n",
      "Validation loss decreased (1.506432 --> 1.506378).         Saving model ...\n",
      "Epoch: 934 \tTraining Loss: 1.089015 \tValidation Loss: 1.506324\n",
      "Validation loss decreased (1.506378 --> 1.506324).         Saving model ...\n",
      "Epoch: 935 \tTraining Loss: 1.089003 \tValidation Loss: 1.506272\n",
      "Validation loss decreased (1.506324 --> 1.506272).         Saving model ...\n",
      "Epoch: 936 \tTraining Loss: 1.088992 \tValidation Loss: 1.506220\n",
      "Validation loss decreased (1.506272 --> 1.506220).         Saving model ...\n",
      "Epoch: 937 \tTraining Loss: 1.088980 \tValidation Loss: 1.506167\n",
      "Validation loss decreased (1.506220 --> 1.506167).         Saving model ...\n",
      "Epoch: 938 \tTraining Loss: 1.088969 \tValidation Loss: 1.506115\n",
      "Validation loss decreased (1.506167 --> 1.506115).         Saving model ...\n",
      "Epoch: 939 \tTraining Loss: 1.088957 \tValidation Loss: 1.506063\n",
      "Validation loss decreased (1.506115 --> 1.506063).         Saving model ...\n",
      "Epoch: 940 \tTraining Loss: 1.088946 \tValidation Loss: 1.506012\n",
      "Validation loss decreased (1.506063 --> 1.506012).         Saving model ...\n",
      "Epoch: 941 \tTraining Loss: 1.088934 \tValidation Loss: 1.505959\n",
      "Validation loss decreased (1.506012 --> 1.505959).         Saving model ...\n",
      "Epoch: 942 \tTraining Loss: 1.088923 \tValidation Loss: 1.505906\n",
      "Validation loss decreased (1.505959 --> 1.505906).         Saving model ...\n",
      "Epoch: 943 \tTraining Loss: 1.088912 \tValidation Loss: 1.505854\n",
      "Validation loss decreased (1.505906 --> 1.505854).         Saving model ...\n",
      "Epoch: 944 \tTraining Loss: 1.088900 \tValidation Loss: 1.505803\n",
      "Validation loss decreased (1.505854 --> 1.505803).         Saving model ...\n",
      "Epoch: 945 \tTraining Loss: 1.088889 \tValidation Loss: 1.505751\n",
      "Validation loss decreased (1.505803 --> 1.505751).         Saving model ...\n",
      "Epoch: 946 \tTraining Loss: 1.088877 \tValidation Loss: 1.505699\n",
      "Validation loss decreased (1.505751 --> 1.505699).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 947 \tTraining Loss: 1.088866 \tValidation Loss: 1.505648\n",
      "Validation loss decreased (1.505699 --> 1.505648).         Saving model ...\n",
      "Epoch: 948 \tTraining Loss: 1.088855 \tValidation Loss: 1.505597\n",
      "Validation loss decreased (1.505648 --> 1.505597).         Saving model ...\n",
      "Epoch: 949 \tTraining Loss: 1.088844 \tValidation Loss: 1.505545\n",
      "Validation loss decreased (1.505597 --> 1.505545).         Saving model ...\n",
      "Epoch: 950 \tTraining Loss: 1.088832 \tValidation Loss: 1.505495\n",
      "Validation loss decreased (1.505545 --> 1.505495).         Saving model ...\n",
      "Epoch: 951 \tTraining Loss: 1.088821 \tValidation Loss: 1.505444\n",
      "Validation loss decreased (1.505495 --> 1.505444).         Saving model ...\n",
      "Epoch: 952 \tTraining Loss: 1.088810 \tValidation Loss: 1.505393\n",
      "Validation loss decreased (1.505444 --> 1.505393).         Saving model ...\n",
      "Epoch: 953 \tTraining Loss: 1.088798 \tValidation Loss: 1.505342\n",
      "Validation loss decreased (1.505393 --> 1.505342).         Saving model ...\n",
      "Epoch: 954 \tTraining Loss: 1.088787 \tValidation Loss: 1.505291\n",
      "Validation loss decreased (1.505342 --> 1.505291).         Saving model ...\n",
      "Epoch: 955 \tTraining Loss: 1.088776 \tValidation Loss: 1.505241\n",
      "Validation loss decreased (1.505291 --> 1.505241).         Saving model ...\n",
      "Epoch: 956 \tTraining Loss: 1.088765 \tValidation Loss: 1.505190\n",
      "Validation loss decreased (1.505241 --> 1.505190).         Saving model ...\n",
      "Epoch: 957 \tTraining Loss: 1.088754 \tValidation Loss: 1.505140\n",
      "Validation loss decreased (1.505190 --> 1.505140).         Saving model ...\n",
      "Epoch: 958 \tTraining Loss: 1.088743 \tValidation Loss: 1.505090\n",
      "Validation loss decreased (1.505140 --> 1.505090).         Saving model ...\n",
      "Epoch: 959 \tTraining Loss: 1.088731 \tValidation Loss: 1.505039\n",
      "Validation loss decreased (1.505090 --> 1.505039).         Saving model ...\n",
      "Epoch: 960 \tTraining Loss: 1.088720 \tValidation Loss: 1.504988\n",
      "Validation loss decreased (1.505039 --> 1.504988).         Saving model ...\n",
      "Epoch: 961 \tTraining Loss: 1.088709 \tValidation Loss: 1.504938\n",
      "Validation loss decreased (1.504988 --> 1.504938).         Saving model ...\n",
      "Epoch: 962 \tTraining Loss: 1.088698 \tValidation Loss: 1.504889\n",
      "Validation loss decreased (1.504938 --> 1.504889).         Saving model ...\n",
      "Epoch: 963 \tTraining Loss: 1.088687 \tValidation Loss: 1.504839\n",
      "Validation loss decreased (1.504889 --> 1.504839).         Saving model ...\n",
      "Epoch: 964 \tTraining Loss: 1.088676 \tValidation Loss: 1.504789\n",
      "Validation loss decreased (1.504839 --> 1.504789).         Saving model ...\n",
      "Epoch: 965 \tTraining Loss: 1.088665 \tValidation Loss: 1.504739\n",
      "Validation loss decreased (1.504789 --> 1.504739).         Saving model ...\n",
      "Epoch: 966 \tTraining Loss: 1.088654 \tValidation Loss: 1.504689\n",
      "Validation loss decreased (1.504739 --> 1.504689).         Saving model ...\n",
      "Epoch: 967 \tTraining Loss: 1.088643 \tValidation Loss: 1.504639\n",
      "Validation loss decreased (1.504689 --> 1.504639).         Saving model ...\n",
      "Epoch: 968 \tTraining Loss: 1.088632 \tValidation Loss: 1.504590\n",
      "Validation loss decreased (1.504639 --> 1.504590).         Saving model ...\n",
      "Epoch: 969 \tTraining Loss: 1.088621 \tValidation Loss: 1.504541\n",
      "Validation loss decreased (1.504590 --> 1.504541).         Saving model ...\n",
      "Epoch: 970 \tTraining Loss: 1.088610 \tValidation Loss: 1.504491\n",
      "Validation loss decreased (1.504541 --> 1.504491).         Saving model ...\n",
      "Epoch: 971 \tTraining Loss: 1.088599 \tValidation Loss: 1.504443\n",
      "Validation loss decreased (1.504491 --> 1.504443).         Saving model ...\n",
      "Epoch: 972 \tTraining Loss: 1.088588 \tValidation Loss: 1.504394\n",
      "Validation loss decreased (1.504443 --> 1.504394).         Saving model ...\n",
      "Epoch: 973 \tTraining Loss: 1.088577 \tValidation Loss: 1.504346\n",
      "Validation loss decreased (1.504394 --> 1.504346).         Saving model ...\n",
      "Epoch: 974 \tTraining Loss: 1.088566 \tValidation Loss: 1.504297\n",
      "Validation loss decreased (1.504346 --> 1.504297).         Saving model ...\n",
      "Epoch: 975 \tTraining Loss: 1.088555 \tValidation Loss: 1.504249\n",
      "Validation loss decreased (1.504297 --> 1.504249).         Saving model ...\n",
      "Epoch: 976 \tTraining Loss: 1.088544 \tValidation Loss: 1.504200\n",
      "Validation loss decreased (1.504249 --> 1.504200).         Saving model ...\n",
      "Epoch: 977 \tTraining Loss: 1.088533 \tValidation Loss: 1.504153\n",
      "Validation loss decreased (1.504200 --> 1.504153).         Saving model ...\n",
      "Epoch: 978 \tTraining Loss: 1.088522 \tValidation Loss: 1.504104\n",
      "Validation loss decreased (1.504153 --> 1.504104).         Saving model ...\n",
      "Epoch: 979 \tTraining Loss: 1.088512 \tValidation Loss: 1.504056\n",
      "Validation loss decreased (1.504104 --> 1.504056).         Saving model ...\n",
      "Epoch: 980 \tTraining Loss: 1.088501 \tValidation Loss: 1.504008\n",
      "Validation loss decreased (1.504056 --> 1.504008).         Saving model ...\n",
      "Epoch: 981 \tTraining Loss: 1.088490 \tValidation Loss: 1.503961\n",
      "Validation loss decreased (1.504008 --> 1.503961).         Saving model ...\n",
      "Epoch: 982 \tTraining Loss: 1.088479 \tValidation Loss: 1.503913\n",
      "Validation loss decreased (1.503961 --> 1.503913).         Saving model ...\n",
      "Epoch: 983 \tTraining Loss: 1.088468 \tValidation Loss: 1.503865\n",
      "Validation loss decreased (1.503913 --> 1.503865).         Saving model ...\n",
      "Epoch: 984 \tTraining Loss: 1.088458 \tValidation Loss: 1.503818\n",
      "Validation loss decreased (1.503865 --> 1.503818).         Saving model ...\n",
      "Epoch: 985 \tTraining Loss: 1.088447 \tValidation Loss: 1.503770\n",
      "Validation loss decreased (1.503818 --> 1.503770).         Saving model ...\n",
      "Epoch: 986 \tTraining Loss: 1.088436 \tValidation Loss: 1.503723\n",
      "Validation loss decreased (1.503770 --> 1.503723).         Saving model ...\n",
      "Epoch: 987 \tTraining Loss: 1.088425 \tValidation Loss: 1.503677\n",
      "Validation loss decreased (1.503723 --> 1.503677).         Saving model ...\n",
      "Epoch: 988 \tTraining Loss: 1.088415 \tValidation Loss: 1.503629\n",
      "Validation loss decreased (1.503677 --> 1.503629).         Saving model ...\n",
      "Epoch: 989 \tTraining Loss: 1.088404 \tValidation Loss: 1.503582\n",
      "Validation loss decreased (1.503629 --> 1.503582).         Saving model ...\n",
      "Epoch: 990 \tTraining Loss: 1.088393 \tValidation Loss: 1.503535\n",
      "Validation loss decreased (1.503582 --> 1.503535).         Saving model ...\n",
      "Epoch: 991 \tTraining Loss: 1.088383 \tValidation Loss: 1.503489\n",
      "Validation loss decreased (1.503535 --> 1.503489).         Saving model ...\n",
      "Epoch: 992 \tTraining Loss: 1.088372 \tValidation Loss: 1.503442\n",
      "Validation loss decreased (1.503489 --> 1.503442).         Saving model ...\n",
      "Epoch: 993 \tTraining Loss: 1.088361 \tValidation Loss: 1.503395\n",
      "Validation loss decreased (1.503442 --> 1.503395).         Saving model ...\n",
      "Epoch: 994 \tTraining Loss: 1.088351 \tValidation Loss: 1.503349\n",
      "Validation loss decreased (1.503395 --> 1.503349).         Saving model ...\n",
      "Epoch: 995 \tTraining Loss: 1.088340 \tValidation Loss: 1.503303\n",
      "Validation loss decreased (1.503349 --> 1.503303).         Saving model ...\n",
      "Epoch: 996 \tTraining Loss: 1.088329 \tValidation Loss: 1.503257\n",
      "Validation loss decreased (1.503303 --> 1.503257).         Saving model ...\n",
      "Epoch: 997 \tTraining Loss: 1.088319 \tValidation Loss: 1.503211\n",
      "Validation loss decreased (1.503257 --> 1.503211).         Saving model ...\n",
      "Epoch: 998 \tTraining Loss: 1.088308 \tValidation Loss: 1.503165\n",
      "Validation loss decreased (1.503211 --> 1.503165).         Saving model ...\n",
      "Epoch: 999 \tTraining Loss: 1.088298 \tValidation Loss: 1.503119\n",
      "Validation loss decreased (1.503165 --> 1.503119).         Saving model ...\n",
      "Epoch: 1000 \tTraining Loss: 1.088287 \tValidation Loss: 1.503074\n",
      "Validation loss decreased (1.503119 --> 1.503074).         Saving model ...\n",
      "Epoch: 1001 \tTraining Loss: 1.088277 \tValidation Loss: 1.503029\n",
      "Validation loss decreased (1.503074 --> 1.503029).         Saving model ...\n",
      "Epoch: 1002 \tTraining Loss: 1.088266 \tValidation Loss: 1.502983\n",
      "Validation loss decreased (1.503029 --> 1.502983).         Saving model ...\n",
      "Epoch: 1003 \tTraining Loss: 1.088255 \tValidation Loss: 1.502937\n",
      "Validation loss decreased (1.502983 --> 1.502937).         Saving model ...\n",
      "Epoch: 1004 \tTraining Loss: 1.088245 \tValidation Loss: 1.502892\n",
      "Validation loss decreased (1.502937 --> 1.502892).         Saving model ...\n",
      "Epoch: 1005 \tTraining Loss: 1.088235 \tValidation Loss: 1.502846\n",
      "Validation loss decreased (1.502892 --> 1.502846).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1006 \tTraining Loss: 1.088224 \tValidation Loss: 1.502800\n",
      "Validation loss decreased (1.502846 --> 1.502800).         Saving model ...\n",
      "Epoch: 1007 \tTraining Loss: 1.088214 \tValidation Loss: 1.502755\n",
      "Validation loss decreased (1.502800 --> 1.502755).         Saving model ...\n",
      "Epoch: 1008 \tTraining Loss: 1.088203 \tValidation Loss: 1.502710\n",
      "Validation loss decreased (1.502755 --> 1.502710).         Saving model ...\n",
      "Epoch: 1009 \tTraining Loss: 1.088193 \tValidation Loss: 1.502664\n",
      "Validation loss decreased (1.502710 --> 1.502664).         Saving model ...\n",
      "Epoch: 1010 \tTraining Loss: 1.088182 \tValidation Loss: 1.502619\n",
      "Validation loss decreased (1.502664 --> 1.502619).         Saving model ...\n",
      "Epoch: 1011 \tTraining Loss: 1.088172 \tValidation Loss: 1.502575\n",
      "Validation loss decreased (1.502619 --> 1.502575).         Saving model ...\n",
      "Epoch: 1012 \tTraining Loss: 1.088162 \tValidation Loss: 1.502529\n",
      "Validation loss decreased (1.502575 --> 1.502529).         Saving model ...\n",
      "Epoch: 1013 \tTraining Loss: 1.088151 \tValidation Loss: 1.502484\n",
      "Validation loss decreased (1.502529 --> 1.502484).         Saving model ...\n",
      "Epoch: 1014 \tTraining Loss: 1.088141 \tValidation Loss: 1.502439\n",
      "Validation loss decreased (1.502484 --> 1.502439).         Saving model ...\n",
      "Epoch: 1015 \tTraining Loss: 1.088130 \tValidation Loss: 1.502395\n",
      "Validation loss decreased (1.502439 --> 1.502395).         Saving model ...\n",
      "Epoch: 1016 \tTraining Loss: 1.088120 \tValidation Loss: 1.502350\n",
      "Validation loss decreased (1.502395 --> 1.502350).         Saving model ...\n",
      "Epoch: 1017 \tTraining Loss: 1.088110 \tValidation Loss: 1.502307\n",
      "Validation loss decreased (1.502350 --> 1.502307).         Saving model ...\n",
      "Epoch: 1018 \tTraining Loss: 1.088099 \tValidation Loss: 1.502262\n",
      "Validation loss decreased (1.502307 --> 1.502262).         Saving model ...\n",
      "Epoch: 1019 \tTraining Loss: 1.088089 \tValidation Loss: 1.502218\n",
      "Validation loss decreased (1.502262 --> 1.502218).         Saving model ...\n",
      "Epoch: 1020 \tTraining Loss: 1.088079 \tValidation Loss: 1.502174\n",
      "Validation loss decreased (1.502218 --> 1.502174).         Saving model ...\n",
      "Epoch: 1021 \tTraining Loss: 1.088069 \tValidation Loss: 1.502130\n",
      "Validation loss decreased (1.502174 --> 1.502130).         Saving model ...\n",
      "Epoch: 1022 \tTraining Loss: 1.088058 \tValidation Loss: 1.502086\n",
      "Validation loss decreased (1.502130 --> 1.502086).         Saving model ...\n",
      "Epoch: 1023 \tTraining Loss: 1.088048 \tValidation Loss: 1.502043\n",
      "Validation loss decreased (1.502086 --> 1.502043).         Saving model ...\n",
      "Epoch: 1024 \tTraining Loss: 1.088038 \tValidation Loss: 1.501999\n",
      "Validation loss decreased (1.502043 --> 1.501999).         Saving model ...\n",
      "Epoch: 1025 \tTraining Loss: 1.088028 \tValidation Loss: 1.501954\n",
      "Validation loss decreased (1.501999 --> 1.501954).         Saving model ...\n",
      "Epoch: 1026 \tTraining Loss: 1.088018 \tValidation Loss: 1.501910\n",
      "Validation loss decreased (1.501954 --> 1.501910).         Saving model ...\n",
      "Epoch: 1027 \tTraining Loss: 1.088007 \tValidation Loss: 1.501868\n",
      "Validation loss decreased (1.501910 --> 1.501868).         Saving model ...\n",
      "Epoch: 1028 \tTraining Loss: 1.087997 \tValidation Loss: 1.501823\n",
      "Validation loss decreased (1.501868 --> 1.501823).         Saving model ...\n",
      "Epoch: 1029 \tTraining Loss: 1.087987 \tValidation Loss: 1.501779\n",
      "Validation loss decreased (1.501823 --> 1.501779).         Saving model ...\n",
      "Epoch: 1030 \tTraining Loss: 1.087977 \tValidation Loss: 1.501736\n",
      "Validation loss decreased (1.501779 --> 1.501736).         Saving model ...\n",
      "Epoch: 1031 \tTraining Loss: 1.087967 \tValidation Loss: 1.501693\n",
      "Validation loss decreased (1.501736 --> 1.501693).         Saving model ...\n",
      "Epoch: 1032 \tTraining Loss: 1.087957 \tValidation Loss: 1.501650\n",
      "Validation loss decreased (1.501693 --> 1.501650).         Saving model ...\n",
      "Epoch: 1033 \tTraining Loss: 1.087946 \tValidation Loss: 1.501607\n",
      "Validation loss decreased (1.501650 --> 1.501607).         Saving model ...\n",
      "Epoch: 1034 \tTraining Loss: 1.087936 \tValidation Loss: 1.501563\n",
      "Validation loss decreased (1.501607 --> 1.501563).         Saving model ...\n",
      "Epoch: 1035 \tTraining Loss: 1.087926 \tValidation Loss: 1.501521\n",
      "Validation loss decreased (1.501563 --> 1.501521).         Saving model ...\n",
      "Epoch: 1036 \tTraining Loss: 1.087916 \tValidation Loss: 1.501478\n",
      "Validation loss decreased (1.501521 --> 1.501478).         Saving model ...\n",
      "Epoch: 1037 \tTraining Loss: 1.087906 \tValidation Loss: 1.501435\n",
      "Validation loss decreased (1.501478 --> 1.501435).         Saving model ...\n",
      "Epoch: 1038 \tTraining Loss: 1.087896 \tValidation Loss: 1.501392\n",
      "Validation loss decreased (1.501435 --> 1.501392).         Saving model ...\n",
      "Epoch: 1039 \tTraining Loss: 1.087886 \tValidation Loss: 1.501349\n",
      "Validation loss decreased (1.501392 --> 1.501349).         Saving model ...\n",
      "Epoch: 1040 \tTraining Loss: 1.087876 \tValidation Loss: 1.501306\n",
      "Validation loss decreased (1.501349 --> 1.501306).         Saving model ...\n",
      "Epoch: 1041 \tTraining Loss: 1.087866 \tValidation Loss: 1.501263\n",
      "Validation loss decreased (1.501306 --> 1.501263).         Saving model ...\n",
      "Epoch: 1042 \tTraining Loss: 1.087856 \tValidation Loss: 1.501220\n",
      "Validation loss decreased (1.501263 --> 1.501220).         Saving model ...\n",
      "Epoch: 1043 \tTraining Loss: 1.087846 \tValidation Loss: 1.501178\n",
      "Validation loss decreased (1.501220 --> 1.501178).         Saving model ...\n",
      "Epoch: 1044 \tTraining Loss: 1.087836 \tValidation Loss: 1.501135\n",
      "Validation loss decreased (1.501178 --> 1.501135).         Saving model ...\n",
      "Epoch: 1045 \tTraining Loss: 1.087826 \tValidation Loss: 1.501093\n",
      "Validation loss decreased (1.501135 --> 1.501093).         Saving model ...\n",
      "Epoch: 1046 \tTraining Loss: 1.087816 \tValidation Loss: 1.501051\n",
      "Validation loss decreased (1.501093 --> 1.501051).         Saving model ...\n",
      "Epoch: 1047 \tTraining Loss: 1.087806 \tValidation Loss: 1.501010\n",
      "Validation loss decreased (1.501051 --> 1.501010).         Saving model ...\n",
      "Epoch: 1048 \tTraining Loss: 1.087796 \tValidation Loss: 1.500968\n",
      "Validation loss decreased (1.501010 --> 1.500968).         Saving model ...\n",
      "Epoch: 1049 \tTraining Loss: 1.087786 \tValidation Loss: 1.500925\n",
      "Validation loss decreased (1.500968 --> 1.500925).         Saving model ...\n",
      "Epoch: 1050 \tTraining Loss: 1.087777 \tValidation Loss: 1.500884\n",
      "Validation loss decreased (1.500925 --> 1.500884).         Saving model ...\n",
      "Epoch: 1051 \tTraining Loss: 1.087767 \tValidation Loss: 1.500842\n",
      "Validation loss decreased (1.500884 --> 1.500842).         Saving model ...\n",
      "Epoch: 1052 \tTraining Loss: 1.087757 \tValidation Loss: 1.500800\n",
      "Validation loss decreased (1.500842 --> 1.500800).         Saving model ...\n",
      "Epoch: 1053 \tTraining Loss: 1.087747 \tValidation Loss: 1.500758\n",
      "Validation loss decreased (1.500800 --> 1.500758).         Saving model ...\n",
      "Epoch: 1054 \tTraining Loss: 1.087737 \tValidation Loss: 1.500718\n",
      "Validation loss decreased (1.500758 --> 1.500718).         Saving model ...\n",
      "Epoch: 1055 \tTraining Loss: 1.087727 \tValidation Loss: 1.500676\n",
      "Validation loss decreased (1.500718 --> 1.500676).         Saving model ...\n",
      "Epoch: 1056 \tTraining Loss: 1.087717 \tValidation Loss: 1.500635\n",
      "Validation loss decreased (1.500676 --> 1.500635).         Saving model ...\n",
      "Epoch: 1057 \tTraining Loss: 1.087708 \tValidation Loss: 1.500594\n",
      "Validation loss decreased (1.500635 --> 1.500594).         Saving model ...\n",
      "Epoch: 1058 \tTraining Loss: 1.087698 \tValidation Loss: 1.500553\n",
      "Validation loss decreased (1.500594 --> 1.500553).         Saving model ...\n",
      "Epoch: 1059 \tTraining Loss: 1.087688 \tValidation Loss: 1.500512\n",
      "Validation loss decreased (1.500553 --> 1.500512).         Saving model ...\n",
      "Epoch: 1060 \tTraining Loss: 1.087678 \tValidation Loss: 1.500472\n",
      "Validation loss decreased (1.500512 --> 1.500472).         Saving model ...\n",
      "Epoch: 1061 \tTraining Loss: 1.087668 \tValidation Loss: 1.500431\n",
      "Validation loss decreased (1.500472 --> 1.500431).         Saving model ...\n",
      "Epoch: 1062 \tTraining Loss: 1.087659 \tValidation Loss: 1.500391\n",
      "Validation loss decreased (1.500431 --> 1.500391).         Saving model ...\n",
      "Epoch: 1063 \tTraining Loss: 1.087649 \tValidation Loss: 1.500350\n",
      "Validation loss decreased (1.500391 --> 1.500350).         Saving model ...\n",
      "Epoch: 1064 \tTraining Loss: 1.087639 \tValidation Loss: 1.500310\n",
      "Validation loss decreased (1.500350 --> 1.500310).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1065 \tTraining Loss: 1.087630 \tValidation Loss: 1.500269\n",
      "Validation loss decreased (1.500310 --> 1.500269).         Saving model ...\n",
      "Epoch: 1066 \tTraining Loss: 1.087620 \tValidation Loss: 1.500229\n",
      "Validation loss decreased (1.500269 --> 1.500229).         Saving model ...\n",
      "Epoch: 1067 \tTraining Loss: 1.087610 \tValidation Loss: 1.500188\n",
      "Validation loss decreased (1.500229 --> 1.500188).         Saving model ...\n",
      "Epoch: 1068 \tTraining Loss: 1.087601 \tValidation Loss: 1.500148\n",
      "Validation loss decreased (1.500188 --> 1.500148).         Saving model ...\n",
      "Epoch: 1069 \tTraining Loss: 1.087591 \tValidation Loss: 1.500108\n",
      "Validation loss decreased (1.500148 --> 1.500108).         Saving model ...\n",
      "Epoch: 1070 \tTraining Loss: 1.087581 \tValidation Loss: 1.500069\n",
      "Validation loss decreased (1.500108 --> 1.500069).         Saving model ...\n",
      "Epoch: 1071 \tTraining Loss: 1.087572 \tValidation Loss: 1.500029\n",
      "Validation loss decreased (1.500069 --> 1.500029).         Saving model ...\n",
      "Epoch: 1072 \tTraining Loss: 1.087562 \tValidation Loss: 1.499990\n",
      "Validation loss decreased (1.500029 --> 1.499990).         Saving model ...\n",
      "Epoch: 1073 \tTraining Loss: 1.087552 \tValidation Loss: 1.499951\n",
      "Validation loss decreased (1.499990 --> 1.499951).         Saving model ...\n",
      "Epoch: 1074 \tTraining Loss: 1.087543 \tValidation Loss: 1.499910\n",
      "Validation loss decreased (1.499951 --> 1.499910).         Saving model ...\n",
      "Epoch: 1075 \tTraining Loss: 1.087533 \tValidation Loss: 1.499871\n",
      "Validation loss decreased (1.499910 --> 1.499871).         Saving model ...\n",
      "Epoch: 1076 \tTraining Loss: 1.087524 \tValidation Loss: 1.499832\n",
      "Validation loss decreased (1.499871 --> 1.499832).         Saving model ...\n",
      "Epoch: 1077 \tTraining Loss: 1.087514 \tValidation Loss: 1.499792\n",
      "Validation loss decreased (1.499832 --> 1.499792).         Saving model ...\n",
      "Epoch: 1078 \tTraining Loss: 1.087504 \tValidation Loss: 1.499753\n",
      "Validation loss decreased (1.499792 --> 1.499753).         Saving model ...\n",
      "Epoch: 1079 \tTraining Loss: 1.087495 \tValidation Loss: 1.499713\n",
      "Validation loss decreased (1.499753 --> 1.499713).         Saving model ...\n",
      "Epoch: 1080 \tTraining Loss: 1.087485 \tValidation Loss: 1.499675\n",
      "Validation loss decreased (1.499713 --> 1.499675).         Saving model ...\n",
      "Epoch: 1081 \tTraining Loss: 1.087476 \tValidation Loss: 1.499636\n",
      "Validation loss decreased (1.499675 --> 1.499636).         Saving model ...\n",
      "Epoch: 1082 \tTraining Loss: 1.087466 \tValidation Loss: 1.499597\n",
      "Validation loss decreased (1.499636 --> 1.499597).         Saving model ...\n",
      "Epoch: 1083 \tTraining Loss: 1.087457 \tValidation Loss: 1.499558\n",
      "Validation loss decreased (1.499597 --> 1.499558).         Saving model ...\n",
      "Epoch: 1084 \tTraining Loss: 1.087447 \tValidation Loss: 1.499518\n",
      "Validation loss decreased (1.499558 --> 1.499518).         Saving model ...\n",
      "Epoch: 1085 \tTraining Loss: 1.087438 \tValidation Loss: 1.499480\n",
      "Validation loss decreased (1.499518 --> 1.499480).         Saving model ...\n",
      "Epoch: 1086 \tTraining Loss: 1.087428 \tValidation Loss: 1.499441\n",
      "Validation loss decreased (1.499480 --> 1.499441).         Saving model ...\n",
      "Epoch: 1087 \tTraining Loss: 1.087419 \tValidation Loss: 1.499401\n",
      "Validation loss decreased (1.499441 --> 1.499401).         Saving model ...\n",
      "Epoch: 1088 \tTraining Loss: 1.087409 \tValidation Loss: 1.499363\n",
      "Validation loss decreased (1.499401 --> 1.499363).         Saving model ...\n",
      "Epoch: 1089 \tTraining Loss: 1.087400 \tValidation Loss: 1.499325\n",
      "Validation loss decreased (1.499363 --> 1.499325).         Saving model ...\n",
      "Epoch: 1090 \tTraining Loss: 1.087391 \tValidation Loss: 1.499287\n",
      "Validation loss decreased (1.499325 --> 1.499287).         Saving model ...\n",
      "Epoch: 1091 \tTraining Loss: 1.087381 \tValidation Loss: 1.499248\n",
      "Validation loss decreased (1.499287 --> 1.499248).         Saving model ...\n",
      "Epoch: 1092 \tTraining Loss: 1.087372 \tValidation Loss: 1.499211\n",
      "Validation loss decreased (1.499248 --> 1.499211).         Saving model ...\n",
      "Epoch: 1093 \tTraining Loss: 1.087362 \tValidation Loss: 1.499172\n",
      "Validation loss decreased (1.499211 --> 1.499172).         Saving model ...\n",
      "Epoch: 1094 \tTraining Loss: 1.087353 \tValidation Loss: 1.499134\n",
      "Validation loss decreased (1.499172 --> 1.499134).         Saving model ...\n",
      "Epoch: 1095 \tTraining Loss: 1.087344 \tValidation Loss: 1.499097\n",
      "Validation loss decreased (1.499134 --> 1.499097).         Saving model ...\n",
      "Epoch: 1096 \tTraining Loss: 1.087334 \tValidation Loss: 1.499059\n",
      "Validation loss decreased (1.499097 --> 1.499059).         Saving model ...\n",
      "Epoch: 1097 \tTraining Loss: 1.087325 \tValidation Loss: 1.499021\n",
      "Validation loss decreased (1.499059 --> 1.499021).         Saving model ...\n",
      "Epoch: 1098 \tTraining Loss: 1.087316 \tValidation Loss: 1.498983\n",
      "Validation loss decreased (1.499021 --> 1.498983).         Saving model ...\n",
      "Epoch: 1099 \tTraining Loss: 1.087306 \tValidation Loss: 1.498945\n",
      "Validation loss decreased (1.498983 --> 1.498945).         Saving model ...\n",
      "Epoch: 1100 \tTraining Loss: 1.087297 \tValidation Loss: 1.498907\n",
      "Validation loss decreased (1.498945 --> 1.498907).         Saving model ...\n",
      "Epoch: 1101 \tTraining Loss: 1.087288 \tValidation Loss: 1.498870\n",
      "Validation loss decreased (1.498907 --> 1.498870).         Saving model ...\n",
      "Epoch: 1102 \tTraining Loss: 1.087278 \tValidation Loss: 1.498831\n",
      "Validation loss decreased (1.498870 --> 1.498831).         Saving model ...\n",
      "Epoch: 1103 \tTraining Loss: 1.087269 \tValidation Loss: 1.498794\n",
      "Validation loss decreased (1.498831 --> 1.498794).         Saving model ...\n",
      "Epoch: 1104 \tTraining Loss: 1.087260 \tValidation Loss: 1.498756\n",
      "Validation loss decreased (1.498794 --> 1.498756).         Saving model ...\n",
      "Epoch: 1105 \tTraining Loss: 1.087251 \tValidation Loss: 1.498719\n",
      "Validation loss decreased (1.498756 --> 1.498719).         Saving model ...\n",
      "Epoch: 1106 \tTraining Loss: 1.087241 \tValidation Loss: 1.498682\n",
      "Validation loss decreased (1.498719 --> 1.498682).         Saving model ...\n",
      "Epoch: 1107 \tTraining Loss: 1.087232 \tValidation Loss: 1.498644\n",
      "Validation loss decreased (1.498682 --> 1.498644).         Saving model ...\n",
      "Epoch: 1108 \tTraining Loss: 1.087223 \tValidation Loss: 1.498607\n",
      "Validation loss decreased (1.498644 --> 1.498607).         Saving model ...\n",
      "Epoch: 1109 \tTraining Loss: 1.087214 \tValidation Loss: 1.498570\n",
      "Validation loss decreased (1.498607 --> 1.498570).         Saving model ...\n",
      "Epoch: 1110 \tTraining Loss: 1.087205 \tValidation Loss: 1.498533\n",
      "Validation loss decreased (1.498570 --> 1.498533).         Saving model ...\n",
      "Epoch: 1111 \tTraining Loss: 1.087195 \tValidation Loss: 1.498497\n",
      "Validation loss decreased (1.498533 --> 1.498497).         Saving model ...\n",
      "Epoch: 1112 \tTraining Loss: 1.087186 \tValidation Loss: 1.498460\n",
      "Validation loss decreased (1.498497 --> 1.498460).         Saving model ...\n",
      "Epoch: 1113 \tTraining Loss: 1.087177 \tValidation Loss: 1.498423\n",
      "Validation loss decreased (1.498460 --> 1.498423).         Saving model ...\n",
      "Epoch: 1114 \tTraining Loss: 1.087168 \tValidation Loss: 1.498387\n",
      "Validation loss decreased (1.498423 --> 1.498387).         Saving model ...\n",
      "Epoch: 1115 \tTraining Loss: 1.087159 \tValidation Loss: 1.498350\n",
      "Validation loss decreased (1.498387 --> 1.498350).         Saving model ...\n",
      "Epoch: 1116 \tTraining Loss: 1.087150 \tValidation Loss: 1.498314\n",
      "Validation loss decreased (1.498350 --> 1.498314).         Saving model ...\n",
      "Epoch: 1117 \tTraining Loss: 1.087140 \tValidation Loss: 1.498277\n",
      "Validation loss decreased (1.498314 --> 1.498277).         Saving model ...\n",
      "Epoch: 1118 \tTraining Loss: 1.087131 \tValidation Loss: 1.498240\n",
      "Validation loss decreased (1.498277 --> 1.498240).         Saving model ...\n",
      "Epoch: 1119 \tTraining Loss: 1.087122 \tValidation Loss: 1.498204\n",
      "Validation loss decreased (1.498240 --> 1.498204).         Saving model ...\n",
      "Epoch: 1120 \tTraining Loss: 1.087113 \tValidation Loss: 1.498167\n",
      "Validation loss decreased (1.498204 --> 1.498167).         Saving model ...\n",
      "Epoch: 1121 \tTraining Loss: 1.087104 \tValidation Loss: 1.498131\n",
      "Validation loss decreased (1.498167 --> 1.498131).         Saving model ...\n",
      "Epoch: 1122 \tTraining Loss: 1.087095 \tValidation Loss: 1.498094\n",
      "Validation loss decreased (1.498131 --> 1.498094).         Saving model ...\n",
      "Epoch: 1123 \tTraining Loss: 1.087086 \tValidation Loss: 1.498058\n",
      "Validation loss decreased (1.498094 --> 1.498058).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1124 \tTraining Loss: 1.087077 \tValidation Loss: 1.498023\n",
      "Validation loss decreased (1.498058 --> 1.498023).         Saving model ...\n",
      "Epoch: 1125 \tTraining Loss: 1.087068 \tValidation Loss: 1.497988\n",
      "Validation loss decreased (1.498023 --> 1.497988).         Saving model ...\n",
      "Epoch: 1126 \tTraining Loss: 1.087059 \tValidation Loss: 1.497951\n",
      "Validation loss decreased (1.497988 --> 1.497951).         Saving model ...\n",
      "Epoch: 1127 \tTraining Loss: 1.087050 \tValidation Loss: 1.497915\n",
      "Validation loss decreased (1.497951 --> 1.497915).         Saving model ...\n",
      "Epoch: 1128 \tTraining Loss: 1.087041 \tValidation Loss: 1.497880\n",
      "Validation loss decreased (1.497915 --> 1.497880).         Saving model ...\n",
      "Epoch: 1129 \tTraining Loss: 1.087032 \tValidation Loss: 1.497844\n",
      "Validation loss decreased (1.497880 --> 1.497844).         Saving model ...\n",
      "Epoch: 1130 \tTraining Loss: 1.087023 \tValidation Loss: 1.497808\n",
      "Validation loss decreased (1.497844 --> 1.497808).         Saving model ...\n",
      "Epoch: 1131 \tTraining Loss: 1.087014 \tValidation Loss: 1.497774\n",
      "Validation loss decreased (1.497808 --> 1.497774).         Saving model ...\n",
      "Epoch: 1132 \tTraining Loss: 1.087005 \tValidation Loss: 1.497738\n",
      "Validation loss decreased (1.497774 --> 1.497738).         Saving model ...\n",
      "Epoch: 1133 \tTraining Loss: 1.086996 \tValidation Loss: 1.497704\n",
      "Validation loss decreased (1.497738 --> 1.497704).         Saving model ...\n",
      "Epoch: 1134 \tTraining Loss: 1.086987 \tValidation Loss: 1.497669\n",
      "Validation loss decreased (1.497704 --> 1.497669).         Saving model ...\n",
      "Epoch: 1135 \tTraining Loss: 1.086978 \tValidation Loss: 1.497634\n",
      "Validation loss decreased (1.497669 --> 1.497634).         Saving model ...\n",
      "Epoch: 1136 \tTraining Loss: 1.086969 \tValidation Loss: 1.497598\n",
      "Validation loss decreased (1.497634 --> 1.497598).         Saving model ...\n",
      "Epoch: 1137 \tTraining Loss: 1.086960 \tValidation Loss: 1.497564\n",
      "Validation loss decreased (1.497598 --> 1.497564).         Saving model ...\n",
      "Epoch: 1138 \tTraining Loss: 1.086951 \tValidation Loss: 1.497529\n",
      "Validation loss decreased (1.497564 --> 1.497529).         Saving model ...\n",
      "Epoch: 1139 \tTraining Loss: 1.086942 \tValidation Loss: 1.497494\n",
      "Validation loss decreased (1.497529 --> 1.497494).         Saving model ...\n",
      "Epoch: 1140 \tTraining Loss: 1.086934 \tValidation Loss: 1.497460\n",
      "Validation loss decreased (1.497494 --> 1.497460).         Saving model ...\n",
      "Epoch: 1141 \tTraining Loss: 1.086925 \tValidation Loss: 1.497425\n",
      "Validation loss decreased (1.497460 --> 1.497425).         Saving model ...\n",
      "Epoch: 1142 \tTraining Loss: 1.086916 \tValidation Loss: 1.497391\n",
      "Validation loss decreased (1.497425 --> 1.497391).         Saving model ...\n",
      "Epoch: 1143 \tTraining Loss: 1.086907 \tValidation Loss: 1.497356\n",
      "Validation loss decreased (1.497391 --> 1.497356).         Saving model ...\n",
      "Epoch: 1144 \tTraining Loss: 1.086898 \tValidation Loss: 1.497322\n",
      "Validation loss decreased (1.497356 --> 1.497322).         Saving model ...\n",
      "Epoch: 1145 \tTraining Loss: 1.086889 \tValidation Loss: 1.497289\n",
      "Validation loss decreased (1.497322 --> 1.497289).         Saving model ...\n",
      "Epoch: 1146 \tTraining Loss: 1.086881 \tValidation Loss: 1.497254\n",
      "Validation loss decreased (1.497289 --> 1.497254).         Saving model ...\n",
      "Epoch: 1147 \tTraining Loss: 1.086872 \tValidation Loss: 1.497222\n",
      "Validation loss decreased (1.497254 --> 1.497222).         Saving model ...\n",
      "Epoch: 1148 \tTraining Loss: 1.086863 \tValidation Loss: 1.497187\n",
      "Validation loss decreased (1.497222 --> 1.497187).         Saving model ...\n",
      "Epoch: 1149 \tTraining Loss: 1.086854 \tValidation Loss: 1.497152\n",
      "Validation loss decreased (1.497187 --> 1.497152).         Saving model ...\n",
      "Epoch: 1150 \tTraining Loss: 1.086845 \tValidation Loss: 1.497119\n",
      "Validation loss decreased (1.497152 --> 1.497119).         Saving model ...\n",
      "Epoch: 1151 \tTraining Loss: 1.086837 \tValidation Loss: 1.497085\n",
      "Validation loss decreased (1.497119 --> 1.497085).         Saving model ...\n",
      "Epoch: 1152 \tTraining Loss: 1.086828 \tValidation Loss: 1.497051\n",
      "Validation loss decreased (1.497085 --> 1.497051).         Saving model ...\n",
      "Epoch: 1153 \tTraining Loss: 1.086819 \tValidation Loss: 1.497018\n",
      "Validation loss decreased (1.497051 --> 1.497018).         Saving model ...\n",
      "Epoch: 1154 \tTraining Loss: 1.086810 \tValidation Loss: 1.496984\n",
      "Validation loss decreased (1.497018 --> 1.496984).         Saving model ...\n",
      "Epoch: 1155 \tTraining Loss: 1.086802 \tValidation Loss: 1.496950\n",
      "Validation loss decreased (1.496984 --> 1.496950).         Saving model ...\n",
      "Epoch: 1156 \tTraining Loss: 1.086793 \tValidation Loss: 1.496916\n",
      "Validation loss decreased (1.496950 --> 1.496916).         Saving model ...\n",
      "Epoch: 1157 \tTraining Loss: 1.086784 \tValidation Loss: 1.496883\n",
      "Validation loss decreased (1.496916 --> 1.496883).         Saving model ...\n",
      "Epoch: 1158 \tTraining Loss: 1.086776 \tValidation Loss: 1.496850\n",
      "Validation loss decreased (1.496883 --> 1.496850).         Saving model ...\n",
      "Epoch: 1159 \tTraining Loss: 1.086767 \tValidation Loss: 1.496816\n",
      "Validation loss decreased (1.496850 --> 1.496816).         Saving model ...\n",
      "Epoch: 1160 \tTraining Loss: 1.086758 \tValidation Loss: 1.496783\n",
      "Validation loss decreased (1.496816 --> 1.496783).         Saving model ...\n",
      "Epoch: 1161 \tTraining Loss: 1.086750 \tValidation Loss: 1.496750\n",
      "Validation loss decreased (1.496783 --> 1.496750).         Saving model ...\n",
      "Epoch: 1162 \tTraining Loss: 1.086741 \tValidation Loss: 1.496716\n",
      "Validation loss decreased (1.496750 --> 1.496716).         Saving model ...\n",
      "Epoch: 1163 \tTraining Loss: 1.086732 \tValidation Loss: 1.496684\n",
      "Validation loss decreased (1.496716 --> 1.496684).         Saving model ...\n",
      "Epoch: 1164 \tTraining Loss: 1.086724 \tValidation Loss: 1.496650\n",
      "Validation loss decreased (1.496684 --> 1.496650).         Saving model ...\n",
      "Epoch: 1165 \tTraining Loss: 1.086715 \tValidation Loss: 1.496617\n",
      "Validation loss decreased (1.496650 --> 1.496617).         Saving model ...\n",
      "Epoch: 1166 \tTraining Loss: 1.086706 \tValidation Loss: 1.496584\n",
      "Validation loss decreased (1.496617 --> 1.496584).         Saving model ...\n",
      "Epoch: 1167 \tTraining Loss: 1.086698 \tValidation Loss: 1.496551\n",
      "Validation loss decreased (1.496584 --> 1.496551).         Saving model ...\n",
      "Epoch: 1168 \tTraining Loss: 1.086689 \tValidation Loss: 1.496519\n",
      "Validation loss decreased (1.496551 --> 1.496519).         Saving model ...\n",
      "Epoch: 1169 \tTraining Loss: 1.086681 \tValidation Loss: 1.496486\n",
      "Validation loss decreased (1.496519 --> 1.496486).         Saving model ...\n",
      "Epoch: 1170 \tTraining Loss: 1.086672 \tValidation Loss: 1.496454\n",
      "Validation loss decreased (1.496486 --> 1.496454).         Saving model ...\n",
      "Epoch: 1171 \tTraining Loss: 1.086663 \tValidation Loss: 1.496421\n",
      "Validation loss decreased (1.496454 --> 1.496421).         Saving model ...\n",
      "Epoch: 1172 \tTraining Loss: 1.086655 \tValidation Loss: 1.496389\n",
      "Validation loss decreased (1.496421 --> 1.496389).         Saving model ...\n",
      "Epoch: 1173 \tTraining Loss: 1.086646 \tValidation Loss: 1.496356\n",
      "Validation loss decreased (1.496389 --> 1.496356).         Saving model ...\n",
      "Epoch: 1174 \tTraining Loss: 1.086638 \tValidation Loss: 1.496324\n",
      "Validation loss decreased (1.496356 --> 1.496324).         Saving model ...\n",
      "Epoch: 1175 \tTraining Loss: 1.086629 \tValidation Loss: 1.496291\n",
      "Validation loss decreased (1.496324 --> 1.496291).         Saving model ...\n",
      "Epoch: 1176 \tTraining Loss: 1.086621 \tValidation Loss: 1.496259\n",
      "Validation loss decreased (1.496291 --> 1.496259).         Saving model ...\n",
      "Epoch: 1177 \tTraining Loss: 1.086612 \tValidation Loss: 1.496227\n",
      "Validation loss decreased (1.496259 --> 1.496227).         Saving model ...\n",
      "Epoch: 1178 \tTraining Loss: 1.086604 \tValidation Loss: 1.496195\n",
      "Validation loss decreased (1.496227 --> 1.496195).         Saving model ...\n",
      "Epoch: 1179 \tTraining Loss: 1.086595 \tValidation Loss: 1.496163\n",
      "Validation loss decreased (1.496195 --> 1.496163).         Saving model ...\n",
      "Epoch: 1180 \tTraining Loss: 1.086587 \tValidation Loss: 1.496130\n",
      "Validation loss decreased (1.496163 --> 1.496130).         Saving model ...\n",
      "Epoch: 1181 \tTraining Loss: 1.086578 \tValidation Loss: 1.496098\n",
      "Validation loss decreased (1.496130 --> 1.496098).         Saving model ...\n",
      "Epoch: 1182 \tTraining Loss: 1.086570 \tValidation Loss: 1.496066\n",
      "Validation loss decreased (1.496098 --> 1.496066).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1183 \tTraining Loss: 1.086561 \tValidation Loss: 1.496035\n",
      "Validation loss decreased (1.496066 --> 1.496035).         Saving model ...\n",
      "Epoch: 1184 \tTraining Loss: 1.086553 \tValidation Loss: 1.496003\n",
      "Validation loss decreased (1.496035 --> 1.496003).         Saving model ...\n",
      "Epoch: 1185 \tTraining Loss: 1.086544 \tValidation Loss: 1.495971\n",
      "Validation loss decreased (1.496003 --> 1.495971).         Saving model ...\n",
      "Epoch: 1186 \tTraining Loss: 1.086536 \tValidation Loss: 1.495939\n",
      "Validation loss decreased (1.495971 --> 1.495939).         Saving model ...\n",
      "Epoch: 1187 \tTraining Loss: 1.086528 \tValidation Loss: 1.495907\n",
      "Validation loss decreased (1.495939 --> 1.495907).         Saving model ...\n",
      "Epoch: 1188 \tTraining Loss: 1.086519 \tValidation Loss: 1.495874\n",
      "Validation loss decreased (1.495907 --> 1.495874).         Saving model ...\n",
      "Epoch: 1189 \tTraining Loss: 1.086511 \tValidation Loss: 1.495843\n",
      "Validation loss decreased (1.495874 --> 1.495843).         Saving model ...\n",
      "Epoch: 1190 \tTraining Loss: 1.086502 \tValidation Loss: 1.495811\n",
      "Validation loss decreased (1.495843 --> 1.495811).         Saving model ...\n",
      "Epoch: 1191 \tTraining Loss: 1.086494 \tValidation Loss: 1.495778\n",
      "Validation loss decreased (1.495811 --> 1.495778).         Saving model ...\n",
      "Epoch: 1192 \tTraining Loss: 1.086486 \tValidation Loss: 1.495747\n",
      "Validation loss decreased (1.495778 --> 1.495747).         Saving model ...\n",
      "Epoch: 1193 \tTraining Loss: 1.086477 \tValidation Loss: 1.495715\n",
      "Validation loss decreased (1.495747 --> 1.495715).         Saving model ...\n",
      "Epoch: 1194 \tTraining Loss: 1.086469 \tValidation Loss: 1.495684\n",
      "Validation loss decreased (1.495715 --> 1.495684).         Saving model ...\n",
      "Epoch: 1195 \tTraining Loss: 1.086461 \tValidation Loss: 1.495653\n",
      "Validation loss decreased (1.495684 --> 1.495653).         Saving model ...\n",
      "Epoch: 1196 \tTraining Loss: 1.086452 \tValidation Loss: 1.495620\n",
      "Validation loss decreased (1.495653 --> 1.495620).         Saving model ...\n",
      "Epoch: 1197 \tTraining Loss: 1.086444 \tValidation Loss: 1.495590\n",
      "Validation loss decreased (1.495620 --> 1.495590).         Saving model ...\n",
      "Epoch: 1198 \tTraining Loss: 1.086436 \tValidation Loss: 1.495558\n",
      "Validation loss decreased (1.495590 --> 1.495558).         Saving model ...\n",
      "Epoch: 1199 \tTraining Loss: 1.086427 \tValidation Loss: 1.495527\n",
      "Validation loss decreased (1.495558 --> 1.495527).         Saving model ...\n",
      "Epoch: 1200 \tTraining Loss: 1.086419 \tValidation Loss: 1.495496\n",
      "Validation loss decreased (1.495527 --> 1.495496).         Saving model ...\n",
      "Epoch: 1201 \tTraining Loss: 1.086411 \tValidation Loss: 1.495465\n",
      "Validation loss decreased (1.495496 --> 1.495465).         Saving model ...\n",
      "Epoch: 1202 \tTraining Loss: 1.086403 \tValidation Loss: 1.495435\n",
      "Validation loss decreased (1.495465 --> 1.495435).         Saving model ...\n",
      "Epoch: 1203 \tTraining Loss: 1.086394 \tValidation Loss: 1.495404\n",
      "Validation loss decreased (1.495435 --> 1.495404).         Saving model ...\n",
      "Epoch: 1204 \tTraining Loss: 1.086386 \tValidation Loss: 1.495373\n",
      "Validation loss decreased (1.495404 --> 1.495373).         Saving model ...\n",
      "Epoch: 1205 \tTraining Loss: 1.086378 \tValidation Loss: 1.495342\n",
      "Validation loss decreased (1.495373 --> 1.495342).         Saving model ...\n",
      "Epoch: 1206 \tTraining Loss: 1.086369 \tValidation Loss: 1.495312\n",
      "Validation loss decreased (1.495342 --> 1.495312).         Saving model ...\n",
      "Epoch: 1207 \tTraining Loss: 1.086361 \tValidation Loss: 1.495282\n",
      "Validation loss decreased (1.495312 --> 1.495282).         Saving model ...\n",
      "Epoch: 1208 \tTraining Loss: 1.086353 \tValidation Loss: 1.495251\n",
      "Validation loss decreased (1.495282 --> 1.495251).         Saving model ...\n",
      "Epoch: 1209 \tTraining Loss: 1.086345 \tValidation Loss: 1.495220\n",
      "Validation loss decreased (1.495251 --> 1.495220).         Saving model ...\n",
      "Epoch: 1210 \tTraining Loss: 1.086337 \tValidation Loss: 1.495189\n",
      "Validation loss decreased (1.495220 --> 1.495189).         Saving model ...\n",
      "Epoch: 1211 \tTraining Loss: 1.086328 \tValidation Loss: 1.495159\n",
      "Validation loss decreased (1.495189 --> 1.495159).         Saving model ...\n",
      "Epoch: 1212 \tTraining Loss: 1.086320 \tValidation Loss: 1.495128\n",
      "Validation loss decreased (1.495159 --> 1.495128).         Saving model ...\n",
      "Epoch: 1213 \tTraining Loss: 1.086312 \tValidation Loss: 1.495099\n",
      "Validation loss decreased (1.495128 --> 1.495099).         Saving model ...\n",
      "Epoch: 1214 \tTraining Loss: 1.086304 \tValidation Loss: 1.495068\n",
      "Validation loss decreased (1.495099 --> 1.495068).         Saving model ...\n",
      "Epoch: 1215 \tTraining Loss: 1.086296 \tValidation Loss: 1.495039\n",
      "Validation loss decreased (1.495068 --> 1.495039).         Saving model ...\n",
      "Epoch: 1216 \tTraining Loss: 1.086288 \tValidation Loss: 1.495009\n",
      "Validation loss decreased (1.495039 --> 1.495009).         Saving model ...\n",
      "Epoch: 1217 \tTraining Loss: 1.086279 \tValidation Loss: 1.494980\n",
      "Validation loss decreased (1.495009 --> 1.494980).         Saving model ...\n",
      "Epoch: 1218 \tTraining Loss: 1.086271 \tValidation Loss: 1.494950\n",
      "Validation loss decreased (1.494980 --> 1.494950).         Saving model ...\n",
      "Epoch: 1219 \tTraining Loss: 1.086263 \tValidation Loss: 1.494921\n",
      "Validation loss decreased (1.494950 --> 1.494921).         Saving model ...\n",
      "Epoch: 1220 \tTraining Loss: 1.086255 \tValidation Loss: 1.494891\n",
      "Validation loss decreased (1.494921 --> 1.494891).         Saving model ...\n",
      "Epoch: 1221 \tTraining Loss: 1.086247 \tValidation Loss: 1.494861\n",
      "Validation loss decreased (1.494891 --> 1.494861).         Saving model ...\n",
      "Epoch: 1222 \tTraining Loss: 1.086239 \tValidation Loss: 1.494831\n",
      "Validation loss decreased (1.494861 --> 1.494831).         Saving model ...\n",
      "Epoch: 1223 \tTraining Loss: 1.086231 \tValidation Loss: 1.494801\n",
      "Validation loss decreased (1.494831 --> 1.494801).         Saving model ...\n",
      "Epoch: 1224 \tTraining Loss: 1.086223 \tValidation Loss: 1.494771\n",
      "Validation loss decreased (1.494801 --> 1.494771).         Saving model ...\n",
      "Epoch: 1225 \tTraining Loss: 1.086215 \tValidation Loss: 1.494742\n",
      "Validation loss decreased (1.494771 --> 1.494742).         Saving model ...\n",
      "Epoch: 1226 \tTraining Loss: 1.086207 \tValidation Loss: 1.494712\n",
      "Validation loss decreased (1.494742 --> 1.494712).         Saving model ...\n",
      "Epoch: 1227 \tTraining Loss: 1.086198 \tValidation Loss: 1.494683\n",
      "Validation loss decreased (1.494712 --> 1.494683).         Saving model ...\n",
      "Epoch: 1228 \tTraining Loss: 1.086190 \tValidation Loss: 1.494653\n",
      "Validation loss decreased (1.494683 --> 1.494653).         Saving model ...\n",
      "Epoch: 1229 \tTraining Loss: 1.086182 \tValidation Loss: 1.494624\n",
      "Validation loss decreased (1.494653 --> 1.494624).         Saving model ...\n",
      "Epoch: 1230 \tTraining Loss: 1.086174 \tValidation Loss: 1.494594\n",
      "Validation loss decreased (1.494624 --> 1.494594).         Saving model ...\n",
      "Epoch: 1231 \tTraining Loss: 1.086166 \tValidation Loss: 1.494566\n",
      "Validation loss decreased (1.494594 --> 1.494566).         Saving model ...\n",
      "Epoch: 1232 \tTraining Loss: 1.086158 \tValidation Loss: 1.494537\n",
      "Validation loss decreased (1.494566 --> 1.494537).         Saving model ...\n",
      "Epoch: 1233 \tTraining Loss: 1.086150 \tValidation Loss: 1.494507\n",
      "Validation loss decreased (1.494537 --> 1.494507).         Saving model ...\n",
      "Epoch: 1234 \tTraining Loss: 1.086142 \tValidation Loss: 1.494479\n",
      "Validation loss decreased (1.494507 --> 1.494479).         Saving model ...\n",
      "Epoch: 1235 \tTraining Loss: 1.086134 \tValidation Loss: 1.494451\n",
      "Validation loss decreased (1.494479 --> 1.494451).         Saving model ...\n",
      "Epoch: 1236 \tTraining Loss: 1.086126 \tValidation Loss: 1.494422\n",
      "Validation loss decreased (1.494451 --> 1.494422).         Saving model ...\n",
      "Epoch: 1237 \tTraining Loss: 1.086118 \tValidation Loss: 1.494392\n",
      "Validation loss decreased (1.494422 --> 1.494392).         Saving model ...\n",
      "Epoch: 1238 \tTraining Loss: 1.086110 \tValidation Loss: 1.494364\n",
      "Validation loss decreased (1.494392 --> 1.494364).         Saving model ...\n",
      "Epoch: 1239 \tTraining Loss: 1.086102 \tValidation Loss: 1.494336\n",
      "Validation loss decreased (1.494364 --> 1.494336).         Saving model ...\n",
      "Epoch: 1240 \tTraining Loss: 1.086095 \tValidation Loss: 1.494309\n",
      "Validation loss decreased (1.494336 --> 1.494309).         Saving model ...\n",
      "Epoch: 1241 \tTraining Loss: 1.086087 \tValidation Loss: 1.494280\n",
      "Validation loss decreased (1.494309 --> 1.494280).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1242 \tTraining Loss: 1.086079 \tValidation Loss: 1.494252\n",
      "Validation loss decreased (1.494280 --> 1.494252).         Saving model ...\n",
      "Epoch: 1243 \tTraining Loss: 1.086071 \tValidation Loss: 1.494224\n",
      "Validation loss decreased (1.494252 --> 1.494224).         Saving model ...\n",
      "Epoch: 1244 \tTraining Loss: 1.086063 \tValidation Loss: 1.494195\n",
      "Validation loss decreased (1.494224 --> 1.494195).         Saving model ...\n",
      "Epoch: 1245 \tTraining Loss: 1.086055 \tValidation Loss: 1.494167\n",
      "Validation loss decreased (1.494195 --> 1.494167).         Saving model ...\n",
      "Epoch: 1246 \tTraining Loss: 1.086047 \tValidation Loss: 1.494139\n",
      "Validation loss decreased (1.494167 --> 1.494139).         Saving model ...\n",
      "Epoch: 1247 \tTraining Loss: 1.086039 \tValidation Loss: 1.494110\n",
      "Validation loss decreased (1.494139 --> 1.494110).         Saving model ...\n",
      "Epoch: 1248 \tTraining Loss: 1.086031 \tValidation Loss: 1.494081\n",
      "Validation loss decreased (1.494110 --> 1.494081).         Saving model ...\n",
      "Epoch: 1249 \tTraining Loss: 1.086023 \tValidation Loss: 1.494052\n",
      "Validation loss decreased (1.494081 --> 1.494052).         Saving model ...\n",
      "Epoch: 1250 \tTraining Loss: 1.086016 \tValidation Loss: 1.494025\n",
      "Validation loss decreased (1.494052 --> 1.494025).         Saving model ...\n",
      "Epoch: 1251 \tTraining Loss: 1.086008 \tValidation Loss: 1.493997\n",
      "Validation loss decreased (1.494025 --> 1.493997).         Saving model ...\n",
      "Epoch: 1252 \tTraining Loss: 1.086000 \tValidation Loss: 1.493969\n",
      "Validation loss decreased (1.493997 --> 1.493969).         Saving model ...\n",
      "Epoch: 1253 \tTraining Loss: 1.085992 \tValidation Loss: 1.493941\n",
      "Validation loss decreased (1.493969 --> 1.493941).         Saving model ...\n",
      "Epoch: 1254 \tTraining Loss: 1.085984 \tValidation Loss: 1.493912\n",
      "Validation loss decreased (1.493941 --> 1.493912).         Saving model ...\n",
      "Epoch: 1255 \tTraining Loss: 1.085976 \tValidation Loss: 1.493884\n",
      "Validation loss decreased (1.493912 --> 1.493884).         Saving model ...\n",
      "Epoch: 1256 \tTraining Loss: 1.085969 \tValidation Loss: 1.493856\n",
      "Validation loss decreased (1.493884 --> 1.493856).         Saving model ...\n",
      "Epoch: 1257 \tTraining Loss: 1.085961 \tValidation Loss: 1.493828\n",
      "Validation loss decreased (1.493856 --> 1.493828).         Saving model ...\n",
      "Epoch: 1258 \tTraining Loss: 1.085953 \tValidation Loss: 1.493799\n",
      "Validation loss decreased (1.493828 --> 1.493799).         Saving model ...\n",
      "Epoch: 1259 \tTraining Loss: 1.085945 \tValidation Loss: 1.493771\n",
      "Validation loss decreased (1.493799 --> 1.493771).         Saving model ...\n",
      "Epoch: 1260 \tTraining Loss: 1.085937 \tValidation Loss: 1.493744\n",
      "Validation loss decreased (1.493771 --> 1.493744).         Saving model ...\n",
      "Epoch: 1261 \tTraining Loss: 1.085930 \tValidation Loss: 1.493716\n",
      "Validation loss decreased (1.493744 --> 1.493716).         Saving model ...\n",
      "Epoch: 1262 \tTraining Loss: 1.085922 \tValidation Loss: 1.493688\n",
      "Validation loss decreased (1.493716 --> 1.493688).         Saving model ...\n",
      "Epoch: 1263 \tTraining Loss: 1.085914 \tValidation Loss: 1.493661\n",
      "Validation loss decreased (1.493688 --> 1.493661).         Saving model ...\n",
      "Epoch: 1264 \tTraining Loss: 1.085906 \tValidation Loss: 1.493634\n",
      "Validation loss decreased (1.493661 --> 1.493634).         Saving model ...\n",
      "Epoch: 1265 \tTraining Loss: 1.085899 \tValidation Loss: 1.493607\n",
      "Validation loss decreased (1.493634 --> 1.493607).         Saving model ...\n",
      "Epoch: 1266 \tTraining Loss: 1.085891 \tValidation Loss: 1.493580\n",
      "Validation loss decreased (1.493607 --> 1.493580).         Saving model ...\n",
      "Epoch: 1267 \tTraining Loss: 1.085883 \tValidation Loss: 1.493553\n",
      "Validation loss decreased (1.493580 --> 1.493553).         Saving model ...\n",
      "Epoch: 1268 \tTraining Loss: 1.085876 \tValidation Loss: 1.493526\n",
      "Validation loss decreased (1.493553 --> 1.493526).         Saving model ...\n",
      "Epoch: 1269 \tTraining Loss: 1.085868 \tValidation Loss: 1.493499\n",
      "Validation loss decreased (1.493526 --> 1.493499).         Saving model ...\n",
      "Epoch: 1270 \tTraining Loss: 1.085860 \tValidation Loss: 1.493472\n",
      "Validation loss decreased (1.493499 --> 1.493472).         Saving model ...\n",
      "Epoch: 1271 \tTraining Loss: 1.085852 \tValidation Loss: 1.493444\n",
      "Validation loss decreased (1.493472 --> 1.493444).         Saving model ...\n",
      "Epoch: 1272 \tTraining Loss: 1.085845 \tValidation Loss: 1.493418\n",
      "Validation loss decreased (1.493444 --> 1.493418).         Saving model ...\n",
      "Epoch: 1273 \tTraining Loss: 1.085837 \tValidation Loss: 1.493391\n",
      "Validation loss decreased (1.493418 --> 1.493391).         Saving model ...\n",
      "Epoch: 1274 \tTraining Loss: 1.085829 \tValidation Loss: 1.493364\n",
      "Validation loss decreased (1.493391 --> 1.493364).         Saving model ...\n",
      "Epoch: 1275 \tTraining Loss: 1.085822 \tValidation Loss: 1.493337\n",
      "Validation loss decreased (1.493364 --> 1.493337).         Saving model ...\n",
      "Epoch: 1276 \tTraining Loss: 1.085814 \tValidation Loss: 1.493311\n",
      "Validation loss decreased (1.493337 --> 1.493311).         Saving model ...\n",
      "Epoch: 1277 \tTraining Loss: 1.085807 \tValidation Loss: 1.493284\n",
      "Validation loss decreased (1.493311 --> 1.493284).         Saving model ...\n",
      "Epoch: 1278 \tTraining Loss: 1.085799 \tValidation Loss: 1.493257\n",
      "Validation loss decreased (1.493284 --> 1.493257).         Saving model ...\n",
      "Epoch: 1279 \tTraining Loss: 1.085791 \tValidation Loss: 1.493230\n",
      "Validation loss decreased (1.493257 --> 1.493230).         Saving model ...\n",
      "Epoch: 1280 \tTraining Loss: 1.085784 \tValidation Loss: 1.493203\n",
      "Validation loss decreased (1.493230 --> 1.493203).         Saving model ...\n",
      "Epoch: 1281 \tTraining Loss: 1.085776 \tValidation Loss: 1.493176\n",
      "Validation loss decreased (1.493203 --> 1.493176).         Saving model ...\n",
      "Epoch: 1282 \tTraining Loss: 1.085768 \tValidation Loss: 1.493150\n",
      "Validation loss decreased (1.493176 --> 1.493150).         Saving model ...\n",
      "Epoch: 1283 \tTraining Loss: 1.085761 \tValidation Loss: 1.493124\n",
      "Validation loss decreased (1.493150 --> 1.493124).         Saving model ...\n",
      "Epoch: 1284 \tTraining Loss: 1.085753 \tValidation Loss: 1.493097\n",
      "Validation loss decreased (1.493124 --> 1.493097).         Saving model ...\n",
      "Epoch: 1285 \tTraining Loss: 1.085746 \tValidation Loss: 1.493071\n",
      "Validation loss decreased (1.493097 --> 1.493071).         Saving model ...\n",
      "Epoch: 1286 \tTraining Loss: 1.085738 \tValidation Loss: 1.493045\n",
      "Validation loss decreased (1.493071 --> 1.493045).         Saving model ...\n",
      "Epoch: 1287 \tTraining Loss: 1.085731 \tValidation Loss: 1.493018\n",
      "Validation loss decreased (1.493045 --> 1.493018).         Saving model ...\n",
      "Epoch: 1288 \tTraining Loss: 1.085723 \tValidation Loss: 1.492993\n",
      "Validation loss decreased (1.493018 --> 1.492993).         Saving model ...\n",
      "Epoch: 1289 \tTraining Loss: 1.085715 \tValidation Loss: 1.492967\n",
      "Validation loss decreased (1.492993 --> 1.492967).         Saving model ...\n",
      "Epoch: 1290 \tTraining Loss: 1.085708 \tValidation Loss: 1.492941\n",
      "Validation loss decreased (1.492967 --> 1.492941).         Saving model ...\n",
      "Epoch: 1291 \tTraining Loss: 1.085700 \tValidation Loss: 1.492916\n",
      "Validation loss decreased (1.492941 --> 1.492916).         Saving model ...\n",
      "Epoch: 1292 \tTraining Loss: 1.085693 \tValidation Loss: 1.492890\n",
      "Validation loss decreased (1.492916 --> 1.492890).         Saving model ...\n",
      "Epoch: 1293 \tTraining Loss: 1.085685 \tValidation Loss: 1.492865\n",
      "Validation loss decreased (1.492890 --> 1.492865).         Saving model ...\n",
      "Epoch: 1294 \tTraining Loss: 1.085678 \tValidation Loss: 1.492840\n",
      "Validation loss decreased (1.492865 --> 1.492840).         Saving model ...\n",
      "Epoch: 1295 \tTraining Loss: 1.085670 \tValidation Loss: 1.492814\n",
      "Validation loss decreased (1.492840 --> 1.492814).         Saving model ...\n",
      "Epoch: 1296 \tTraining Loss: 1.085663 \tValidation Loss: 1.492787\n",
      "Validation loss decreased (1.492814 --> 1.492787).         Saving model ...\n",
      "Epoch: 1297 \tTraining Loss: 1.085655 \tValidation Loss: 1.492761\n",
      "Validation loss decreased (1.492787 --> 1.492761).         Saving model ...\n",
      "Epoch: 1298 \tTraining Loss: 1.085648 \tValidation Loss: 1.492736\n",
      "Validation loss decreased (1.492761 --> 1.492736).         Saving model ...\n",
      "Epoch: 1299 \tTraining Loss: 1.085640 \tValidation Loss: 1.492710\n",
      "Validation loss decreased (1.492736 --> 1.492710).         Saving model ...\n",
      "Epoch: 1300 \tTraining Loss: 1.085633 \tValidation Loss: 1.492684\n",
      "Validation loss decreased (1.492710 --> 1.492684).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1301 \tTraining Loss: 1.085626 \tValidation Loss: 1.492659\n",
      "Validation loss decreased (1.492684 --> 1.492659).         Saving model ...\n",
      "Epoch: 1302 \tTraining Loss: 1.085618 \tValidation Loss: 1.492633\n",
      "Validation loss decreased (1.492659 --> 1.492633).         Saving model ...\n",
      "Epoch: 1303 \tTraining Loss: 1.085611 \tValidation Loss: 1.492607\n",
      "Validation loss decreased (1.492633 --> 1.492607).         Saving model ...\n",
      "Epoch: 1304 \tTraining Loss: 1.085603 \tValidation Loss: 1.492582\n",
      "Validation loss decreased (1.492607 --> 1.492582).         Saving model ...\n",
      "Epoch: 1305 \tTraining Loss: 1.085596 \tValidation Loss: 1.492556\n",
      "Validation loss decreased (1.492582 --> 1.492556).         Saving model ...\n",
      "Epoch: 1306 \tTraining Loss: 1.085588 \tValidation Loss: 1.492531\n",
      "Validation loss decreased (1.492556 --> 1.492531).         Saving model ...\n",
      "Epoch: 1307 \tTraining Loss: 1.085581 \tValidation Loss: 1.492505\n",
      "Validation loss decreased (1.492531 --> 1.492505).         Saving model ...\n",
      "Epoch: 1308 \tTraining Loss: 1.085574 \tValidation Loss: 1.492479\n",
      "Validation loss decreased (1.492505 --> 1.492479).         Saving model ...\n",
      "Epoch: 1309 \tTraining Loss: 1.085566 \tValidation Loss: 1.492455\n",
      "Validation loss decreased (1.492479 --> 1.492455).         Saving model ...\n",
      "Epoch: 1310 \tTraining Loss: 1.085559 \tValidation Loss: 1.492430\n",
      "Validation loss decreased (1.492455 --> 1.492430).         Saving model ...\n",
      "Epoch: 1311 \tTraining Loss: 1.085551 \tValidation Loss: 1.492405\n",
      "Validation loss decreased (1.492430 --> 1.492405).         Saving model ...\n",
      "Epoch: 1312 \tTraining Loss: 1.085544 \tValidation Loss: 1.492380\n",
      "Validation loss decreased (1.492405 --> 1.492380).         Saving model ...\n",
      "Epoch: 1313 \tTraining Loss: 1.085537 \tValidation Loss: 1.492355\n",
      "Validation loss decreased (1.492380 --> 1.492355).         Saving model ...\n",
      "Epoch: 1314 \tTraining Loss: 1.085529 \tValidation Loss: 1.492329\n",
      "Validation loss decreased (1.492355 --> 1.492329).         Saving model ...\n",
      "Epoch: 1315 \tTraining Loss: 1.085522 \tValidation Loss: 1.492305\n",
      "Validation loss decreased (1.492329 --> 1.492305).         Saving model ...\n",
      "Epoch: 1316 \tTraining Loss: 1.085515 \tValidation Loss: 1.492280\n",
      "Validation loss decreased (1.492305 --> 1.492280).         Saving model ...\n",
      "Epoch: 1317 \tTraining Loss: 1.085507 \tValidation Loss: 1.492254\n",
      "Validation loss decreased (1.492280 --> 1.492254).         Saving model ...\n",
      "Epoch: 1318 \tTraining Loss: 1.085500 \tValidation Loss: 1.492230\n",
      "Validation loss decreased (1.492254 --> 1.492230).         Saving model ...\n",
      "Epoch: 1319 \tTraining Loss: 1.085493 \tValidation Loss: 1.492205\n",
      "Validation loss decreased (1.492230 --> 1.492205).         Saving model ...\n",
      "Epoch: 1320 \tTraining Loss: 1.085485 \tValidation Loss: 1.492181\n",
      "Validation loss decreased (1.492205 --> 1.492181).         Saving model ...\n",
      "Epoch: 1321 \tTraining Loss: 1.085478 \tValidation Loss: 1.492156\n",
      "Validation loss decreased (1.492181 --> 1.492156).         Saving model ...\n",
      "Epoch: 1322 \tTraining Loss: 1.085471 \tValidation Loss: 1.492132\n",
      "Validation loss decreased (1.492156 --> 1.492132).         Saving model ...\n",
      "Epoch: 1323 \tTraining Loss: 1.085464 \tValidation Loss: 1.492107\n",
      "Validation loss decreased (1.492132 --> 1.492107).         Saving model ...\n",
      "Epoch: 1324 \tTraining Loss: 1.085456 \tValidation Loss: 1.492083\n",
      "Validation loss decreased (1.492107 --> 1.492083).         Saving model ...\n",
      "Epoch: 1325 \tTraining Loss: 1.085449 \tValidation Loss: 1.492060\n",
      "Validation loss decreased (1.492083 --> 1.492060).         Saving model ...\n",
      "Epoch: 1326 \tTraining Loss: 1.085442 \tValidation Loss: 1.492035\n",
      "Validation loss decreased (1.492060 --> 1.492035).         Saving model ...\n",
      "Epoch: 1327 \tTraining Loss: 1.085434 \tValidation Loss: 1.492011\n",
      "Validation loss decreased (1.492035 --> 1.492011).         Saving model ...\n",
      "Epoch: 1328 \tTraining Loss: 1.085427 \tValidation Loss: 1.491987\n",
      "Validation loss decreased (1.492011 --> 1.491987).         Saving model ...\n",
      "Epoch: 1329 \tTraining Loss: 1.085420 \tValidation Loss: 1.491964\n",
      "Validation loss decreased (1.491987 --> 1.491964).         Saving model ...\n",
      "Epoch: 1330 \tTraining Loss: 1.085413 \tValidation Loss: 1.491939\n",
      "Validation loss decreased (1.491964 --> 1.491939).         Saving model ...\n",
      "Epoch: 1331 \tTraining Loss: 1.085406 \tValidation Loss: 1.491916\n",
      "Validation loss decreased (1.491939 --> 1.491916).         Saving model ...\n",
      "Epoch: 1332 \tTraining Loss: 1.085398 \tValidation Loss: 1.491892\n",
      "Validation loss decreased (1.491916 --> 1.491892).         Saving model ...\n",
      "Epoch: 1333 \tTraining Loss: 1.085391 \tValidation Loss: 1.491869\n",
      "Validation loss decreased (1.491892 --> 1.491869).         Saving model ...\n",
      "Epoch: 1334 \tTraining Loss: 1.085384 \tValidation Loss: 1.491845\n",
      "Validation loss decreased (1.491869 --> 1.491845).         Saving model ...\n",
      "Epoch: 1335 \tTraining Loss: 1.085377 \tValidation Loss: 1.491821\n",
      "Validation loss decreased (1.491845 --> 1.491821).         Saving model ...\n",
      "Epoch: 1336 \tTraining Loss: 1.085370 \tValidation Loss: 1.491796\n",
      "Validation loss decreased (1.491821 --> 1.491796).         Saving model ...\n",
      "Epoch: 1337 \tTraining Loss: 1.085362 \tValidation Loss: 1.491773\n",
      "Validation loss decreased (1.491796 --> 1.491773).         Saving model ...\n",
      "Epoch: 1338 \tTraining Loss: 1.085355 \tValidation Loss: 1.491749\n",
      "Validation loss decreased (1.491773 --> 1.491749).         Saving model ...\n",
      "Epoch: 1339 \tTraining Loss: 1.085348 \tValidation Loss: 1.491726\n",
      "Validation loss decreased (1.491749 --> 1.491726).         Saving model ...\n",
      "Epoch: 1340 \tTraining Loss: 1.085341 \tValidation Loss: 1.491701\n",
      "Validation loss decreased (1.491726 --> 1.491701).         Saving model ...\n",
      "Epoch: 1341 \tTraining Loss: 1.085334 \tValidation Loss: 1.491678\n",
      "Validation loss decreased (1.491701 --> 1.491678).         Saving model ...\n",
      "Epoch: 1342 \tTraining Loss: 1.085326 \tValidation Loss: 1.491654\n",
      "Validation loss decreased (1.491678 --> 1.491654).         Saving model ...\n",
      "Epoch: 1343 \tTraining Loss: 1.085319 \tValidation Loss: 1.491630\n",
      "Validation loss decreased (1.491654 --> 1.491630).         Saving model ...\n",
      "Epoch: 1344 \tTraining Loss: 1.085312 \tValidation Loss: 1.491606\n",
      "Validation loss decreased (1.491630 --> 1.491606).         Saving model ...\n",
      "Epoch: 1345 \tTraining Loss: 1.085305 \tValidation Loss: 1.491584\n",
      "Validation loss decreased (1.491606 --> 1.491584).         Saving model ...\n",
      "Epoch: 1346 \tTraining Loss: 1.085298 \tValidation Loss: 1.491562\n",
      "Validation loss decreased (1.491584 --> 1.491562).         Saving model ...\n",
      "Epoch: 1347 \tTraining Loss: 1.085291 \tValidation Loss: 1.491537\n",
      "Validation loss decreased (1.491562 --> 1.491537).         Saving model ...\n",
      "Epoch: 1348 \tTraining Loss: 1.085284 \tValidation Loss: 1.491514\n",
      "Validation loss decreased (1.491537 --> 1.491514).         Saving model ...\n",
      "Epoch: 1349 \tTraining Loss: 1.085277 \tValidation Loss: 1.491492\n",
      "Validation loss decreased (1.491514 --> 1.491492).         Saving model ...\n",
      "Epoch: 1350 \tTraining Loss: 1.085270 \tValidation Loss: 1.491468\n",
      "Validation loss decreased (1.491492 --> 1.491468).         Saving model ...\n",
      "Epoch: 1351 \tTraining Loss: 1.085262 \tValidation Loss: 1.491446\n",
      "Validation loss decreased (1.491468 --> 1.491446).         Saving model ...\n",
      "Epoch: 1352 \tTraining Loss: 1.085255 \tValidation Loss: 1.491423\n",
      "Validation loss decreased (1.491446 --> 1.491423).         Saving model ...\n",
      "Epoch: 1353 \tTraining Loss: 1.085248 \tValidation Loss: 1.491400\n",
      "Validation loss decreased (1.491423 --> 1.491400).         Saving model ...\n",
      "Epoch: 1354 \tTraining Loss: 1.085241 \tValidation Loss: 1.491378\n",
      "Validation loss decreased (1.491400 --> 1.491378).         Saving model ...\n",
      "Epoch: 1355 \tTraining Loss: 1.085234 \tValidation Loss: 1.491355\n",
      "Validation loss decreased (1.491378 --> 1.491355).         Saving model ...\n",
      "Epoch: 1356 \tTraining Loss: 1.085227 \tValidation Loss: 1.491331\n",
      "Validation loss decreased (1.491355 --> 1.491331).         Saving model ...\n",
      "Epoch: 1357 \tTraining Loss: 1.085220 \tValidation Loss: 1.491309\n",
      "Validation loss decreased (1.491331 --> 1.491309).         Saving model ...\n",
      "Epoch: 1358 \tTraining Loss: 1.085213 \tValidation Loss: 1.491287\n",
      "Validation loss decreased (1.491309 --> 1.491287).         Saving model ...\n",
      "Epoch: 1359 \tTraining Loss: 1.085206 \tValidation Loss: 1.491264\n",
      "Validation loss decreased (1.491287 --> 1.491264).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1360 \tTraining Loss: 1.085199 \tValidation Loss: 1.491242\n",
      "Validation loss decreased (1.491264 --> 1.491242).         Saving model ...\n",
      "Epoch: 1361 \tTraining Loss: 1.085192 \tValidation Loss: 1.491220\n",
      "Validation loss decreased (1.491242 --> 1.491220).         Saving model ...\n",
      "Epoch: 1362 \tTraining Loss: 1.085185 \tValidation Loss: 1.491197\n",
      "Validation loss decreased (1.491220 --> 1.491197).         Saving model ...\n",
      "Epoch: 1363 \tTraining Loss: 1.085178 \tValidation Loss: 1.491175\n",
      "Validation loss decreased (1.491197 --> 1.491175).         Saving model ...\n",
      "Epoch: 1364 \tTraining Loss: 1.085171 \tValidation Loss: 1.491152\n",
      "Validation loss decreased (1.491175 --> 1.491152).         Saving model ...\n",
      "Epoch: 1365 \tTraining Loss: 1.085164 \tValidation Loss: 1.491129\n",
      "Validation loss decreased (1.491152 --> 1.491129).         Saving model ...\n",
      "Epoch: 1366 \tTraining Loss: 1.085157 \tValidation Loss: 1.491107\n",
      "Validation loss decreased (1.491129 --> 1.491107).         Saving model ...\n",
      "Epoch: 1367 \tTraining Loss: 1.085150 \tValidation Loss: 1.491084\n",
      "Validation loss decreased (1.491107 --> 1.491084).         Saving model ...\n",
      "Epoch: 1368 \tTraining Loss: 1.085143 \tValidation Loss: 1.491061\n",
      "Validation loss decreased (1.491084 --> 1.491061).         Saving model ...\n",
      "Epoch: 1369 \tTraining Loss: 1.085136 \tValidation Loss: 1.491039\n",
      "Validation loss decreased (1.491061 --> 1.491039).         Saving model ...\n",
      "Epoch: 1370 \tTraining Loss: 1.085129 \tValidation Loss: 1.491016\n",
      "Validation loss decreased (1.491039 --> 1.491016).         Saving model ...\n",
      "Epoch: 1371 \tTraining Loss: 1.085122 \tValidation Loss: 1.490994\n",
      "Validation loss decreased (1.491016 --> 1.490994).         Saving model ...\n",
      "Epoch: 1372 \tTraining Loss: 1.085115 \tValidation Loss: 1.490971\n",
      "Validation loss decreased (1.490994 --> 1.490971).         Saving model ...\n",
      "Epoch: 1373 \tTraining Loss: 1.085108 \tValidation Loss: 1.490948\n",
      "Validation loss decreased (1.490971 --> 1.490948).         Saving model ...\n",
      "Epoch: 1374 \tTraining Loss: 1.085101 \tValidation Loss: 1.490926\n",
      "Validation loss decreased (1.490948 --> 1.490926).         Saving model ...\n",
      "Epoch: 1375 \tTraining Loss: 1.085094 \tValidation Loss: 1.490904\n",
      "Validation loss decreased (1.490926 --> 1.490904).         Saving model ...\n",
      "Epoch: 1376 \tTraining Loss: 1.085088 \tValidation Loss: 1.490882\n",
      "Validation loss decreased (1.490904 --> 1.490882).         Saving model ...\n",
      "Epoch: 1377 \tTraining Loss: 1.085081 \tValidation Loss: 1.490860\n",
      "Validation loss decreased (1.490882 --> 1.490860).         Saving model ...\n",
      "Epoch: 1378 \tTraining Loss: 1.085074 \tValidation Loss: 1.490837\n",
      "Validation loss decreased (1.490860 --> 1.490837).         Saving model ...\n",
      "Epoch: 1379 \tTraining Loss: 1.085067 \tValidation Loss: 1.490816\n",
      "Validation loss decreased (1.490837 --> 1.490816).         Saving model ...\n",
      "Epoch: 1380 \tTraining Loss: 1.085060 \tValidation Loss: 1.490792\n",
      "Validation loss decreased (1.490816 --> 1.490792).         Saving model ...\n",
      "Epoch: 1381 \tTraining Loss: 1.085053 \tValidation Loss: 1.490770\n",
      "Validation loss decreased (1.490792 --> 1.490770).         Saving model ...\n",
      "Epoch: 1382 \tTraining Loss: 1.085046 \tValidation Loss: 1.490748\n",
      "Validation loss decreased (1.490770 --> 1.490748).         Saving model ...\n",
      "Epoch: 1383 \tTraining Loss: 1.085039 \tValidation Loss: 1.490726\n",
      "Validation loss decreased (1.490748 --> 1.490726).         Saving model ...\n",
      "Epoch: 1384 \tTraining Loss: 1.085032 \tValidation Loss: 1.490704\n",
      "Validation loss decreased (1.490726 --> 1.490704).         Saving model ...\n",
      "Epoch: 1385 \tTraining Loss: 1.085026 \tValidation Loss: 1.490682\n",
      "Validation loss decreased (1.490704 --> 1.490682).         Saving model ...\n",
      "Epoch: 1386 \tTraining Loss: 1.085019 \tValidation Loss: 1.490659\n",
      "Validation loss decreased (1.490682 --> 1.490659).         Saving model ...\n",
      "Epoch: 1387 \tTraining Loss: 1.085012 \tValidation Loss: 1.490638\n",
      "Validation loss decreased (1.490659 --> 1.490638).         Saving model ...\n",
      "Epoch: 1388 \tTraining Loss: 1.085005 \tValidation Loss: 1.490616\n",
      "Validation loss decreased (1.490638 --> 1.490616).         Saving model ...\n",
      "Epoch: 1389 \tTraining Loss: 1.084998 \tValidation Loss: 1.490594\n",
      "Validation loss decreased (1.490616 --> 1.490594).         Saving model ...\n",
      "Epoch: 1390 \tTraining Loss: 1.084991 \tValidation Loss: 1.490572\n",
      "Validation loss decreased (1.490594 --> 1.490572).         Saving model ...\n",
      "Epoch: 1391 \tTraining Loss: 1.084985 \tValidation Loss: 1.490551\n",
      "Validation loss decreased (1.490572 --> 1.490551).         Saving model ...\n",
      "Epoch: 1392 \tTraining Loss: 1.084978 \tValidation Loss: 1.490529\n",
      "Validation loss decreased (1.490551 --> 1.490529).         Saving model ...\n",
      "Epoch: 1393 \tTraining Loss: 1.084971 \tValidation Loss: 1.490508\n",
      "Validation loss decreased (1.490529 --> 1.490508).         Saving model ...\n",
      "Epoch: 1394 \tTraining Loss: 1.084964 \tValidation Loss: 1.490487\n",
      "Validation loss decreased (1.490508 --> 1.490487).         Saving model ...\n",
      "Epoch: 1395 \tTraining Loss: 1.084957 \tValidation Loss: 1.490465\n",
      "Validation loss decreased (1.490487 --> 1.490465).         Saving model ...\n",
      "Epoch: 1396 \tTraining Loss: 1.084951 \tValidation Loss: 1.490445\n",
      "Validation loss decreased (1.490465 --> 1.490445).         Saving model ...\n",
      "Epoch: 1397 \tTraining Loss: 1.084944 \tValidation Loss: 1.490423\n",
      "Validation loss decreased (1.490445 --> 1.490423).         Saving model ...\n",
      "Epoch: 1398 \tTraining Loss: 1.084937 \tValidation Loss: 1.490402\n",
      "Validation loss decreased (1.490423 --> 1.490402).         Saving model ...\n",
      "Epoch: 1399 \tTraining Loss: 1.084930 \tValidation Loss: 1.490381\n",
      "Validation loss decreased (1.490402 --> 1.490381).         Saving model ...\n",
      "Epoch: 1400 \tTraining Loss: 1.084924 \tValidation Loss: 1.490360\n",
      "Validation loss decreased (1.490381 --> 1.490360).         Saving model ...\n",
      "Epoch: 1401 \tTraining Loss: 1.084917 \tValidation Loss: 1.490339\n",
      "Validation loss decreased (1.490360 --> 1.490339).         Saving model ...\n",
      "Epoch: 1402 \tTraining Loss: 1.084910 \tValidation Loss: 1.490319\n",
      "Validation loss decreased (1.490339 --> 1.490319).         Saving model ...\n",
      "Epoch: 1403 \tTraining Loss: 1.084903 \tValidation Loss: 1.490298\n",
      "Validation loss decreased (1.490319 --> 1.490298).         Saving model ...\n",
      "Epoch: 1404 \tTraining Loss: 1.084897 \tValidation Loss: 1.490276\n",
      "Validation loss decreased (1.490298 --> 1.490276).         Saving model ...\n",
      "Epoch: 1405 \tTraining Loss: 1.084890 \tValidation Loss: 1.490256\n",
      "Validation loss decreased (1.490276 --> 1.490256).         Saving model ...\n",
      "Epoch: 1406 \tTraining Loss: 1.084883 \tValidation Loss: 1.490235\n",
      "Validation loss decreased (1.490256 --> 1.490235).         Saving model ...\n",
      "Epoch: 1407 \tTraining Loss: 1.084876 \tValidation Loss: 1.490213\n",
      "Validation loss decreased (1.490235 --> 1.490213).         Saving model ...\n",
      "Epoch: 1408 \tTraining Loss: 1.084870 \tValidation Loss: 1.490193\n",
      "Validation loss decreased (1.490213 --> 1.490193).         Saving model ...\n",
      "Epoch: 1409 \tTraining Loss: 1.084863 \tValidation Loss: 1.490173\n",
      "Validation loss decreased (1.490193 --> 1.490173).         Saving model ...\n",
      "Epoch: 1410 \tTraining Loss: 1.084856 \tValidation Loss: 1.490152\n",
      "Validation loss decreased (1.490173 --> 1.490152).         Saving model ...\n",
      "Epoch: 1411 \tTraining Loss: 1.084850 \tValidation Loss: 1.490132\n",
      "Validation loss decreased (1.490152 --> 1.490132).         Saving model ...\n",
      "Epoch: 1412 \tTraining Loss: 1.084843 \tValidation Loss: 1.490112\n",
      "Validation loss decreased (1.490132 --> 1.490112).         Saving model ...\n",
      "Epoch: 1413 \tTraining Loss: 1.084836 \tValidation Loss: 1.490091\n",
      "Validation loss decreased (1.490112 --> 1.490091).         Saving model ...\n",
      "Epoch: 1414 \tTraining Loss: 1.084830 \tValidation Loss: 1.490070\n",
      "Validation loss decreased (1.490091 --> 1.490070).         Saving model ...\n",
      "Epoch: 1415 \tTraining Loss: 1.084823 \tValidation Loss: 1.490049\n",
      "Validation loss decreased (1.490070 --> 1.490049).         Saving model ...\n",
      "Epoch: 1416 \tTraining Loss: 1.084816 \tValidation Loss: 1.490029\n",
      "Validation loss decreased (1.490049 --> 1.490029).         Saving model ...\n",
      "Epoch: 1417 \tTraining Loss: 1.084810 \tValidation Loss: 1.490009\n",
      "Validation loss decreased (1.490029 --> 1.490009).         Saving model ...\n",
      "Epoch: 1418 \tTraining Loss: 1.084803 \tValidation Loss: 1.489988\n",
      "Validation loss decreased (1.490009 --> 1.489988).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1419 \tTraining Loss: 1.084796 \tValidation Loss: 1.489967\n",
      "Validation loss decreased (1.489988 --> 1.489967).         Saving model ...\n",
      "Epoch: 1420 \tTraining Loss: 1.084790 \tValidation Loss: 1.489947\n",
      "Validation loss decreased (1.489967 --> 1.489947).         Saving model ...\n",
      "Epoch: 1421 \tTraining Loss: 1.084783 \tValidation Loss: 1.489926\n",
      "Validation loss decreased (1.489947 --> 1.489926).         Saving model ...\n",
      "Epoch: 1422 \tTraining Loss: 1.084777 \tValidation Loss: 1.489906\n",
      "Validation loss decreased (1.489926 --> 1.489906).         Saving model ...\n",
      "Epoch: 1423 \tTraining Loss: 1.084770 \tValidation Loss: 1.489886\n",
      "Validation loss decreased (1.489906 --> 1.489886).         Saving model ...\n",
      "Epoch: 1424 \tTraining Loss: 1.084763 \tValidation Loss: 1.489864\n",
      "Validation loss decreased (1.489886 --> 1.489864).         Saving model ...\n",
      "Epoch: 1425 \tTraining Loss: 1.084757 \tValidation Loss: 1.489844\n",
      "Validation loss decreased (1.489864 --> 1.489844).         Saving model ...\n",
      "Epoch: 1426 \tTraining Loss: 1.084750 \tValidation Loss: 1.489823\n",
      "Validation loss decreased (1.489844 --> 1.489823).         Saving model ...\n",
      "Epoch: 1427 \tTraining Loss: 1.084744 \tValidation Loss: 1.489802\n",
      "Validation loss decreased (1.489823 --> 1.489802).         Saving model ...\n",
      "Epoch: 1428 \tTraining Loss: 1.084737 \tValidation Loss: 1.489781\n",
      "Validation loss decreased (1.489802 --> 1.489781).         Saving model ...\n",
      "Epoch: 1429 \tTraining Loss: 1.084730 \tValidation Loss: 1.489760\n",
      "Validation loss decreased (1.489781 --> 1.489760).         Saving model ...\n",
      "Epoch: 1430 \tTraining Loss: 1.084724 \tValidation Loss: 1.489741\n",
      "Validation loss decreased (1.489760 --> 1.489741).         Saving model ...\n",
      "Epoch: 1431 \tTraining Loss: 1.084717 \tValidation Loss: 1.489721\n",
      "Validation loss decreased (1.489741 --> 1.489721).         Saving model ...\n",
      "Epoch: 1432 \tTraining Loss: 1.084711 \tValidation Loss: 1.489700\n",
      "Validation loss decreased (1.489721 --> 1.489700).         Saving model ...\n",
      "Epoch: 1433 \tTraining Loss: 1.084704 \tValidation Loss: 1.489680\n",
      "Validation loss decreased (1.489700 --> 1.489680).         Saving model ...\n",
      "Epoch: 1434 \tTraining Loss: 1.084698 \tValidation Loss: 1.489661\n",
      "Validation loss decreased (1.489680 --> 1.489661).         Saving model ...\n",
      "Epoch: 1435 \tTraining Loss: 1.084691 \tValidation Loss: 1.489641\n",
      "Validation loss decreased (1.489661 --> 1.489641).         Saving model ...\n",
      "Epoch: 1436 \tTraining Loss: 1.084685 \tValidation Loss: 1.489622\n",
      "Validation loss decreased (1.489641 --> 1.489622).         Saving model ...\n",
      "Epoch: 1437 \tTraining Loss: 1.084678 \tValidation Loss: 1.489602\n",
      "Validation loss decreased (1.489622 --> 1.489602).         Saving model ...\n",
      "Epoch: 1438 \tTraining Loss: 1.084672 \tValidation Loss: 1.489581\n",
      "Validation loss decreased (1.489602 --> 1.489581).         Saving model ...\n",
      "Epoch: 1439 \tTraining Loss: 1.084665 \tValidation Loss: 1.489562\n",
      "Validation loss decreased (1.489581 --> 1.489562).         Saving model ...\n",
      "Epoch: 1440 \tTraining Loss: 1.084659 \tValidation Loss: 1.489542\n",
      "Validation loss decreased (1.489562 --> 1.489542).         Saving model ...\n",
      "Epoch: 1441 \tTraining Loss: 1.084652 \tValidation Loss: 1.489522\n",
      "Validation loss decreased (1.489542 --> 1.489522).         Saving model ...\n",
      "Epoch: 1442 \tTraining Loss: 1.084646 \tValidation Loss: 1.489503\n",
      "Validation loss decreased (1.489522 --> 1.489503).         Saving model ...\n",
      "Epoch: 1443 \tTraining Loss: 1.084639 \tValidation Loss: 1.489483\n",
      "Validation loss decreased (1.489503 --> 1.489483).         Saving model ...\n",
      "Epoch: 1444 \tTraining Loss: 1.084633 \tValidation Loss: 1.489465\n",
      "Validation loss decreased (1.489483 --> 1.489465).         Saving model ...\n",
      "Epoch: 1445 \tTraining Loss: 1.084626 \tValidation Loss: 1.489445\n",
      "Validation loss decreased (1.489465 --> 1.489445).         Saving model ...\n",
      "Epoch: 1446 \tTraining Loss: 1.084620 \tValidation Loss: 1.489427\n",
      "Validation loss decreased (1.489445 --> 1.489427).         Saving model ...\n",
      "Epoch: 1447 \tTraining Loss: 1.084613 \tValidation Loss: 1.489407\n",
      "Validation loss decreased (1.489427 --> 1.489407).         Saving model ...\n",
      "Epoch: 1448 \tTraining Loss: 1.084607 \tValidation Loss: 1.489388\n",
      "Validation loss decreased (1.489407 --> 1.489388).         Saving model ...\n",
      "Epoch: 1449 \tTraining Loss: 1.084600 \tValidation Loss: 1.489370\n",
      "Validation loss decreased (1.489388 --> 1.489370).         Saving model ...\n",
      "Epoch: 1450 \tTraining Loss: 1.084594 \tValidation Loss: 1.489351\n",
      "Validation loss decreased (1.489370 --> 1.489351).         Saving model ...\n",
      "Epoch: 1451 \tTraining Loss: 1.084587 \tValidation Loss: 1.489331\n",
      "Validation loss decreased (1.489351 --> 1.489331).         Saving model ...\n",
      "Epoch: 1452 \tTraining Loss: 1.084581 \tValidation Loss: 1.489313\n",
      "Validation loss decreased (1.489331 --> 1.489313).         Saving model ...\n",
      "Epoch: 1453 \tTraining Loss: 1.084574 \tValidation Loss: 1.489294\n",
      "Validation loss decreased (1.489313 --> 1.489294).         Saving model ...\n",
      "Epoch: 1454 \tTraining Loss: 1.084568 \tValidation Loss: 1.489275\n",
      "Validation loss decreased (1.489294 --> 1.489275).         Saving model ...\n",
      "Epoch: 1455 \tTraining Loss: 1.084562 \tValidation Loss: 1.489255\n",
      "Validation loss decreased (1.489275 --> 1.489255).         Saving model ...\n",
      "Epoch: 1456 \tTraining Loss: 1.084555 \tValidation Loss: 1.489236\n",
      "Validation loss decreased (1.489255 --> 1.489236).         Saving model ...\n",
      "Epoch: 1457 \tTraining Loss: 1.084549 \tValidation Loss: 1.489217\n",
      "Validation loss decreased (1.489236 --> 1.489217).         Saving model ...\n",
      "Epoch: 1458 \tTraining Loss: 1.084542 \tValidation Loss: 1.489198\n",
      "Validation loss decreased (1.489217 --> 1.489198).         Saving model ...\n",
      "Epoch: 1459 \tTraining Loss: 1.084536 \tValidation Loss: 1.489179\n",
      "Validation loss decreased (1.489198 --> 1.489179).         Saving model ...\n",
      "Epoch: 1460 \tTraining Loss: 1.084530 \tValidation Loss: 1.489161\n",
      "Validation loss decreased (1.489179 --> 1.489161).         Saving model ...\n",
      "Epoch: 1461 \tTraining Loss: 1.084523 \tValidation Loss: 1.489141\n",
      "Validation loss decreased (1.489161 --> 1.489141).         Saving model ...\n",
      "Epoch: 1462 \tTraining Loss: 1.084517 \tValidation Loss: 1.489123\n",
      "Validation loss decreased (1.489141 --> 1.489123).         Saving model ...\n",
      "Epoch: 1463 \tTraining Loss: 1.084511 \tValidation Loss: 1.489104\n",
      "Validation loss decreased (1.489123 --> 1.489104).         Saving model ...\n",
      "Epoch: 1464 \tTraining Loss: 1.084504 \tValidation Loss: 1.489086\n",
      "Validation loss decreased (1.489104 --> 1.489086).         Saving model ...\n",
      "Epoch: 1465 \tTraining Loss: 1.084498 \tValidation Loss: 1.489068\n",
      "Validation loss decreased (1.489086 --> 1.489068).         Saving model ...\n",
      "Epoch: 1466 \tTraining Loss: 1.084491 \tValidation Loss: 1.489049\n",
      "Validation loss decreased (1.489068 --> 1.489049).         Saving model ...\n",
      "Epoch: 1467 \tTraining Loss: 1.084485 \tValidation Loss: 1.489029\n",
      "Validation loss decreased (1.489049 --> 1.489029).         Saving model ...\n",
      "Epoch: 1468 \tTraining Loss: 1.084479 \tValidation Loss: 1.489011\n",
      "Validation loss decreased (1.489029 --> 1.489011).         Saving model ...\n",
      "Epoch: 1469 \tTraining Loss: 1.084472 \tValidation Loss: 1.488992\n",
      "Validation loss decreased (1.489011 --> 1.488992).         Saving model ...\n",
      "Epoch: 1470 \tTraining Loss: 1.084466 \tValidation Loss: 1.488973\n",
      "Validation loss decreased (1.488992 --> 1.488973).         Saving model ...\n",
      "Epoch: 1471 \tTraining Loss: 1.084460 \tValidation Loss: 1.488955\n",
      "Validation loss decreased (1.488973 --> 1.488955).         Saving model ...\n",
      "Epoch: 1472 \tTraining Loss: 1.084453 \tValidation Loss: 1.488936\n",
      "Validation loss decreased (1.488955 --> 1.488936).         Saving model ...\n",
      "Epoch: 1473 \tTraining Loss: 1.084447 \tValidation Loss: 1.488917\n",
      "Validation loss decreased (1.488936 --> 1.488917).         Saving model ...\n",
      "Epoch: 1474 \tTraining Loss: 1.084441 \tValidation Loss: 1.488899\n",
      "Validation loss decreased (1.488917 --> 1.488899).         Saving model ...\n",
      "Epoch: 1475 \tTraining Loss: 1.084435 \tValidation Loss: 1.488880\n",
      "Validation loss decreased (1.488899 --> 1.488880).         Saving model ...\n",
      "Epoch: 1476 \tTraining Loss: 1.084428 \tValidation Loss: 1.488862\n",
      "Validation loss decreased (1.488880 --> 1.488862).         Saving model ...\n",
      "Epoch: 1477 \tTraining Loss: 1.084422 \tValidation Loss: 1.488844\n",
      "Validation loss decreased (1.488862 --> 1.488844).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1478 \tTraining Loss: 1.084416 \tValidation Loss: 1.488826\n",
      "Validation loss decreased (1.488844 --> 1.488826).         Saving model ...\n",
      "Epoch: 1479 \tTraining Loss: 1.084409 \tValidation Loss: 1.488808\n",
      "Validation loss decreased (1.488826 --> 1.488808).         Saving model ...\n",
      "Epoch: 1480 \tTraining Loss: 1.084403 \tValidation Loss: 1.488788\n",
      "Validation loss decreased (1.488808 --> 1.488788).         Saving model ...\n",
      "Epoch: 1481 \tTraining Loss: 1.084397 \tValidation Loss: 1.488771\n",
      "Validation loss decreased (1.488788 --> 1.488771).         Saving model ...\n",
      "Epoch: 1482 \tTraining Loss: 1.084391 \tValidation Loss: 1.488752\n",
      "Validation loss decreased (1.488771 --> 1.488752).         Saving model ...\n",
      "Epoch: 1483 \tTraining Loss: 1.084384 \tValidation Loss: 1.488735\n",
      "Validation loss decreased (1.488752 --> 1.488735).         Saving model ...\n",
      "Epoch: 1484 \tTraining Loss: 1.084378 \tValidation Loss: 1.488717\n",
      "Validation loss decreased (1.488735 --> 1.488717).         Saving model ...\n",
      "Epoch: 1485 \tTraining Loss: 1.084372 \tValidation Loss: 1.488699\n",
      "Validation loss decreased (1.488717 --> 1.488699).         Saving model ...\n",
      "Epoch: 1486 \tTraining Loss: 1.084366 \tValidation Loss: 1.488681\n",
      "Validation loss decreased (1.488699 --> 1.488681).         Saving model ...\n",
      "Epoch: 1487 \tTraining Loss: 1.084359 \tValidation Loss: 1.488662\n",
      "Validation loss decreased (1.488681 --> 1.488662).         Saving model ...\n",
      "Epoch: 1488 \tTraining Loss: 1.084353 \tValidation Loss: 1.488644\n",
      "Validation loss decreased (1.488662 --> 1.488644).         Saving model ...\n",
      "Epoch: 1489 \tTraining Loss: 1.084347 \tValidation Loss: 1.488627\n",
      "Validation loss decreased (1.488644 --> 1.488627).         Saving model ...\n",
      "Epoch: 1490 \tTraining Loss: 1.084341 \tValidation Loss: 1.488609\n",
      "Validation loss decreased (1.488627 --> 1.488609).         Saving model ...\n",
      "Epoch: 1491 \tTraining Loss: 1.084335 \tValidation Loss: 1.488591\n",
      "Validation loss decreased (1.488609 --> 1.488591).         Saving model ...\n",
      "Epoch: 1492 \tTraining Loss: 1.084328 \tValidation Loss: 1.488573\n",
      "Validation loss decreased (1.488591 --> 1.488573).         Saving model ...\n",
      "Epoch: 1493 \tTraining Loss: 1.084322 \tValidation Loss: 1.488555\n",
      "Validation loss decreased (1.488573 --> 1.488555).         Saving model ...\n",
      "Epoch: 1494 \tTraining Loss: 1.084316 \tValidation Loss: 1.488538\n",
      "Validation loss decreased (1.488555 --> 1.488538).         Saving model ...\n",
      "Epoch: 1495 \tTraining Loss: 1.084310 \tValidation Loss: 1.488520\n",
      "Validation loss decreased (1.488538 --> 1.488520).         Saving model ...\n",
      "Epoch: 1496 \tTraining Loss: 1.084304 \tValidation Loss: 1.488502\n",
      "Validation loss decreased (1.488520 --> 1.488502).         Saving model ...\n",
      "Epoch: 1497 \tTraining Loss: 1.084297 \tValidation Loss: 1.488485\n",
      "Validation loss decreased (1.488502 --> 1.488485).         Saving model ...\n",
      "Epoch: 1498 \tTraining Loss: 1.084291 \tValidation Loss: 1.488466\n",
      "Validation loss decreased (1.488485 --> 1.488466).         Saving model ...\n",
      "Epoch: 1499 \tTraining Loss: 1.084285 \tValidation Loss: 1.488449\n",
      "Validation loss decreased (1.488466 --> 1.488449).         Saving model ...\n",
      "Epoch: 1500 \tTraining Loss: 1.084279 \tValidation Loss: 1.488432\n",
      "Validation loss decreased (1.488449 --> 1.488432).         Saving model ...\n",
      "Epoch: 1501 \tTraining Loss: 1.084273 \tValidation Loss: 1.488414\n",
      "Validation loss decreased (1.488432 --> 1.488414).         Saving model ...\n",
      "Epoch: 1502 \tTraining Loss: 1.084267 \tValidation Loss: 1.488398\n",
      "Validation loss decreased (1.488414 --> 1.488398).         Saving model ...\n",
      "Epoch: 1503 \tTraining Loss: 1.084260 \tValidation Loss: 1.488380\n",
      "Validation loss decreased (1.488398 --> 1.488380).         Saving model ...\n",
      "Epoch: 1504 \tTraining Loss: 1.084254 \tValidation Loss: 1.488363\n",
      "Validation loss decreased (1.488380 --> 1.488363).         Saving model ...\n",
      "Epoch: 1505 \tTraining Loss: 1.084248 \tValidation Loss: 1.488346\n",
      "Validation loss decreased (1.488363 --> 1.488346).         Saving model ...\n",
      "Epoch: 1506 \tTraining Loss: 1.084242 \tValidation Loss: 1.488329\n",
      "Validation loss decreased (1.488346 --> 1.488329).         Saving model ...\n",
      "Epoch: 1507 \tTraining Loss: 1.084236 \tValidation Loss: 1.488312\n",
      "Validation loss decreased (1.488329 --> 1.488312).         Saving model ...\n",
      "Epoch: 1508 \tTraining Loss: 1.084230 \tValidation Loss: 1.488295\n",
      "Validation loss decreased (1.488312 --> 1.488295).         Saving model ...\n",
      "Epoch: 1509 \tTraining Loss: 1.084224 \tValidation Loss: 1.488277\n",
      "Validation loss decreased (1.488295 --> 1.488277).         Saving model ...\n",
      "Epoch: 1510 \tTraining Loss: 1.084218 \tValidation Loss: 1.488260\n",
      "Validation loss decreased (1.488277 --> 1.488260).         Saving model ...\n",
      "Epoch: 1511 \tTraining Loss: 1.084212 \tValidation Loss: 1.488242\n",
      "Validation loss decreased (1.488260 --> 1.488242).         Saving model ...\n",
      "Epoch: 1512 \tTraining Loss: 1.084205 \tValidation Loss: 1.488225\n",
      "Validation loss decreased (1.488242 --> 1.488225).         Saving model ...\n",
      "Epoch: 1513 \tTraining Loss: 1.084199 \tValidation Loss: 1.488208\n",
      "Validation loss decreased (1.488225 --> 1.488208).         Saving model ...\n",
      "Epoch: 1514 \tTraining Loss: 1.084193 \tValidation Loss: 1.488191\n",
      "Validation loss decreased (1.488208 --> 1.488191).         Saving model ...\n",
      "Epoch: 1515 \tTraining Loss: 1.084187 \tValidation Loss: 1.488173\n",
      "Validation loss decreased (1.488191 --> 1.488173).         Saving model ...\n",
      "Epoch: 1516 \tTraining Loss: 1.084181 \tValidation Loss: 1.488156\n",
      "Validation loss decreased (1.488173 --> 1.488156).         Saving model ...\n",
      "Epoch: 1517 \tTraining Loss: 1.084175 \tValidation Loss: 1.488139\n",
      "Validation loss decreased (1.488156 --> 1.488139).         Saving model ...\n",
      "Epoch: 1518 \tTraining Loss: 1.084169 \tValidation Loss: 1.488122\n",
      "Validation loss decreased (1.488139 --> 1.488122).         Saving model ...\n",
      "Epoch: 1519 \tTraining Loss: 1.084163 \tValidation Loss: 1.488105\n",
      "Validation loss decreased (1.488122 --> 1.488105).         Saving model ...\n",
      "Epoch: 1520 \tTraining Loss: 1.084157 \tValidation Loss: 1.488088\n",
      "Validation loss decreased (1.488105 --> 1.488088).         Saving model ...\n",
      "Epoch: 1521 \tTraining Loss: 1.084151 \tValidation Loss: 1.488071\n",
      "Validation loss decreased (1.488088 --> 1.488071).         Saving model ...\n",
      "Epoch: 1522 \tTraining Loss: 1.084145 \tValidation Loss: 1.488054\n",
      "Validation loss decreased (1.488071 --> 1.488054).         Saving model ...\n",
      "Epoch: 1523 \tTraining Loss: 1.084139 \tValidation Loss: 1.488037\n",
      "Validation loss decreased (1.488054 --> 1.488037).         Saving model ...\n",
      "Epoch: 1524 \tTraining Loss: 1.084133 \tValidation Loss: 1.488021\n",
      "Validation loss decreased (1.488037 --> 1.488021).         Saving model ...\n",
      "Epoch: 1525 \tTraining Loss: 1.084127 \tValidation Loss: 1.488004\n",
      "Validation loss decreased (1.488021 --> 1.488004).         Saving model ...\n",
      "Epoch: 1526 \tTraining Loss: 1.084121 \tValidation Loss: 1.487987\n",
      "Validation loss decreased (1.488004 --> 1.487987).         Saving model ...\n",
      "Epoch: 1527 \tTraining Loss: 1.084115 \tValidation Loss: 1.487970\n",
      "Validation loss decreased (1.487987 --> 1.487970).         Saving model ...\n",
      "Epoch: 1528 \tTraining Loss: 1.084109 \tValidation Loss: 1.487953\n",
      "Validation loss decreased (1.487970 --> 1.487953).         Saving model ...\n",
      "Epoch: 1529 \tTraining Loss: 1.084103 \tValidation Loss: 1.487936\n",
      "Validation loss decreased (1.487953 --> 1.487936).         Saving model ...\n",
      "Epoch: 1530 \tTraining Loss: 1.084097 \tValidation Loss: 1.487919\n",
      "Validation loss decreased (1.487936 --> 1.487919).         Saving model ...\n",
      "Epoch: 1531 \tTraining Loss: 1.084091 \tValidation Loss: 1.487902\n",
      "Validation loss decreased (1.487919 --> 1.487902).         Saving model ...\n",
      "Epoch: 1532 \tTraining Loss: 1.084085 \tValidation Loss: 1.487885\n",
      "Validation loss decreased (1.487902 --> 1.487885).         Saving model ...\n",
      "Epoch: 1533 \tTraining Loss: 1.084079 \tValidation Loss: 1.487867\n",
      "Validation loss decreased (1.487885 --> 1.487867).         Saving model ...\n",
      "Epoch: 1534 \tTraining Loss: 1.084073 \tValidation Loss: 1.487851\n",
      "Validation loss decreased (1.487867 --> 1.487851).         Saving model ...\n",
      "Epoch: 1535 \tTraining Loss: 1.084067 \tValidation Loss: 1.487834\n",
      "Validation loss decreased (1.487851 --> 1.487834).         Saving model ...\n",
      "Epoch: 1536 \tTraining Loss: 1.084061 \tValidation Loss: 1.487817\n",
      "Validation loss decreased (1.487834 --> 1.487817).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1537 \tTraining Loss: 1.084055 \tValidation Loss: 1.487800\n",
      "Validation loss decreased (1.487817 --> 1.487800).         Saving model ...\n",
      "Epoch: 1538 \tTraining Loss: 1.084049 \tValidation Loss: 1.487784\n",
      "Validation loss decreased (1.487800 --> 1.487784).         Saving model ...\n",
      "Epoch: 1539 \tTraining Loss: 1.084043 \tValidation Loss: 1.487767\n",
      "Validation loss decreased (1.487784 --> 1.487767).         Saving model ...\n",
      "Epoch: 1540 \tTraining Loss: 1.084037 \tValidation Loss: 1.487751\n",
      "Validation loss decreased (1.487767 --> 1.487751).         Saving model ...\n",
      "Epoch: 1541 \tTraining Loss: 1.084031 \tValidation Loss: 1.487734\n",
      "Validation loss decreased (1.487751 --> 1.487734).         Saving model ...\n",
      "Epoch: 1542 \tTraining Loss: 1.084025 \tValidation Loss: 1.487718\n",
      "Validation loss decreased (1.487734 --> 1.487718).         Saving model ...\n",
      "Epoch: 1543 \tTraining Loss: 1.084019 \tValidation Loss: 1.487703\n",
      "Validation loss decreased (1.487718 --> 1.487703).         Saving model ...\n",
      "Epoch: 1544 \tTraining Loss: 1.084013 \tValidation Loss: 1.487687\n",
      "Validation loss decreased (1.487703 --> 1.487687).         Saving model ...\n",
      "Epoch: 1545 \tTraining Loss: 1.084007 \tValidation Loss: 1.487670\n",
      "Validation loss decreased (1.487687 --> 1.487670).         Saving model ...\n",
      "Epoch: 1546 \tTraining Loss: 1.084001 \tValidation Loss: 1.487655\n",
      "Validation loss decreased (1.487670 --> 1.487655).         Saving model ...\n",
      "Epoch: 1547 \tTraining Loss: 1.083996 \tValidation Loss: 1.487639\n",
      "Validation loss decreased (1.487655 --> 1.487639).         Saving model ...\n",
      "Epoch: 1548 \tTraining Loss: 1.083990 \tValidation Loss: 1.487622\n",
      "Validation loss decreased (1.487639 --> 1.487622).         Saving model ...\n",
      "Epoch: 1549 \tTraining Loss: 1.083984 \tValidation Loss: 1.487607\n",
      "Validation loss decreased (1.487622 --> 1.487607).         Saving model ...\n",
      "Epoch: 1550 \tTraining Loss: 1.083978 \tValidation Loss: 1.487590\n",
      "Validation loss decreased (1.487607 --> 1.487590).         Saving model ...\n",
      "Epoch: 1551 \tTraining Loss: 1.083972 \tValidation Loss: 1.487575\n",
      "Validation loss decreased (1.487590 --> 1.487575).         Saving model ...\n",
      "Epoch: 1552 \tTraining Loss: 1.083966 \tValidation Loss: 1.487559\n",
      "Validation loss decreased (1.487575 --> 1.487559).         Saving model ...\n",
      "Epoch: 1553 \tTraining Loss: 1.083960 \tValidation Loss: 1.487543\n",
      "Validation loss decreased (1.487559 --> 1.487543).         Saving model ...\n",
      "Epoch: 1554 \tTraining Loss: 1.083954 \tValidation Loss: 1.487527\n",
      "Validation loss decreased (1.487543 --> 1.487527).         Saving model ...\n",
      "Epoch: 1555 \tTraining Loss: 1.083948 \tValidation Loss: 1.487512\n",
      "Validation loss decreased (1.487527 --> 1.487512).         Saving model ...\n",
      "Epoch: 1556 \tTraining Loss: 1.083943 \tValidation Loss: 1.487496\n",
      "Validation loss decreased (1.487512 --> 1.487496).         Saving model ...\n",
      "Epoch: 1557 \tTraining Loss: 1.083937 \tValidation Loss: 1.487480\n",
      "Validation loss decreased (1.487496 --> 1.487480).         Saving model ...\n",
      "Epoch: 1558 \tTraining Loss: 1.083931 \tValidation Loss: 1.487465\n",
      "Validation loss decreased (1.487480 --> 1.487465).         Saving model ...\n",
      "Epoch: 1559 \tTraining Loss: 1.083925 \tValidation Loss: 1.487450\n",
      "Validation loss decreased (1.487465 --> 1.487450).         Saving model ...\n",
      "Epoch: 1560 \tTraining Loss: 1.083919 \tValidation Loss: 1.487435\n",
      "Validation loss decreased (1.487450 --> 1.487435).         Saving model ...\n",
      "Epoch: 1561 \tTraining Loss: 1.083913 \tValidation Loss: 1.487419\n",
      "Validation loss decreased (1.487435 --> 1.487419).         Saving model ...\n",
      "Epoch: 1562 \tTraining Loss: 1.083908 \tValidation Loss: 1.487404\n",
      "Validation loss decreased (1.487419 --> 1.487404).         Saving model ...\n",
      "Epoch: 1563 \tTraining Loss: 1.083902 \tValidation Loss: 1.487388\n",
      "Validation loss decreased (1.487404 --> 1.487388).         Saving model ...\n",
      "Epoch: 1564 \tTraining Loss: 1.083896 \tValidation Loss: 1.487373\n",
      "Validation loss decreased (1.487388 --> 1.487373).         Saving model ...\n",
      "Epoch: 1565 \tTraining Loss: 1.083890 \tValidation Loss: 1.487358\n",
      "Validation loss decreased (1.487373 --> 1.487358).         Saving model ...\n",
      "Epoch: 1566 \tTraining Loss: 1.083884 \tValidation Loss: 1.487342\n",
      "Validation loss decreased (1.487358 --> 1.487342).         Saving model ...\n",
      "Epoch: 1567 \tTraining Loss: 1.083878 \tValidation Loss: 1.487327\n",
      "Validation loss decreased (1.487342 --> 1.487327).         Saving model ...\n",
      "Epoch: 1568 \tTraining Loss: 1.083873 \tValidation Loss: 1.487312\n",
      "Validation loss decreased (1.487327 --> 1.487312).         Saving model ...\n",
      "Epoch: 1569 \tTraining Loss: 1.083867 \tValidation Loss: 1.487297\n",
      "Validation loss decreased (1.487312 --> 1.487297).         Saving model ...\n",
      "Epoch: 1570 \tTraining Loss: 1.083861 \tValidation Loss: 1.487282\n",
      "Validation loss decreased (1.487297 --> 1.487282).         Saving model ...\n",
      "Epoch: 1571 \tTraining Loss: 1.083855 \tValidation Loss: 1.487266\n",
      "Validation loss decreased (1.487282 --> 1.487266).         Saving model ...\n",
      "Epoch: 1572 \tTraining Loss: 1.083849 \tValidation Loss: 1.487251\n",
      "Validation loss decreased (1.487266 --> 1.487251).         Saving model ...\n",
      "Epoch: 1573 \tTraining Loss: 1.083844 \tValidation Loss: 1.487235\n",
      "Validation loss decreased (1.487251 --> 1.487235).         Saving model ...\n",
      "Epoch: 1574 \tTraining Loss: 1.083838 \tValidation Loss: 1.487220\n",
      "Validation loss decreased (1.487235 --> 1.487220).         Saving model ...\n",
      "Epoch: 1575 \tTraining Loss: 1.083832 \tValidation Loss: 1.487204\n",
      "Validation loss decreased (1.487220 --> 1.487204).         Saving model ...\n",
      "Epoch: 1576 \tTraining Loss: 1.083826 \tValidation Loss: 1.487190\n",
      "Validation loss decreased (1.487204 --> 1.487190).         Saving model ...\n",
      "Epoch: 1577 \tTraining Loss: 1.083821 \tValidation Loss: 1.487175\n",
      "Validation loss decreased (1.487190 --> 1.487175).         Saving model ...\n",
      "Epoch: 1578 \tTraining Loss: 1.083815 \tValidation Loss: 1.487160\n",
      "Validation loss decreased (1.487175 --> 1.487160).         Saving model ...\n",
      "Epoch: 1579 \tTraining Loss: 1.083809 \tValidation Loss: 1.487143\n",
      "Validation loss decreased (1.487160 --> 1.487143).         Saving model ...\n",
      "Epoch: 1580 \tTraining Loss: 1.083803 \tValidation Loss: 1.487128\n",
      "Validation loss decreased (1.487143 --> 1.487128).         Saving model ...\n",
      "Epoch: 1581 \tTraining Loss: 1.083798 \tValidation Loss: 1.487113\n",
      "Validation loss decreased (1.487128 --> 1.487113).         Saving model ...\n",
      "Epoch: 1582 \tTraining Loss: 1.083792 \tValidation Loss: 1.487098\n",
      "Validation loss decreased (1.487113 --> 1.487098).         Saving model ...\n",
      "Epoch: 1583 \tTraining Loss: 1.083786 \tValidation Loss: 1.487083\n",
      "Validation loss decreased (1.487098 --> 1.487083).         Saving model ...\n",
      "Epoch: 1584 \tTraining Loss: 1.083781 \tValidation Loss: 1.487068\n",
      "Validation loss decreased (1.487083 --> 1.487068).         Saving model ...\n",
      "Epoch: 1585 \tTraining Loss: 1.083775 \tValidation Loss: 1.487053\n",
      "Validation loss decreased (1.487068 --> 1.487053).         Saving model ...\n",
      "Epoch: 1586 \tTraining Loss: 1.083769 \tValidation Loss: 1.487038\n",
      "Validation loss decreased (1.487053 --> 1.487038).         Saving model ...\n",
      "Epoch: 1587 \tTraining Loss: 1.083763 \tValidation Loss: 1.487023\n",
      "Validation loss decreased (1.487038 --> 1.487023).         Saving model ...\n",
      "Epoch: 1588 \tTraining Loss: 1.083758 \tValidation Loss: 1.487009\n",
      "Validation loss decreased (1.487023 --> 1.487009).         Saving model ...\n",
      "Epoch: 1589 \tTraining Loss: 1.083752 \tValidation Loss: 1.486994\n",
      "Validation loss decreased (1.487009 --> 1.486994).         Saving model ...\n",
      "Epoch: 1590 \tTraining Loss: 1.083746 \tValidation Loss: 1.486979\n",
      "Validation loss decreased (1.486994 --> 1.486979).         Saving model ...\n",
      "Epoch: 1591 \tTraining Loss: 1.083741 \tValidation Loss: 1.486965\n",
      "Validation loss decreased (1.486979 --> 1.486965).         Saving model ...\n",
      "Epoch: 1592 \tTraining Loss: 1.083735 \tValidation Loss: 1.486951\n",
      "Validation loss decreased (1.486965 --> 1.486951).         Saving model ...\n",
      "Epoch: 1593 \tTraining Loss: 1.083729 \tValidation Loss: 1.486935\n",
      "Validation loss decreased (1.486951 --> 1.486935).         Saving model ...\n",
      "Epoch: 1594 \tTraining Loss: 1.083724 \tValidation Loss: 1.486921\n",
      "Validation loss decreased (1.486935 --> 1.486921).         Saving model ...\n",
      "Epoch: 1595 \tTraining Loss: 1.083718 \tValidation Loss: 1.486906\n",
      "Validation loss decreased (1.486921 --> 1.486906).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1596 \tTraining Loss: 1.083712 \tValidation Loss: 1.486891\n",
      "Validation loss decreased (1.486906 --> 1.486891).         Saving model ...\n",
      "Epoch: 1597 \tTraining Loss: 1.083707 \tValidation Loss: 1.486876\n",
      "Validation loss decreased (1.486891 --> 1.486876).         Saving model ...\n",
      "Epoch: 1598 \tTraining Loss: 1.083701 \tValidation Loss: 1.486862\n",
      "Validation loss decreased (1.486876 --> 1.486862).         Saving model ...\n",
      "Epoch: 1599 \tTraining Loss: 1.083695 \tValidation Loss: 1.486846\n",
      "Validation loss decreased (1.486862 --> 1.486846).         Saving model ...\n",
      "Epoch: 1600 \tTraining Loss: 1.083690 \tValidation Loss: 1.486832\n",
      "Validation loss decreased (1.486846 --> 1.486832).         Saving model ...\n",
      "Epoch: 1601 \tTraining Loss: 1.083684 \tValidation Loss: 1.486818\n",
      "Validation loss decreased (1.486832 --> 1.486818).         Saving model ...\n",
      "Epoch: 1602 \tTraining Loss: 1.083678 \tValidation Loss: 1.486803\n",
      "Validation loss decreased (1.486818 --> 1.486803).         Saving model ...\n",
      "Epoch: 1603 \tTraining Loss: 1.083673 \tValidation Loss: 1.486788\n",
      "Validation loss decreased (1.486803 --> 1.486788).         Saving model ...\n",
      "Epoch: 1604 \tTraining Loss: 1.083667 \tValidation Loss: 1.486775\n",
      "Validation loss decreased (1.486788 --> 1.486775).         Saving model ...\n",
      "Epoch: 1605 \tTraining Loss: 1.083661 \tValidation Loss: 1.486760\n",
      "Validation loss decreased (1.486775 --> 1.486760).         Saving model ...\n",
      "Epoch: 1606 \tTraining Loss: 1.083656 \tValidation Loss: 1.486745\n",
      "Validation loss decreased (1.486760 --> 1.486745).         Saving model ...\n",
      "Epoch: 1607 \tTraining Loss: 1.083650 \tValidation Loss: 1.486731\n",
      "Validation loss decreased (1.486745 --> 1.486731).         Saving model ...\n",
      "Epoch: 1608 \tTraining Loss: 1.083645 \tValidation Loss: 1.486717\n",
      "Validation loss decreased (1.486731 --> 1.486717).         Saving model ...\n",
      "Epoch: 1609 \tTraining Loss: 1.083639 \tValidation Loss: 1.486703\n",
      "Validation loss decreased (1.486717 --> 1.486703).         Saving model ...\n",
      "Epoch: 1610 \tTraining Loss: 1.083633 \tValidation Loss: 1.486689\n",
      "Validation loss decreased (1.486703 --> 1.486689).         Saving model ...\n",
      "Epoch: 1611 \tTraining Loss: 1.083628 \tValidation Loss: 1.486675\n",
      "Validation loss decreased (1.486689 --> 1.486675).         Saving model ...\n",
      "Epoch: 1612 \tTraining Loss: 1.083622 \tValidation Loss: 1.486660\n",
      "Validation loss decreased (1.486675 --> 1.486660).         Saving model ...\n",
      "Epoch: 1613 \tTraining Loss: 1.083617 \tValidation Loss: 1.486646\n",
      "Validation loss decreased (1.486660 --> 1.486646).         Saving model ...\n",
      "Epoch: 1614 \tTraining Loss: 1.083611 \tValidation Loss: 1.486632\n",
      "Validation loss decreased (1.486646 --> 1.486632).         Saving model ...\n",
      "Epoch: 1615 \tTraining Loss: 1.083606 \tValidation Loss: 1.486617\n",
      "Validation loss decreased (1.486632 --> 1.486617).         Saving model ...\n",
      "Epoch: 1616 \tTraining Loss: 1.083600 \tValidation Loss: 1.486604\n",
      "Validation loss decreased (1.486617 --> 1.486604).         Saving model ...\n",
      "Epoch: 1617 \tTraining Loss: 1.083594 \tValidation Loss: 1.486589\n",
      "Validation loss decreased (1.486604 --> 1.486589).         Saving model ...\n",
      "Epoch: 1618 \tTraining Loss: 1.083589 \tValidation Loss: 1.486575\n",
      "Validation loss decreased (1.486589 --> 1.486575).         Saving model ...\n",
      "Epoch: 1619 \tTraining Loss: 1.083583 \tValidation Loss: 1.486560\n",
      "Validation loss decreased (1.486575 --> 1.486560).         Saving model ...\n",
      "Epoch: 1620 \tTraining Loss: 1.083578 \tValidation Loss: 1.486547\n",
      "Validation loss decreased (1.486560 --> 1.486547).         Saving model ...\n",
      "Epoch: 1621 \tTraining Loss: 1.083572 \tValidation Loss: 1.486532\n",
      "Validation loss decreased (1.486547 --> 1.486532).         Saving model ...\n",
      "Epoch: 1622 \tTraining Loss: 1.083567 \tValidation Loss: 1.486518\n",
      "Validation loss decreased (1.486532 --> 1.486518).         Saving model ...\n",
      "Epoch: 1623 \tTraining Loss: 1.083561 \tValidation Loss: 1.486504\n",
      "Validation loss decreased (1.486518 --> 1.486504).         Saving model ...\n",
      "Epoch: 1624 \tTraining Loss: 1.083556 \tValidation Loss: 1.486490\n",
      "Validation loss decreased (1.486504 --> 1.486490).         Saving model ...\n",
      "Epoch: 1625 \tTraining Loss: 1.083550 \tValidation Loss: 1.486476\n",
      "Validation loss decreased (1.486490 --> 1.486476).         Saving model ...\n",
      "Epoch: 1626 \tTraining Loss: 1.083545 \tValidation Loss: 1.486461\n",
      "Validation loss decreased (1.486476 --> 1.486461).         Saving model ...\n",
      "Epoch: 1627 \tTraining Loss: 1.083539 \tValidation Loss: 1.486447\n",
      "Validation loss decreased (1.486461 --> 1.486447).         Saving model ...\n",
      "Epoch: 1628 \tTraining Loss: 1.083534 \tValidation Loss: 1.486433\n",
      "Validation loss decreased (1.486447 --> 1.486433).         Saving model ...\n",
      "Epoch: 1629 \tTraining Loss: 1.083528 \tValidation Loss: 1.486419\n",
      "Validation loss decreased (1.486433 --> 1.486419).         Saving model ...\n",
      "Epoch: 1630 \tTraining Loss: 1.083523 \tValidation Loss: 1.486405\n",
      "Validation loss decreased (1.486419 --> 1.486405).         Saving model ...\n",
      "Epoch: 1631 \tTraining Loss: 1.083517 \tValidation Loss: 1.486391\n",
      "Validation loss decreased (1.486405 --> 1.486391).         Saving model ...\n",
      "Epoch: 1632 \tTraining Loss: 1.083512 \tValidation Loss: 1.486377\n",
      "Validation loss decreased (1.486391 --> 1.486377).         Saving model ...\n",
      "Epoch: 1633 \tTraining Loss: 1.083506 \tValidation Loss: 1.486363\n",
      "Validation loss decreased (1.486377 --> 1.486363).         Saving model ...\n",
      "Epoch: 1634 \tTraining Loss: 1.083501 \tValidation Loss: 1.486351\n",
      "Validation loss decreased (1.486363 --> 1.486351).         Saving model ...\n",
      "Epoch: 1635 \tTraining Loss: 1.083495 \tValidation Loss: 1.486337\n",
      "Validation loss decreased (1.486351 --> 1.486337).         Saving model ...\n",
      "Epoch: 1636 \tTraining Loss: 1.083490 \tValidation Loss: 1.486323\n",
      "Validation loss decreased (1.486337 --> 1.486323).         Saving model ...\n",
      "Epoch: 1637 \tTraining Loss: 1.083484 \tValidation Loss: 1.486310\n",
      "Validation loss decreased (1.486323 --> 1.486310).         Saving model ...\n",
      "Epoch: 1638 \tTraining Loss: 1.083479 \tValidation Loss: 1.486296\n",
      "Validation loss decreased (1.486310 --> 1.486296).         Saving model ...\n",
      "Epoch: 1639 \tTraining Loss: 1.083473 \tValidation Loss: 1.486282\n",
      "Validation loss decreased (1.486296 --> 1.486282).         Saving model ...\n",
      "Epoch: 1640 \tTraining Loss: 1.083468 \tValidation Loss: 1.486269\n",
      "Validation loss decreased (1.486282 --> 1.486269).         Saving model ...\n",
      "Epoch: 1641 \tTraining Loss: 1.083462 \tValidation Loss: 1.486254\n",
      "Validation loss decreased (1.486269 --> 1.486254).         Saving model ...\n",
      "Epoch: 1642 \tTraining Loss: 1.083457 \tValidation Loss: 1.486241\n",
      "Validation loss decreased (1.486254 --> 1.486241).         Saving model ...\n",
      "Epoch: 1643 \tTraining Loss: 1.083451 \tValidation Loss: 1.486227\n",
      "Validation loss decreased (1.486241 --> 1.486227).         Saving model ...\n",
      "Epoch: 1644 \tTraining Loss: 1.083446 \tValidation Loss: 1.486214\n",
      "Validation loss decreased (1.486227 --> 1.486214).         Saving model ...\n",
      "Epoch: 1645 \tTraining Loss: 1.083441 \tValidation Loss: 1.486200\n",
      "Validation loss decreased (1.486214 --> 1.486200).         Saving model ...\n",
      "Epoch: 1646 \tTraining Loss: 1.083435 \tValidation Loss: 1.486187\n",
      "Validation loss decreased (1.486200 --> 1.486187).         Saving model ...\n",
      "Epoch: 1647 \tTraining Loss: 1.083430 \tValidation Loss: 1.486173\n",
      "Validation loss decreased (1.486187 --> 1.486173).         Saving model ...\n",
      "Epoch: 1648 \tTraining Loss: 1.083424 \tValidation Loss: 1.486160\n",
      "Validation loss decreased (1.486173 --> 1.486160).         Saving model ...\n",
      "Epoch: 1649 \tTraining Loss: 1.083419 \tValidation Loss: 1.486146\n",
      "Validation loss decreased (1.486160 --> 1.486146).         Saving model ...\n",
      "Epoch: 1650 \tTraining Loss: 1.083413 \tValidation Loss: 1.486132\n",
      "Validation loss decreased (1.486146 --> 1.486132).         Saving model ...\n",
      "Epoch: 1651 \tTraining Loss: 1.083408 \tValidation Loss: 1.486119\n",
      "Validation loss decreased (1.486132 --> 1.486119).         Saving model ...\n",
      "Epoch: 1652 \tTraining Loss: 1.083403 \tValidation Loss: 1.486106\n",
      "Validation loss decreased (1.486119 --> 1.486106).         Saving model ...\n",
      "Epoch: 1653 \tTraining Loss: 1.083397 \tValidation Loss: 1.486093\n",
      "Validation loss decreased (1.486106 --> 1.486093).         Saving model ...\n",
      "Epoch: 1654 \tTraining Loss: 1.083392 \tValidation Loss: 1.486079\n",
      "Validation loss decreased (1.486093 --> 1.486079).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1655 \tTraining Loss: 1.083386 \tValidation Loss: 1.486065\n",
      "Validation loss decreased (1.486079 --> 1.486065).         Saving model ...\n",
      "Epoch: 1656 \tTraining Loss: 1.083381 \tValidation Loss: 1.486052\n",
      "Validation loss decreased (1.486065 --> 1.486052).         Saving model ...\n",
      "Epoch: 1657 \tTraining Loss: 1.083376 \tValidation Loss: 1.486039\n",
      "Validation loss decreased (1.486052 --> 1.486039).         Saving model ...\n",
      "Epoch: 1658 \tTraining Loss: 1.083370 \tValidation Loss: 1.486025\n",
      "Validation loss decreased (1.486039 --> 1.486025).         Saving model ...\n",
      "Epoch: 1659 \tTraining Loss: 1.083365 \tValidation Loss: 1.486012\n",
      "Validation loss decreased (1.486025 --> 1.486012).         Saving model ...\n",
      "Epoch: 1660 \tTraining Loss: 1.083359 \tValidation Loss: 1.485999\n",
      "Validation loss decreased (1.486012 --> 1.485999).         Saving model ...\n",
      "Epoch: 1661 \tTraining Loss: 1.083354 \tValidation Loss: 1.485986\n",
      "Validation loss decreased (1.485999 --> 1.485986).         Saving model ...\n",
      "Epoch: 1662 \tTraining Loss: 1.083349 \tValidation Loss: 1.485973\n",
      "Validation loss decreased (1.485986 --> 1.485973).         Saving model ...\n",
      "Epoch: 1663 \tTraining Loss: 1.083343 \tValidation Loss: 1.485960\n",
      "Validation loss decreased (1.485973 --> 1.485960).         Saving model ...\n",
      "Epoch: 1664 \tTraining Loss: 1.083338 \tValidation Loss: 1.485947\n",
      "Validation loss decreased (1.485960 --> 1.485947).         Saving model ...\n",
      "Epoch: 1665 \tTraining Loss: 1.083333 \tValidation Loss: 1.485935\n",
      "Validation loss decreased (1.485947 --> 1.485935).         Saving model ...\n",
      "Epoch: 1666 \tTraining Loss: 1.083327 \tValidation Loss: 1.485921\n",
      "Validation loss decreased (1.485935 --> 1.485921).         Saving model ...\n",
      "Epoch: 1667 \tTraining Loss: 1.083322 \tValidation Loss: 1.485909\n",
      "Validation loss decreased (1.485921 --> 1.485909).         Saving model ...\n",
      "Epoch: 1668 \tTraining Loss: 1.083317 \tValidation Loss: 1.485896\n",
      "Validation loss decreased (1.485909 --> 1.485896).         Saving model ...\n",
      "Epoch: 1669 \tTraining Loss: 1.083311 \tValidation Loss: 1.485884\n",
      "Validation loss decreased (1.485896 --> 1.485884).         Saving model ...\n",
      "Epoch: 1670 \tTraining Loss: 1.083306 \tValidation Loss: 1.485871\n",
      "Validation loss decreased (1.485884 --> 1.485871).         Saving model ...\n",
      "Epoch: 1671 \tTraining Loss: 1.083301 \tValidation Loss: 1.485858\n",
      "Validation loss decreased (1.485871 --> 1.485858).         Saving model ...\n",
      "Epoch: 1672 \tTraining Loss: 1.083295 \tValidation Loss: 1.485845\n",
      "Validation loss decreased (1.485858 --> 1.485845).         Saving model ...\n",
      "Epoch: 1673 \tTraining Loss: 1.083290 \tValidation Loss: 1.485833\n",
      "Validation loss decreased (1.485845 --> 1.485833).         Saving model ...\n",
      "Epoch: 1674 \tTraining Loss: 1.083285 \tValidation Loss: 1.485821\n",
      "Validation loss decreased (1.485833 --> 1.485821).         Saving model ...\n",
      "Epoch: 1675 \tTraining Loss: 1.083279 \tValidation Loss: 1.485807\n",
      "Validation loss decreased (1.485821 --> 1.485807).         Saving model ...\n",
      "Epoch: 1676 \tTraining Loss: 1.083274 \tValidation Loss: 1.485794\n",
      "Validation loss decreased (1.485807 --> 1.485794).         Saving model ...\n",
      "Epoch: 1677 \tTraining Loss: 1.083269 \tValidation Loss: 1.485782\n",
      "Validation loss decreased (1.485794 --> 1.485782).         Saving model ...\n",
      "Epoch: 1678 \tTraining Loss: 1.083264 \tValidation Loss: 1.485769\n",
      "Validation loss decreased (1.485782 --> 1.485769).         Saving model ...\n",
      "Epoch: 1679 \tTraining Loss: 1.083258 \tValidation Loss: 1.485757\n",
      "Validation loss decreased (1.485769 --> 1.485757).         Saving model ...\n",
      "Epoch: 1680 \tTraining Loss: 1.083253 \tValidation Loss: 1.485744\n",
      "Validation loss decreased (1.485757 --> 1.485744).         Saving model ...\n",
      "Epoch: 1681 \tTraining Loss: 1.083248 \tValidation Loss: 1.485732\n",
      "Validation loss decreased (1.485744 --> 1.485732).         Saving model ...\n",
      "Epoch: 1682 \tTraining Loss: 1.083242 \tValidation Loss: 1.485719\n",
      "Validation loss decreased (1.485732 --> 1.485719).         Saving model ...\n",
      "Epoch: 1683 \tTraining Loss: 1.083237 \tValidation Loss: 1.485706\n",
      "Validation loss decreased (1.485719 --> 1.485706).         Saving model ...\n",
      "Epoch: 1684 \tTraining Loss: 1.083232 \tValidation Loss: 1.485693\n",
      "Validation loss decreased (1.485706 --> 1.485693).         Saving model ...\n",
      "Epoch: 1685 \tTraining Loss: 1.083227 \tValidation Loss: 1.485681\n",
      "Validation loss decreased (1.485693 --> 1.485681).         Saving model ...\n",
      "Epoch: 1686 \tTraining Loss: 1.083221 \tValidation Loss: 1.485669\n",
      "Validation loss decreased (1.485681 --> 1.485669).         Saving model ...\n",
      "Epoch: 1687 \tTraining Loss: 1.083216 \tValidation Loss: 1.485657\n",
      "Validation loss decreased (1.485669 --> 1.485657).         Saving model ...\n",
      "Epoch: 1688 \tTraining Loss: 1.083211 \tValidation Loss: 1.485645\n",
      "Validation loss decreased (1.485657 --> 1.485645).         Saving model ...\n",
      "Epoch: 1689 \tTraining Loss: 1.083206 \tValidation Loss: 1.485633\n",
      "Validation loss decreased (1.485645 --> 1.485633).         Saving model ...\n",
      "Epoch: 1690 \tTraining Loss: 1.083200 \tValidation Loss: 1.485621\n",
      "Validation loss decreased (1.485633 --> 1.485621).         Saving model ...\n",
      "Epoch: 1691 \tTraining Loss: 1.083195 \tValidation Loss: 1.485608\n",
      "Validation loss decreased (1.485621 --> 1.485608).         Saving model ...\n",
      "Epoch: 1692 \tTraining Loss: 1.083190 \tValidation Loss: 1.485596\n",
      "Validation loss decreased (1.485608 --> 1.485596).         Saving model ...\n",
      "Epoch: 1693 \tTraining Loss: 1.083185 \tValidation Loss: 1.485584\n",
      "Validation loss decreased (1.485596 --> 1.485584).         Saving model ...\n",
      "Epoch: 1694 \tTraining Loss: 1.083179 \tValidation Loss: 1.485572\n",
      "Validation loss decreased (1.485584 --> 1.485572).         Saving model ...\n",
      "Epoch: 1695 \tTraining Loss: 1.083174 \tValidation Loss: 1.485560\n",
      "Validation loss decreased (1.485572 --> 1.485560).         Saving model ...\n",
      "Epoch: 1696 \tTraining Loss: 1.083169 \tValidation Loss: 1.485550\n",
      "Validation loss decreased (1.485560 --> 1.485550).         Saving model ...\n",
      "Epoch: 1697 \tTraining Loss: 1.083164 \tValidation Loss: 1.485536\n",
      "Validation loss decreased (1.485550 --> 1.485536).         Saving model ...\n",
      "Epoch: 1698 \tTraining Loss: 1.083159 \tValidation Loss: 1.485524\n",
      "Validation loss decreased (1.485536 --> 1.485524).         Saving model ...\n",
      "Epoch: 1699 \tTraining Loss: 1.083153 \tValidation Loss: 1.485512\n",
      "Validation loss decreased (1.485524 --> 1.485512).         Saving model ...\n",
      "Epoch: 1700 \tTraining Loss: 1.083148 \tValidation Loss: 1.485499\n",
      "Validation loss decreased (1.485512 --> 1.485499).         Saving model ...\n",
      "Epoch: 1701 \tTraining Loss: 1.083143 \tValidation Loss: 1.485486\n",
      "Validation loss decreased (1.485499 --> 1.485486).         Saving model ...\n",
      "Epoch: 1702 \tTraining Loss: 1.083138 \tValidation Loss: 1.485475\n",
      "Validation loss decreased (1.485486 --> 1.485475).         Saving model ...\n",
      "Epoch: 1703 \tTraining Loss: 1.083133 \tValidation Loss: 1.485462\n",
      "Validation loss decreased (1.485475 --> 1.485462).         Saving model ...\n",
      "Epoch: 1704 \tTraining Loss: 1.083127 \tValidation Loss: 1.485450\n",
      "Validation loss decreased (1.485462 --> 1.485450).         Saving model ...\n",
      "Epoch: 1705 \tTraining Loss: 1.083122 \tValidation Loss: 1.485438\n",
      "Validation loss decreased (1.485450 --> 1.485438).         Saving model ...\n",
      "Epoch: 1706 \tTraining Loss: 1.083117 \tValidation Loss: 1.485426\n",
      "Validation loss decreased (1.485438 --> 1.485426).         Saving model ...\n",
      "Epoch: 1707 \tTraining Loss: 1.083112 \tValidation Loss: 1.485414\n",
      "Validation loss decreased (1.485426 --> 1.485414).         Saving model ...\n",
      "Epoch: 1708 \tTraining Loss: 1.083107 \tValidation Loss: 1.485403\n",
      "Validation loss decreased (1.485414 --> 1.485403).         Saving model ...\n",
      "Epoch: 1709 \tTraining Loss: 1.083102 \tValidation Loss: 1.485392\n",
      "Validation loss decreased (1.485403 --> 1.485392).         Saving model ...\n",
      "Epoch: 1710 \tTraining Loss: 1.083096 \tValidation Loss: 1.485381\n",
      "Validation loss decreased (1.485392 --> 1.485381).         Saving model ...\n",
      "Epoch: 1711 \tTraining Loss: 1.083091 \tValidation Loss: 1.485369\n",
      "Validation loss decreased (1.485381 --> 1.485369).         Saving model ...\n",
      "Epoch: 1712 \tTraining Loss: 1.083086 \tValidation Loss: 1.485357\n",
      "Validation loss decreased (1.485369 --> 1.485357).         Saving model ...\n",
      "Epoch: 1713 \tTraining Loss: 1.083081 \tValidation Loss: 1.485346\n",
      "Validation loss decreased (1.485357 --> 1.485346).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1714 \tTraining Loss: 1.083076 \tValidation Loss: 1.485334\n",
      "Validation loss decreased (1.485346 --> 1.485334).         Saving model ...\n",
      "Epoch: 1715 \tTraining Loss: 1.083071 \tValidation Loss: 1.485322\n",
      "Validation loss decreased (1.485334 --> 1.485322).         Saving model ...\n",
      "Epoch: 1716 \tTraining Loss: 1.083066 \tValidation Loss: 1.485311\n",
      "Validation loss decreased (1.485322 --> 1.485311).         Saving model ...\n",
      "Epoch: 1717 \tTraining Loss: 1.083060 \tValidation Loss: 1.485299\n",
      "Validation loss decreased (1.485311 --> 1.485299).         Saving model ...\n",
      "Epoch: 1718 \tTraining Loss: 1.083055 \tValidation Loss: 1.485288\n",
      "Validation loss decreased (1.485299 --> 1.485288).         Saving model ...\n",
      "Epoch: 1719 \tTraining Loss: 1.083050 \tValidation Loss: 1.485277\n",
      "Validation loss decreased (1.485288 --> 1.485277).         Saving model ...\n",
      "Epoch: 1720 \tTraining Loss: 1.083045 \tValidation Loss: 1.485265\n",
      "Validation loss decreased (1.485277 --> 1.485265).         Saving model ...\n",
      "Epoch: 1721 \tTraining Loss: 1.083040 \tValidation Loss: 1.485254\n",
      "Validation loss decreased (1.485265 --> 1.485254).         Saving model ...\n",
      "Epoch: 1722 \tTraining Loss: 1.083035 \tValidation Loss: 1.485242\n",
      "Validation loss decreased (1.485254 --> 1.485242).         Saving model ...\n",
      "Epoch: 1723 \tTraining Loss: 1.083030 \tValidation Loss: 1.485230\n",
      "Validation loss decreased (1.485242 --> 1.485230).         Saving model ...\n",
      "Epoch: 1724 \tTraining Loss: 1.083025 \tValidation Loss: 1.485219\n",
      "Validation loss decreased (1.485230 --> 1.485219).         Saving model ...\n",
      "Epoch: 1725 \tTraining Loss: 1.083019 \tValidation Loss: 1.485208\n",
      "Validation loss decreased (1.485219 --> 1.485208).         Saving model ...\n",
      "Epoch: 1726 \tTraining Loss: 1.083014 \tValidation Loss: 1.485197\n",
      "Validation loss decreased (1.485208 --> 1.485197).         Saving model ...\n",
      "Epoch: 1727 \tTraining Loss: 1.083009 \tValidation Loss: 1.485185\n",
      "Validation loss decreased (1.485197 --> 1.485185).         Saving model ...\n",
      "Epoch: 1728 \tTraining Loss: 1.083004 \tValidation Loss: 1.485174\n",
      "Validation loss decreased (1.485185 --> 1.485174).         Saving model ...\n",
      "Epoch: 1729 \tTraining Loss: 1.082999 \tValidation Loss: 1.485163\n",
      "Validation loss decreased (1.485174 --> 1.485163).         Saving model ...\n",
      "Epoch: 1730 \tTraining Loss: 1.082994 \tValidation Loss: 1.485151\n",
      "Validation loss decreased (1.485163 --> 1.485151).         Saving model ...\n",
      "Epoch: 1731 \tTraining Loss: 1.082989 \tValidation Loss: 1.485140\n",
      "Validation loss decreased (1.485151 --> 1.485140).         Saving model ...\n",
      "Epoch: 1732 \tTraining Loss: 1.082984 \tValidation Loss: 1.485129\n",
      "Validation loss decreased (1.485140 --> 1.485129).         Saving model ...\n",
      "Epoch: 1733 \tTraining Loss: 1.082979 \tValidation Loss: 1.485117\n",
      "Validation loss decreased (1.485129 --> 1.485117).         Saving model ...\n",
      "Epoch: 1734 \tTraining Loss: 1.082974 \tValidation Loss: 1.485105\n",
      "Validation loss decreased (1.485117 --> 1.485105).         Saving model ...\n",
      "Epoch: 1735 \tTraining Loss: 1.082969 \tValidation Loss: 1.485093\n",
      "Validation loss decreased (1.485105 --> 1.485093).         Saving model ...\n",
      "Epoch: 1736 \tTraining Loss: 1.082964 \tValidation Loss: 1.485082\n",
      "Validation loss decreased (1.485093 --> 1.485082).         Saving model ...\n",
      "Epoch: 1737 \tTraining Loss: 1.082959 \tValidation Loss: 1.485071\n",
      "Validation loss decreased (1.485082 --> 1.485071).         Saving model ...\n",
      "Epoch: 1738 \tTraining Loss: 1.082954 \tValidation Loss: 1.485060\n",
      "Validation loss decreased (1.485071 --> 1.485060).         Saving model ...\n",
      "Epoch: 1739 \tTraining Loss: 1.082949 \tValidation Loss: 1.485048\n",
      "Validation loss decreased (1.485060 --> 1.485048).         Saving model ...\n",
      "Epoch: 1740 \tTraining Loss: 1.082944 \tValidation Loss: 1.485036\n",
      "Validation loss decreased (1.485048 --> 1.485036).         Saving model ...\n",
      "Epoch: 1741 \tTraining Loss: 1.082938 \tValidation Loss: 1.485026\n",
      "Validation loss decreased (1.485036 --> 1.485026).         Saving model ...\n",
      "Epoch: 1742 \tTraining Loss: 1.082933 \tValidation Loss: 1.485014\n",
      "Validation loss decreased (1.485026 --> 1.485014).         Saving model ...\n",
      "Epoch: 1743 \tTraining Loss: 1.082928 \tValidation Loss: 1.485003\n",
      "Validation loss decreased (1.485014 --> 1.485003).         Saving model ...\n",
      "Epoch: 1744 \tTraining Loss: 1.082923 \tValidation Loss: 1.484992\n",
      "Validation loss decreased (1.485003 --> 1.484992).         Saving model ...\n",
      "Epoch: 1745 \tTraining Loss: 1.082918 \tValidation Loss: 1.484980\n",
      "Validation loss decreased (1.484992 --> 1.484980).         Saving model ...\n",
      "Epoch: 1746 \tTraining Loss: 1.082913 \tValidation Loss: 1.484969\n",
      "Validation loss decreased (1.484980 --> 1.484969).         Saving model ...\n",
      "Epoch: 1747 \tTraining Loss: 1.082908 \tValidation Loss: 1.484958\n",
      "Validation loss decreased (1.484969 --> 1.484958).         Saving model ...\n",
      "Epoch: 1748 \tTraining Loss: 1.082903 \tValidation Loss: 1.484946\n",
      "Validation loss decreased (1.484958 --> 1.484946).         Saving model ...\n",
      "Epoch: 1749 \tTraining Loss: 1.082898 \tValidation Loss: 1.484935\n",
      "Validation loss decreased (1.484946 --> 1.484935).         Saving model ...\n",
      "Epoch: 1750 \tTraining Loss: 1.082893 \tValidation Loss: 1.484924\n",
      "Validation loss decreased (1.484935 --> 1.484924).         Saving model ...\n",
      "Epoch: 1751 \tTraining Loss: 1.082888 \tValidation Loss: 1.484912\n",
      "Validation loss decreased (1.484924 --> 1.484912).         Saving model ...\n",
      "Epoch: 1752 \tTraining Loss: 1.082883 \tValidation Loss: 1.484902\n",
      "Validation loss decreased (1.484912 --> 1.484902).         Saving model ...\n",
      "Epoch: 1753 \tTraining Loss: 1.082878 \tValidation Loss: 1.484891\n",
      "Validation loss decreased (1.484902 --> 1.484891).         Saving model ...\n",
      "Epoch: 1754 \tTraining Loss: 1.082873 \tValidation Loss: 1.484879\n",
      "Validation loss decreased (1.484891 --> 1.484879).         Saving model ...\n",
      "Epoch: 1755 \tTraining Loss: 1.082868 \tValidation Loss: 1.484868\n",
      "Validation loss decreased (1.484879 --> 1.484868).         Saving model ...\n",
      "Epoch: 1756 \tTraining Loss: 1.082863 \tValidation Loss: 1.484856\n",
      "Validation loss decreased (1.484868 --> 1.484856).         Saving model ...\n",
      "Epoch: 1757 \tTraining Loss: 1.082859 \tValidation Loss: 1.484845\n",
      "Validation loss decreased (1.484856 --> 1.484845).         Saving model ...\n",
      "Epoch: 1758 \tTraining Loss: 1.082854 \tValidation Loss: 1.484835\n",
      "Validation loss decreased (1.484845 --> 1.484835).         Saving model ...\n",
      "Epoch: 1759 \tTraining Loss: 1.082849 \tValidation Loss: 1.484824\n",
      "Validation loss decreased (1.484835 --> 1.484824).         Saving model ...\n",
      "Epoch: 1760 \tTraining Loss: 1.082844 \tValidation Loss: 1.484812\n",
      "Validation loss decreased (1.484824 --> 1.484812).         Saving model ...\n",
      "Epoch: 1761 \tTraining Loss: 1.082839 \tValidation Loss: 1.484802\n",
      "Validation loss decreased (1.484812 --> 1.484802).         Saving model ...\n",
      "Epoch: 1762 \tTraining Loss: 1.082834 \tValidation Loss: 1.484791\n",
      "Validation loss decreased (1.484802 --> 1.484791).         Saving model ...\n",
      "Epoch: 1763 \tTraining Loss: 1.082829 \tValidation Loss: 1.484779\n",
      "Validation loss decreased (1.484791 --> 1.484779).         Saving model ...\n",
      "Epoch: 1764 \tTraining Loss: 1.082824 \tValidation Loss: 1.484769\n",
      "Validation loss decreased (1.484779 --> 1.484769).         Saving model ...\n",
      "Epoch: 1765 \tTraining Loss: 1.082819 \tValidation Loss: 1.484757\n",
      "Validation loss decreased (1.484769 --> 1.484757).         Saving model ...\n",
      "Epoch: 1766 \tTraining Loss: 1.082814 \tValidation Loss: 1.484747\n",
      "Validation loss decreased (1.484757 --> 1.484747).         Saving model ...\n",
      "Epoch: 1767 \tTraining Loss: 1.082809 \tValidation Loss: 1.484736\n",
      "Validation loss decreased (1.484747 --> 1.484736).         Saving model ...\n",
      "Epoch: 1768 \tTraining Loss: 1.082804 \tValidation Loss: 1.484726\n",
      "Validation loss decreased (1.484736 --> 1.484726).         Saving model ...\n",
      "Epoch: 1769 \tTraining Loss: 1.082799 \tValidation Loss: 1.484715\n",
      "Validation loss decreased (1.484726 --> 1.484715).         Saving model ...\n",
      "Epoch: 1770 \tTraining Loss: 1.082794 \tValidation Loss: 1.484704\n",
      "Validation loss decreased (1.484715 --> 1.484704).         Saving model ...\n",
      "Epoch: 1771 \tTraining Loss: 1.082789 \tValidation Loss: 1.484694\n",
      "Validation loss decreased (1.484704 --> 1.484694).         Saving model ...\n",
      "Epoch: 1772 \tTraining Loss: 1.082784 \tValidation Loss: 1.484683\n",
      "Validation loss decreased (1.484694 --> 1.484683).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1773 \tTraining Loss: 1.082780 \tValidation Loss: 1.484672\n",
      "Validation loss decreased (1.484683 --> 1.484672).         Saving model ...\n",
      "Epoch: 1774 \tTraining Loss: 1.082775 \tValidation Loss: 1.484661\n",
      "Validation loss decreased (1.484672 --> 1.484661).         Saving model ...\n",
      "Epoch: 1775 \tTraining Loss: 1.082770 \tValidation Loss: 1.484650\n",
      "Validation loss decreased (1.484661 --> 1.484650).         Saving model ...\n",
      "Epoch: 1776 \tTraining Loss: 1.082765 \tValidation Loss: 1.484639\n",
      "Validation loss decreased (1.484650 --> 1.484639).         Saving model ...\n",
      "Epoch: 1777 \tTraining Loss: 1.082760 \tValidation Loss: 1.484627\n",
      "Validation loss decreased (1.484639 --> 1.484627).         Saving model ...\n",
      "Epoch: 1778 \tTraining Loss: 1.082755 \tValidation Loss: 1.484617\n",
      "Validation loss decreased (1.484627 --> 1.484617).         Saving model ...\n",
      "Epoch: 1779 \tTraining Loss: 1.082750 \tValidation Loss: 1.484606\n",
      "Validation loss decreased (1.484617 --> 1.484606).         Saving model ...\n",
      "Epoch: 1780 \tTraining Loss: 1.082745 \tValidation Loss: 1.484595\n",
      "Validation loss decreased (1.484606 --> 1.484595).         Saving model ...\n",
      "Epoch: 1781 \tTraining Loss: 1.082740 \tValidation Loss: 1.484585\n",
      "Validation loss decreased (1.484595 --> 1.484585).         Saving model ...\n",
      "Epoch: 1782 \tTraining Loss: 1.082736 \tValidation Loss: 1.484575\n",
      "Validation loss decreased (1.484585 --> 1.484575).         Saving model ...\n",
      "Epoch: 1783 \tTraining Loss: 1.082731 \tValidation Loss: 1.484565\n",
      "Validation loss decreased (1.484575 --> 1.484565).         Saving model ...\n",
      "Epoch: 1784 \tTraining Loss: 1.082726 \tValidation Loss: 1.484554\n",
      "Validation loss decreased (1.484565 --> 1.484554).         Saving model ...\n",
      "Epoch: 1785 \tTraining Loss: 1.082721 \tValidation Loss: 1.484544\n",
      "Validation loss decreased (1.484554 --> 1.484544).         Saving model ...\n",
      "Epoch: 1786 \tTraining Loss: 1.082716 \tValidation Loss: 1.484533\n",
      "Validation loss decreased (1.484544 --> 1.484533).         Saving model ...\n",
      "Epoch: 1787 \tTraining Loss: 1.082711 \tValidation Loss: 1.484524\n",
      "Validation loss decreased (1.484533 --> 1.484524).         Saving model ...\n",
      "Epoch: 1788 \tTraining Loss: 1.082706 \tValidation Loss: 1.484514\n",
      "Validation loss decreased (1.484524 --> 1.484514).         Saving model ...\n",
      "Epoch: 1789 \tTraining Loss: 1.082702 \tValidation Loss: 1.484505\n",
      "Validation loss decreased (1.484514 --> 1.484505).         Saving model ...\n",
      "Epoch: 1790 \tTraining Loss: 1.082697 \tValidation Loss: 1.484495\n",
      "Validation loss decreased (1.484505 --> 1.484495).         Saving model ...\n",
      "Epoch: 1791 \tTraining Loss: 1.082692 \tValidation Loss: 1.484486\n",
      "Validation loss decreased (1.484495 --> 1.484486).         Saving model ...\n",
      "Epoch: 1792 \tTraining Loss: 1.082687 \tValidation Loss: 1.484477\n",
      "Validation loss decreased (1.484486 --> 1.484477).         Saving model ...\n",
      "Epoch: 1793 \tTraining Loss: 1.082682 \tValidation Loss: 1.484466\n",
      "Validation loss decreased (1.484477 --> 1.484466).         Saving model ...\n",
      "Epoch: 1794 \tTraining Loss: 1.082677 \tValidation Loss: 1.484457\n",
      "Validation loss decreased (1.484466 --> 1.484457).         Saving model ...\n",
      "Epoch: 1795 \tTraining Loss: 1.082673 \tValidation Loss: 1.484447\n",
      "Validation loss decreased (1.484457 --> 1.484447).         Saving model ...\n",
      "Epoch: 1796 \tTraining Loss: 1.082668 \tValidation Loss: 1.484437\n",
      "Validation loss decreased (1.484447 --> 1.484437).         Saving model ...\n",
      "Epoch: 1797 \tTraining Loss: 1.082663 \tValidation Loss: 1.484427\n",
      "Validation loss decreased (1.484437 --> 1.484427).         Saving model ...\n",
      "Epoch: 1798 \tTraining Loss: 1.082658 \tValidation Loss: 1.484418\n",
      "Validation loss decreased (1.484427 --> 1.484418).         Saving model ...\n",
      "Epoch: 1799 \tTraining Loss: 1.082653 \tValidation Loss: 1.484407\n",
      "Validation loss decreased (1.484418 --> 1.484407).         Saving model ...\n",
      "Epoch: 1800 \tTraining Loss: 1.082648 \tValidation Loss: 1.484397\n",
      "Validation loss decreased (1.484407 --> 1.484397).         Saving model ...\n",
      "Epoch: 1801 \tTraining Loss: 1.082644 \tValidation Loss: 1.484387\n",
      "Validation loss decreased (1.484397 --> 1.484387).         Saving model ...\n",
      "Epoch: 1802 \tTraining Loss: 1.082639 \tValidation Loss: 1.484376\n",
      "Validation loss decreased (1.484387 --> 1.484376).         Saving model ...\n",
      "Epoch: 1803 \tTraining Loss: 1.082634 \tValidation Loss: 1.484365\n",
      "Validation loss decreased (1.484376 --> 1.484365).         Saving model ...\n",
      "Epoch: 1804 \tTraining Loss: 1.082629 \tValidation Loss: 1.484355\n",
      "Validation loss decreased (1.484365 --> 1.484355).         Saving model ...\n",
      "Epoch: 1805 \tTraining Loss: 1.082624 \tValidation Loss: 1.484344\n",
      "Validation loss decreased (1.484355 --> 1.484344).         Saving model ...\n",
      "Epoch: 1806 \tTraining Loss: 1.082620 \tValidation Loss: 1.484334\n",
      "Validation loss decreased (1.484344 --> 1.484334).         Saving model ...\n",
      "Epoch: 1807 \tTraining Loss: 1.082615 \tValidation Loss: 1.484323\n",
      "Validation loss decreased (1.484334 --> 1.484323).         Saving model ...\n",
      "Epoch: 1808 \tTraining Loss: 1.082610 \tValidation Loss: 1.484313\n",
      "Validation loss decreased (1.484323 --> 1.484313).         Saving model ...\n",
      "Epoch: 1809 \tTraining Loss: 1.082605 \tValidation Loss: 1.484302\n",
      "Validation loss decreased (1.484313 --> 1.484302).         Saving model ...\n",
      "Epoch: 1810 \tTraining Loss: 1.082601 \tValidation Loss: 1.484292\n",
      "Validation loss decreased (1.484302 --> 1.484292).         Saving model ...\n",
      "Epoch: 1811 \tTraining Loss: 1.082596 \tValidation Loss: 1.484281\n",
      "Validation loss decreased (1.484292 --> 1.484281).         Saving model ...\n",
      "Epoch: 1812 \tTraining Loss: 1.082591 \tValidation Loss: 1.484271\n",
      "Validation loss decreased (1.484281 --> 1.484271).         Saving model ...\n",
      "Epoch: 1813 \tTraining Loss: 1.082586 \tValidation Loss: 1.484260\n",
      "Validation loss decreased (1.484271 --> 1.484260).         Saving model ...\n",
      "Epoch: 1814 \tTraining Loss: 1.082582 \tValidation Loss: 1.484250\n",
      "Validation loss decreased (1.484260 --> 1.484250).         Saving model ...\n",
      "Epoch: 1815 \tTraining Loss: 1.082577 \tValidation Loss: 1.484239\n",
      "Validation loss decreased (1.484250 --> 1.484239).         Saving model ...\n",
      "Epoch: 1816 \tTraining Loss: 1.082572 \tValidation Loss: 1.484230\n",
      "Validation loss decreased (1.484239 --> 1.484230).         Saving model ...\n",
      "Epoch: 1817 \tTraining Loss: 1.082567 \tValidation Loss: 1.484219\n",
      "Validation loss decreased (1.484230 --> 1.484219).         Saving model ...\n",
      "Epoch: 1818 \tTraining Loss: 1.082563 \tValidation Loss: 1.484209\n",
      "Validation loss decreased (1.484219 --> 1.484209).         Saving model ...\n",
      "Epoch: 1819 \tTraining Loss: 1.082558 \tValidation Loss: 1.484200\n",
      "Validation loss decreased (1.484209 --> 1.484200).         Saving model ...\n",
      "Epoch: 1820 \tTraining Loss: 1.082553 \tValidation Loss: 1.484189\n",
      "Validation loss decreased (1.484200 --> 1.484189).         Saving model ...\n",
      "Epoch: 1821 \tTraining Loss: 1.082548 \tValidation Loss: 1.484179\n",
      "Validation loss decreased (1.484189 --> 1.484179).         Saving model ...\n",
      "Epoch: 1822 \tTraining Loss: 1.082544 \tValidation Loss: 1.484169\n",
      "Validation loss decreased (1.484179 --> 1.484169).         Saving model ...\n",
      "Epoch: 1823 \tTraining Loss: 1.082539 \tValidation Loss: 1.484158\n",
      "Validation loss decreased (1.484169 --> 1.484158).         Saving model ...\n",
      "Epoch: 1824 \tTraining Loss: 1.082534 \tValidation Loss: 1.484148\n",
      "Validation loss decreased (1.484158 --> 1.484148).         Saving model ...\n",
      "Epoch: 1825 \tTraining Loss: 1.082529 \tValidation Loss: 1.484139\n",
      "Validation loss decreased (1.484148 --> 1.484139).         Saving model ...\n",
      "Epoch: 1826 \tTraining Loss: 1.082525 \tValidation Loss: 1.484129\n",
      "Validation loss decreased (1.484139 --> 1.484129).         Saving model ...\n",
      "Epoch: 1827 \tTraining Loss: 1.082520 \tValidation Loss: 1.484119\n",
      "Validation loss decreased (1.484129 --> 1.484119).         Saving model ...\n",
      "Epoch: 1828 \tTraining Loss: 1.082515 \tValidation Loss: 1.484109\n",
      "Validation loss decreased (1.484119 --> 1.484109).         Saving model ...\n",
      "Epoch: 1829 \tTraining Loss: 1.082511 \tValidation Loss: 1.484099\n",
      "Validation loss decreased (1.484109 --> 1.484099).         Saving model ...\n",
      "Epoch: 1830 \tTraining Loss: 1.082506 \tValidation Loss: 1.484089\n",
      "Validation loss decreased (1.484099 --> 1.484089).         Saving model ...\n",
      "Epoch: 1831 \tTraining Loss: 1.082501 \tValidation Loss: 1.484080\n",
      "Validation loss decreased (1.484089 --> 1.484080).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1832 \tTraining Loss: 1.082496 \tValidation Loss: 1.484071\n",
      "Validation loss decreased (1.484080 --> 1.484071).         Saving model ...\n",
      "Epoch: 1833 \tTraining Loss: 1.082492 \tValidation Loss: 1.484061\n",
      "Validation loss decreased (1.484071 --> 1.484061).         Saving model ...\n",
      "Epoch: 1834 \tTraining Loss: 1.082487 \tValidation Loss: 1.484050\n",
      "Validation loss decreased (1.484061 --> 1.484050).         Saving model ...\n",
      "Epoch: 1835 \tTraining Loss: 1.082482 \tValidation Loss: 1.484040\n",
      "Validation loss decreased (1.484050 --> 1.484040).         Saving model ...\n",
      "Epoch: 1836 \tTraining Loss: 1.082478 \tValidation Loss: 1.484030\n",
      "Validation loss decreased (1.484040 --> 1.484030).         Saving model ...\n",
      "Epoch: 1837 \tTraining Loss: 1.082473 \tValidation Loss: 1.484021\n",
      "Validation loss decreased (1.484030 --> 1.484021).         Saving model ...\n",
      "Epoch: 1838 \tTraining Loss: 1.082468 \tValidation Loss: 1.484010\n",
      "Validation loss decreased (1.484021 --> 1.484010).         Saving model ...\n",
      "Epoch: 1839 \tTraining Loss: 1.082464 \tValidation Loss: 1.484001\n",
      "Validation loss decreased (1.484010 --> 1.484001).         Saving model ...\n",
      "Epoch: 1840 \tTraining Loss: 1.082459 \tValidation Loss: 1.483991\n",
      "Validation loss decreased (1.484001 --> 1.483991).         Saving model ...\n",
      "Epoch: 1841 \tTraining Loss: 1.082454 \tValidation Loss: 1.483981\n",
      "Validation loss decreased (1.483991 --> 1.483981).         Saving model ...\n",
      "Epoch: 1842 \tTraining Loss: 1.082450 \tValidation Loss: 1.483970\n",
      "Validation loss decreased (1.483981 --> 1.483970).         Saving model ...\n",
      "Epoch: 1843 \tTraining Loss: 1.082445 \tValidation Loss: 1.483961\n",
      "Validation loss decreased (1.483970 --> 1.483961).         Saving model ...\n",
      "Epoch: 1844 \tTraining Loss: 1.082440 \tValidation Loss: 1.483951\n",
      "Validation loss decreased (1.483961 --> 1.483951).         Saving model ...\n",
      "Epoch: 1845 \tTraining Loss: 1.082436 \tValidation Loss: 1.483941\n",
      "Validation loss decreased (1.483951 --> 1.483941).         Saving model ...\n",
      "Epoch: 1846 \tTraining Loss: 1.082431 \tValidation Loss: 1.483932\n",
      "Validation loss decreased (1.483941 --> 1.483932).         Saving model ...\n",
      "Epoch: 1847 \tTraining Loss: 1.082426 \tValidation Loss: 1.483923\n",
      "Validation loss decreased (1.483932 --> 1.483923).         Saving model ...\n",
      "Epoch: 1848 \tTraining Loss: 1.082422 \tValidation Loss: 1.483913\n",
      "Validation loss decreased (1.483923 --> 1.483913).         Saving model ...\n",
      "Epoch: 1849 \tTraining Loss: 1.082417 \tValidation Loss: 1.483905\n",
      "Validation loss decreased (1.483913 --> 1.483905).         Saving model ...\n",
      "Epoch: 1850 \tTraining Loss: 1.082413 \tValidation Loss: 1.483895\n",
      "Validation loss decreased (1.483905 --> 1.483895).         Saving model ...\n",
      "Epoch: 1851 \tTraining Loss: 1.082408 \tValidation Loss: 1.483886\n",
      "Validation loss decreased (1.483895 --> 1.483886).         Saving model ...\n",
      "Epoch: 1852 \tTraining Loss: 1.082403 \tValidation Loss: 1.483876\n",
      "Validation loss decreased (1.483886 --> 1.483876).         Saving model ...\n",
      "Epoch: 1853 \tTraining Loss: 1.082399 \tValidation Loss: 1.483867\n",
      "Validation loss decreased (1.483876 --> 1.483867).         Saving model ...\n",
      "Epoch: 1854 \tTraining Loss: 1.082394 \tValidation Loss: 1.483859\n",
      "Validation loss decreased (1.483867 --> 1.483859).         Saving model ...\n",
      "Epoch: 1855 \tTraining Loss: 1.082389 \tValidation Loss: 1.483849\n",
      "Validation loss decreased (1.483859 --> 1.483849).         Saving model ...\n",
      "Epoch: 1856 \tTraining Loss: 1.082385 \tValidation Loss: 1.483841\n",
      "Validation loss decreased (1.483849 --> 1.483841).         Saving model ...\n",
      "Epoch: 1857 \tTraining Loss: 1.082380 \tValidation Loss: 1.483831\n",
      "Validation loss decreased (1.483841 --> 1.483831).         Saving model ...\n",
      "Epoch: 1858 \tTraining Loss: 1.082376 \tValidation Loss: 1.483822\n",
      "Validation loss decreased (1.483831 --> 1.483822).         Saving model ...\n",
      "Epoch: 1859 \tTraining Loss: 1.082371 \tValidation Loss: 1.483812\n",
      "Validation loss decreased (1.483822 --> 1.483812).         Saving model ...\n",
      "Epoch: 1860 \tTraining Loss: 1.082366 \tValidation Loss: 1.483802\n",
      "Validation loss decreased (1.483812 --> 1.483802).         Saving model ...\n",
      "Epoch: 1861 \tTraining Loss: 1.082362 \tValidation Loss: 1.483794\n",
      "Validation loss decreased (1.483802 --> 1.483794).         Saving model ...\n",
      "Epoch: 1862 \tTraining Loss: 1.082357 \tValidation Loss: 1.483784\n",
      "Validation loss decreased (1.483794 --> 1.483784).         Saving model ...\n",
      "Epoch: 1863 \tTraining Loss: 1.082353 \tValidation Loss: 1.483774\n",
      "Validation loss decreased (1.483784 --> 1.483774).         Saving model ...\n",
      "Epoch: 1864 \tTraining Loss: 1.082348 \tValidation Loss: 1.483766\n",
      "Validation loss decreased (1.483774 --> 1.483766).         Saving model ...\n",
      "Epoch: 1865 \tTraining Loss: 1.082343 \tValidation Loss: 1.483757\n",
      "Validation loss decreased (1.483766 --> 1.483757).         Saving model ...\n",
      "Epoch: 1866 \tTraining Loss: 1.082339 \tValidation Loss: 1.483748\n",
      "Validation loss decreased (1.483757 --> 1.483748).         Saving model ...\n",
      "Epoch: 1867 \tTraining Loss: 1.082334 \tValidation Loss: 1.483739\n",
      "Validation loss decreased (1.483748 --> 1.483739).         Saving model ...\n",
      "Epoch: 1868 \tTraining Loss: 1.082330 \tValidation Loss: 1.483731\n",
      "Validation loss decreased (1.483739 --> 1.483731).         Saving model ...\n",
      "Epoch: 1869 \tTraining Loss: 1.082325 \tValidation Loss: 1.483722\n",
      "Validation loss decreased (1.483731 --> 1.483722).         Saving model ...\n",
      "Epoch: 1870 \tTraining Loss: 1.082321 \tValidation Loss: 1.483712\n",
      "Validation loss decreased (1.483722 --> 1.483712).         Saving model ...\n",
      "Epoch: 1871 \tTraining Loss: 1.082316 \tValidation Loss: 1.483704\n",
      "Validation loss decreased (1.483712 --> 1.483704).         Saving model ...\n",
      "Epoch: 1872 \tTraining Loss: 1.082311 \tValidation Loss: 1.483697\n",
      "Validation loss decreased (1.483704 --> 1.483697).         Saving model ...\n",
      "Epoch: 1873 \tTraining Loss: 1.082307 \tValidation Loss: 1.483687\n",
      "Validation loss decreased (1.483697 --> 1.483687).         Saving model ...\n",
      "Epoch: 1874 \tTraining Loss: 1.082302 \tValidation Loss: 1.483681\n",
      "Validation loss decreased (1.483687 --> 1.483681).         Saving model ...\n",
      "Epoch: 1875 \tTraining Loss: 1.082298 \tValidation Loss: 1.483672\n",
      "Validation loss decreased (1.483681 --> 1.483672).         Saving model ...\n",
      "Epoch: 1876 \tTraining Loss: 1.082293 \tValidation Loss: 1.483663\n",
      "Validation loss decreased (1.483672 --> 1.483663).         Saving model ...\n",
      "Epoch: 1877 \tTraining Loss: 1.082289 \tValidation Loss: 1.483656\n",
      "Validation loss decreased (1.483663 --> 1.483656).         Saving model ...\n",
      "Epoch: 1878 \tTraining Loss: 1.082284 \tValidation Loss: 1.483647\n",
      "Validation loss decreased (1.483656 --> 1.483647).         Saving model ...\n",
      "Epoch: 1879 \tTraining Loss: 1.082280 \tValidation Loss: 1.483639\n",
      "Validation loss decreased (1.483647 --> 1.483639).         Saving model ...\n",
      "Epoch: 1880 \tTraining Loss: 1.082275 \tValidation Loss: 1.483630\n",
      "Validation loss decreased (1.483639 --> 1.483630).         Saving model ...\n",
      "Epoch: 1881 \tTraining Loss: 1.082271 \tValidation Loss: 1.483622\n",
      "Validation loss decreased (1.483630 --> 1.483622).         Saving model ...\n",
      "Epoch: 1882 \tTraining Loss: 1.082266 \tValidation Loss: 1.483615\n",
      "Validation loss decreased (1.483622 --> 1.483615).         Saving model ...\n",
      "Epoch: 1883 \tTraining Loss: 1.082262 \tValidation Loss: 1.483605\n",
      "Validation loss decreased (1.483615 --> 1.483605).         Saving model ...\n",
      "Epoch: 1884 \tTraining Loss: 1.082257 \tValidation Loss: 1.483598\n",
      "Validation loss decreased (1.483605 --> 1.483598).         Saving model ...\n",
      "Epoch: 1885 \tTraining Loss: 1.082253 \tValidation Loss: 1.483589\n",
      "Validation loss decreased (1.483598 --> 1.483589).         Saving model ...\n",
      "Epoch: 1886 \tTraining Loss: 1.082248 \tValidation Loss: 1.483580\n",
      "Validation loss decreased (1.483589 --> 1.483580).         Saving model ...\n",
      "Epoch: 1887 \tTraining Loss: 1.082244 \tValidation Loss: 1.483572\n",
      "Validation loss decreased (1.483580 --> 1.483572).         Saving model ...\n",
      "Epoch: 1888 \tTraining Loss: 1.082239 \tValidation Loss: 1.483563\n",
      "Validation loss decreased (1.483572 --> 1.483563).         Saving model ...\n",
      "Epoch: 1889 \tTraining Loss: 1.082235 \tValidation Loss: 1.483555\n",
      "Validation loss decreased (1.483563 --> 1.483555).         Saving model ...\n",
      "Epoch: 1890 \tTraining Loss: 1.082230 \tValidation Loss: 1.483546\n",
      "Validation loss decreased (1.483555 --> 1.483546).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1891 \tTraining Loss: 1.082226 \tValidation Loss: 1.483537\n",
      "Validation loss decreased (1.483546 --> 1.483537).         Saving model ...\n",
      "Epoch: 1892 \tTraining Loss: 1.082221 \tValidation Loss: 1.483528\n",
      "Validation loss decreased (1.483537 --> 1.483528).         Saving model ...\n",
      "Epoch: 1893 \tTraining Loss: 1.082217 \tValidation Loss: 1.483519\n",
      "Validation loss decreased (1.483528 --> 1.483519).         Saving model ...\n",
      "Epoch: 1894 \tTraining Loss: 1.082212 \tValidation Loss: 1.483511\n",
      "Validation loss decreased (1.483519 --> 1.483511).         Saving model ...\n",
      "Epoch: 1895 \tTraining Loss: 1.082208 \tValidation Loss: 1.483501\n",
      "Validation loss decreased (1.483511 --> 1.483501).         Saving model ...\n",
      "Epoch: 1896 \tTraining Loss: 1.082203 \tValidation Loss: 1.483493\n",
      "Validation loss decreased (1.483501 --> 1.483493).         Saving model ...\n",
      "Epoch: 1897 \tTraining Loss: 1.082199 \tValidation Loss: 1.483484\n",
      "Validation loss decreased (1.483493 --> 1.483484).         Saving model ...\n",
      "Epoch: 1898 \tTraining Loss: 1.082194 \tValidation Loss: 1.483475\n",
      "Validation loss decreased (1.483484 --> 1.483475).         Saving model ...\n",
      "Epoch: 1899 \tTraining Loss: 1.082190 \tValidation Loss: 1.483466\n",
      "Validation loss decreased (1.483475 --> 1.483466).         Saving model ...\n",
      "Epoch: 1900 \tTraining Loss: 1.082185 \tValidation Loss: 1.483458\n",
      "Validation loss decreased (1.483466 --> 1.483458).         Saving model ...\n",
      "Epoch: 1901 \tTraining Loss: 1.082181 \tValidation Loss: 1.483449\n",
      "Validation loss decreased (1.483458 --> 1.483449).         Saving model ...\n",
      "Epoch: 1902 \tTraining Loss: 1.082176 \tValidation Loss: 1.483441\n",
      "Validation loss decreased (1.483449 --> 1.483441).         Saving model ...\n",
      "Epoch: 1903 \tTraining Loss: 1.082172 \tValidation Loss: 1.483432\n",
      "Validation loss decreased (1.483441 --> 1.483432).         Saving model ...\n",
      "Epoch: 1904 \tTraining Loss: 1.082167 \tValidation Loss: 1.483423\n",
      "Validation loss decreased (1.483432 --> 1.483423).         Saving model ...\n",
      "Epoch: 1905 \tTraining Loss: 1.082163 \tValidation Loss: 1.483414\n",
      "Validation loss decreased (1.483423 --> 1.483414).         Saving model ...\n",
      "Epoch: 1906 \tTraining Loss: 1.082159 \tValidation Loss: 1.483406\n",
      "Validation loss decreased (1.483414 --> 1.483406).         Saving model ...\n",
      "Epoch: 1907 \tTraining Loss: 1.082154 \tValidation Loss: 1.483397\n",
      "Validation loss decreased (1.483406 --> 1.483397).         Saving model ...\n",
      "Epoch: 1908 \tTraining Loss: 1.082150 \tValidation Loss: 1.483389\n",
      "Validation loss decreased (1.483397 --> 1.483389).         Saving model ...\n",
      "Epoch: 1909 \tTraining Loss: 1.082145 \tValidation Loss: 1.483381\n",
      "Validation loss decreased (1.483389 --> 1.483381).         Saving model ...\n",
      "Epoch: 1910 \tTraining Loss: 1.082141 \tValidation Loss: 1.483372\n",
      "Validation loss decreased (1.483381 --> 1.483372).         Saving model ...\n",
      "Epoch: 1911 \tTraining Loss: 1.082136 \tValidation Loss: 1.483365\n",
      "Validation loss decreased (1.483372 --> 1.483365).         Saving model ...\n",
      "Epoch: 1912 \tTraining Loss: 1.082132 \tValidation Loss: 1.483356\n",
      "Validation loss decreased (1.483365 --> 1.483356).         Saving model ...\n",
      "Epoch: 1913 \tTraining Loss: 1.082128 \tValidation Loss: 1.483348\n",
      "Validation loss decreased (1.483356 --> 1.483348).         Saving model ...\n",
      "Epoch: 1914 \tTraining Loss: 1.082123 \tValidation Loss: 1.483339\n",
      "Validation loss decreased (1.483348 --> 1.483339).         Saving model ...\n",
      "Epoch: 1915 \tTraining Loss: 1.082119 \tValidation Loss: 1.483332\n",
      "Validation loss decreased (1.483339 --> 1.483332).         Saving model ...\n",
      "Epoch: 1916 \tTraining Loss: 1.082114 \tValidation Loss: 1.483324\n",
      "Validation loss decreased (1.483332 --> 1.483324).         Saving model ...\n",
      "Epoch: 1917 \tTraining Loss: 1.082110 \tValidation Loss: 1.483315\n",
      "Validation loss decreased (1.483324 --> 1.483315).         Saving model ...\n",
      "Epoch: 1918 \tTraining Loss: 1.082105 \tValidation Loss: 1.483307\n",
      "Validation loss decreased (1.483315 --> 1.483307).         Saving model ...\n",
      "Epoch: 1919 \tTraining Loss: 1.082101 \tValidation Loss: 1.483299\n",
      "Validation loss decreased (1.483307 --> 1.483299).         Saving model ...\n",
      "Epoch: 1920 \tTraining Loss: 1.082097 \tValidation Loss: 1.483291\n",
      "Validation loss decreased (1.483299 --> 1.483291).         Saving model ...\n",
      "Epoch: 1921 \tTraining Loss: 1.082092 \tValidation Loss: 1.483283\n",
      "Validation loss decreased (1.483291 --> 1.483283).         Saving model ...\n",
      "Epoch: 1922 \tTraining Loss: 1.082088 \tValidation Loss: 1.483274\n",
      "Validation loss decreased (1.483283 --> 1.483274).         Saving model ...\n",
      "Epoch: 1923 \tTraining Loss: 1.082083 \tValidation Loss: 1.483267\n",
      "Validation loss decreased (1.483274 --> 1.483267).         Saving model ...\n",
      "Epoch: 1924 \tTraining Loss: 1.082079 \tValidation Loss: 1.483258\n",
      "Validation loss decreased (1.483267 --> 1.483258).         Saving model ...\n",
      "Epoch: 1925 \tTraining Loss: 1.082075 \tValidation Loss: 1.483250\n",
      "Validation loss decreased (1.483258 --> 1.483250).         Saving model ...\n",
      "Epoch: 1926 \tTraining Loss: 1.082070 \tValidation Loss: 1.483242\n",
      "Validation loss decreased (1.483250 --> 1.483242).         Saving model ...\n",
      "Epoch: 1927 \tTraining Loss: 1.082066 \tValidation Loss: 1.483236\n",
      "Validation loss decreased (1.483242 --> 1.483236).         Saving model ...\n",
      "Epoch: 1928 \tTraining Loss: 1.082062 \tValidation Loss: 1.483228\n",
      "Validation loss decreased (1.483236 --> 1.483228).         Saving model ...\n",
      "Epoch: 1929 \tTraining Loss: 1.082057 \tValidation Loss: 1.483220\n",
      "Validation loss decreased (1.483228 --> 1.483220).         Saving model ...\n",
      "Epoch: 1930 \tTraining Loss: 1.082053 \tValidation Loss: 1.483212\n",
      "Validation loss decreased (1.483220 --> 1.483212).         Saving model ...\n",
      "Epoch: 1931 \tTraining Loss: 1.082048 \tValidation Loss: 1.483204\n",
      "Validation loss decreased (1.483212 --> 1.483204).         Saving model ...\n",
      "Epoch: 1932 \tTraining Loss: 1.082044 \tValidation Loss: 1.483197\n",
      "Validation loss decreased (1.483204 --> 1.483197).         Saving model ...\n",
      "Epoch: 1933 \tTraining Loss: 1.082040 \tValidation Loss: 1.483189\n",
      "Validation loss decreased (1.483197 --> 1.483189).         Saving model ...\n",
      "Epoch: 1934 \tTraining Loss: 1.082035 \tValidation Loss: 1.483182\n",
      "Validation loss decreased (1.483189 --> 1.483182).         Saving model ...\n",
      "Epoch: 1935 \tTraining Loss: 1.082031 \tValidation Loss: 1.483174\n",
      "Validation loss decreased (1.483182 --> 1.483174).         Saving model ...\n",
      "Epoch: 1936 \tTraining Loss: 1.082027 \tValidation Loss: 1.483166\n",
      "Validation loss decreased (1.483174 --> 1.483166).         Saving model ...\n",
      "Epoch: 1937 \tTraining Loss: 1.082022 \tValidation Loss: 1.483160\n",
      "Validation loss decreased (1.483166 --> 1.483160).         Saving model ...\n",
      "Epoch: 1938 \tTraining Loss: 1.082018 \tValidation Loss: 1.483152\n",
      "Validation loss decreased (1.483160 --> 1.483152).         Saving model ...\n",
      "Epoch: 1939 \tTraining Loss: 1.082014 \tValidation Loss: 1.483145\n",
      "Validation loss decreased (1.483152 --> 1.483145).         Saving model ...\n",
      "Epoch: 1940 \tTraining Loss: 1.082009 \tValidation Loss: 1.483137\n",
      "Validation loss decreased (1.483145 --> 1.483137).         Saving model ...\n",
      "Epoch: 1941 \tTraining Loss: 1.082005 \tValidation Loss: 1.483129\n",
      "Validation loss decreased (1.483137 --> 1.483129).         Saving model ...\n",
      "Epoch: 1942 \tTraining Loss: 1.082001 \tValidation Loss: 1.483122\n",
      "Validation loss decreased (1.483129 --> 1.483122).         Saving model ...\n",
      "Epoch: 1943 \tTraining Loss: 1.081996 \tValidation Loss: 1.483114\n",
      "Validation loss decreased (1.483122 --> 1.483114).         Saving model ...\n",
      "Epoch: 1944 \tTraining Loss: 1.081992 \tValidation Loss: 1.483107\n",
      "Validation loss decreased (1.483114 --> 1.483107).         Saving model ...\n",
      "Epoch: 1945 \tTraining Loss: 1.081988 \tValidation Loss: 1.483099\n",
      "Validation loss decreased (1.483107 --> 1.483099).         Saving model ...\n",
      "Epoch: 1946 \tTraining Loss: 1.081983 \tValidation Loss: 1.483091\n",
      "Validation loss decreased (1.483099 --> 1.483091).         Saving model ...\n",
      "Epoch: 1947 \tTraining Loss: 1.081979 \tValidation Loss: 1.483083\n",
      "Validation loss decreased (1.483091 --> 1.483083).         Saving model ...\n",
      "Epoch: 1948 \tTraining Loss: 1.081975 \tValidation Loss: 1.483075\n",
      "Validation loss decreased (1.483083 --> 1.483075).         Saving model ...\n",
      "Epoch: 1949 \tTraining Loss: 1.081970 \tValidation Loss: 1.483067\n",
      "Validation loss decreased (1.483075 --> 1.483067).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1950 \tTraining Loss: 1.081966 \tValidation Loss: 1.483059\n",
      "Validation loss decreased (1.483067 --> 1.483059).         Saving model ...\n",
      "Epoch: 1951 \tTraining Loss: 1.081962 \tValidation Loss: 1.483051\n",
      "Validation loss decreased (1.483059 --> 1.483051).         Saving model ...\n",
      "Epoch: 1952 \tTraining Loss: 1.081957 \tValidation Loss: 1.483043\n",
      "Validation loss decreased (1.483051 --> 1.483043).         Saving model ...\n",
      "Epoch: 1953 \tTraining Loss: 1.081953 \tValidation Loss: 1.483035\n",
      "Validation loss decreased (1.483043 --> 1.483035).         Saving model ...\n",
      "Epoch: 1954 \tTraining Loss: 1.081949 \tValidation Loss: 1.483027\n",
      "Validation loss decreased (1.483035 --> 1.483027).         Saving model ...\n",
      "Epoch: 1955 \tTraining Loss: 1.081945 \tValidation Loss: 1.483019\n",
      "Validation loss decreased (1.483027 --> 1.483019).         Saving model ...\n",
      "Epoch: 1956 \tTraining Loss: 1.081940 \tValidation Loss: 1.483011\n",
      "Validation loss decreased (1.483019 --> 1.483011).         Saving model ...\n",
      "Epoch: 1957 \tTraining Loss: 1.081936 \tValidation Loss: 1.483004\n",
      "Validation loss decreased (1.483011 --> 1.483004).         Saving model ...\n",
      "Epoch: 1958 \tTraining Loss: 1.081932 \tValidation Loss: 1.482996\n",
      "Validation loss decreased (1.483004 --> 1.482996).         Saving model ...\n",
      "Epoch: 1959 \tTraining Loss: 1.081927 \tValidation Loss: 1.482989\n",
      "Validation loss decreased (1.482996 --> 1.482989).         Saving model ...\n",
      "Epoch: 1960 \tTraining Loss: 1.081923 \tValidation Loss: 1.482981\n",
      "Validation loss decreased (1.482989 --> 1.482981).         Saving model ...\n",
      "Epoch: 1961 \tTraining Loss: 1.081919 \tValidation Loss: 1.482974\n",
      "Validation loss decreased (1.482981 --> 1.482974).         Saving model ...\n",
      "Epoch: 1962 \tTraining Loss: 1.081915 \tValidation Loss: 1.482966\n",
      "Validation loss decreased (1.482974 --> 1.482966).         Saving model ...\n",
      "Epoch: 1963 \tTraining Loss: 1.081910 \tValidation Loss: 1.482958\n",
      "Validation loss decreased (1.482966 --> 1.482958).         Saving model ...\n",
      "Epoch: 1964 \tTraining Loss: 1.081906 \tValidation Loss: 1.482951\n",
      "Validation loss decreased (1.482958 --> 1.482951).         Saving model ...\n",
      "Epoch: 1965 \tTraining Loss: 1.081902 \tValidation Loss: 1.482943\n",
      "Validation loss decreased (1.482951 --> 1.482943).         Saving model ...\n",
      "Epoch: 1966 \tTraining Loss: 1.081898 \tValidation Loss: 1.482935\n",
      "Validation loss decreased (1.482943 --> 1.482935).         Saving model ...\n",
      "Epoch: 1967 \tTraining Loss: 1.081893 \tValidation Loss: 1.482928\n",
      "Validation loss decreased (1.482935 --> 1.482928).         Saving model ...\n",
      "Epoch: 1968 \tTraining Loss: 1.081889 \tValidation Loss: 1.482920\n",
      "Validation loss decreased (1.482928 --> 1.482920).         Saving model ...\n",
      "Epoch: 1969 \tTraining Loss: 1.081885 \tValidation Loss: 1.482913\n",
      "Validation loss decreased (1.482920 --> 1.482913).         Saving model ...\n",
      "Epoch: 1970 \tTraining Loss: 1.081881 \tValidation Loss: 1.482905\n",
      "Validation loss decreased (1.482913 --> 1.482905).         Saving model ...\n",
      "Epoch: 1971 \tTraining Loss: 1.081876 \tValidation Loss: 1.482897\n",
      "Validation loss decreased (1.482905 --> 1.482897).         Saving model ...\n",
      "Epoch: 1972 \tTraining Loss: 1.081872 \tValidation Loss: 1.482890\n",
      "Validation loss decreased (1.482897 --> 1.482890).         Saving model ...\n",
      "Epoch: 1973 \tTraining Loss: 1.081868 \tValidation Loss: 1.482883\n",
      "Validation loss decreased (1.482890 --> 1.482883).         Saving model ...\n",
      "Epoch: 1974 \tTraining Loss: 1.081864 \tValidation Loss: 1.482875\n",
      "Validation loss decreased (1.482883 --> 1.482875).         Saving model ...\n",
      "Epoch: 1975 \tTraining Loss: 1.081859 \tValidation Loss: 1.482866\n",
      "Validation loss decreased (1.482875 --> 1.482866).         Saving model ...\n",
      "Epoch: 1976 \tTraining Loss: 1.081855 \tValidation Loss: 1.482860\n",
      "Validation loss decreased (1.482866 --> 1.482860).         Saving model ...\n",
      "Epoch: 1977 \tTraining Loss: 1.081851 \tValidation Loss: 1.482851\n",
      "Validation loss decreased (1.482860 --> 1.482851).         Saving model ...\n",
      "Epoch: 1978 \tTraining Loss: 1.081847 \tValidation Loss: 1.482844\n",
      "Validation loss decreased (1.482851 --> 1.482844).         Saving model ...\n",
      "Epoch: 1979 \tTraining Loss: 1.081842 \tValidation Loss: 1.482837\n",
      "Validation loss decreased (1.482844 --> 1.482837).         Saving model ...\n",
      "Epoch: 1980 \tTraining Loss: 1.081838 \tValidation Loss: 1.482830\n",
      "Validation loss decreased (1.482837 --> 1.482830).         Saving model ...\n",
      "Epoch: 1981 \tTraining Loss: 1.081834 \tValidation Loss: 1.482822\n",
      "Validation loss decreased (1.482830 --> 1.482822).         Saving model ...\n",
      "Epoch: 1982 \tTraining Loss: 1.081830 \tValidation Loss: 1.482815\n",
      "Validation loss decreased (1.482822 --> 1.482815).         Saving model ...\n",
      "Epoch: 1983 \tTraining Loss: 1.081826 \tValidation Loss: 1.482807\n",
      "Validation loss decreased (1.482815 --> 1.482807).         Saving model ...\n",
      "Epoch: 1984 \tTraining Loss: 1.081821 \tValidation Loss: 1.482800\n",
      "Validation loss decreased (1.482807 --> 1.482800).         Saving model ...\n",
      "Epoch: 1985 \tTraining Loss: 1.081817 \tValidation Loss: 1.482793\n",
      "Validation loss decreased (1.482800 --> 1.482793).         Saving model ...\n",
      "Epoch: 1986 \tTraining Loss: 1.081813 \tValidation Loss: 1.482785\n",
      "Validation loss decreased (1.482793 --> 1.482785).         Saving model ...\n",
      "Epoch: 1987 \tTraining Loss: 1.081809 \tValidation Loss: 1.482777\n",
      "Validation loss decreased (1.482785 --> 1.482777).         Saving model ...\n",
      "Epoch: 1988 \tTraining Loss: 1.081805 \tValidation Loss: 1.482771\n",
      "Validation loss decreased (1.482777 --> 1.482771).         Saving model ...\n",
      "Epoch: 1989 \tTraining Loss: 1.081800 \tValidation Loss: 1.482763\n",
      "Validation loss decreased (1.482771 --> 1.482763).         Saving model ...\n",
      "Epoch: 1990 \tTraining Loss: 1.081796 \tValidation Loss: 1.482756\n",
      "Validation loss decreased (1.482763 --> 1.482756).         Saving model ...\n",
      "Epoch: 1991 \tTraining Loss: 1.081792 \tValidation Loss: 1.482747\n",
      "Validation loss decreased (1.482756 --> 1.482747).         Saving model ...\n",
      "Epoch: 1992 \tTraining Loss: 1.081788 \tValidation Loss: 1.482740\n",
      "Validation loss decreased (1.482747 --> 1.482740).         Saving model ...\n",
      "Epoch: 1993 \tTraining Loss: 1.081784 \tValidation Loss: 1.482733\n",
      "Validation loss decreased (1.482740 --> 1.482733).         Saving model ...\n",
      "Epoch: 1994 \tTraining Loss: 1.081780 \tValidation Loss: 1.482726\n",
      "Validation loss decreased (1.482733 --> 1.482726).         Saving model ...\n",
      "Epoch: 1995 \tTraining Loss: 1.081775 \tValidation Loss: 1.482718\n",
      "Validation loss decreased (1.482726 --> 1.482718).         Saving model ...\n",
      "Epoch: 1996 \tTraining Loss: 1.081771 \tValidation Loss: 1.482712\n",
      "Validation loss decreased (1.482718 --> 1.482712).         Saving model ...\n",
      "Epoch: 1997 \tTraining Loss: 1.081767 \tValidation Loss: 1.482704\n",
      "Validation loss decreased (1.482712 --> 1.482704).         Saving model ...\n",
      "Epoch: 1998 \tTraining Loss: 1.081763 \tValidation Loss: 1.482697\n",
      "Validation loss decreased (1.482704 --> 1.482697).         Saving model ...\n",
      "Epoch: 1999 \tTraining Loss: 1.081759 \tValidation Loss: 1.482690\n",
      "Validation loss decreased (1.482697 --> 1.482690).         Saving model ...\n",
      "Epoch: 2000 \tTraining Loss: 1.081755 \tValidation Loss: 1.482684\n",
      "Validation loss decreased (1.482690 --> 1.482684).         Saving model ...\n",
      "Epoch: 2001 \tTraining Loss: 1.081750 \tValidation Loss: 1.482677\n",
      "Validation loss decreased (1.482684 --> 1.482677).         Saving model ...\n",
      "Epoch: 2002 \tTraining Loss: 1.081746 \tValidation Loss: 1.482670\n",
      "Validation loss decreased (1.482677 --> 1.482670).         Saving model ...\n",
      "Epoch: 2003 \tTraining Loss: 1.081742 \tValidation Loss: 1.482663\n",
      "Validation loss decreased (1.482670 --> 1.482663).         Saving model ...\n",
      "Epoch: 2004 \tTraining Loss: 1.081738 \tValidation Loss: 1.482657\n",
      "Validation loss decreased (1.482663 --> 1.482657).         Saving model ...\n",
      "Epoch: 2005 \tTraining Loss: 1.081734 \tValidation Loss: 1.482649\n",
      "Validation loss decreased (1.482657 --> 1.482649).         Saving model ...\n",
      "Epoch: 2006 \tTraining Loss: 1.081730 \tValidation Loss: 1.482642\n",
      "Validation loss decreased (1.482649 --> 1.482642).         Saving model ...\n",
      "Epoch: 2007 \tTraining Loss: 1.081726 \tValidation Loss: 1.482636\n",
      "Validation loss decreased (1.482642 --> 1.482636).         Saving model ...\n",
      "Epoch: 2008 \tTraining Loss: 1.081721 \tValidation Loss: 1.482629\n",
      "Validation loss decreased (1.482636 --> 1.482629).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2009 \tTraining Loss: 1.081717 \tValidation Loss: 1.482622\n",
      "Validation loss decreased (1.482629 --> 1.482622).         Saving model ...\n",
      "Epoch: 2010 \tTraining Loss: 1.081713 \tValidation Loss: 1.482615\n",
      "Validation loss decreased (1.482622 --> 1.482615).         Saving model ...\n",
      "Epoch: 2011 \tTraining Loss: 1.081709 \tValidation Loss: 1.482609\n",
      "Validation loss decreased (1.482615 --> 1.482609).         Saving model ...\n",
      "Epoch: 2012 \tTraining Loss: 1.081705 \tValidation Loss: 1.482602\n",
      "Validation loss decreased (1.482609 --> 1.482602).         Saving model ...\n",
      "Epoch: 2013 \tTraining Loss: 1.081701 \tValidation Loss: 1.482596\n",
      "Validation loss decreased (1.482602 --> 1.482596).         Saving model ...\n",
      "Epoch: 2014 \tTraining Loss: 1.081697 \tValidation Loss: 1.482588\n",
      "Validation loss decreased (1.482596 --> 1.482588).         Saving model ...\n",
      "Epoch: 2015 \tTraining Loss: 1.081693 \tValidation Loss: 1.482582\n",
      "Validation loss decreased (1.482588 --> 1.482582).         Saving model ...\n",
      "Epoch: 2016 \tTraining Loss: 1.081688 \tValidation Loss: 1.482574\n",
      "Validation loss decreased (1.482582 --> 1.482574).         Saving model ...\n",
      "Epoch: 2017 \tTraining Loss: 1.081684 \tValidation Loss: 1.482567\n",
      "Validation loss decreased (1.482574 --> 1.482567).         Saving model ...\n",
      "Epoch: 2018 \tTraining Loss: 1.081680 \tValidation Loss: 1.482560\n",
      "Validation loss decreased (1.482567 --> 1.482560).         Saving model ...\n",
      "Epoch: 2019 \tTraining Loss: 1.081676 \tValidation Loss: 1.482553\n",
      "Validation loss decreased (1.482560 --> 1.482553).         Saving model ...\n",
      "Epoch: 2020 \tTraining Loss: 1.081672 \tValidation Loss: 1.482546\n",
      "Validation loss decreased (1.482553 --> 1.482546).         Saving model ...\n",
      "Epoch: 2021 \tTraining Loss: 1.081668 \tValidation Loss: 1.482539\n",
      "Validation loss decreased (1.482546 --> 1.482539).         Saving model ...\n",
      "Epoch: 2022 \tTraining Loss: 1.081664 \tValidation Loss: 1.482532\n",
      "Validation loss decreased (1.482539 --> 1.482532).         Saving model ...\n",
      "Epoch: 2023 \tTraining Loss: 1.081660 \tValidation Loss: 1.482526\n",
      "Validation loss decreased (1.482532 --> 1.482526).         Saving model ...\n",
      "Epoch: 2024 \tTraining Loss: 1.081656 \tValidation Loss: 1.482520\n",
      "Validation loss decreased (1.482526 --> 1.482520).         Saving model ...\n",
      "Epoch: 2025 \tTraining Loss: 1.081652 \tValidation Loss: 1.482513\n",
      "Validation loss decreased (1.482520 --> 1.482513).         Saving model ...\n",
      "Epoch: 2026 \tTraining Loss: 1.081647 \tValidation Loss: 1.482507\n",
      "Validation loss decreased (1.482513 --> 1.482507).         Saving model ...\n",
      "Epoch: 2027 \tTraining Loss: 1.081643 \tValidation Loss: 1.482501\n",
      "Validation loss decreased (1.482507 --> 1.482501).         Saving model ...\n",
      "Epoch: 2028 \tTraining Loss: 1.081639 \tValidation Loss: 1.482495\n",
      "Validation loss decreased (1.482501 --> 1.482495).         Saving model ...\n",
      "Epoch: 2029 \tTraining Loss: 1.081635 \tValidation Loss: 1.482489\n",
      "Validation loss decreased (1.482495 --> 1.482489).         Saving model ...\n",
      "Epoch: 2030 \tTraining Loss: 1.081631 \tValidation Loss: 1.482481\n",
      "Validation loss decreased (1.482489 --> 1.482481).         Saving model ...\n",
      "Epoch: 2031 \tTraining Loss: 1.081627 \tValidation Loss: 1.482476\n",
      "Validation loss decreased (1.482481 --> 1.482476).         Saving model ...\n",
      "Epoch: 2032 \tTraining Loss: 1.081623 \tValidation Loss: 1.482469\n",
      "Validation loss decreased (1.482476 --> 1.482469).         Saving model ...\n",
      "Epoch: 2033 \tTraining Loss: 1.081619 \tValidation Loss: 1.482462\n",
      "Validation loss decreased (1.482469 --> 1.482462).         Saving model ...\n",
      "Epoch: 2034 \tTraining Loss: 1.081615 \tValidation Loss: 1.482456\n",
      "Validation loss decreased (1.482462 --> 1.482456).         Saving model ...\n",
      "Epoch: 2035 \tTraining Loss: 1.081611 \tValidation Loss: 1.482450\n",
      "Validation loss decreased (1.482456 --> 1.482450).         Saving model ...\n",
      "Epoch: 2036 \tTraining Loss: 1.081607 \tValidation Loss: 1.482443\n",
      "Validation loss decreased (1.482450 --> 1.482443).         Saving model ...\n",
      "Epoch: 2037 \tTraining Loss: 1.081603 \tValidation Loss: 1.482438\n",
      "Validation loss decreased (1.482443 --> 1.482438).         Saving model ...\n",
      "Epoch: 2038 \tTraining Loss: 1.081599 \tValidation Loss: 1.482431\n",
      "Validation loss decreased (1.482438 --> 1.482431).         Saving model ...\n",
      "Epoch: 2039 \tTraining Loss: 1.081595 \tValidation Loss: 1.482425\n",
      "Validation loss decreased (1.482431 --> 1.482425).         Saving model ...\n",
      "Epoch: 2040 \tTraining Loss: 1.081591 \tValidation Loss: 1.482418\n",
      "Validation loss decreased (1.482425 --> 1.482418).         Saving model ...\n",
      "Epoch: 2041 \tTraining Loss: 1.081587 \tValidation Loss: 1.482412\n",
      "Validation loss decreased (1.482418 --> 1.482412).         Saving model ...\n",
      "Epoch: 2042 \tTraining Loss: 1.081582 \tValidation Loss: 1.482406\n",
      "Validation loss decreased (1.482412 --> 1.482406).         Saving model ...\n",
      "Epoch: 2043 \tTraining Loss: 1.081578 \tValidation Loss: 1.482399\n",
      "Validation loss decreased (1.482406 --> 1.482399).         Saving model ...\n",
      "Epoch: 2044 \tTraining Loss: 1.081574 \tValidation Loss: 1.482392\n",
      "Validation loss decreased (1.482399 --> 1.482392).         Saving model ...\n",
      "Epoch: 2045 \tTraining Loss: 1.081570 \tValidation Loss: 1.482386\n",
      "Validation loss decreased (1.482392 --> 1.482386).         Saving model ...\n",
      "Epoch: 2046 \tTraining Loss: 1.081566 \tValidation Loss: 1.482379\n",
      "Validation loss decreased (1.482386 --> 1.482379).         Saving model ...\n",
      "Epoch: 2047 \tTraining Loss: 1.081562 \tValidation Loss: 1.482373\n",
      "Validation loss decreased (1.482379 --> 1.482373).         Saving model ...\n",
      "Epoch: 2048 \tTraining Loss: 1.081558 \tValidation Loss: 1.482365\n",
      "Validation loss decreased (1.482373 --> 1.482365).         Saving model ...\n",
      "Epoch: 2049 \tTraining Loss: 1.081554 \tValidation Loss: 1.482359\n",
      "Validation loss decreased (1.482365 --> 1.482359).         Saving model ...\n",
      "Epoch: 2050 \tTraining Loss: 1.081550 \tValidation Loss: 1.482353\n",
      "Validation loss decreased (1.482359 --> 1.482353).         Saving model ...\n",
      "Epoch: 2051 \tTraining Loss: 1.081546 \tValidation Loss: 1.482348\n",
      "Validation loss decreased (1.482353 --> 1.482348).         Saving model ...\n",
      "Epoch: 2052 \tTraining Loss: 1.081542 \tValidation Loss: 1.482342\n",
      "Validation loss decreased (1.482348 --> 1.482342).         Saving model ...\n",
      "Epoch: 2053 \tTraining Loss: 1.081538 \tValidation Loss: 1.482335\n",
      "Validation loss decreased (1.482342 --> 1.482335).         Saving model ...\n",
      "Epoch: 2054 \tTraining Loss: 1.081534 \tValidation Loss: 1.482329\n",
      "Validation loss decreased (1.482335 --> 1.482329).         Saving model ...\n",
      "Epoch: 2055 \tTraining Loss: 1.081530 \tValidation Loss: 1.482323\n",
      "Validation loss decreased (1.482329 --> 1.482323).         Saving model ...\n",
      "Epoch: 2056 \tTraining Loss: 1.081526 \tValidation Loss: 1.482317\n",
      "Validation loss decreased (1.482323 --> 1.482317).         Saving model ...\n",
      "Epoch: 2057 \tTraining Loss: 1.081522 \tValidation Loss: 1.482311\n",
      "Validation loss decreased (1.482317 --> 1.482311).         Saving model ...\n",
      "Epoch: 2058 \tTraining Loss: 1.081518 \tValidation Loss: 1.482305\n",
      "Validation loss decreased (1.482311 --> 1.482305).         Saving model ...\n",
      "Epoch: 2059 \tTraining Loss: 1.081514 \tValidation Loss: 1.482299\n",
      "Validation loss decreased (1.482305 --> 1.482299).         Saving model ...\n",
      "Epoch: 2060 \tTraining Loss: 1.081510 \tValidation Loss: 1.482293\n",
      "Validation loss decreased (1.482299 --> 1.482293).         Saving model ...\n",
      "Epoch: 2061 \tTraining Loss: 1.081506 \tValidation Loss: 1.482287\n",
      "Validation loss decreased (1.482293 --> 1.482287).         Saving model ...\n",
      "Epoch: 2062 \tTraining Loss: 1.081502 \tValidation Loss: 1.482281\n",
      "Validation loss decreased (1.482287 --> 1.482281).         Saving model ...\n",
      "Epoch: 2063 \tTraining Loss: 1.081498 \tValidation Loss: 1.482274\n",
      "Validation loss decreased (1.482281 --> 1.482274).         Saving model ...\n",
      "Epoch: 2064 \tTraining Loss: 1.081494 \tValidation Loss: 1.482269\n",
      "Validation loss decreased (1.482274 --> 1.482269).         Saving model ...\n",
      "Epoch: 2065 \tTraining Loss: 1.081490 \tValidation Loss: 1.482263\n",
      "Validation loss decreased (1.482269 --> 1.482263).         Saving model ...\n",
      "Epoch: 2066 \tTraining Loss: 1.081486 \tValidation Loss: 1.482257\n",
      "Validation loss decreased (1.482263 --> 1.482257).         Saving model ...\n",
      "Epoch: 2067 \tTraining Loss: 1.081482 \tValidation Loss: 1.482251\n",
      "Validation loss decreased (1.482257 --> 1.482251).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2068 \tTraining Loss: 1.081478 \tValidation Loss: 1.482246\n",
      "Validation loss decreased (1.482251 --> 1.482246).         Saving model ...\n",
      "Epoch: 2069 \tTraining Loss: 1.081474 \tValidation Loss: 1.482240\n",
      "Validation loss decreased (1.482246 --> 1.482240).         Saving model ...\n",
      "Epoch: 2070 \tTraining Loss: 1.081470 \tValidation Loss: 1.482234\n",
      "Validation loss decreased (1.482240 --> 1.482234).         Saving model ...\n",
      "Epoch: 2071 \tTraining Loss: 1.081466 \tValidation Loss: 1.482228\n",
      "Validation loss decreased (1.482234 --> 1.482228).         Saving model ...\n",
      "Epoch: 2072 \tTraining Loss: 1.081462 \tValidation Loss: 1.482223\n",
      "Validation loss decreased (1.482228 --> 1.482223).         Saving model ...\n",
      "Epoch: 2073 \tTraining Loss: 1.081459 \tValidation Loss: 1.482218\n",
      "Validation loss decreased (1.482223 --> 1.482218).         Saving model ...\n",
      "Epoch: 2074 \tTraining Loss: 1.081455 \tValidation Loss: 1.482212\n",
      "Validation loss decreased (1.482218 --> 1.482212).         Saving model ...\n",
      "Epoch: 2075 \tTraining Loss: 1.081451 \tValidation Loss: 1.482206\n",
      "Validation loss decreased (1.482212 --> 1.482206).         Saving model ...\n",
      "Epoch: 2076 \tTraining Loss: 1.081447 \tValidation Loss: 1.482201\n",
      "Validation loss decreased (1.482206 --> 1.482201).         Saving model ...\n",
      "Epoch: 2077 \tTraining Loss: 1.081443 \tValidation Loss: 1.482195\n",
      "Validation loss decreased (1.482201 --> 1.482195).         Saving model ...\n",
      "Epoch: 2078 \tTraining Loss: 1.081439 \tValidation Loss: 1.482189\n",
      "Validation loss decreased (1.482195 --> 1.482189).         Saving model ...\n",
      "Epoch: 2079 \tTraining Loss: 1.081435 \tValidation Loss: 1.482184\n",
      "Validation loss decreased (1.482189 --> 1.482184).         Saving model ...\n",
      "Epoch: 2080 \tTraining Loss: 1.081431 \tValidation Loss: 1.482177\n",
      "Validation loss decreased (1.482184 --> 1.482177).         Saving model ...\n",
      "Epoch: 2081 \tTraining Loss: 1.081427 \tValidation Loss: 1.482172\n",
      "Validation loss decreased (1.482177 --> 1.482172).         Saving model ...\n",
      "Epoch: 2082 \tTraining Loss: 1.081423 \tValidation Loss: 1.482166\n",
      "Validation loss decreased (1.482172 --> 1.482166).         Saving model ...\n",
      "Epoch: 2083 \tTraining Loss: 1.081419 \tValidation Loss: 1.482160\n",
      "Validation loss decreased (1.482166 --> 1.482160).         Saving model ...\n",
      "Epoch: 2084 \tTraining Loss: 1.081415 \tValidation Loss: 1.482155\n",
      "Validation loss decreased (1.482160 --> 1.482155).         Saving model ...\n",
      "Epoch: 2085 \tTraining Loss: 1.081411 \tValidation Loss: 1.482149\n",
      "Validation loss decreased (1.482155 --> 1.482149).         Saving model ...\n",
      "Epoch: 2086 \tTraining Loss: 1.081407 \tValidation Loss: 1.482143\n",
      "Validation loss decreased (1.482149 --> 1.482143).         Saving model ...\n",
      "Epoch: 2087 \tTraining Loss: 1.081403 \tValidation Loss: 1.482138\n",
      "Validation loss decreased (1.482143 --> 1.482138).         Saving model ...\n",
      "Epoch: 2088 \tTraining Loss: 1.081399 \tValidation Loss: 1.482133\n",
      "Validation loss decreased (1.482138 --> 1.482133).         Saving model ...\n",
      "Epoch: 2089 \tTraining Loss: 1.081396 \tValidation Loss: 1.482128\n",
      "Validation loss decreased (1.482133 --> 1.482128).         Saving model ...\n",
      "Epoch: 2090 \tTraining Loss: 1.081392 \tValidation Loss: 1.482123\n",
      "Validation loss decreased (1.482128 --> 1.482123).         Saving model ...\n",
      "Epoch: 2091 \tTraining Loss: 1.081388 \tValidation Loss: 1.482118\n",
      "Validation loss decreased (1.482123 --> 1.482118).         Saving model ...\n",
      "Epoch: 2092 \tTraining Loss: 1.081384 \tValidation Loss: 1.482114\n",
      "Validation loss decreased (1.482118 --> 1.482114).         Saving model ...\n",
      "Epoch: 2093 \tTraining Loss: 1.081380 \tValidation Loss: 1.482109\n",
      "Validation loss decreased (1.482114 --> 1.482109).         Saving model ...\n",
      "Epoch: 2094 \tTraining Loss: 1.081376 \tValidation Loss: 1.482103\n",
      "Validation loss decreased (1.482109 --> 1.482103).         Saving model ...\n",
      "Epoch: 2095 \tTraining Loss: 1.081372 \tValidation Loss: 1.482098\n",
      "Validation loss decreased (1.482103 --> 1.482098).         Saving model ...\n",
      "Epoch: 2096 \tTraining Loss: 1.081368 \tValidation Loss: 1.482094\n",
      "Validation loss decreased (1.482098 --> 1.482094).         Saving model ...\n",
      "Epoch: 2097 \tTraining Loss: 1.081364 \tValidation Loss: 1.482087\n",
      "Validation loss decreased (1.482094 --> 1.482087).         Saving model ...\n",
      "Epoch: 2098 \tTraining Loss: 1.081360 \tValidation Loss: 1.482081\n",
      "Validation loss decreased (1.482087 --> 1.482081).         Saving model ...\n",
      "Epoch: 2099 \tTraining Loss: 1.081357 \tValidation Loss: 1.482076\n",
      "Validation loss decreased (1.482081 --> 1.482076).         Saving model ...\n",
      "Epoch: 2100 \tTraining Loss: 1.081353 \tValidation Loss: 1.482070\n",
      "Validation loss decreased (1.482076 --> 1.482070).         Saving model ...\n",
      "Epoch: 2101 \tTraining Loss: 1.081349 \tValidation Loss: 1.482065\n",
      "Validation loss decreased (1.482070 --> 1.482065).         Saving model ...\n",
      "Epoch: 2102 \tTraining Loss: 1.081345 \tValidation Loss: 1.482059\n",
      "Validation loss decreased (1.482065 --> 1.482059).         Saving model ...\n",
      "Epoch: 2103 \tTraining Loss: 1.081341 \tValidation Loss: 1.482052\n",
      "Validation loss decreased (1.482059 --> 1.482052).         Saving model ...\n",
      "Epoch: 2104 \tTraining Loss: 1.081337 \tValidation Loss: 1.482047\n",
      "Validation loss decreased (1.482052 --> 1.482047).         Saving model ...\n",
      "Epoch: 2105 \tTraining Loss: 1.081333 \tValidation Loss: 1.482041\n",
      "Validation loss decreased (1.482047 --> 1.482041).         Saving model ...\n",
      "Epoch: 2106 \tTraining Loss: 1.081329 \tValidation Loss: 1.482035\n",
      "Validation loss decreased (1.482041 --> 1.482035).         Saving model ...\n",
      "Epoch: 2107 \tTraining Loss: 1.081326 \tValidation Loss: 1.482028\n",
      "Validation loss decreased (1.482035 --> 1.482028).         Saving model ...\n",
      "Epoch: 2108 \tTraining Loss: 1.081322 \tValidation Loss: 1.482023\n",
      "Validation loss decreased (1.482028 --> 1.482023).         Saving model ...\n",
      "Epoch: 2109 \tTraining Loss: 1.081318 \tValidation Loss: 1.482017\n",
      "Validation loss decreased (1.482023 --> 1.482017).         Saving model ...\n",
      "Epoch: 2110 \tTraining Loss: 1.081314 \tValidation Loss: 1.482011\n",
      "Validation loss decreased (1.482017 --> 1.482011).         Saving model ...\n",
      "Epoch: 2111 \tTraining Loss: 1.081310 \tValidation Loss: 1.482005\n",
      "Validation loss decreased (1.482011 --> 1.482005).         Saving model ...\n",
      "Epoch: 2112 \tTraining Loss: 1.081306 \tValidation Loss: 1.482000\n",
      "Validation loss decreased (1.482005 --> 1.482000).         Saving model ...\n",
      "Epoch: 2113 \tTraining Loss: 1.081302 \tValidation Loss: 1.481994\n",
      "Validation loss decreased (1.482000 --> 1.481994).         Saving model ...\n",
      "Epoch: 2114 \tTraining Loss: 1.081299 \tValidation Loss: 1.481988\n",
      "Validation loss decreased (1.481994 --> 1.481988).         Saving model ...\n",
      "Epoch: 2115 \tTraining Loss: 1.081295 \tValidation Loss: 1.481984\n",
      "Validation loss decreased (1.481988 --> 1.481984).         Saving model ...\n",
      "Epoch: 2116 \tTraining Loss: 1.081291 \tValidation Loss: 1.481978\n",
      "Validation loss decreased (1.481984 --> 1.481978).         Saving model ...\n",
      "Epoch: 2117 \tTraining Loss: 1.081287 \tValidation Loss: 1.481972\n",
      "Validation loss decreased (1.481978 --> 1.481972).         Saving model ...\n",
      "Epoch: 2118 \tTraining Loss: 1.081283 \tValidation Loss: 1.481967\n",
      "Validation loss decreased (1.481972 --> 1.481967).         Saving model ...\n",
      "Epoch: 2119 \tTraining Loss: 1.081279 \tValidation Loss: 1.481961\n",
      "Validation loss decreased (1.481967 --> 1.481961).         Saving model ...\n",
      "Epoch: 2120 \tTraining Loss: 1.081276 \tValidation Loss: 1.481956\n",
      "Validation loss decreased (1.481961 --> 1.481956).         Saving model ...\n",
      "Epoch: 2121 \tTraining Loss: 1.081272 \tValidation Loss: 1.481949\n",
      "Validation loss decreased (1.481956 --> 1.481949).         Saving model ...\n",
      "Epoch: 2122 \tTraining Loss: 1.081268 \tValidation Loss: 1.481944\n",
      "Validation loss decreased (1.481949 --> 1.481944).         Saving model ...\n",
      "Epoch: 2123 \tTraining Loss: 1.081264 \tValidation Loss: 1.481938\n",
      "Validation loss decreased (1.481944 --> 1.481938).         Saving model ...\n",
      "Epoch: 2124 \tTraining Loss: 1.081260 \tValidation Loss: 1.481931\n",
      "Validation loss decreased (1.481938 --> 1.481931).         Saving model ...\n",
      "Epoch: 2125 \tTraining Loss: 1.081256 \tValidation Loss: 1.481926\n",
      "Validation loss decreased (1.481931 --> 1.481926).         Saving model ...\n",
      "Epoch: 2126 \tTraining Loss: 1.081253 \tValidation Loss: 1.481919\n",
      "Validation loss decreased (1.481926 --> 1.481919).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2127 \tTraining Loss: 1.081249 \tValidation Loss: 1.481915\n",
      "Validation loss decreased (1.481919 --> 1.481915).         Saving model ...\n",
      "Epoch: 2128 \tTraining Loss: 1.081245 \tValidation Loss: 1.481909\n",
      "Validation loss decreased (1.481915 --> 1.481909).         Saving model ...\n",
      "Epoch: 2129 \tTraining Loss: 1.081241 \tValidation Loss: 1.481904\n",
      "Validation loss decreased (1.481909 --> 1.481904).         Saving model ...\n",
      "Epoch: 2130 \tTraining Loss: 1.081237 \tValidation Loss: 1.481898\n",
      "Validation loss decreased (1.481904 --> 1.481898).         Saving model ...\n",
      "Epoch: 2131 \tTraining Loss: 1.081234 \tValidation Loss: 1.481892\n",
      "Validation loss decreased (1.481898 --> 1.481892).         Saving model ...\n",
      "Epoch: 2132 \tTraining Loss: 1.081230 \tValidation Loss: 1.481887\n",
      "Validation loss decreased (1.481892 --> 1.481887).         Saving model ...\n",
      "Epoch: 2133 \tTraining Loss: 1.081226 \tValidation Loss: 1.481881\n",
      "Validation loss decreased (1.481887 --> 1.481881).         Saving model ...\n",
      "Epoch: 2134 \tTraining Loss: 1.081222 \tValidation Loss: 1.481876\n",
      "Validation loss decreased (1.481881 --> 1.481876).         Saving model ...\n",
      "Epoch: 2135 \tTraining Loss: 1.081218 \tValidation Loss: 1.481871\n",
      "Validation loss decreased (1.481876 --> 1.481871).         Saving model ...\n",
      "Epoch: 2136 \tTraining Loss: 1.081215 \tValidation Loss: 1.481865\n",
      "Validation loss decreased (1.481871 --> 1.481865).         Saving model ...\n",
      "Epoch: 2137 \tTraining Loss: 1.081211 \tValidation Loss: 1.481860\n",
      "Validation loss decreased (1.481865 --> 1.481860).         Saving model ...\n",
      "Epoch: 2138 \tTraining Loss: 1.081207 \tValidation Loss: 1.481855\n",
      "Validation loss decreased (1.481860 --> 1.481855).         Saving model ...\n",
      "Epoch: 2139 \tTraining Loss: 1.081203 \tValidation Loss: 1.481850\n",
      "Validation loss decreased (1.481855 --> 1.481850).         Saving model ...\n",
      "Epoch: 2140 \tTraining Loss: 1.081199 \tValidation Loss: 1.481845\n",
      "Validation loss decreased (1.481850 --> 1.481845).         Saving model ...\n",
      "Epoch: 2141 \tTraining Loss: 1.081196 \tValidation Loss: 1.481840\n",
      "Validation loss decreased (1.481845 --> 1.481840).         Saving model ...\n",
      "Epoch: 2142 \tTraining Loss: 1.081192 \tValidation Loss: 1.481836\n",
      "Validation loss decreased (1.481840 --> 1.481836).         Saving model ...\n",
      "Epoch: 2143 \tTraining Loss: 1.081188 \tValidation Loss: 1.481831\n",
      "Validation loss decreased (1.481836 --> 1.481831).         Saving model ...\n",
      "Epoch: 2144 \tTraining Loss: 1.081184 \tValidation Loss: 1.481826\n",
      "Validation loss decreased (1.481831 --> 1.481826).         Saving model ...\n",
      "Epoch: 2145 \tTraining Loss: 1.081180 \tValidation Loss: 1.481821\n",
      "Validation loss decreased (1.481826 --> 1.481821).         Saving model ...\n",
      "Epoch: 2146 \tTraining Loss: 1.081177 \tValidation Loss: 1.481816\n",
      "Validation loss decreased (1.481821 --> 1.481816).         Saving model ...\n",
      "Epoch: 2147 \tTraining Loss: 1.081173 \tValidation Loss: 1.481812\n",
      "Validation loss decreased (1.481816 --> 1.481812).         Saving model ...\n",
      "Epoch: 2148 \tTraining Loss: 1.081169 \tValidation Loss: 1.481807\n",
      "Validation loss decreased (1.481812 --> 1.481807).         Saving model ...\n",
      "Epoch: 2149 \tTraining Loss: 1.081165 \tValidation Loss: 1.481802\n",
      "Validation loss decreased (1.481807 --> 1.481802).         Saving model ...\n",
      "Epoch: 2150 \tTraining Loss: 1.081162 \tValidation Loss: 1.481796\n",
      "Validation loss decreased (1.481802 --> 1.481796).         Saving model ...\n",
      "Epoch: 2151 \tTraining Loss: 1.081158 \tValidation Loss: 1.481792\n",
      "Validation loss decreased (1.481796 --> 1.481792).         Saving model ...\n",
      "Epoch: 2152 \tTraining Loss: 1.081154 \tValidation Loss: 1.481786\n",
      "Validation loss decreased (1.481792 --> 1.481786).         Saving model ...\n",
      "Epoch: 2153 \tTraining Loss: 1.081150 \tValidation Loss: 1.481780\n",
      "Validation loss decreased (1.481786 --> 1.481780).         Saving model ...\n",
      "Epoch: 2154 \tTraining Loss: 1.081147 \tValidation Loss: 1.481775\n",
      "Validation loss decreased (1.481780 --> 1.481775).         Saving model ...\n",
      "Epoch: 2155 \tTraining Loss: 1.081143 \tValidation Loss: 1.481770\n",
      "Validation loss decreased (1.481775 --> 1.481770).         Saving model ...\n",
      "Epoch: 2156 \tTraining Loss: 1.081139 \tValidation Loss: 1.481764\n",
      "Validation loss decreased (1.481770 --> 1.481764).         Saving model ...\n",
      "Epoch: 2157 \tTraining Loss: 1.081135 \tValidation Loss: 1.481758\n",
      "Validation loss decreased (1.481764 --> 1.481758).         Saving model ...\n",
      "Epoch: 2158 \tTraining Loss: 1.081132 \tValidation Loss: 1.481753\n",
      "Validation loss decreased (1.481758 --> 1.481753).         Saving model ...\n",
      "Epoch: 2159 \tTraining Loss: 1.081128 \tValidation Loss: 1.481748\n",
      "Validation loss decreased (1.481753 --> 1.481748).         Saving model ...\n",
      "Epoch: 2160 \tTraining Loss: 1.081124 \tValidation Loss: 1.481743\n",
      "Validation loss decreased (1.481748 --> 1.481743).         Saving model ...\n",
      "Epoch: 2161 \tTraining Loss: 1.081120 \tValidation Loss: 1.481738\n",
      "Validation loss decreased (1.481743 --> 1.481738).         Saving model ...\n",
      "Epoch: 2162 \tTraining Loss: 1.081117 \tValidation Loss: 1.481732\n",
      "Validation loss decreased (1.481738 --> 1.481732).         Saving model ...\n",
      "Epoch: 2163 \tTraining Loss: 1.081113 \tValidation Loss: 1.481728\n",
      "Validation loss decreased (1.481732 --> 1.481728).         Saving model ...\n",
      "Epoch: 2164 \tTraining Loss: 1.081109 \tValidation Loss: 1.481723\n",
      "Validation loss decreased (1.481728 --> 1.481723).         Saving model ...\n",
      "Epoch: 2165 \tTraining Loss: 1.081106 \tValidation Loss: 1.481718\n",
      "Validation loss decreased (1.481723 --> 1.481718).         Saving model ...\n",
      "Epoch: 2166 \tTraining Loss: 1.081102 \tValidation Loss: 1.481713\n",
      "Validation loss decreased (1.481718 --> 1.481713).         Saving model ...\n",
      "Epoch: 2167 \tTraining Loss: 1.081098 \tValidation Loss: 1.481708\n",
      "Validation loss decreased (1.481713 --> 1.481708).         Saving model ...\n",
      "Epoch: 2168 \tTraining Loss: 1.081094 \tValidation Loss: 1.481702\n",
      "Validation loss decreased (1.481708 --> 1.481702).         Saving model ...\n",
      "Epoch: 2169 \tTraining Loss: 1.081091 \tValidation Loss: 1.481698\n",
      "Validation loss decreased (1.481702 --> 1.481698).         Saving model ...\n",
      "Epoch: 2170 \tTraining Loss: 1.081087 \tValidation Loss: 1.481692\n",
      "Validation loss decreased (1.481698 --> 1.481692).         Saving model ...\n",
      "Epoch: 2171 \tTraining Loss: 1.081083 \tValidation Loss: 1.481687\n",
      "Validation loss decreased (1.481692 --> 1.481687).         Saving model ...\n",
      "Epoch: 2172 \tTraining Loss: 1.081080 \tValidation Loss: 1.481683\n",
      "Validation loss decreased (1.481687 --> 1.481683).         Saving model ...\n",
      "Epoch: 2173 \tTraining Loss: 1.081076 \tValidation Loss: 1.481677\n",
      "Validation loss decreased (1.481683 --> 1.481677).         Saving model ...\n",
      "Epoch: 2174 \tTraining Loss: 1.081072 \tValidation Loss: 1.481671\n",
      "Validation loss decreased (1.481677 --> 1.481671).         Saving model ...\n",
      "Epoch: 2175 \tTraining Loss: 1.081068 \tValidation Loss: 1.481667\n",
      "Validation loss decreased (1.481671 --> 1.481667).         Saving model ...\n",
      "Epoch: 2176 \tTraining Loss: 1.081065 \tValidation Loss: 1.481662\n",
      "Validation loss decreased (1.481667 --> 1.481662).         Saving model ...\n",
      "Epoch: 2177 \tTraining Loss: 1.081061 \tValidation Loss: 1.481657\n",
      "Validation loss decreased (1.481662 --> 1.481657).         Saving model ...\n",
      "Epoch: 2178 \tTraining Loss: 1.081057 \tValidation Loss: 1.481652\n",
      "Validation loss decreased (1.481657 --> 1.481652).         Saving model ...\n",
      "Epoch: 2179 \tTraining Loss: 1.081054 \tValidation Loss: 1.481647\n",
      "Validation loss decreased (1.481652 --> 1.481647).         Saving model ...\n",
      "Epoch: 2180 \tTraining Loss: 1.081050 \tValidation Loss: 1.481641\n",
      "Validation loss decreased (1.481647 --> 1.481641).         Saving model ...\n",
      "Epoch: 2181 \tTraining Loss: 1.081046 \tValidation Loss: 1.481636\n",
      "Validation loss decreased (1.481641 --> 1.481636).         Saving model ...\n",
      "Epoch: 2182 \tTraining Loss: 1.081043 \tValidation Loss: 1.481631\n",
      "Validation loss decreased (1.481636 --> 1.481631).         Saving model ...\n",
      "Epoch: 2183 \tTraining Loss: 1.081039 \tValidation Loss: 1.481626\n",
      "Validation loss decreased (1.481631 --> 1.481626).         Saving model ...\n",
      "Epoch: 2184 \tTraining Loss: 1.081035 \tValidation Loss: 1.481620\n",
      "Validation loss decreased (1.481626 --> 1.481620).         Saving model ...\n",
      "Epoch: 2185 \tTraining Loss: 1.081032 \tValidation Loss: 1.481615\n",
      "Validation loss decreased (1.481620 --> 1.481615).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2186 \tTraining Loss: 1.081028 \tValidation Loss: 1.481610\n",
      "Validation loss decreased (1.481615 --> 1.481610).         Saving model ...\n",
      "Epoch: 2187 \tTraining Loss: 1.081024 \tValidation Loss: 1.481604\n",
      "Validation loss decreased (1.481610 --> 1.481604).         Saving model ...\n",
      "Epoch: 2188 \tTraining Loss: 1.081021 \tValidation Loss: 1.481599\n",
      "Validation loss decreased (1.481604 --> 1.481599).         Saving model ...\n",
      "Epoch: 2189 \tTraining Loss: 1.081017 \tValidation Loss: 1.481594\n",
      "Validation loss decreased (1.481599 --> 1.481594).         Saving model ...\n",
      "Epoch: 2190 \tTraining Loss: 1.081013 \tValidation Loss: 1.481589\n",
      "Validation loss decreased (1.481594 --> 1.481589).         Saving model ...\n",
      "Epoch: 2191 \tTraining Loss: 1.081010 \tValidation Loss: 1.481584\n",
      "Validation loss decreased (1.481589 --> 1.481584).         Saving model ...\n",
      "Epoch: 2192 \tTraining Loss: 1.081006 \tValidation Loss: 1.481579\n",
      "Validation loss decreased (1.481584 --> 1.481579).         Saving model ...\n",
      "Epoch: 2193 \tTraining Loss: 1.081002 \tValidation Loss: 1.481573\n",
      "Validation loss decreased (1.481579 --> 1.481573).         Saving model ...\n",
      "Epoch: 2194 \tTraining Loss: 1.080999 \tValidation Loss: 1.481568\n",
      "Validation loss decreased (1.481573 --> 1.481568).         Saving model ...\n",
      "Epoch: 2195 \tTraining Loss: 1.080995 \tValidation Loss: 1.481563\n",
      "Validation loss decreased (1.481568 --> 1.481563).         Saving model ...\n",
      "Epoch: 2196 \tTraining Loss: 1.080991 \tValidation Loss: 1.481557\n",
      "Validation loss decreased (1.481563 --> 1.481557).         Saving model ...\n",
      "Epoch: 2197 \tTraining Loss: 1.080988 \tValidation Loss: 1.481551\n",
      "Validation loss decreased (1.481557 --> 1.481551).         Saving model ...\n",
      "Epoch: 2198 \tTraining Loss: 1.080984 \tValidation Loss: 1.481547\n",
      "Validation loss decreased (1.481551 --> 1.481547).         Saving model ...\n",
      "Epoch: 2199 \tTraining Loss: 1.080980 \tValidation Loss: 1.481542\n",
      "Validation loss decreased (1.481547 --> 1.481542).         Saving model ...\n",
      "Epoch: 2200 \tTraining Loss: 1.080977 \tValidation Loss: 1.481537\n",
      "Validation loss decreased (1.481542 --> 1.481537).         Saving model ...\n",
      "Epoch: 2201 \tTraining Loss: 1.080973 \tValidation Loss: 1.481532\n",
      "Validation loss decreased (1.481537 --> 1.481532).         Saving model ...\n",
      "Epoch: 2202 \tTraining Loss: 1.080969 \tValidation Loss: 1.481527\n",
      "Validation loss decreased (1.481532 --> 1.481527).         Saving model ...\n",
      "Epoch: 2203 \tTraining Loss: 1.080966 \tValidation Loss: 1.481523\n",
      "Validation loss decreased (1.481527 --> 1.481523).         Saving model ...\n",
      "Epoch: 2204 \tTraining Loss: 1.080962 \tValidation Loss: 1.481518\n",
      "Validation loss decreased (1.481523 --> 1.481518).         Saving model ...\n",
      "Epoch: 2205 \tTraining Loss: 1.080958 \tValidation Loss: 1.481513\n",
      "Validation loss decreased (1.481518 --> 1.481513).         Saving model ...\n",
      "Epoch: 2206 \tTraining Loss: 1.080955 \tValidation Loss: 1.481509\n",
      "Validation loss decreased (1.481513 --> 1.481509).         Saving model ...\n",
      "Epoch: 2207 \tTraining Loss: 1.080951 \tValidation Loss: 1.481503\n",
      "Validation loss decreased (1.481509 --> 1.481503).         Saving model ...\n",
      "Epoch: 2208 \tTraining Loss: 1.080948 \tValidation Loss: 1.481498\n",
      "Validation loss decreased (1.481503 --> 1.481498).         Saving model ...\n",
      "Epoch: 2209 \tTraining Loss: 1.080944 \tValidation Loss: 1.481494\n",
      "Validation loss decreased (1.481498 --> 1.481494).         Saving model ...\n",
      "Epoch: 2210 \tTraining Loss: 1.080940 \tValidation Loss: 1.481489\n",
      "Validation loss decreased (1.481494 --> 1.481489).         Saving model ...\n",
      "Epoch: 2211 \tTraining Loss: 1.080937 \tValidation Loss: 1.481484\n",
      "Validation loss decreased (1.481489 --> 1.481484).         Saving model ...\n",
      "Epoch: 2212 \tTraining Loss: 1.080933 \tValidation Loss: 1.481478\n",
      "Validation loss decreased (1.481484 --> 1.481478).         Saving model ...\n",
      "Epoch: 2213 \tTraining Loss: 1.080930 \tValidation Loss: 1.481474\n",
      "Validation loss decreased (1.481478 --> 1.481474).         Saving model ...\n",
      "Epoch: 2214 \tTraining Loss: 1.080926 \tValidation Loss: 1.481470\n",
      "Validation loss decreased (1.481474 --> 1.481470).         Saving model ...\n",
      "Epoch: 2215 \tTraining Loss: 1.080922 \tValidation Loss: 1.481465\n",
      "Validation loss decreased (1.481470 --> 1.481465).         Saving model ...\n",
      "Epoch: 2216 \tTraining Loss: 1.080919 \tValidation Loss: 1.481460\n",
      "Validation loss decreased (1.481465 --> 1.481460).         Saving model ...\n",
      "Epoch: 2217 \tTraining Loss: 1.080915 \tValidation Loss: 1.481455\n",
      "Validation loss decreased (1.481460 --> 1.481455).         Saving model ...\n",
      "Epoch: 2218 \tTraining Loss: 1.080912 \tValidation Loss: 1.481451\n",
      "Validation loss decreased (1.481455 --> 1.481451).         Saving model ...\n",
      "Epoch: 2219 \tTraining Loss: 1.080908 \tValidation Loss: 1.481446\n",
      "Validation loss decreased (1.481451 --> 1.481446).         Saving model ...\n",
      "Epoch: 2220 \tTraining Loss: 1.080904 \tValidation Loss: 1.481441\n",
      "Validation loss decreased (1.481446 --> 1.481441).         Saving model ...\n",
      "Epoch: 2221 \tTraining Loss: 1.080901 \tValidation Loss: 1.481437\n",
      "Validation loss decreased (1.481441 --> 1.481437).         Saving model ...\n",
      "Epoch: 2222 \tTraining Loss: 1.080897 \tValidation Loss: 1.481432\n",
      "Validation loss decreased (1.481437 --> 1.481432).         Saving model ...\n",
      "Epoch: 2223 \tTraining Loss: 1.080894 \tValidation Loss: 1.481427\n",
      "Validation loss decreased (1.481432 --> 1.481427).         Saving model ...\n",
      "Epoch: 2224 \tTraining Loss: 1.080890 \tValidation Loss: 1.481423\n",
      "Validation loss decreased (1.481427 --> 1.481423).         Saving model ...\n",
      "Epoch: 2225 \tTraining Loss: 1.080886 \tValidation Loss: 1.481417\n",
      "Validation loss decreased (1.481423 --> 1.481417).         Saving model ...\n",
      "Epoch: 2226 \tTraining Loss: 1.080883 \tValidation Loss: 1.481413\n",
      "Validation loss decreased (1.481417 --> 1.481413).         Saving model ...\n",
      "Epoch: 2227 \tTraining Loss: 1.080879 \tValidation Loss: 1.481408\n",
      "Validation loss decreased (1.481413 --> 1.481408).         Saving model ...\n",
      "Epoch: 2228 \tTraining Loss: 1.080876 \tValidation Loss: 1.481402\n",
      "Validation loss decreased (1.481408 --> 1.481402).         Saving model ...\n",
      "Epoch: 2229 \tTraining Loss: 1.080872 \tValidation Loss: 1.481397\n",
      "Validation loss decreased (1.481402 --> 1.481397).         Saving model ...\n",
      "Epoch: 2230 \tTraining Loss: 1.080868 \tValidation Loss: 1.481392\n",
      "Validation loss decreased (1.481397 --> 1.481392).         Saving model ...\n",
      "Epoch: 2231 \tTraining Loss: 1.080865 \tValidation Loss: 1.481388\n",
      "Validation loss decreased (1.481392 --> 1.481388).         Saving model ...\n",
      "Epoch: 2232 \tTraining Loss: 1.080861 \tValidation Loss: 1.481383\n",
      "Validation loss decreased (1.481388 --> 1.481383).         Saving model ...\n",
      "Epoch: 2233 \tTraining Loss: 1.080858 \tValidation Loss: 1.481379\n",
      "Validation loss decreased (1.481383 --> 1.481379).         Saving model ...\n",
      "Epoch: 2234 \tTraining Loss: 1.080854 \tValidation Loss: 1.481374\n",
      "Validation loss decreased (1.481379 --> 1.481374).         Saving model ...\n",
      "Epoch: 2235 \tTraining Loss: 1.080851 \tValidation Loss: 1.481370\n",
      "Validation loss decreased (1.481374 --> 1.481370).         Saving model ...\n",
      "Epoch: 2236 \tTraining Loss: 1.080847 \tValidation Loss: 1.481364\n",
      "Validation loss decreased (1.481370 --> 1.481364).         Saving model ...\n",
      "Epoch: 2237 \tTraining Loss: 1.080844 \tValidation Loss: 1.481360\n",
      "Validation loss decreased (1.481364 --> 1.481360).         Saving model ...\n",
      "Epoch: 2238 \tTraining Loss: 1.080840 \tValidation Loss: 1.481355\n",
      "Validation loss decreased (1.481360 --> 1.481355).         Saving model ...\n",
      "Epoch: 2239 \tTraining Loss: 1.080836 \tValidation Loss: 1.481350\n",
      "Validation loss decreased (1.481355 --> 1.481350).         Saving model ...\n",
      "Epoch: 2240 \tTraining Loss: 1.080833 \tValidation Loss: 1.481345\n",
      "Validation loss decreased (1.481350 --> 1.481345).         Saving model ...\n",
      "Epoch: 2241 \tTraining Loss: 1.080829 \tValidation Loss: 1.481340\n",
      "Validation loss decreased (1.481345 --> 1.481340).         Saving model ...\n",
      "Epoch: 2242 \tTraining Loss: 1.080826 \tValidation Loss: 1.481335\n",
      "Validation loss decreased (1.481340 --> 1.481335).         Saving model ...\n",
      "Epoch: 2243 \tTraining Loss: 1.080822 \tValidation Loss: 1.481330\n",
      "Validation loss decreased (1.481335 --> 1.481330).         Saving model ...\n",
      "Epoch: 2244 \tTraining Loss: 1.080819 \tValidation Loss: 1.481325\n",
      "Validation loss decreased (1.481330 --> 1.481325).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2245 \tTraining Loss: 1.080815 \tValidation Loss: 1.481321\n",
      "Validation loss decreased (1.481325 --> 1.481321).         Saving model ...\n",
      "Epoch: 2246 \tTraining Loss: 1.080812 \tValidation Loss: 1.481316\n",
      "Validation loss decreased (1.481321 --> 1.481316).         Saving model ...\n",
      "Epoch: 2247 \tTraining Loss: 1.080808 \tValidation Loss: 1.481311\n",
      "Validation loss decreased (1.481316 --> 1.481311).         Saving model ...\n",
      "Epoch: 2248 \tTraining Loss: 1.080805 \tValidation Loss: 1.481307\n",
      "Validation loss decreased (1.481311 --> 1.481307).         Saving model ...\n",
      "Epoch: 2249 \tTraining Loss: 1.080801 \tValidation Loss: 1.481302\n",
      "Validation loss decreased (1.481307 --> 1.481302).         Saving model ...\n",
      "Epoch: 2250 \tTraining Loss: 1.080798 \tValidation Loss: 1.481298\n",
      "Validation loss decreased (1.481302 --> 1.481298).         Saving model ...\n",
      "Epoch: 2251 \tTraining Loss: 1.080794 \tValidation Loss: 1.481293\n",
      "Validation loss decreased (1.481298 --> 1.481293).         Saving model ...\n",
      "Epoch: 2252 \tTraining Loss: 1.080790 \tValidation Loss: 1.481289\n",
      "Validation loss decreased (1.481293 --> 1.481289).         Saving model ...\n",
      "Epoch: 2253 \tTraining Loss: 1.080787 \tValidation Loss: 1.481285\n",
      "Validation loss decreased (1.481289 --> 1.481285).         Saving model ...\n",
      "Epoch: 2254 \tTraining Loss: 1.080783 \tValidation Loss: 1.481281\n",
      "Validation loss decreased (1.481285 --> 1.481281).         Saving model ...\n",
      "Epoch: 2255 \tTraining Loss: 1.080780 \tValidation Loss: 1.481277\n",
      "Validation loss decreased (1.481281 --> 1.481277).         Saving model ...\n",
      "Epoch: 2256 \tTraining Loss: 1.080776 \tValidation Loss: 1.481273\n",
      "Validation loss decreased (1.481277 --> 1.481273).         Saving model ...\n",
      "Epoch: 2257 \tTraining Loss: 1.080773 \tValidation Loss: 1.481269\n",
      "Validation loss decreased (1.481273 --> 1.481269).         Saving model ...\n",
      "Epoch: 2258 \tTraining Loss: 1.080769 \tValidation Loss: 1.481265\n",
      "Validation loss decreased (1.481269 --> 1.481265).         Saving model ...\n",
      "Epoch: 2259 \tTraining Loss: 1.080766 \tValidation Loss: 1.481260\n",
      "Validation loss decreased (1.481265 --> 1.481260).         Saving model ...\n",
      "Epoch: 2260 \tTraining Loss: 1.080762 \tValidation Loss: 1.481257\n",
      "Validation loss decreased (1.481260 --> 1.481257).         Saving model ...\n",
      "Epoch: 2261 \tTraining Loss: 1.080759 \tValidation Loss: 1.481253\n",
      "Validation loss decreased (1.481257 --> 1.481253).         Saving model ...\n",
      "Epoch: 2262 \tTraining Loss: 1.080755 \tValidation Loss: 1.481249\n",
      "Validation loss decreased (1.481253 --> 1.481249).         Saving model ...\n",
      "Epoch: 2263 \tTraining Loss: 1.080752 \tValidation Loss: 1.481245\n",
      "Validation loss decreased (1.481249 --> 1.481245).         Saving model ...\n",
      "Epoch: 2264 \tTraining Loss: 1.080748 \tValidation Loss: 1.481241\n",
      "Validation loss decreased (1.481245 --> 1.481241).         Saving model ...\n",
      "Epoch: 2265 \tTraining Loss: 1.080745 \tValidation Loss: 1.481237\n",
      "Validation loss decreased (1.481241 --> 1.481237).         Saving model ...\n",
      "Epoch: 2266 \tTraining Loss: 1.080741 \tValidation Loss: 1.481233\n",
      "Validation loss decreased (1.481237 --> 1.481233).         Saving model ...\n",
      "Epoch: 2267 \tTraining Loss: 1.080738 \tValidation Loss: 1.481230\n",
      "Validation loss decreased (1.481233 --> 1.481230).         Saving model ...\n",
      "Epoch: 2268 \tTraining Loss: 1.080734 \tValidation Loss: 1.481226\n",
      "Validation loss decreased (1.481230 --> 1.481226).         Saving model ...\n",
      "Epoch: 2269 \tTraining Loss: 1.080731 \tValidation Loss: 1.481222\n",
      "Validation loss decreased (1.481226 --> 1.481222).         Saving model ...\n",
      "Epoch: 2270 \tTraining Loss: 1.080727 \tValidation Loss: 1.481219\n",
      "Validation loss decreased (1.481222 --> 1.481219).         Saving model ...\n",
      "Epoch: 2271 \tTraining Loss: 1.080724 \tValidation Loss: 1.481215\n",
      "Validation loss decreased (1.481219 --> 1.481215).         Saving model ...\n",
      "Epoch: 2272 \tTraining Loss: 1.080720 \tValidation Loss: 1.481211\n",
      "Validation loss decreased (1.481215 --> 1.481211).         Saving model ...\n",
      "Epoch: 2273 \tTraining Loss: 1.080717 \tValidation Loss: 1.481207\n",
      "Validation loss decreased (1.481211 --> 1.481207).         Saving model ...\n",
      "Epoch: 2274 \tTraining Loss: 1.080713 \tValidation Loss: 1.481203\n",
      "Validation loss decreased (1.481207 --> 1.481203).         Saving model ...\n",
      "Epoch: 2275 \tTraining Loss: 1.080710 \tValidation Loss: 1.481200\n",
      "Validation loss decreased (1.481203 --> 1.481200).         Saving model ...\n",
      "Epoch: 2276 \tTraining Loss: 1.080707 \tValidation Loss: 1.481196\n",
      "Validation loss decreased (1.481200 --> 1.481196).         Saving model ...\n",
      "Epoch: 2277 \tTraining Loss: 1.080703 \tValidation Loss: 1.481192\n",
      "Validation loss decreased (1.481196 --> 1.481192).         Saving model ...\n",
      "Epoch: 2278 \tTraining Loss: 1.080700 \tValidation Loss: 1.481189\n",
      "Validation loss decreased (1.481192 --> 1.481189).         Saving model ...\n",
      "Epoch: 2279 \tTraining Loss: 1.080696 \tValidation Loss: 1.481185\n",
      "Validation loss decreased (1.481189 --> 1.481185).         Saving model ...\n",
      "Epoch: 2280 \tTraining Loss: 1.080693 \tValidation Loss: 1.481181\n",
      "Validation loss decreased (1.481185 --> 1.481181).         Saving model ...\n",
      "Epoch: 2281 \tTraining Loss: 1.080689 \tValidation Loss: 1.481177\n",
      "Validation loss decreased (1.481181 --> 1.481177).         Saving model ...\n",
      "Epoch: 2282 \tTraining Loss: 1.080686 \tValidation Loss: 1.481173\n",
      "Validation loss decreased (1.481177 --> 1.481173).         Saving model ...\n",
      "Epoch: 2283 \tTraining Loss: 1.080682 \tValidation Loss: 1.481169\n",
      "Validation loss decreased (1.481173 --> 1.481169).         Saving model ...\n",
      "Epoch: 2284 \tTraining Loss: 1.080679 \tValidation Loss: 1.481166\n",
      "Validation loss decreased (1.481169 --> 1.481166).         Saving model ...\n",
      "Epoch: 2285 \tTraining Loss: 1.080675 \tValidation Loss: 1.481161\n",
      "Validation loss decreased (1.481166 --> 1.481161).         Saving model ...\n",
      "Epoch: 2286 \tTraining Loss: 1.080672 \tValidation Loss: 1.481157\n",
      "Validation loss decreased (1.481161 --> 1.481157).         Saving model ...\n",
      "Epoch: 2287 \tTraining Loss: 1.080668 \tValidation Loss: 1.481154\n",
      "Validation loss decreased (1.481157 --> 1.481154).         Saving model ...\n",
      "Epoch: 2288 \tTraining Loss: 1.080665 \tValidation Loss: 1.481149\n",
      "Validation loss decreased (1.481154 --> 1.481149).         Saving model ...\n",
      "Epoch: 2289 \tTraining Loss: 1.080662 \tValidation Loss: 1.481145\n",
      "Validation loss decreased (1.481149 --> 1.481145).         Saving model ...\n",
      "Epoch: 2290 \tTraining Loss: 1.080658 \tValidation Loss: 1.481141\n",
      "Validation loss decreased (1.481145 --> 1.481141).         Saving model ...\n",
      "Epoch: 2291 \tTraining Loss: 1.080655 \tValidation Loss: 1.481136\n",
      "Validation loss decreased (1.481141 --> 1.481136).         Saving model ...\n",
      "Epoch: 2292 \tTraining Loss: 1.080651 \tValidation Loss: 1.481132\n",
      "Validation loss decreased (1.481136 --> 1.481132).         Saving model ...\n",
      "Epoch: 2293 \tTraining Loss: 1.080648 \tValidation Loss: 1.481128\n",
      "Validation loss decreased (1.481132 --> 1.481128).         Saving model ...\n",
      "Epoch: 2294 \tTraining Loss: 1.080644 \tValidation Loss: 1.481124\n",
      "Validation loss decreased (1.481128 --> 1.481124).         Saving model ...\n",
      "Epoch: 2295 \tTraining Loss: 1.080641 \tValidation Loss: 1.481120\n",
      "Validation loss decreased (1.481124 --> 1.481120).         Saving model ...\n",
      "Epoch: 2296 \tTraining Loss: 1.080638 \tValidation Loss: 1.481118\n",
      "Validation loss decreased (1.481120 --> 1.481118).         Saving model ...\n",
      "Epoch: 2297 \tTraining Loss: 1.080634 \tValidation Loss: 1.481113\n",
      "Validation loss decreased (1.481118 --> 1.481113).         Saving model ...\n",
      "Epoch: 2298 \tTraining Loss: 1.080631 \tValidation Loss: 1.481109\n",
      "Validation loss decreased (1.481113 --> 1.481109).         Saving model ...\n",
      "Epoch: 2299 \tTraining Loss: 1.080627 \tValidation Loss: 1.481106\n",
      "Validation loss decreased (1.481109 --> 1.481106).         Saving model ...\n",
      "Epoch: 2300 \tTraining Loss: 1.080624 \tValidation Loss: 1.481102\n",
      "Validation loss decreased (1.481106 --> 1.481102).         Saving model ...\n",
      "Epoch: 2301 \tTraining Loss: 1.080620 \tValidation Loss: 1.481098\n",
      "Validation loss decreased (1.481102 --> 1.481098).         Saving model ...\n",
      "Epoch: 2302 \tTraining Loss: 1.080617 \tValidation Loss: 1.481094\n",
      "Validation loss decreased (1.481098 --> 1.481094).         Saving model ...\n",
      "Epoch: 2303 \tTraining Loss: 1.080614 \tValidation Loss: 1.481090\n",
      "Validation loss decreased (1.481094 --> 1.481090).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2304 \tTraining Loss: 1.080610 \tValidation Loss: 1.481086\n",
      "Validation loss decreased (1.481090 --> 1.481086).         Saving model ...\n",
      "Epoch: 2305 \tTraining Loss: 1.080607 \tValidation Loss: 1.481082\n",
      "Validation loss decreased (1.481086 --> 1.481082).         Saving model ...\n",
      "Epoch: 2306 \tTraining Loss: 1.080603 \tValidation Loss: 1.481078\n",
      "Validation loss decreased (1.481082 --> 1.481078).         Saving model ...\n",
      "Epoch: 2307 \tTraining Loss: 1.080600 \tValidation Loss: 1.481075\n",
      "Validation loss decreased (1.481078 --> 1.481075).         Saving model ...\n",
      "Epoch: 2308 \tTraining Loss: 1.080597 \tValidation Loss: 1.481070\n",
      "Validation loss decreased (1.481075 --> 1.481070).         Saving model ...\n",
      "Epoch: 2309 \tTraining Loss: 1.080593 \tValidation Loss: 1.481066\n",
      "Validation loss decreased (1.481070 --> 1.481066).         Saving model ...\n",
      "Epoch: 2310 \tTraining Loss: 1.080590 \tValidation Loss: 1.481062\n",
      "Validation loss decreased (1.481066 --> 1.481062).         Saving model ...\n",
      "Epoch: 2311 \tTraining Loss: 1.080586 \tValidation Loss: 1.481058\n",
      "Validation loss decreased (1.481062 --> 1.481058).         Saving model ...\n",
      "Epoch: 2312 \tTraining Loss: 1.080583 \tValidation Loss: 1.481054\n",
      "Validation loss decreased (1.481058 --> 1.481054).         Saving model ...\n",
      "Epoch: 2313 \tTraining Loss: 1.080580 \tValidation Loss: 1.481051\n",
      "Validation loss decreased (1.481054 --> 1.481051).         Saving model ...\n",
      "Epoch: 2314 \tTraining Loss: 1.080576 \tValidation Loss: 1.481046\n",
      "Validation loss decreased (1.481051 --> 1.481046).         Saving model ...\n",
      "Epoch: 2315 \tTraining Loss: 1.080573 \tValidation Loss: 1.481042\n",
      "Validation loss decreased (1.481046 --> 1.481042).         Saving model ...\n",
      "Epoch: 2316 \tTraining Loss: 1.080569 \tValidation Loss: 1.481038\n",
      "Validation loss decreased (1.481042 --> 1.481038).         Saving model ...\n",
      "Epoch: 2317 \tTraining Loss: 1.080566 \tValidation Loss: 1.481034\n",
      "Validation loss decreased (1.481038 --> 1.481034).         Saving model ...\n",
      "Epoch: 2318 \tTraining Loss: 1.080563 \tValidation Loss: 1.481030\n",
      "Validation loss decreased (1.481034 --> 1.481030).         Saving model ...\n",
      "Epoch: 2319 \tTraining Loss: 1.080559 \tValidation Loss: 1.481025\n",
      "Validation loss decreased (1.481030 --> 1.481025).         Saving model ...\n",
      "Epoch: 2320 \tTraining Loss: 1.080556 \tValidation Loss: 1.481022\n",
      "Validation loss decreased (1.481025 --> 1.481022).         Saving model ...\n",
      "Epoch: 2321 \tTraining Loss: 1.080552 \tValidation Loss: 1.481018\n",
      "Validation loss decreased (1.481022 --> 1.481018).         Saving model ...\n",
      "Epoch: 2322 \tTraining Loss: 1.080549 \tValidation Loss: 1.481013\n",
      "Validation loss decreased (1.481018 --> 1.481013).         Saving model ...\n",
      "Epoch: 2323 \tTraining Loss: 1.080546 \tValidation Loss: 1.481010\n",
      "Validation loss decreased (1.481013 --> 1.481010).         Saving model ...\n",
      "Epoch: 2324 \tTraining Loss: 1.080542 \tValidation Loss: 1.481006\n",
      "Validation loss decreased (1.481010 --> 1.481006).         Saving model ...\n",
      "Epoch: 2325 \tTraining Loss: 1.080539 \tValidation Loss: 1.481002\n",
      "Validation loss decreased (1.481006 --> 1.481002).         Saving model ...\n",
      "Epoch: 2326 \tTraining Loss: 1.080536 \tValidation Loss: 1.480998\n",
      "Validation loss decreased (1.481002 --> 1.480998).         Saving model ...\n",
      "Epoch: 2327 \tTraining Loss: 1.080532 \tValidation Loss: 1.480994\n",
      "Validation loss decreased (1.480998 --> 1.480994).         Saving model ...\n",
      "Epoch: 2328 \tTraining Loss: 1.080529 \tValidation Loss: 1.480990\n",
      "Validation loss decreased (1.480994 --> 1.480990).         Saving model ...\n",
      "Epoch: 2329 \tTraining Loss: 1.080526 \tValidation Loss: 1.480986\n",
      "Validation loss decreased (1.480990 --> 1.480986).         Saving model ...\n",
      "Epoch: 2330 \tTraining Loss: 1.080522 \tValidation Loss: 1.480982\n",
      "Validation loss decreased (1.480986 --> 1.480982).         Saving model ...\n",
      "Epoch: 2331 \tTraining Loss: 1.080519 \tValidation Loss: 1.480978\n",
      "Validation loss decreased (1.480982 --> 1.480978).         Saving model ...\n",
      "Epoch: 2332 \tTraining Loss: 1.080515 \tValidation Loss: 1.480975\n",
      "Validation loss decreased (1.480978 --> 1.480975).         Saving model ...\n",
      "Epoch: 2333 \tTraining Loss: 1.080512 \tValidation Loss: 1.480972\n",
      "Validation loss decreased (1.480975 --> 1.480972).         Saving model ...\n",
      "Epoch: 2334 \tTraining Loss: 1.080509 \tValidation Loss: 1.480967\n",
      "Validation loss decreased (1.480972 --> 1.480967).         Saving model ...\n",
      "Epoch: 2335 \tTraining Loss: 1.080505 \tValidation Loss: 1.480964\n",
      "Validation loss decreased (1.480967 --> 1.480964).         Saving model ...\n",
      "Epoch: 2336 \tTraining Loss: 1.080502 \tValidation Loss: 1.480960\n",
      "Validation loss decreased (1.480964 --> 1.480960).         Saving model ...\n",
      "Epoch: 2337 \tTraining Loss: 1.080499 \tValidation Loss: 1.480957\n",
      "Validation loss decreased (1.480960 --> 1.480957).         Saving model ...\n",
      "Epoch: 2338 \tTraining Loss: 1.080495 \tValidation Loss: 1.480954\n",
      "Validation loss decreased (1.480957 --> 1.480954).         Saving model ...\n",
      "Epoch: 2339 \tTraining Loss: 1.080492 \tValidation Loss: 1.480951\n",
      "Validation loss decreased (1.480954 --> 1.480951).         Saving model ...\n",
      "Epoch: 2340 \tTraining Loss: 1.080489 \tValidation Loss: 1.480948\n",
      "Validation loss decreased (1.480951 --> 1.480948).         Saving model ...\n",
      "Epoch: 2341 \tTraining Loss: 1.080485 \tValidation Loss: 1.480944\n",
      "Validation loss decreased (1.480948 --> 1.480944).         Saving model ...\n",
      "Epoch: 2342 \tTraining Loss: 1.080482 \tValidation Loss: 1.480941\n",
      "Validation loss decreased (1.480944 --> 1.480941).         Saving model ...\n",
      "Epoch: 2343 \tTraining Loss: 1.080479 \tValidation Loss: 1.480937\n",
      "Validation loss decreased (1.480941 --> 1.480937).         Saving model ...\n",
      "Epoch: 2344 \tTraining Loss: 1.080475 \tValidation Loss: 1.480934\n",
      "Validation loss decreased (1.480937 --> 1.480934).         Saving model ...\n",
      "Epoch: 2345 \tTraining Loss: 1.080472 \tValidation Loss: 1.480929\n",
      "Validation loss decreased (1.480934 --> 1.480929).         Saving model ...\n",
      "Epoch: 2346 \tTraining Loss: 1.080469 \tValidation Loss: 1.480926\n",
      "Validation loss decreased (1.480929 --> 1.480926).         Saving model ...\n",
      "Epoch: 2347 \tTraining Loss: 1.080465 \tValidation Loss: 1.480923\n",
      "Validation loss decreased (1.480926 --> 1.480923).         Saving model ...\n",
      "Epoch: 2348 \tTraining Loss: 1.080462 \tValidation Loss: 1.480918\n",
      "Validation loss decreased (1.480923 --> 1.480918).         Saving model ...\n",
      "Epoch: 2349 \tTraining Loss: 1.080459 \tValidation Loss: 1.480915\n",
      "Validation loss decreased (1.480918 --> 1.480915).         Saving model ...\n",
      "Epoch: 2350 \tTraining Loss: 1.080455 \tValidation Loss: 1.480911\n",
      "Validation loss decreased (1.480915 --> 1.480911).         Saving model ...\n",
      "Epoch: 2351 \tTraining Loss: 1.080452 \tValidation Loss: 1.480907\n",
      "Validation loss decreased (1.480911 --> 1.480907).         Saving model ...\n",
      "Epoch: 2352 \tTraining Loss: 1.080449 \tValidation Loss: 1.480903\n",
      "Validation loss decreased (1.480907 --> 1.480903).         Saving model ...\n",
      "Epoch: 2353 \tTraining Loss: 1.080445 \tValidation Loss: 1.480900\n",
      "Validation loss decreased (1.480903 --> 1.480900).         Saving model ...\n",
      "Epoch: 2354 \tTraining Loss: 1.080442 \tValidation Loss: 1.480897\n",
      "Validation loss decreased (1.480900 --> 1.480897).         Saving model ...\n",
      "Epoch: 2355 \tTraining Loss: 1.080439 \tValidation Loss: 1.480894\n",
      "Validation loss decreased (1.480897 --> 1.480894).         Saving model ...\n",
      "Epoch: 2356 \tTraining Loss: 1.080436 \tValidation Loss: 1.480890\n",
      "Validation loss decreased (1.480894 --> 1.480890).         Saving model ...\n",
      "Epoch: 2357 \tTraining Loss: 1.080432 \tValidation Loss: 1.480887\n",
      "Validation loss decreased (1.480890 --> 1.480887).         Saving model ...\n",
      "Epoch: 2358 \tTraining Loss: 1.080429 \tValidation Loss: 1.480884\n",
      "Validation loss decreased (1.480887 --> 1.480884).         Saving model ...\n",
      "Epoch: 2359 \tTraining Loss: 1.080426 \tValidation Loss: 1.480880\n",
      "Validation loss decreased (1.480884 --> 1.480880).         Saving model ...\n",
      "Epoch: 2360 \tTraining Loss: 1.080422 \tValidation Loss: 1.480877\n",
      "Validation loss decreased (1.480880 --> 1.480877).         Saving model ...\n",
      "Epoch: 2361 \tTraining Loss: 1.080419 \tValidation Loss: 1.480873\n",
      "Validation loss decreased (1.480877 --> 1.480873).         Saving model ...\n",
      "Epoch: 2362 \tTraining Loss: 1.080416 \tValidation Loss: 1.480871\n",
      "Validation loss decreased (1.480873 --> 1.480871).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2363 \tTraining Loss: 1.080412 \tValidation Loss: 1.480868\n",
      "Validation loss decreased (1.480871 --> 1.480868).         Saving model ...\n",
      "Epoch: 2364 \tTraining Loss: 1.080409 \tValidation Loss: 1.480865\n",
      "Validation loss decreased (1.480868 --> 1.480865).         Saving model ...\n",
      "Epoch: 2365 \tTraining Loss: 1.080406 \tValidation Loss: 1.480863\n",
      "Validation loss decreased (1.480865 --> 1.480863).         Saving model ...\n",
      "Epoch: 2366 \tTraining Loss: 1.080403 \tValidation Loss: 1.480860\n",
      "Validation loss decreased (1.480863 --> 1.480860).         Saving model ...\n",
      "Epoch: 2367 \tTraining Loss: 1.080399 \tValidation Loss: 1.480857\n",
      "Validation loss decreased (1.480860 --> 1.480857).         Saving model ...\n",
      "Epoch: 2368 \tTraining Loss: 1.080396 \tValidation Loss: 1.480856\n",
      "Validation loss decreased (1.480857 --> 1.480856).         Saving model ...\n",
      "Epoch: 2369 \tTraining Loss: 1.080393 \tValidation Loss: 1.480853\n",
      "Validation loss decreased (1.480856 --> 1.480853).         Saving model ...\n",
      "Epoch: 2370 \tTraining Loss: 1.080389 \tValidation Loss: 1.480850\n",
      "Validation loss decreased (1.480853 --> 1.480850).         Saving model ...\n",
      "Epoch: 2371 \tTraining Loss: 1.080386 \tValidation Loss: 1.480848\n",
      "Validation loss decreased (1.480850 --> 1.480848).         Saving model ...\n",
      "Epoch: 2372 \tTraining Loss: 1.080383 \tValidation Loss: 1.480845\n",
      "Validation loss decreased (1.480848 --> 1.480845).         Saving model ...\n",
      "Epoch: 2373 \tTraining Loss: 1.080380 \tValidation Loss: 1.480843\n",
      "Validation loss decreased (1.480845 --> 1.480843).         Saving model ...\n",
      "Epoch: 2374 \tTraining Loss: 1.080376 \tValidation Loss: 1.480840\n",
      "Validation loss decreased (1.480843 --> 1.480840).         Saving model ...\n",
      "Epoch: 2375 \tTraining Loss: 1.080373 \tValidation Loss: 1.480836\n",
      "Validation loss decreased (1.480840 --> 1.480836).         Saving model ...\n",
      "Epoch: 2376 \tTraining Loss: 1.080370 \tValidation Loss: 1.480833\n",
      "Validation loss decreased (1.480836 --> 1.480833).         Saving model ...\n",
      "Epoch: 2377 \tTraining Loss: 1.080367 \tValidation Loss: 1.480830\n",
      "Validation loss decreased (1.480833 --> 1.480830).         Saving model ...\n",
      "Epoch: 2378 \tTraining Loss: 1.080363 \tValidation Loss: 1.480827\n",
      "Validation loss decreased (1.480830 --> 1.480827).         Saving model ...\n",
      "Epoch: 2379 \tTraining Loss: 1.080360 \tValidation Loss: 1.480824\n",
      "Validation loss decreased (1.480827 --> 1.480824).         Saving model ...\n",
      "Epoch: 2380 \tTraining Loss: 1.080357 \tValidation Loss: 1.480820\n",
      "Validation loss decreased (1.480824 --> 1.480820).         Saving model ...\n",
      "Epoch: 2381 \tTraining Loss: 1.080353 \tValidation Loss: 1.480817\n",
      "Validation loss decreased (1.480820 --> 1.480817).         Saving model ...\n",
      "Epoch: 2382 \tTraining Loss: 1.080350 \tValidation Loss: 1.480814\n",
      "Validation loss decreased (1.480817 --> 1.480814).         Saving model ...\n",
      "Epoch: 2383 \tTraining Loss: 1.080347 \tValidation Loss: 1.480811\n",
      "Validation loss decreased (1.480814 --> 1.480811).         Saving model ...\n",
      "Epoch: 2384 \tTraining Loss: 1.080344 \tValidation Loss: 1.480808\n",
      "Validation loss decreased (1.480811 --> 1.480808).         Saving model ...\n",
      "Epoch: 2385 \tTraining Loss: 1.080340 \tValidation Loss: 1.480805\n",
      "Validation loss decreased (1.480808 --> 1.480805).         Saving model ...\n",
      "Epoch: 2386 \tTraining Loss: 1.080337 \tValidation Loss: 1.480802\n",
      "Validation loss decreased (1.480805 --> 1.480802).         Saving model ...\n",
      "Epoch: 2387 \tTraining Loss: 1.080334 \tValidation Loss: 1.480799\n",
      "Validation loss decreased (1.480802 --> 1.480799).         Saving model ...\n",
      "Epoch: 2388 \tTraining Loss: 1.080331 \tValidation Loss: 1.480795\n",
      "Validation loss decreased (1.480799 --> 1.480795).         Saving model ...\n",
      "Epoch: 2389 \tTraining Loss: 1.080327 \tValidation Loss: 1.480793\n",
      "Validation loss decreased (1.480795 --> 1.480793).         Saving model ...\n",
      "Epoch: 2390 \tTraining Loss: 1.080324 \tValidation Loss: 1.480790\n",
      "Validation loss decreased (1.480793 --> 1.480790).         Saving model ...\n",
      "Epoch: 2391 \tTraining Loss: 1.080321 \tValidation Loss: 1.480787\n",
      "Validation loss decreased (1.480790 --> 1.480787).         Saving model ...\n",
      "Epoch: 2392 \tTraining Loss: 1.080318 \tValidation Loss: 1.480783\n",
      "Validation loss decreased (1.480787 --> 1.480783).         Saving model ...\n",
      "Epoch: 2393 \tTraining Loss: 1.080315 \tValidation Loss: 1.480779\n",
      "Validation loss decreased (1.480783 --> 1.480779).         Saving model ...\n",
      "Epoch: 2394 \tTraining Loss: 1.080311 \tValidation Loss: 1.480776\n",
      "Validation loss decreased (1.480779 --> 1.480776).         Saving model ...\n",
      "Epoch: 2395 \tTraining Loss: 1.080308 \tValidation Loss: 1.480772\n",
      "Validation loss decreased (1.480776 --> 1.480772).         Saving model ...\n",
      "Epoch: 2396 \tTraining Loss: 1.080305 \tValidation Loss: 1.480769\n",
      "Validation loss decreased (1.480772 --> 1.480769).         Saving model ...\n",
      "Epoch: 2397 \tTraining Loss: 1.080302 \tValidation Loss: 1.480767\n",
      "Validation loss decreased (1.480769 --> 1.480767).         Saving model ...\n",
      "Epoch: 2398 \tTraining Loss: 1.080298 \tValidation Loss: 1.480764\n",
      "Validation loss decreased (1.480767 --> 1.480764).         Saving model ...\n",
      "Epoch: 2399 \tTraining Loss: 1.080295 \tValidation Loss: 1.480760\n",
      "Validation loss decreased (1.480764 --> 1.480760).         Saving model ...\n",
      "Epoch: 2400 \tTraining Loss: 1.080292 \tValidation Loss: 1.480758\n",
      "Validation loss decreased (1.480760 --> 1.480758).         Saving model ...\n",
      "Epoch: 2401 \tTraining Loss: 1.080289 \tValidation Loss: 1.480755\n",
      "Validation loss decreased (1.480758 --> 1.480755).         Saving model ...\n",
      "Epoch: 2402 \tTraining Loss: 1.080285 \tValidation Loss: 1.480751\n",
      "Validation loss decreased (1.480755 --> 1.480751).         Saving model ...\n",
      "Epoch: 2403 \tTraining Loss: 1.080282 \tValidation Loss: 1.480748\n",
      "Validation loss decreased (1.480751 --> 1.480748).         Saving model ...\n",
      "Epoch: 2404 \tTraining Loss: 1.080279 \tValidation Loss: 1.480745\n",
      "Validation loss decreased (1.480748 --> 1.480745).         Saving model ...\n",
      "Epoch: 2405 \tTraining Loss: 1.080276 \tValidation Loss: 1.480741\n",
      "Validation loss decreased (1.480745 --> 1.480741).         Saving model ...\n",
      "Epoch: 2406 \tTraining Loss: 1.080273 \tValidation Loss: 1.480737\n",
      "Validation loss decreased (1.480741 --> 1.480737).         Saving model ...\n",
      "Epoch: 2407 \tTraining Loss: 1.080269 \tValidation Loss: 1.480734\n",
      "Validation loss decreased (1.480737 --> 1.480734).         Saving model ...\n",
      "Epoch: 2408 \tTraining Loss: 1.080266 \tValidation Loss: 1.480730\n",
      "Validation loss decreased (1.480734 --> 1.480730).         Saving model ...\n",
      "Epoch: 2409 \tTraining Loss: 1.080263 \tValidation Loss: 1.480727\n",
      "Validation loss decreased (1.480730 --> 1.480727).         Saving model ...\n",
      "Epoch: 2410 \tTraining Loss: 1.080260 \tValidation Loss: 1.480723\n",
      "Validation loss decreased (1.480727 --> 1.480723).         Saving model ...\n",
      "Epoch: 2411 \tTraining Loss: 1.080257 \tValidation Loss: 1.480720\n",
      "Validation loss decreased (1.480723 --> 1.480720).         Saving model ...\n",
      "Epoch: 2412 \tTraining Loss: 1.080253 \tValidation Loss: 1.480716\n",
      "Validation loss decreased (1.480720 --> 1.480716).         Saving model ...\n",
      "Epoch: 2413 \tTraining Loss: 1.080250 \tValidation Loss: 1.480714\n",
      "Validation loss decreased (1.480716 --> 1.480714).         Saving model ...\n",
      "Epoch: 2414 \tTraining Loss: 1.080247 \tValidation Loss: 1.480711\n",
      "Validation loss decreased (1.480714 --> 1.480711).         Saving model ...\n",
      "Epoch: 2415 \tTraining Loss: 1.080244 \tValidation Loss: 1.480707\n",
      "Validation loss decreased (1.480711 --> 1.480707).         Saving model ...\n",
      "Epoch: 2416 \tTraining Loss: 1.080241 \tValidation Loss: 1.480704\n",
      "Validation loss decreased (1.480707 --> 1.480704).         Saving model ...\n",
      "Epoch: 2417 \tTraining Loss: 1.080237 \tValidation Loss: 1.480700\n",
      "Validation loss decreased (1.480704 --> 1.480700).         Saving model ...\n",
      "Epoch: 2418 \tTraining Loss: 1.080234 \tValidation Loss: 1.480696\n",
      "Validation loss decreased (1.480700 --> 1.480696).         Saving model ...\n",
      "Epoch: 2419 \tTraining Loss: 1.080231 \tValidation Loss: 1.480693\n",
      "Validation loss decreased (1.480696 --> 1.480693).         Saving model ...\n",
      "Epoch: 2420 \tTraining Loss: 1.080228 \tValidation Loss: 1.480691\n",
      "Validation loss decreased (1.480693 --> 1.480691).         Saving model ...\n",
      "Epoch: 2421 \tTraining Loss: 1.080225 \tValidation Loss: 1.480687\n",
      "Validation loss decreased (1.480691 --> 1.480687).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2422 \tTraining Loss: 1.080222 \tValidation Loss: 1.480685\n",
      "Validation loss decreased (1.480687 --> 1.480685).         Saving model ...\n",
      "Epoch: 2423 \tTraining Loss: 1.080218 \tValidation Loss: 1.480681\n",
      "Validation loss decreased (1.480685 --> 1.480681).         Saving model ...\n",
      "Epoch: 2424 \tTraining Loss: 1.080215 \tValidation Loss: 1.480679\n",
      "Validation loss decreased (1.480681 --> 1.480679).         Saving model ...\n",
      "Epoch: 2425 \tTraining Loss: 1.080212 \tValidation Loss: 1.480676\n",
      "Validation loss decreased (1.480679 --> 1.480676).         Saving model ...\n",
      "Epoch: 2426 \tTraining Loss: 1.080209 \tValidation Loss: 1.480673\n",
      "Validation loss decreased (1.480676 --> 1.480673).         Saving model ...\n",
      "Epoch: 2427 \tTraining Loss: 1.080206 \tValidation Loss: 1.480670\n",
      "Validation loss decreased (1.480673 --> 1.480670).         Saving model ...\n",
      "Epoch: 2428 \tTraining Loss: 1.080202 \tValidation Loss: 1.480666\n",
      "Validation loss decreased (1.480670 --> 1.480666).         Saving model ...\n",
      "Epoch: 2429 \tTraining Loss: 1.080199 \tValidation Loss: 1.480662\n",
      "Validation loss decreased (1.480666 --> 1.480662).         Saving model ...\n",
      "Epoch: 2430 \tTraining Loss: 1.080196 \tValidation Loss: 1.480659\n",
      "Validation loss decreased (1.480662 --> 1.480659).         Saving model ...\n",
      "Epoch: 2431 \tTraining Loss: 1.080193 \tValidation Loss: 1.480655\n",
      "Validation loss decreased (1.480659 --> 1.480655).         Saving model ...\n",
      "Epoch: 2432 \tTraining Loss: 1.080190 \tValidation Loss: 1.480652\n",
      "Validation loss decreased (1.480655 --> 1.480652).         Saving model ...\n",
      "Epoch: 2433 \tTraining Loss: 1.080187 \tValidation Loss: 1.480649\n",
      "Validation loss decreased (1.480652 --> 1.480649).         Saving model ...\n",
      "Epoch: 2434 \tTraining Loss: 1.080184 \tValidation Loss: 1.480646\n",
      "Validation loss decreased (1.480649 --> 1.480646).         Saving model ...\n",
      "Epoch: 2435 \tTraining Loss: 1.080180 \tValidation Loss: 1.480643\n",
      "Validation loss decreased (1.480646 --> 1.480643).         Saving model ...\n",
      "Epoch: 2436 \tTraining Loss: 1.080177 \tValidation Loss: 1.480639\n",
      "Validation loss decreased (1.480643 --> 1.480639).         Saving model ...\n",
      "Epoch: 2437 \tTraining Loss: 1.080174 \tValidation Loss: 1.480637\n",
      "Validation loss decreased (1.480639 --> 1.480637).         Saving model ...\n",
      "Epoch: 2438 \tTraining Loss: 1.080171 \tValidation Loss: 1.480633\n",
      "Validation loss decreased (1.480637 --> 1.480633).         Saving model ...\n",
      "Epoch: 2439 \tTraining Loss: 1.080168 \tValidation Loss: 1.480631\n",
      "Validation loss decreased (1.480633 --> 1.480631).         Saving model ...\n",
      "Epoch: 2440 \tTraining Loss: 1.080165 \tValidation Loss: 1.480628\n",
      "Validation loss decreased (1.480631 --> 1.480628).         Saving model ...\n",
      "Epoch: 2441 \tTraining Loss: 1.080161 \tValidation Loss: 1.480625\n",
      "Validation loss decreased (1.480628 --> 1.480625).         Saving model ...\n",
      "Epoch: 2442 \tTraining Loss: 1.080158 \tValidation Loss: 1.480622\n",
      "Validation loss decreased (1.480625 --> 1.480622).         Saving model ...\n",
      "Epoch: 2443 \tTraining Loss: 1.080155 \tValidation Loss: 1.480619\n",
      "Validation loss decreased (1.480622 --> 1.480619).         Saving model ...\n",
      "Epoch: 2444 \tTraining Loss: 1.080152 \tValidation Loss: 1.480616\n",
      "Validation loss decreased (1.480619 --> 1.480616).         Saving model ...\n",
      "Epoch: 2445 \tTraining Loss: 1.080149 \tValidation Loss: 1.480613\n",
      "Validation loss decreased (1.480616 --> 1.480613).         Saving model ...\n",
      "Epoch: 2446 \tTraining Loss: 1.080146 \tValidation Loss: 1.480609\n",
      "Validation loss decreased (1.480613 --> 1.480609).         Saving model ...\n",
      "Epoch: 2447 \tTraining Loss: 1.080143 \tValidation Loss: 1.480607\n",
      "Validation loss decreased (1.480609 --> 1.480607).         Saving model ...\n",
      "Epoch: 2448 \tTraining Loss: 1.080140 \tValidation Loss: 1.480602\n",
      "Validation loss decreased (1.480607 --> 1.480602).         Saving model ...\n",
      "Epoch: 2449 \tTraining Loss: 1.080136 \tValidation Loss: 1.480599\n",
      "Validation loss decreased (1.480602 --> 1.480599).         Saving model ...\n",
      "Epoch: 2450 \tTraining Loss: 1.080133 \tValidation Loss: 1.480596\n",
      "Validation loss decreased (1.480599 --> 1.480596).         Saving model ...\n",
      "Epoch: 2451 \tTraining Loss: 1.080130 \tValidation Loss: 1.480593\n",
      "Validation loss decreased (1.480596 --> 1.480593).         Saving model ...\n",
      "Epoch: 2452 \tTraining Loss: 1.080127 \tValidation Loss: 1.480590\n",
      "Validation loss decreased (1.480593 --> 1.480590).         Saving model ...\n",
      "Epoch: 2453 \tTraining Loss: 1.080124 \tValidation Loss: 1.480587\n",
      "Validation loss decreased (1.480590 --> 1.480587).         Saving model ...\n",
      "Epoch: 2454 \tTraining Loss: 1.080121 \tValidation Loss: 1.480584\n",
      "Validation loss decreased (1.480587 --> 1.480584).         Saving model ...\n",
      "Epoch: 2455 \tTraining Loss: 1.080118 \tValidation Loss: 1.480581\n",
      "Validation loss decreased (1.480584 --> 1.480581).         Saving model ...\n",
      "Epoch: 2456 \tTraining Loss: 1.080115 \tValidation Loss: 1.480578\n",
      "Validation loss decreased (1.480581 --> 1.480578).         Saving model ...\n",
      "Epoch: 2457 \tTraining Loss: 1.080111 \tValidation Loss: 1.480576\n",
      "Validation loss decreased (1.480578 --> 1.480576).         Saving model ...\n",
      "Epoch: 2458 \tTraining Loss: 1.080108 \tValidation Loss: 1.480573\n",
      "Validation loss decreased (1.480576 --> 1.480573).         Saving model ...\n",
      "Epoch: 2459 \tTraining Loss: 1.080105 \tValidation Loss: 1.480571\n",
      "Validation loss decreased (1.480573 --> 1.480571).         Saving model ...\n",
      "Epoch: 2460 \tTraining Loss: 1.080102 \tValidation Loss: 1.480568\n",
      "Validation loss decreased (1.480571 --> 1.480568).         Saving model ...\n",
      "Epoch: 2461 \tTraining Loss: 1.080099 \tValidation Loss: 1.480566\n",
      "Validation loss decreased (1.480568 --> 1.480566).         Saving model ...\n",
      "Epoch: 2462 \tTraining Loss: 1.080096 \tValidation Loss: 1.480563\n",
      "Validation loss decreased (1.480566 --> 1.480563).         Saving model ...\n",
      "Epoch: 2463 \tTraining Loss: 1.080093 \tValidation Loss: 1.480560\n",
      "Validation loss decreased (1.480563 --> 1.480560).         Saving model ...\n",
      "Epoch: 2464 \tTraining Loss: 1.080090 \tValidation Loss: 1.480557\n",
      "Validation loss decreased (1.480560 --> 1.480557).         Saving model ...\n",
      "Epoch: 2465 \tTraining Loss: 1.080087 \tValidation Loss: 1.480554\n",
      "Validation loss decreased (1.480557 --> 1.480554).         Saving model ...\n",
      "Epoch: 2466 \tTraining Loss: 1.080083 \tValidation Loss: 1.480552\n",
      "Validation loss decreased (1.480554 --> 1.480552).         Saving model ...\n",
      "Epoch: 2467 \tTraining Loss: 1.080080 \tValidation Loss: 1.480548\n",
      "Validation loss decreased (1.480552 --> 1.480548).         Saving model ...\n",
      "Epoch: 2468 \tTraining Loss: 1.080077 \tValidation Loss: 1.480546\n",
      "Validation loss decreased (1.480548 --> 1.480546).         Saving model ...\n",
      "Epoch: 2469 \tTraining Loss: 1.080074 \tValidation Loss: 1.480543\n",
      "Validation loss decreased (1.480546 --> 1.480543).         Saving model ...\n",
      "Epoch: 2470 \tTraining Loss: 1.080071 \tValidation Loss: 1.480541\n",
      "Validation loss decreased (1.480543 --> 1.480541).         Saving model ...\n",
      "Epoch: 2471 \tTraining Loss: 1.080068 \tValidation Loss: 1.480538\n",
      "Validation loss decreased (1.480541 --> 1.480538).         Saving model ...\n",
      "Epoch: 2472 \tTraining Loss: 1.080065 \tValidation Loss: 1.480534\n",
      "Validation loss decreased (1.480538 --> 1.480534).         Saving model ...\n",
      "Epoch: 2473 \tTraining Loss: 1.080062 \tValidation Loss: 1.480532\n",
      "Validation loss decreased (1.480534 --> 1.480532).         Saving model ...\n",
      "Epoch: 2474 \tTraining Loss: 1.080059 \tValidation Loss: 1.480529\n",
      "Validation loss decreased (1.480532 --> 1.480529).         Saving model ...\n",
      "Epoch: 2475 \tTraining Loss: 1.080056 \tValidation Loss: 1.480527\n",
      "Validation loss decreased (1.480529 --> 1.480527).         Saving model ...\n",
      "Epoch: 2476 \tTraining Loss: 1.080053 \tValidation Loss: 1.480524\n",
      "Validation loss decreased (1.480527 --> 1.480524).         Saving model ...\n",
      "Epoch: 2477 \tTraining Loss: 1.080049 \tValidation Loss: 1.480520\n",
      "Validation loss decreased (1.480524 --> 1.480520).         Saving model ...\n",
      "Epoch: 2478 \tTraining Loss: 1.080046 \tValidation Loss: 1.480517\n",
      "Validation loss decreased (1.480520 --> 1.480517).         Saving model ...\n",
      "Epoch: 2479 \tTraining Loss: 1.080043 \tValidation Loss: 1.480514\n",
      "Validation loss decreased (1.480517 --> 1.480514).         Saving model ...\n",
      "Epoch: 2480 \tTraining Loss: 1.080040 \tValidation Loss: 1.480511\n",
      "Validation loss decreased (1.480514 --> 1.480511).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2481 \tTraining Loss: 1.080037 \tValidation Loss: 1.480507\n",
      "Validation loss decreased (1.480511 --> 1.480507).         Saving model ...\n",
      "Epoch: 2482 \tTraining Loss: 1.080034 \tValidation Loss: 1.480505\n",
      "Validation loss decreased (1.480507 --> 1.480505).         Saving model ...\n",
      "Epoch: 2483 \tTraining Loss: 1.080031 \tValidation Loss: 1.480501\n",
      "Validation loss decreased (1.480505 --> 1.480501).         Saving model ...\n",
      "Epoch: 2484 \tTraining Loss: 1.080028 \tValidation Loss: 1.480497\n",
      "Validation loss decreased (1.480501 --> 1.480497).         Saving model ...\n",
      "Epoch: 2485 \tTraining Loss: 1.080025 \tValidation Loss: 1.480495\n",
      "Validation loss decreased (1.480497 --> 1.480495).         Saving model ...\n",
      "Epoch: 2486 \tTraining Loss: 1.080022 \tValidation Loss: 1.480492\n",
      "Validation loss decreased (1.480495 --> 1.480492).         Saving model ...\n",
      "Epoch: 2487 \tTraining Loss: 1.080019 \tValidation Loss: 1.480489\n",
      "Validation loss decreased (1.480492 --> 1.480489).         Saving model ...\n",
      "Epoch: 2488 \tTraining Loss: 1.080016 \tValidation Loss: 1.480486\n",
      "Validation loss decreased (1.480489 --> 1.480486).         Saving model ...\n",
      "Epoch: 2489 \tTraining Loss: 1.080013 \tValidation Loss: 1.480483\n",
      "Validation loss decreased (1.480486 --> 1.480483).         Saving model ...\n",
      "Epoch: 2490 \tTraining Loss: 1.080010 \tValidation Loss: 1.480480\n",
      "Validation loss decreased (1.480483 --> 1.480480).         Saving model ...\n",
      "Epoch: 2491 \tTraining Loss: 1.080007 \tValidation Loss: 1.480477\n",
      "Validation loss decreased (1.480480 --> 1.480477).         Saving model ...\n",
      "Epoch: 2492 \tTraining Loss: 1.080003 \tValidation Loss: 1.480474\n",
      "Validation loss decreased (1.480477 --> 1.480474).         Saving model ...\n",
      "Epoch: 2493 \tTraining Loss: 1.080000 \tValidation Loss: 1.480472\n",
      "Validation loss decreased (1.480474 --> 1.480472).         Saving model ...\n",
      "Epoch: 2494 \tTraining Loss: 1.079997 \tValidation Loss: 1.480469\n",
      "Validation loss decreased (1.480472 --> 1.480469).         Saving model ...\n",
      "Epoch: 2495 \tTraining Loss: 1.079994 \tValidation Loss: 1.480466\n",
      "Validation loss decreased (1.480469 --> 1.480466).         Saving model ...\n",
      "Epoch: 2496 \tTraining Loss: 1.079991 \tValidation Loss: 1.480462\n",
      "Validation loss decreased (1.480466 --> 1.480462).         Saving model ...\n",
      "Epoch: 2497 \tTraining Loss: 1.079988 \tValidation Loss: 1.480460\n",
      "Validation loss decreased (1.480462 --> 1.480460).         Saving model ...\n",
      "Epoch: 2498 \tTraining Loss: 1.079985 \tValidation Loss: 1.480457\n",
      "Validation loss decreased (1.480460 --> 1.480457).         Saving model ...\n",
      "Epoch: 2499 \tTraining Loss: 1.079982 \tValidation Loss: 1.480454\n",
      "Validation loss decreased (1.480457 --> 1.480454).         Saving model ...\n",
      "Epoch: 2500 \tTraining Loss: 1.079979 \tValidation Loss: 1.480451\n",
      "Validation loss decreased (1.480454 --> 1.480451).         Saving model ...\n",
      "Epoch: 2501 \tTraining Loss: 1.079976 \tValidation Loss: 1.480448\n",
      "Validation loss decreased (1.480451 --> 1.480448).         Saving model ...\n",
      "Epoch: 2502 \tTraining Loss: 1.079973 \tValidation Loss: 1.480446\n",
      "Validation loss decreased (1.480448 --> 1.480446).         Saving model ...\n",
      "Epoch: 2503 \tTraining Loss: 1.079970 \tValidation Loss: 1.480445\n",
      "Validation loss decreased (1.480446 --> 1.480445).         Saving model ...\n",
      "Epoch: 2504 \tTraining Loss: 1.079967 \tValidation Loss: 1.480442\n",
      "Validation loss decreased (1.480445 --> 1.480442).         Saving model ...\n",
      "Epoch: 2505 \tTraining Loss: 1.079964 \tValidation Loss: 1.480440\n",
      "Validation loss decreased (1.480442 --> 1.480440).         Saving model ...\n",
      "Epoch: 2506 \tTraining Loss: 1.079961 \tValidation Loss: 1.480438\n",
      "Validation loss decreased (1.480440 --> 1.480438).         Saving model ...\n",
      "Epoch: 2507 \tTraining Loss: 1.079958 \tValidation Loss: 1.480435\n",
      "Validation loss decreased (1.480438 --> 1.480435).         Saving model ...\n",
      "Epoch: 2508 \tTraining Loss: 1.079955 \tValidation Loss: 1.480433\n",
      "Validation loss decreased (1.480435 --> 1.480433).         Saving model ...\n",
      "Epoch: 2509 \tTraining Loss: 1.079952 \tValidation Loss: 1.480430\n",
      "Validation loss decreased (1.480433 --> 1.480430).         Saving model ...\n",
      "Epoch: 2510 \tTraining Loss: 1.079949 \tValidation Loss: 1.480428\n",
      "Validation loss decreased (1.480430 --> 1.480428).         Saving model ...\n",
      "Epoch: 2511 \tTraining Loss: 1.079946 \tValidation Loss: 1.480425\n",
      "Validation loss decreased (1.480428 --> 1.480425).         Saving model ...\n",
      "Epoch: 2512 \tTraining Loss: 1.079943 \tValidation Loss: 1.480423\n",
      "Validation loss decreased (1.480425 --> 1.480423).         Saving model ...\n",
      "Epoch: 2513 \tTraining Loss: 1.079940 \tValidation Loss: 1.480420\n",
      "Validation loss decreased (1.480423 --> 1.480420).         Saving model ...\n",
      "Epoch: 2514 \tTraining Loss: 1.079937 \tValidation Loss: 1.480417\n",
      "Validation loss decreased (1.480420 --> 1.480417).         Saving model ...\n",
      "Epoch: 2515 \tTraining Loss: 1.079934 \tValidation Loss: 1.480415\n",
      "Validation loss decreased (1.480417 --> 1.480415).         Saving model ...\n",
      "Epoch: 2516 \tTraining Loss: 1.079931 \tValidation Loss: 1.480412\n",
      "Validation loss decreased (1.480415 --> 1.480412).         Saving model ...\n",
      "Epoch: 2517 \tTraining Loss: 1.079928 \tValidation Loss: 1.480410\n",
      "Validation loss decreased (1.480412 --> 1.480410).         Saving model ...\n",
      "Epoch: 2518 \tTraining Loss: 1.079925 \tValidation Loss: 1.480406\n",
      "Validation loss decreased (1.480410 --> 1.480406).         Saving model ...\n",
      "Epoch: 2519 \tTraining Loss: 1.079922 \tValidation Loss: 1.480404\n",
      "Validation loss decreased (1.480406 --> 1.480404).         Saving model ...\n",
      "Epoch: 2520 \tTraining Loss: 1.079919 \tValidation Loss: 1.480401\n",
      "Validation loss decreased (1.480404 --> 1.480401).         Saving model ...\n",
      "Epoch: 2521 \tTraining Loss: 1.079916 \tValidation Loss: 1.480398\n",
      "Validation loss decreased (1.480401 --> 1.480398).         Saving model ...\n",
      "Epoch: 2522 \tTraining Loss: 1.079913 \tValidation Loss: 1.480396\n",
      "Validation loss decreased (1.480398 --> 1.480396).         Saving model ...\n",
      "Epoch: 2523 \tTraining Loss: 1.079910 \tValidation Loss: 1.480393\n",
      "Validation loss decreased (1.480396 --> 1.480393).         Saving model ...\n",
      "Epoch: 2524 \tTraining Loss: 1.079907 \tValidation Loss: 1.480392\n",
      "Validation loss decreased (1.480393 --> 1.480392).         Saving model ...\n",
      "Epoch: 2525 \tTraining Loss: 1.079904 \tValidation Loss: 1.480390\n",
      "Validation loss decreased (1.480392 --> 1.480390).         Saving model ...\n",
      "Epoch: 2526 \tTraining Loss: 1.079901 \tValidation Loss: 1.480388\n",
      "Validation loss decreased (1.480390 --> 1.480388).         Saving model ...\n",
      "Epoch: 2527 \tTraining Loss: 1.079898 \tValidation Loss: 1.480386\n",
      "Validation loss decreased (1.480388 --> 1.480386).         Saving model ...\n",
      "Epoch: 2528 \tTraining Loss: 1.079895 \tValidation Loss: 1.480384\n",
      "Validation loss decreased (1.480386 --> 1.480384).         Saving model ...\n",
      "Epoch: 2529 \tTraining Loss: 1.079892 \tValidation Loss: 1.480381\n",
      "Validation loss decreased (1.480384 --> 1.480381).         Saving model ...\n",
      "Epoch: 2530 \tTraining Loss: 1.079889 \tValidation Loss: 1.480379\n",
      "Validation loss decreased (1.480381 --> 1.480379).         Saving model ...\n",
      "Epoch: 2531 \tTraining Loss: 1.079886 \tValidation Loss: 1.480377\n",
      "Validation loss decreased (1.480379 --> 1.480377).         Saving model ...\n",
      "Epoch: 2532 \tTraining Loss: 1.079883 \tValidation Loss: 1.480374\n",
      "Validation loss decreased (1.480377 --> 1.480374).         Saving model ...\n",
      "Epoch: 2533 \tTraining Loss: 1.079880 \tValidation Loss: 1.480371\n",
      "Validation loss decreased (1.480374 --> 1.480371).         Saving model ...\n",
      "Epoch: 2534 \tTraining Loss: 1.079877 \tValidation Loss: 1.480369\n",
      "Validation loss decreased (1.480371 --> 1.480369).         Saving model ...\n",
      "Epoch: 2535 \tTraining Loss: 1.079874 \tValidation Loss: 1.480365\n",
      "Validation loss decreased (1.480369 --> 1.480365).         Saving model ...\n",
      "Epoch: 2536 \tTraining Loss: 1.079871 \tValidation Loss: 1.480363\n",
      "Validation loss decreased (1.480365 --> 1.480363).         Saving model ...\n",
      "Epoch: 2537 \tTraining Loss: 1.079868 \tValidation Loss: 1.480361\n",
      "Validation loss decreased (1.480363 --> 1.480361).         Saving model ...\n",
      "Epoch: 2538 \tTraining Loss: 1.079865 \tValidation Loss: 1.480359\n",
      "Validation loss decreased (1.480361 --> 1.480359).         Saving model ...\n",
      "Epoch: 2539 \tTraining Loss: 1.079862 \tValidation Loss: 1.480356\n",
      "Validation loss decreased (1.480359 --> 1.480356).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2540 \tTraining Loss: 1.079859 \tValidation Loss: 1.480353\n",
      "Validation loss decreased (1.480356 --> 1.480353).         Saving model ...\n",
      "Epoch: 2541 \tTraining Loss: 1.079856 \tValidation Loss: 1.480351\n",
      "Validation loss decreased (1.480353 --> 1.480351).         Saving model ...\n",
      "Epoch: 2542 \tTraining Loss: 1.079853 \tValidation Loss: 1.480349\n",
      "Validation loss decreased (1.480351 --> 1.480349).         Saving model ...\n",
      "Epoch: 2543 \tTraining Loss: 1.079850 \tValidation Loss: 1.480346\n",
      "Validation loss decreased (1.480349 --> 1.480346).         Saving model ...\n",
      "Epoch: 2544 \tTraining Loss: 1.079847 \tValidation Loss: 1.480344\n",
      "Validation loss decreased (1.480346 --> 1.480344).         Saving model ...\n",
      "Epoch: 2545 \tTraining Loss: 1.079844 \tValidation Loss: 1.480341\n",
      "Validation loss decreased (1.480344 --> 1.480341).         Saving model ...\n",
      "Epoch: 2546 \tTraining Loss: 1.079841 \tValidation Loss: 1.480339\n",
      "Validation loss decreased (1.480341 --> 1.480339).         Saving model ...\n",
      "Epoch: 2547 \tTraining Loss: 1.079838 \tValidation Loss: 1.480336\n",
      "Validation loss decreased (1.480339 --> 1.480336).         Saving model ...\n",
      "Epoch: 2548 \tTraining Loss: 1.079835 \tValidation Loss: 1.480334\n",
      "Validation loss decreased (1.480336 --> 1.480334).         Saving model ...\n",
      "Epoch: 2549 \tTraining Loss: 1.079832 \tValidation Loss: 1.480331\n",
      "Validation loss decreased (1.480334 --> 1.480331).         Saving model ...\n",
      "Epoch: 2550 \tTraining Loss: 1.079829 \tValidation Loss: 1.480328\n",
      "Validation loss decreased (1.480331 --> 1.480328).         Saving model ...\n",
      "Epoch: 2551 \tTraining Loss: 1.079826 \tValidation Loss: 1.480326\n",
      "Validation loss decreased (1.480328 --> 1.480326).         Saving model ...\n",
      "Epoch: 2552 \tTraining Loss: 1.079823 \tValidation Loss: 1.480324\n",
      "Validation loss decreased (1.480326 --> 1.480324).         Saving model ...\n",
      "Epoch: 2553 \tTraining Loss: 1.079820 \tValidation Loss: 1.480321\n",
      "Validation loss decreased (1.480324 --> 1.480321).         Saving model ...\n",
      "Epoch: 2554 \tTraining Loss: 1.079817 \tValidation Loss: 1.480319\n",
      "Validation loss decreased (1.480321 --> 1.480319).         Saving model ...\n",
      "Epoch: 2555 \tTraining Loss: 1.079815 \tValidation Loss: 1.480317\n",
      "Validation loss decreased (1.480319 --> 1.480317).         Saving model ...\n",
      "Epoch: 2556 \tTraining Loss: 1.079812 \tValidation Loss: 1.480313\n",
      "Validation loss decreased (1.480317 --> 1.480313).         Saving model ...\n",
      "Epoch: 2557 \tTraining Loss: 1.079809 \tValidation Loss: 1.480311\n",
      "Validation loss decreased (1.480313 --> 1.480311).         Saving model ...\n",
      "Epoch: 2558 \tTraining Loss: 1.079806 \tValidation Loss: 1.480309\n",
      "Validation loss decreased (1.480311 --> 1.480309).         Saving model ...\n",
      "Epoch: 2559 \tTraining Loss: 1.079803 \tValidation Loss: 1.480306\n",
      "Validation loss decreased (1.480309 --> 1.480306).         Saving model ...\n",
      "Epoch: 2560 \tTraining Loss: 1.079800 \tValidation Loss: 1.480303\n",
      "Validation loss decreased (1.480306 --> 1.480303).         Saving model ...\n",
      "Epoch: 2561 \tTraining Loss: 1.079797 \tValidation Loss: 1.480301\n",
      "Validation loss decreased (1.480303 --> 1.480301).         Saving model ...\n",
      "Epoch: 2562 \tTraining Loss: 1.079794 \tValidation Loss: 1.480298\n",
      "Validation loss decreased (1.480301 --> 1.480298).         Saving model ...\n",
      "Epoch: 2563 \tTraining Loss: 1.079791 \tValidation Loss: 1.480296\n",
      "Validation loss decreased (1.480298 --> 1.480296).         Saving model ...\n",
      "Epoch: 2564 \tTraining Loss: 1.079788 \tValidation Loss: 1.480293\n",
      "Validation loss decreased (1.480296 --> 1.480293).         Saving model ...\n",
      "Epoch: 2565 \tTraining Loss: 1.079785 \tValidation Loss: 1.480291\n",
      "Validation loss decreased (1.480293 --> 1.480291).         Saving model ...\n",
      "Epoch: 2566 \tTraining Loss: 1.079782 \tValidation Loss: 1.480288\n",
      "Validation loss decreased (1.480291 --> 1.480288).         Saving model ...\n",
      "Epoch: 2567 \tTraining Loss: 1.079779 \tValidation Loss: 1.480286\n",
      "Validation loss decreased (1.480288 --> 1.480286).         Saving model ...\n",
      "Epoch: 2568 \tTraining Loss: 1.079776 \tValidation Loss: 1.480284\n",
      "Validation loss decreased (1.480286 --> 1.480284).         Saving model ...\n",
      "Epoch: 2569 \tTraining Loss: 1.079773 \tValidation Loss: 1.480281\n",
      "Validation loss decreased (1.480284 --> 1.480281).         Saving model ...\n",
      "Epoch: 2570 \tTraining Loss: 1.079771 \tValidation Loss: 1.480279\n",
      "Validation loss decreased (1.480281 --> 1.480279).         Saving model ...\n",
      "Epoch: 2571 \tTraining Loss: 1.079768 \tValidation Loss: 1.480277\n",
      "Validation loss decreased (1.480279 --> 1.480277).         Saving model ...\n",
      "Epoch: 2572 \tTraining Loss: 1.079765 \tValidation Loss: 1.480275\n",
      "Validation loss decreased (1.480277 --> 1.480275).         Saving model ...\n",
      "Epoch: 2573 \tTraining Loss: 1.079762 \tValidation Loss: 1.480273\n",
      "Validation loss decreased (1.480275 --> 1.480273).         Saving model ...\n",
      "Epoch: 2574 \tTraining Loss: 1.079759 \tValidation Loss: 1.480272\n",
      "Validation loss decreased (1.480273 --> 1.480272).         Saving model ...\n",
      "Epoch: 2575 \tTraining Loss: 1.079756 \tValidation Loss: 1.480269\n",
      "Validation loss decreased (1.480272 --> 1.480269).         Saving model ...\n",
      "Epoch: 2576 \tTraining Loss: 1.079753 \tValidation Loss: 1.480268\n",
      "Validation loss decreased (1.480269 --> 1.480268).         Saving model ...\n",
      "Epoch: 2577 \tTraining Loss: 1.079750 \tValidation Loss: 1.480265\n",
      "Validation loss decreased (1.480268 --> 1.480265).         Saving model ...\n",
      "Epoch: 2578 \tTraining Loss: 1.079747 \tValidation Loss: 1.480264\n",
      "Validation loss decreased (1.480265 --> 1.480264).         Saving model ...\n",
      "Epoch: 2579 \tTraining Loss: 1.079744 \tValidation Loss: 1.480262\n",
      "Validation loss decreased (1.480264 --> 1.480262).         Saving model ...\n",
      "Epoch: 2580 \tTraining Loss: 1.079741 \tValidation Loss: 1.480259\n",
      "Validation loss decreased (1.480262 --> 1.480259).         Saving model ...\n",
      "Epoch: 2581 \tTraining Loss: 1.079739 \tValidation Loss: 1.480258\n",
      "Validation loss decreased (1.480259 --> 1.480258).         Saving model ...\n",
      "Epoch: 2582 \tTraining Loss: 1.079736 \tValidation Loss: 1.480256\n",
      "Validation loss decreased (1.480258 --> 1.480256).         Saving model ...\n",
      "Epoch: 2583 \tTraining Loss: 1.079733 \tValidation Loss: 1.480254\n",
      "Validation loss decreased (1.480256 --> 1.480254).         Saving model ...\n",
      "Epoch: 2584 \tTraining Loss: 1.079730 \tValidation Loss: 1.480251\n",
      "Validation loss decreased (1.480254 --> 1.480251).         Saving model ...\n",
      "Epoch: 2585 \tTraining Loss: 1.079727 \tValidation Loss: 1.480250\n",
      "Validation loss decreased (1.480251 --> 1.480250).         Saving model ...\n",
      "Epoch: 2586 \tTraining Loss: 1.079724 \tValidation Loss: 1.480247\n",
      "Validation loss decreased (1.480250 --> 1.480247).         Saving model ...\n",
      "Epoch: 2587 \tTraining Loss: 1.079721 \tValidation Loss: 1.480246\n",
      "Validation loss decreased (1.480247 --> 1.480246).         Saving model ...\n",
      "Epoch: 2588 \tTraining Loss: 1.079718 \tValidation Loss: 1.480243\n",
      "Validation loss decreased (1.480246 --> 1.480243).         Saving model ...\n",
      "Epoch: 2589 \tTraining Loss: 1.079715 \tValidation Loss: 1.480241\n",
      "Validation loss decreased (1.480243 --> 1.480241).         Saving model ...\n",
      "Epoch: 2590 \tTraining Loss: 1.079712 \tValidation Loss: 1.480238\n",
      "Validation loss decreased (1.480241 --> 1.480238).         Saving model ...\n",
      "Epoch: 2591 \tTraining Loss: 1.079710 \tValidation Loss: 1.480237\n",
      "Validation loss decreased (1.480238 --> 1.480237).         Saving model ...\n",
      "Epoch: 2592 \tTraining Loss: 1.079707 \tValidation Loss: 1.480234\n",
      "Validation loss decreased (1.480237 --> 1.480234).         Saving model ...\n",
      "Epoch: 2593 \tTraining Loss: 1.079704 \tValidation Loss: 1.480232\n",
      "Validation loss decreased (1.480234 --> 1.480232).         Saving model ...\n",
      "Epoch: 2594 \tTraining Loss: 1.079701 \tValidation Loss: 1.480229\n",
      "Validation loss decreased (1.480232 --> 1.480229).         Saving model ...\n",
      "Epoch: 2595 \tTraining Loss: 1.079698 \tValidation Loss: 1.480226\n",
      "Validation loss decreased (1.480229 --> 1.480226).         Saving model ...\n",
      "Epoch: 2596 \tTraining Loss: 1.079695 \tValidation Loss: 1.480224\n",
      "Validation loss decreased (1.480226 --> 1.480224).         Saving model ...\n",
      "Epoch: 2597 \tTraining Loss: 1.079692 \tValidation Loss: 1.480221\n",
      "Validation loss decreased (1.480224 --> 1.480221).         Saving model ...\n",
      "Epoch: 2598 \tTraining Loss: 1.079689 \tValidation Loss: 1.480219\n",
      "Validation loss decreased (1.480221 --> 1.480219).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2599 \tTraining Loss: 1.079686 \tValidation Loss: 1.480216\n",
      "Validation loss decreased (1.480219 --> 1.480216).         Saving model ...\n",
      "Epoch: 2600 \tTraining Loss: 1.079684 \tValidation Loss: 1.480214\n",
      "Validation loss decreased (1.480216 --> 1.480214).         Saving model ...\n",
      "Epoch: 2601 \tTraining Loss: 1.079681 \tValidation Loss: 1.480211\n",
      "Validation loss decreased (1.480214 --> 1.480211).         Saving model ...\n",
      "Epoch: 2602 \tTraining Loss: 1.079678 \tValidation Loss: 1.480210\n",
      "Validation loss decreased (1.480211 --> 1.480210).         Saving model ...\n",
      "Epoch: 2603 \tTraining Loss: 1.079675 \tValidation Loss: 1.480207\n",
      "Validation loss decreased (1.480210 --> 1.480207).         Saving model ...\n",
      "Epoch: 2604 \tTraining Loss: 1.079672 \tValidation Loss: 1.480205\n",
      "Validation loss decreased (1.480207 --> 1.480205).         Saving model ...\n",
      "Epoch: 2605 \tTraining Loss: 1.079669 \tValidation Loss: 1.480204\n",
      "Validation loss decreased (1.480205 --> 1.480204).         Saving model ...\n",
      "Epoch: 2606 \tTraining Loss: 1.079666 \tValidation Loss: 1.480201\n",
      "Validation loss decreased (1.480204 --> 1.480201).         Saving model ...\n",
      "Epoch: 2607 \tTraining Loss: 1.079664 \tValidation Loss: 1.480199\n",
      "Validation loss decreased (1.480201 --> 1.480199).         Saving model ...\n",
      "Epoch: 2608 \tTraining Loss: 1.079661 \tValidation Loss: 1.480196\n",
      "Validation loss decreased (1.480199 --> 1.480196).         Saving model ...\n",
      "Epoch: 2609 \tTraining Loss: 1.079658 \tValidation Loss: 1.480195\n",
      "Validation loss decreased (1.480196 --> 1.480195).         Saving model ...\n",
      "Epoch: 2610 \tTraining Loss: 1.079655 \tValidation Loss: 1.480192\n",
      "Validation loss decreased (1.480195 --> 1.480192).         Saving model ...\n",
      "Epoch: 2611 \tTraining Loss: 1.079652 \tValidation Loss: 1.480190\n",
      "Validation loss decreased (1.480192 --> 1.480190).         Saving model ...\n",
      "Epoch: 2612 \tTraining Loss: 1.079649 \tValidation Loss: 1.480187\n",
      "Validation loss decreased (1.480190 --> 1.480187).         Saving model ...\n",
      "Epoch: 2613 \tTraining Loss: 1.079646 \tValidation Loss: 1.480185\n",
      "Validation loss decreased (1.480187 --> 1.480185).         Saving model ...\n",
      "Epoch: 2614 \tTraining Loss: 1.079644 \tValidation Loss: 1.480182\n",
      "Validation loss decreased (1.480185 --> 1.480182).         Saving model ...\n",
      "Epoch: 2615 \tTraining Loss: 1.079641 \tValidation Loss: 1.480180\n",
      "Validation loss decreased (1.480182 --> 1.480180).         Saving model ...\n",
      "Epoch: 2616 \tTraining Loss: 1.079638 \tValidation Loss: 1.480178\n",
      "Validation loss decreased (1.480180 --> 1.480178).         Saving model ...\n",
      "Epoch: 2617 \tTraining Loss: 1.079635 \tValidation Loss: 1.480176\n",
      "Validation loss decreased (1.480178 --> 1.480176).         Saving model ...\n",
      "Epoch: 2618 \tTraining Loss: 1.079632 \tValidation Loss: 1.480173\n",
      "Validation loss decreased (1.480176 --> 1.480173).         Saving model ...\n",
      "Epoch: 2619 \tTraining Loss: 1.079629 \tValidation Loss: 1.480171\n",
      "Validation loss decreased (1.480173 --> 1.480171).         Saving model ...\n",
      "Epoch: 2620 \tTraining Loss: 1.079626 \tValidation Loss: 1.480168\n",
      "Validation loss decreased (1.480171 --> 1.480168).         Saving model ...\n",
      "Epoch: 2621 \tTraining Loss: 1.079624 \tValidation Loss: 1.480166\n",
      "Validation loss decreased (1.480168 --> 1.480166).         Saving model ...\n",
      "Epoch: 2622 \tTraining Loss: 1.079621 \tValidation Loss: 1.480164\n",
      "Validation loss decreased (1.480166 --> 1.480164).         Saving model ...\n",
      "Epoch: 2623 \tTraining Loss: 1.079618 \tValidation Loss: 1.480162\n",
      "Validation loss decreased (1.480164 --> 1.480162).         Saving model ...\n",
      "Epoch: 2624 \tTraining Loss: 1.079615 \tValidation Loss: 1.480159\n",
      "Validation loss decreased (1.480162 --> 1.480159).         Saving model ...\n",
      "Epoch: 2625 \tTraining Loss: 1.079612 \tValidation Loss: 1.480157\n",
      "Validation loss decreased (1.480159 --> 1.480157).         Saving model ...\n",
      "Epoch: 2626 \tTraining Loss: 1.079609 \tValidation Loss: 1.480155\n",
      "Validation loss decreased (1.480157 --> 1.480155).         Saving model ...\n",
      "Epoch: 2627 \tTraining Loss: 1.079607 \tValidation Loss: 1.480153\n",
      "Validation loss decreased (1.480155 --> 1.480153).         Saving model ...\n",
      "Epoch: 2628 \tTraining Loss: 1.079604 \tValidation Loss: 1.480151\n",
      "Validation loss decreased (1.480153 --> 1.480151).         Saving model ...\n",
      "Epoch: 2629 \tTraining Loss: 1.079601 \tValidation Loss: 1.480148\n",
      "Validation loss decreased (1.480151 --> 1.480148).         Saving model ...\n",
      "Epoch: 2630 \tTraining Loss: 1.079598 \tValidation Loss: 1.480146\n",
      "Validation loss decreased (1.480148 --> 1.480146).         Saving model ...\n",
      "Epoch: 2631 \tTraining Loss: 1.079595 \tValidation Loss: 1.480144\n",
      "Validation loss decreased (1.480146 --> 1.480144).         Saving model ...\n",
      "Epoch: 2632 \tTraining Loss: 1.079592 \tValidation Loss: 1.480141\n",
      "Validation loss decreased (1.480144 --> 1.480141).         Saving model ...\n",
      "Epoch: 2633 \tTraining Loss: 1.079590 \tValidation Loss: 1.480139\n",
      "Validation loss decreased (1.480141 --> 1.480139).         Saving model ...\n",
      "Epoch: 2634 \tTraining Loss: 1.079587 \tValidation Loss: 1.480137\n",
      "Validation loss decreased (1.480139 --> 1.480137).         Saving model ...\n",
      "Epoch: 2635 \tTraining Loss: 1.079584 \tValidation Loss: 1.480135\n",
      "Validation loss decreased (1.480137 --> 1.480135).         Saving model ...\n",
      "Epoch: 2636 \tTraining Loss: 1.079581 \tValidation Loss: 1.480132\n",
      "Validation loss decreased (1.480135 --> 1.480132).         Saving model ...\n",
      "Epoch: 2637 \tTraining Loss: 1.079578 \tValidation Loss: 1.480131\n",
      "Validation loss decreased (1.480132 --> 1.480131).         Saving model ...\n",
      "Epoch: 2638 \tTraining Loss: 1.079576 \tValidation Loss: 1.480128\n",
      "Validation loss decreased (1.480131 --> 1.480128).         Saving model ...\n",
      "Epoch: 2639 \tTraining Loss: 1.079573 \tValidation Loss: 1.480126\n",
      "Validation loss decreased (1.480128 --> 1.480126).         Saving model ...\n",
      "Epoch: 2640 \tTraining Loss: 1.079570 \tValidation Loss: 1.480124\n",
      "Validation loss decreased (1.480126 --> 1.480124).         Saving model ...\n",
      "Epoch: 2641 \tTraining Loss: 1.079567 \tValidation Loss: 1.480121\n",
      "Validation loss decreased (1.480124 --> 1.480121).         Saving model ...\n",
      "Epoch: 2642 \tTraining Loss: 1.079564 \tValidation Loss: 1.480119\n",
      "Validation loss decreased (1.480121 --> 1.480119).         Saving model ...\n",
      "Epoch: 2643 \tTraining Loss: 1.079562 \tValidation Loss: 1.480116\n",
      "Validation loss decreased (1.480119 --> 1.480116).         Saving model ...\n",
      "Epoch: 2644 \tTraining Loss: 1.079559 \tValidation Loss: 1.480113\n",
      "Validation loss decreased (1.480116 --> 1.480113).         Saving model ...\n",
      "Epoch: 2645 \tTraining Loss: 1.079556 \tValidation Loss: 1.480110\n",
      "Validation loss decreased (1.480113 --> 1.480110).         Saving model ...\n",
      "Epoch: 2646 \tTraining Loss: 1.079553 \tValidation Loss: 1.480108\n",
      "Validation loss decreased (1.480110 --> 1.480108).         Saving model ...\n",
      "Epoch: 2647 \tTraining Loss: 1.079550 \tValidation Loss: 1.480105\n",
      "Validation loss decreased (1.480108 --> 1.480105).         Saving model ...\n",
      "Epoch: 2648 \tTraining Loss: 1.079547 \tValidation Loss: 1.480103\n",
      "Validation loss decreased (1.480105 --> 1.480103).         Saving model ...\n",
      "Epoch: 2649 \tTraining Loss: 1.079545 \tValidation Loss: 1.480100\n",
      "Validation loss decreased (1.480103 --> 1.480100).         Saving model ...\n",
      "Epoch: 2650 \tTraining Loss: 1.079542 \tValidation Loss: 1.480097\n",
      "Validation loss decreased (1.480100 --> 1.480097).         Saving model ...\n",
      "Epoch: 2651 \tTraining Loss: 1.079539 \tValidation Loss: 1.480096\n",
      "Validation loss decreased (1.480097 --> 1.480096).         Saving model ...\n",
      "Epoch: 2652 \tTraining Loss: 1.079536 \tValidation Loss: 1.480093\n",
      "Validation loss decreased (1.480096 --> 1.480093).         Saving model ...\n",
      "Epoch: 2653 \tTraining Loss: 1.079534 \tValidation Loss: 1.480090\n",
      "Validation loss decreased (1.480093 --> 1.480090).         Saving model ...\n",
      "Epoch: 2654 \tTraining Loss: 1.079531 \tValidation Loss: 1.480089\n",
      "Validation loss decreased (1.480090 --> 1.480089).         Saving model ...\n",
      "Epoch: 2655 \tTraining Loss: 1.079528 \tValidation Loss: 1.480086\n",
      "Validation loss decreased (1.480089 --> 1.480086).         Saving model ...\n",
      "Epoch: 2656 \tTraining Loss: 1.079525 \tValidation Loss: 1.480084\n",
      "Validation loss decreased (1.480086 --> 1.480084).         Saving model ...\n",
      "Epoch: 2657 \tTraining Loss: 1.079522 \tValidation Loss: 1.480082\n",
      "Validation loss decreased (1.480084 --> 1.480082).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2658 \tTraining Loss: 1.079520 \tValidation Loss: 1.480080\n",
      "Validation loss decreased (1.480082 --> 1.480080).         Saving model ...\n",
      "Epoch: 2659 \tTraining Loss: 1.079517 \tValidation Loss: 1.480078\n",
      "Validation loss decreased (1.480080 --> 1.480078).         Saving model ...\n",
      "Epoch: 2660 \tTraining Loss: 1.079514 \tValidation Loss: 1.480076\n",
      "Validation loss decreased (1.480078 --> 1.480076).         Saving model ...\n",
      "Epoch: 2661 \tTraining Loss: 1.079511 \tValidation Loss: 1.480074\n",
      "Validation loss decreased (1.480076 --> 1.480074).         Saving model ...\n",
      "Epoch: 2662 \tTraining Loss: 1.079508 \tValidation Loss: 1.480072\n",
      "Validation loss decreased (1.480074 --> 1.480072).         Saving model ...\n",
      "Epoch: 2663 \tTraining Loss: 1.079506 \tValidation Loss: 1.480070\n",
      "Validation loss decreased (1.480072 --> 1.480070).         Saving model ...\n",
      "Epoch: 2664 \tTraining Loss: 1.079503 \tValidation Loss: 1.480067\n",
      "Validation loss decreased (1.480070 --> 1.480067).         Saving model ...\n",
      "Epoch: 2665 \tTraining Loss: 1.079500 \tValidation Loss: 1.480065\n",
      "Validation loss decreased (1.480067 --> 1.480065).         Saving model ...\n",
      "Epoch: 2666 \tTraining Loss: 1.079497 \tValidation Loss: 1.480062\n",
      "Validation loss decreased (1.480065 --> 1.480062).         Saving model ...\n",
      "Epoch: 2667 \tTraining Loss: 1.079495 \tValidation Loss: 1.480061\n",
      "Validation loss decreased (1.480062 --> 1.480061).         Saving model ...\n",
      "Epoch: 2668 \tTraining Loss: 1.079492 \tValidation Loss: 1.480058\n",
      "Validation loss decreased (1.480061 --> 1.480058).         Saving model ...\n",
      "Epoch: 2669 \tTraining Loss: 1.079489 \tValidation Loss: 1.480056\n",
      "Validation loss decreased (1.480058 --> 1.480056).         Saving model ...\n",
      "Epoch: 2670 \tTraining Loss: 1.079486 \tValidation Loss: 1.480053\n",
      "Validation loss decreased (1.480056 --> 1.480053).         Saving model ...\n",
      "Epoch: 2671 \tTraining Loss: 1.079484 \tValidation Loss: 1.480051\n",
      "Validation loss decreased (1.480053 --> 1.480051).         Saving model ...\n",
      "Epoch: 2672 \tTraining Loss: 1.079481 \tValidation Loss: 1.480048\n",
      "Validation loss decreased (1.480051 --> 1.480048).         Saving model ...\n",
      "Epoch: 2673 \tTraining Loss: 1.079478 \tValidation Loss: 1.480046\n",
      "Validation loss decreased (1.480048 --> 1.480046).         Saving model ...\n",
      "Epoch: 2674 \tTraining Loss: 1.079475 \tValidation Loss: 1.480044\n",
      "Validation loss decreased (1.480046 --> 1.480044).         Saving model ...\n",
      "Epoch: 2675 \tTraining Loss: 1.079472 \tValidation Loss: 1.480042\n",
      "Validation loss decreased (1.480044 --> 1.480042).         Saving model ...\n",
      "Epoch: 2676 \tTraining Loss: 1.079470 \tValidation Loss: 1.480040\n",
      "Validation loss decreased (1.480042 --> 1.480040).         Saving model ...\n",
      "Epoch: 2677 \tTraining Loss: 1.079467 \tValidation Loss: 1.480038\n",
      "Validation loss decreased (1.480040 --> 1.480038).         Saving model ...\n",
      "Epoch: 2678 \tTraining Loss: 1.079464 \tValidation Loss: 1.480036\n",
      "Validation loss decreased (1.480038 --> 1.480036).         Saving model ...\n",
      "Epoch: 2679 \tTraining Loss: 1.079461 \tValidation Loss: 1.480034\n",
      "Validation loss decreased (1.480036 --> 1.480034).         Saving model ...\n",
      "Epoch: 2680 \tTraining Loss: 1.079459 \tValidation Loss: 1.480031\n",
      "Validation loss decreased (1.480034 --> 1.480031).         Saving model ...\n",
      "Epoch: 2681 \tTraining Loss: 1.079456 \tValidation Loss: 1.480030\n",
      "Validation loss decreased (1.480031 --> 1.480030).         Saving model ...\n",
      "Epoch: 2682 \tTraining Loss: 1.079453 \tValidation Loss: 1.480027\n",
      "Validation loss decreased (1.480030 --> 1.480027).         Saving model ...\n",
      "Epoch: 2683 \tTraining Loss: 1.079450 \tValidation Loss: 1.480025\n",
      "Validation loss decreased (1.480027 --> 1.480025).         Saving model ...\n",
      "Epoch: 2684 \tTraining Loss: 1.079448 \tValidation Loss: 1.480023\n",
      "Validation loss decreased (1.480025 --> 1.480023).         Saving model ...\n",
      "Epoch: 2685 \tTraining Loss: 1.079445 \tValidation Loss: 1.480020\n",
      "Validation loss decreased (1.480023 --> 1.480020).         Saving model ...\n",
      "Epoch: 2686 \tTraining Loss: 1.079442 \tValidation Loss: 1.480018\n",
      "Validation loss decreased (1.480020 --> 1.480018).         Saving model ...\n",
      "Epoch: 2687 \tTraining Loss: 1.079439 \tValidation Loss: 1.480016\n",
      "Validation loss decreased (1.480018 --> 1.480016).         Saving model ...\n",
      "Epoch: 2688 \tTraining Loss: 1.079437 \tValidation Loss: 1.480014\n",
      "Validation loss decreased (1.480016 --> 1.480014).         Saving model ...\n",
      "Epoch: 2689 \tTraining Loss: 1.079434 \tValidation Loss: 1.480012\n",
      "Validation loss decreased (1.480014 --> 1.480012).         Saving model ...\n",
      "Epoch: 2690 \tTraining Loss: 1.079431 \tValidation Loss: 1.480011\n",
      "Validation loss decreased (1.480012 --> 1.480011).         Saving model ...\n",
      "Epoch: 2691 \tTraining Loss: 1.079429 \tValidation Loss: 1.480009\n",
      "Validation loss decreased (1.480011 --> 1.480009).         Saving model ...\n",
      "Epoch: 2692 \tTraining Loss: 1.079426 \tValidation Loss: 1.480008\n",
      "Validation loss decreased (1.480009 --> 1.480008).         Saving model ...\n",
      "Epoch: 2693 \tTraining Loss: 1.079423 \tValidation Loss: 1.480005\n",
      "Validation loss decreased (1.480008 --> 1.480005).         Saving model ...\n",
      "Epoch: 2694 \tTraining Loss: 1.079420 \tValidation Loss: 1.480003\n",
      "Validation loss decreased (1.480005 --> 1.480003).         Saving model ...\n",
      "Epoch: 2695 \tTraining Loss: 1.079418 \tValidation Loss: 1.480000\n",
      "Validation loss decreased (1.480003 --> 1.480000).         Saving model ...\n",
      "Epoch: 2696 \tTraining Loss: 1.079415 \tValidation Loss: 1.479999\n",
      "Validation loss decreased (1.480000 --> 1.479999).         Saving model ...\n",
      "Epoch: 2697 \tTraining Loss: 1.079412 \tValidation Loss: 1.479996\n",
      "Validation loss decreased (1.479999 --> 1.479996).         Saving model ...\n",
      "Epoch: 2698 \tTraining Loss: 1.079409 \tValidation Loss: 1.479994\n",
      "Validation loss decreased (1.479996 --> 1.479994).         Saving model ...\n",
      "Epoch: 2699 \tTraining Loss: 1.079407 \tValidation Loss: 1.479993\n",
      "Validation loss decreased (1.479994 --> 1.479993).         Saving model ...\n",
      "Epoch: 2700 \tTraining Loss: 1.079404 \tValidation Loss: 1.479992\n",
      "Validation loss decreased (1.479993 --> 1.479992).         Saving model ...\n",
      "Epoch: 2701 \tTraining Loss: 1.079401 \tValidation Loss: 1.479991\n",
      "Validation loss decreased (1.479992 --> 1.479991).         Saving model ...\n",
      "Epoch: 2702 \tTraining Loss: 1.079399 \tValidation Loss: 1.479989\n",
      "Validation loss decreased (1.479991 --> 1.479989).         Saving model ...\n",
      "Epoch: 2703 \tTraining Loss: 1.079396 \tValidation Loss: 1.479988\n",
      "Validation loss decreased (1.479989 --> 1.479988).         Saving model ...\n",
      "Epoch: 2704 \tTraining Loss: 1.079393 \tValidation Loss: 1.479986\n",
      "Validation loss decreased (1.479988 --> 1.479986).         Saving model ...\n",
      "Epoch: 2705 \tTraining Loss: 1.079390 \tValidation Loss: 1.479984\n",
      "Validation loss decreased (1.479986 --> 1.479984).         Saving model ...\n",
      "Epoch: 2706 \tTraining Loss: 1.079388 \tValidation Loss: 1.479983\n",
      "Validation loss decreased (1.479984 --> 1.479983).         Saving model ...\n",
      "Epoch: 2707 \tTraining Loss: 1.079385 \tValidation Loss: 1.479982\n",
      "Validation loss decreased (1.479983 --> 1.479982).         Saving model ...\n",
      "Epoch: 2708 \tTraining Loss: 1.079382 \tValidation Loss: 1.479980\n",
      "Validation loss decreased (1.479982 --> 1.479980).         Saving model ...\n",
      "Epoch: 2709 \tTraining Loss: 1.079380 \tValidation Loss: 1.479978\n",
      "Validation loss decreased (1.479980 --> 1.479978).         Saving model ...\n",
      "Epoch: 2710 \tTraining Loss: 1.079377 \tValidation Loss: 1.479975\n",
      "Validation loss decreased (1.479978 --> 1.479975).         Saving model ...\n",
      "Epoch: 2711 \tTraining Loss: 1.079374 \tValidation Loss: 1.479974\n",
      "Validation loss decreased (1.479975 --> 1.479974).         Saving model ...\n",
      "Epoch: 2712 \tTraining Loss: 1.079371 \tValidation Loss: 1.479972\n",
      "Validation loss decreased (1.479974 --> 1.479972).         Saving model ...\n",
      "Epoch: 2713 \tTraining Loss: 1.079369 \tValidation Loss: 1.479972\n",
      "Validation loss decreased (1.479972 --> 1.479972).         Saving model ...\n",
      "Epoch: 2714 \tTraining Loss: 1.079366 \tValidation Loss: 1.479970\n",
      "Validation loss decreased (1.479972 --> 1.479970).         Saving model ...\n",
      "Epoch: 2715 \tTraining Loss: 1.079363 \tValidation Loss: 1.479968\n",
      "Validation loss decreased (1.479970 --> 1.479968).         Saving model ...\n",
      "Epoch: 2716 \tTraining Loss: 1.079361 \tValidation Loss: 1.479967\n",
      "Validation loss decreased (1.479968 --> 1.479967).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2717 \tTraining Loss: 1.079358 \tValidation Loss: 1.479966\n",
      "Validation loss decreased (1.479967 --> 1.479966).         Saving model ...\n",
      "Epoch: 2718 \tTraining Loss: 1.079355 \tValidation Loss: 1.479964\n",
      "Validation loss decreased (1.479966 --> 1.479964).         Saving model ...\n",
      "Epoch: 2719 \tTraining Loss: 1.079353 \tValidation Loss: 1.479963\n",
      "Validation loss decreased (1.479964 --> 1.479963).         Saving model ...\n",
      "Epoch: 2720 \tTraining Loss: 1.079350 \tValidation Loss: 1.479961\n",
      "Validation loss decreased (1.479963 --> 1.479961).         Saving model ...\n",
      "Epoch: 2721 \tTraining Loss: 1.079347 \tValidation Loss: 1.479960\n",
      "Validation loss decreased (1.479961 --> 1.479960).         Saving model ...\n",
      "Epoch: 2722 \tTraining Loss: 1.079344 \tValidation Loss: 1.479958\n",
      "Validation loss decreased (1.479960 --> 1.479958).         Saving model ...\n",
      "Epoch: 2723 \tTraining Loss: 1.079342 \tValidation Loss: 1.479957\n",
      "Validation loss decreased (1.479958 --> 1.479957).         Saving model ...\n",
      "Epoch: 2724 \tTraining Loss: 1.079339 \tValidation Loss: 1.479954\n",
      "Validation loss decreased (1.479957 --> 1.479954).         Saving model ...\n",
      "Epoch: 2725 \tTraining Loss: 1.079336 \tValidation Loss: 1.479953\n",
      "Validation loss decreased (1.479954 --> 1.479953).         Saving model ...\n",
      "Epoch: 2726 \tTraining Loss: 1.079334 \tValidation Loss: 1.479951\n",
      "Validation loss decreased (1.479953 --> 1.479951).         Saving model ...\n",
      "Epoch: 2727 \tTraining Loss: 1.079331 \tValidation Loss: 1.479949\n",
      "Validation loss decreased (1.479951 --> 1.479949).         Saving model ...\n",
      "Epoch: 2728 \tTraining Loss: 1.079328 \tValidation Loss: 1.479947\n",
      "Validation loss decreased (1.479949 --> 1.479947).         Saving model ...\n",
      "Epoch: 2729 \tTraining Loss: 1.079326 \tValidation Loss: 1.479945\n",
      "Validation loss decreased (1.479947 --> 1.479945).         Saving model ...\n",
      "Epoch: 2730 \tTraining Loss: 1.079323 \tValidation Loss: 1.479943\n",
      "Validation loss decreased (1.479945 --> 1.479943).         Saving model ...\n",
      "Epoch: 2731 \tTraining Loss: 1.079320 \tValidation Loss: 1.479940\n",
      "Validation loss decreased (1.479943 --> 1.479940).         Saving model ...\n",
      "Epoch: 2732 \tTraining Loss: 1.079318 \tValidation Loss: 1.479938\n",
      "Validation loss decreased (1.479940 --> 1.479938).         Saving model ...\n",
      "Epoch: 2733 \tTraining Loss: 1.079315 \tValidation Loss: 1.479936\n",
      "Validation loss decreased (1.479938 --> 1.479936).         Saving model ...\n",
      "Epoch: 2734 \tTraining Loss: 1.079312 \tValidation Loss: 1.479933\n",
      "Validation loss decreased (1.479936 --> 1.479933).         Saving model ...\n",
      "Epoch: 2735 \tTraining Loss: 1.079310 \tValidation Loss: 1.479931\n",
      "Validation loss decreased (1.479933 --> 1.479931).         Saving model ...\n",
      "Epoch: 2736 \tTraining Loss: 1.079307 \tValidation Loss: 1.479930\n",
      "Validation loss decreased (1.479931 --> 1.479930).         Saving model ...\n",
      "Epoch: 2737 \tTraining Loss: 1.079304 \tValidation Loss: 1.479927\n",
      "Validation loss decreased (1.479930 --> 1.479927).         Saving model ...\n",
      "Epoch: 2738 \tTraining Loss: 1.079302 \tValidation Loss: 1.479925\n",
      "Validation loss decreased (1.479927 --> 1.479925).         Saving model ...\n",
      "Epoch: 2739 \tTraining Loss: 1.079299 \tValidation Loss: 1.479923\n",
      "Validation loss decreased (1.479925 --> 1.479923).         Saving model ...\n",
      "Epoch: 2740 \tTraining Loss: 1.079296 \tValidation Loss: 1.479922\n",
      "Validation loss decreased (1.479923 --> 1.479922).         Saving model ...\n",
      "Epoch: 2741 \tTraining Loss: 1.079294 \tValidation Loss: 1.479920\n",
      "Validation loss decreased (1.479922 --> 1.479920).         Saving model ...\n",
      "Epoch: 2742 \tTraining Loss: 1.079291 \tValidation Loss: 1.479918\n",
      "Validation loss decreased (1.479920 --> 1.479918).         Saving model ...\n",
      "Epoch: 2743 \tTraining Loss: 1.079288 \tValidation Loss: 1.479916\n",
      "Validation loss decreased (1.479918 --> 1.479916).         Saving model ...\n",
      "Epoch: 2744 \tTraining Loss: 1.079286 \tValidation Loss: 1.479915\n",
      "Validation loss decreased (1.479916 --> 1.479915).         Saving model ...\n",
      "Epoch: 2745 \tTraining Loss: 1.079283 \tValidation Loss: 1.479913\n",
      "Validation loss decreased (1.479915 --> 1.479913).         Saving model ...\n",
      "Epoch: 2746 \tTraining Loss: 1.079280 \tValidation Loss: 1.479911\n",
      "Validation loss decreased (1.479913 --> 1.479911).         Saving model ...\n",
      "Epoch: 2747 \tTraining Loss: 1.079278 \tValidation Loss: 1.479910\n",
      "Validation loss decreased (1.479911 --> 1.479910).         Saving model ...\n",
      "Epoch: 2748 \tTraining Loss: 1.079275 \tValidation Loss: 1.479909\n",
      "Validation loss decreased (1.479910 --> 1.479909).         Saving model ...\n",
      "Epoch: 2749 \tTraining Loss: 1.079272 \tValidation Loss: 1.479908\n",
      "Validation loss decreased (1.479909 --> 1.479908).         Saving model ...\n",
      "Epoch: 2750 \tTraining Loss: 1.079270 \tValidation Loss: 1.479907\n",
      "Validation loss decreased (1.479908 --> 1.479907).         Saving model ...\n",
      "Epoch: 2751 \tTraining Loss: 1.079267 \tValidation Loss: 1.479905\n",
      "Validation loss decreased (1.479907 --> 1.479905).         Saving model ...\n",
      "Epoch: 2752 \tTraining Loss: 1.079264 \tValidation Loss: 1.479904\n",
      "Validation loss decreased (1.479905 --> 1.479904).         Saving model ...\n",
      "Epoch: 2753 \tTraining Loss: 1.079262 \tValidation Loss: 1.479902\n",
      "Validation loss decreased (1.479904 --> 1.479902).         Saving model ...\n",
      "Epoch: 2754 \tTraining Loss: 1.079259 \tValidation Loss: 1.479901\n",
      "Validation loss decreased (1.479902 --> 1.479901).         Saving model ...\n",
      "Epoch: 2755 \tTraining Loss: 1.079256 \tValidation Loss: 1.479899\n",
      "Validation loss decreased (1.479901 --> 1.479899).         Saving model ...\n",
      "Epoch: 2756 \tTraining Loss: 1.079254 \tValidation Loss: 1.479898\n",
      "Validation loss decreased (1.479899 --> 1.479898).         Saving model ...\n",
      "Epoch: 2757 \tTraining Loss: 1.079251 \tValidation Loss: 1.479895\n",
      "Validation loss decreased (1.479898 --> 1.479895).         Saving model ...\n",
      "Epoch: 2758 \tTraining Loss: 1.079249 \tValidation Loss: 1.479894\n",
      "Validation loss decreased (1.479895 --> 1.479894).         Saving model ...\n",
      "Epoch: 2759 \tTraining Loss: 1.079246 \tValidation Loss: 1.479892\n",
      "Validation loss decreased (1.479894 --> 1.479892).         Saving model ...\n",
      "Epoch: 2760 \tTraining Loss: 1.079243 \tValidation Loss: 1.479891\n",
      "Validation loss decreased (1.479892 --> 1.479891).         Saving model ...\n",
      "Epoch: 2761 \tTraining Loss: 1.079241 \tValidation Loss: 1.479889\n",
      "Validation loss decreased (1.479891 --> 1.479889).         Saving model ...\n",
      "Epoch: 2762 \tTraining Loss: 1.079238 \tValidation Loss: 1.479887\n",
      "Validation loss decreased (1.479889 --> 1.479887).         Saving model ...\n",
      "Epoch: 2763 \tTraining Loss: 1.079235 \tValidation Loss: 1.479886\n",
      "Validation loss decreased (1.479887 --> 1.479886).         Saving model ...\n",
      "Epoch: 2764 \tTraining Loss: 1.079233 \tValidation Loss: 1.479884\n",
      "Validation loss decreased (1.479886 --> 1.479884).         Saving model ...\n",
      "Epoch: 2765 \tTraining Loss: 1.079230 \tValidation Loss: 1.479882\n",
      "Validation loss decreased (1.479884 --> 1.479882).         Saving model ...\n",
      "Epoch: 2766 \tTraining Loss: 1.079227 \tValidation Loss: 1.479881\n",
      "Validation loss decreased (1.479882 --> 1.479881).         Saving model ...\n",
      "Epoch: 2767 \tTraining Loss: 1.079225 \tValidation Loss: 1.479879\n",
      "Validation loss decreased (1.479881 --> 1.479879).         Saving model ...\n",
      "Epoch: 2768 \tTraining Loss: 1.079222 \tValidation Loss: 1.479877\n",
      "Validation loss decreased (1.479879 --> 1.479877).         Saving model ...\n",
      "Epoch: 2769 \tTraining Loss: 1.079220 \tValidation Loss: 1.479876\n",
      "Validation loss decreased (1.479877 --> 1.479876).         Saving model ...\n",
      "Epoch: 2770 \tTraining Loss: 1.079217 \tValidation Loss: 1.479874\n",
      "Validation loss decreased (1.479876 --> 1.479874).         Saving model ...\n",
      "Epoch: 2771 \tTraining Loss: 1.079214 \tValidation Loss: 1.479873\n",
      "Validation loss decreased (1.479874 --> 1.479873).         Saving model ...\n",
      "Epoch: 2772 \tTraining Loss: 1.079212 \tValidation Loss: 1.479872\n",
      "Validation loss decreased (1.479873 --> 1.479872).         Saving model ...\n",
      "Epoch: 2773 \tTraining Loss: 1.079209 \tValidation Loss: 1.479870\n",
      "Validation loss decreased (1.479872 --> 1.479870).         Saving model ...\n",
      "Epoch: 2774 \tTraining Loss: 1.079206 \tValidation Loss: 1.479868\n",
      "Validation loss decreased (1.479870 --> 1.479868).         Saving model ...\n",
      "Epoch: 2775 \tTraining Loss: 1.079204 \tValidation Loss: 1.479866\n",
      "Validation loss decreased (1.479868 --> 1.479866).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2776 \tTraining Loss: 1.079201 \tValidation Loss: 1.479864\n",
      "Validation loss decreased (1.479866 --> 1.479864).         Saving model ...\n",
      "Epoch: 2777 \tTraining Loss: 1.079199 \tValidation Loss: 1.479862\n",
      "Validation loss decreased (1.479864 --> 1.479862).         Saving model ...\n",
      "Epoch: 2778 \tTraining Loss: 1.079196 \tValidation Loss: 1.479861\n",
      "Validation loss decreased (1.479862 --> 1.479861).         Saving model ...\n",
      "Epoch: 2779 \tTraining Loss: 1.079193 \tValidation Loss: 1.479859\n",
      "Validation loss decreased (1.479861 --> 1.479859).         Saving model ...\n",
      "Epoch: 2780 \tTraining Loss: 1.079191 \tValidation Loss: 1.479858\n",
      "Validation loss decreased (1.479859 --> 1.479858).         Saving model ...\n",
      "Epoch: 2781 \tTraining Loss: 1.079188 \tValidation Loss: 1.479856\n",
      "Validation loss decreased (1.479858 --> 1.479856).         Saving model ...\n",
      "Epoch: 2782 \tTraining Loss: 1.079186 \tValidation Loss: 1.479854\n",
      "Validation loss decreased (1.479856 --> 1.479854).         Saving model ...\n",
      "Epoch: 2783 \tTraining Loss: 1.079183 \tValidation Loss: 1.479852\n",
      "Validation loss decreased (1.479854 --> 1.479852).         Saving model ...\n",
      "Epoch: 2784 \tTraining Loss: 1.079180 \tValidation Loss: 1.479851\n",
      "Validation loss decreased (1.479852 --> 1.479851).         Saving model ...\n",
      "Epoch: 2785 \tTraining Loss: 1.079178 \tValidation Loss: 1.479850\n",
      "Validation loss decreased (1.479851 --> 1.479850).         Saving model ...\n",
      "Epoch: 2786 \tTraining Loss: 1.079175 \tValidation Loss: 1.479848\n",
      "Validation loss decreased (1.479850 --> 1.479848).         Saving model ...\n",
      "Epoch: 2787 \tTraining Loss: 1.079173 \tValidation Loss: 1.479847\n",
      "Validation loss decreased (1.479848 --> 1.479847).         Saving model ...\n",
      "Epoch: 2788 \tTraining Loss: 1.079170 \tValidation Loss: 1.479846\n",
      "Validation loss decreased (1.479847 --> 1.479846).         Saving model ...\n",
      "Epoch: 2789 \tTraining Loss: 1.079167 \tValidation Loss: 1.479844\n",
      "Validation loss decreased (1.479846 --> 1.479844).         Saving model ...\n",
      "Epoch: 2790 \tTraining Loss: 1.079165 \tValidation Loss: 1.479843\n",
      "Validation loss decreased (1.479844 --> 1.479843).         Saving model ...\n",
      "Epoch: 2791 \tTraining Loss: 1.079162 \tValidation Loss: 1.479841\n",
      "Validation loss decreased (1.479843 --> 1.479841).         Saving model ...\n",
      "Epoch: 2792 \tTraining Loss: 1.079160 \tValidation Loss: 1.479839\n",
      "Validation loss decreased (1.479841 --> 1.479839).         Saving model ...\n",
      "Epoch: 2793 \tTraining Loss: 1.079157 \tValidation Loss: 1.479837\n",
      "Validation loss decreased (1.479839 --> 1.479837).         Saving model ...\n",
      "Epoch: 2794 \tTraining Loss: 1.079154 \tValidation Loss: 1.479835\n",
      "Validation loss decreased (1.479837 --> 1.479835).         Saving model ...\n",
      "Epoch: 2795 \tTraining Loss: 1.079152 \tValidation Loss: 1.479833\n",
      "Validation loss decreased (1.479835 --> 1.479833).         Saving model ...\n",
      "Epoch: 2796 \tTraining Loss: 1.079149 \tValidation Loss: 1.479831\n",
      "Validation loss decreased (1.479833 --> 1.479831).         Saving model ...\n",
      "Epoch: 2797 \tTraining Loss: 1.079147 \tValidation Loss: 1.479829\n",
      "Validation loss decreased (1.479831 --> 1.479829).         Saving model ...\n",
      "Epoch: 2798 \tTraining Loss: 1.079144 \tValidation Loss: 1.479827\n",
      "Validation loss decreased (1.479829 --> 1.479827).         Saving model ...\n",
      "Epoch: 2799 \tTraining Loss: 1.079141 \tValidation Loss: 1.479826\n",
      "Validation loss decreased (1.479827 --> 1.479826).         Saving model ...\n",
      "Epoch: 2800 \tTraining Loss: 1.079139 \tValidation Loss: 1.479824\n",
      "Validation loss decreased (1.479826 --> 1.479824).         Saving model ...\n",
      "Epoch: 2801 \tTraining Loss: 1.079136 \tValidation Loss: 1.479821\n",
      "Validation loss decreased (1.479824 --> 1.479821).         Saving model ...\n",
      "Epoch: 2802 \tTraining Loss: 1.079134 \tValidation Loss: 1.479820\n",
      "Validation loss decreased (1.479821 --> 1.479820).         Saving model ...\n",
      "Epoch: 2803 \tTraining Loss: 1.079131 \tValidation Loss: 1.479819\n",
      "Validation loss decreased (1.479820 --> 1.479819).         Saving model ...\n",
      "Epoch: 2804 \tTraining Loss: 1.079129 \tValidation Loss: 1.479816\n",
      "Validation loss decreased (1.479819 --> 1.479816).         Saving model ...\n",
      "Epoch: 2805 \tTraining Loss: 1.079126 \tValidation Loss: 1.479815\n",
      "Validation loss decreased (1.479816 --> 1.479815).         Saving model ...\n",
      "Epoch: 2806 \tTraining Loss: 1.079123 \tValidation Loss: 1.479813\n",
      "Validation loss decreased (1.479815 --> 1.479813).         Saving model ...\n",
      "Epoch: 2807 \tTraining Loss: 1.079121 \tValidation Loss: 1.479812\n",
      "Validation loss decreased (1.479813 --> 1.479812).         Saving model ...\n",
      "Epoch: 2808 \tTraining Loss: 1.079118 \tValidation Loss: 1.479810\n",
      "Validation loss decreased (1.479812 --> 1.479810).         Saving model ...\n",
      "Epoch: 2809 \tTraining Loss: 1.079116 \tValidation Loss: 1.479809\n",
      "Validation loss decreased (1.479810 --> 1.479809).         Saving model ...\n",
      "Epoch: 2810 \tTraining Loss: 1.079113 \tValidation Loss: 1.479807\n",
      "Validation loss decreased (1.479809 --> 1.479807).         Saving model ...\n",
      "Epoch: 2811 \tTraining Loss: 1.079111 \tValidation Loss: 1.479805\n",
      "Validation loss decreased (1.479807 --> 1.479805).         Saving model ...\n",
      "Epoch: 2812 \tTraining Loss: 1.079108 \tValidation Loss: 1.479804\n",
      "Validation loss decreased (1.479805 --> 1.479804).         Saving model ...\n",
      "Epoch: 2813 \tTraining Loss: 1.079105 \tValidation Loss: 1.479803\n",
      "Validation loss decreased (1.479804 --> 1.479803).         Saving model ...\n",
      "Epoch: 2814 \tTraining Loss: 1.079103 \tValidation Loss: 1.479801\n",
      "Validation loss decreased (1.479803 --> 1.479801).         Saving model ...\n",
      "Epoch: 2815 \tTraining Loss: 1.079100 \tValidation Loss: 1.479799\n",
      "Validation loss decreased (1.479801 --> 1.479799).         Saving model ...\n",
      "Epoch: 2816 \tTraining Loss: 1.079098 \tValidation Loss: 1.479798\n",
      "Validation loss decreased (1.479799 --> 1.479798).         Saving model ...\n",
      "Epoch: 2817 \tTraining Loss: 1.079095 \tValidation Loss: 1.479796\n",
      "Validation loss decreased (1.479798 --> 1.479796).         Saving model ...\n",
      "Epoch: 2818 \tTraining Loss: 1.079093 \tValidation Loss: 1.479795\n",
      "Validation loss decreased (1.479796 --> 1.479795).         Saving model ...\n",
      "Epoch: 2819 \tTraining Loss: 1.079090 \tValidation Loss: 1.479793\n",
      "Validation loss decreased (1.479795 --> 1.479793).         Saving model ...\n",
      "Epoch: 2820 \tTraining Loss: 1.079088 \tValidation Loss: 1.479791\n",
      "Validation loss decreased (1.479793 --> 1.479791).         Saving model ...\n",
      "Epoch: 2821 \tTraining Loss: 1.079085 \tValidation Loss: 1.479790\n",
      "Validation loss decreased (1.479791 --> 1.479790).         Saving model ...\n",
      "Epoch: 2822 \tTraining Loss: 1.079082 \tValidation Loss: 1.479790\n",
      "Validation loss decreased (1.479790 --> 1.479790).         Saving model ...\n",
      "Epoch: 2823 \tTraining Loss: 1.079080 \tValidation Loss: 1.479789\n",
      "Validation loss decreased (1.479790 --> 1.479789).         Saving model ...\n",
      "Epoch: 2824 \tTraining Loss: 1.079077 \tValidation Loss: 1.479787\n",
      "Validation loss decreased (1.479789 --> 1.479787).         Saving model ...\n",
      "Epoch: 2825 \tTraining Loss: 1.079075 \tValidation Loss: 1.479786\n",
      "Validation loss decreased (1.479787 --> 1.479786).         Saving model ...\n",
      "Epoch: 2826 \tTraining Loss: 1.079072 \tValidation Loss: 1.479785\n",
      "Validation loss decreased (1.479786 --> 1.479785).         Saving model ...\n",
      "Epoch: 2827 \tTraining Loss: 1.079070 \tValidation Loss: 1.479785\n",
      "Validation loss decreased (1.479785 --> 1.479785).         Saving model ...\n",
      "Epoch: 2828 \tTraining Loss: 1.079067 \tValidation Loss: 1.479783\n",
      "Validation loss decreased (1.479785 --> 1.479783).         Saving model ...\n",
      "Epoch: 2829 \tTraining Loss: 1.079065 \tValidation Loss: 1.479783\n",
      "Validation loss decreased (1.479783 --> 1.479783).         Saving model ...\n",
      "Epoch: 2830 \tTraining Loss: 1.079062 \tValidation Loss: 1.479782\n",
      "Validation loss decreased (1.479783 --> 1.479782).         Saving model ...\n",
      "Epoch: 2831 \tTraining Loss: 1.079059 \tValidation Loss: 1.479782\n",
      "Validation loss decreased (1.479782 --> 1.479782).         Saving model ...\n",
      "Epoch: 2832 \tTraining Loss: 1.079057 \tValidation Loss: 1.479781\n",
      "Validation loss decreased (1.479782 --> 1.479781).         Saving model ...\n",
      "Epoch: 2833 \tTraining Loss: 1.079054 \tValidation Loss: 1.479780\n",
      "Validation loss decreased (1.479781 --> 1.479780).         Saving model ...\n",
      "Epoch: 2834 \tTraining Loss: 1.079052 \tValidation Loss: 1.479779\n",
      "Validation loss decreased (1.479780 --> 1.479779).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2835 \tTraining Loss: 1.079049 \tValidation Loss: 1.479778\n",
      "Validation loss decreased (1.479779 --> 1.479778).         Saving model ...\n",
      "Epoch: 2836 \tTraining Loss: 1.079047 \tValidation Loss: 1.479777\n",
      "Validation loss decreased (1.479778 --> 1.479777).         Saving model ...\n",
      "Epoch: 2837 \tTraining Loss: 1.079044 \tValidation Loss: 1.479776\n",
      "Validation loss decreased (1.479777 --> 1.479776).         Saving model ...\n",
      "Epoch: 2838 \tTraining Loss: 1.079042 \tValidation Loss: 1.479774\n",
      "Validation loss decreased (1.479776 --> 1.479774).         Saving model ...\n",
      "Epoch: 2839 \tTraining Loss: 1.079039 \tValidation Loss: 1.479773\n",
      "Validation loss decreased (1.479774 --> 1.479773).         Saving model ...\n",
      "Epoch: 2840 \tTraining Loss: 1.079037 \tValidation Loss: 1.479772\n",
      "Validation loss decreased (1.479773 --> 1.479772).         Saving model ...\n",
      "Epoch: 2841 \tTraining Loss: 1.079034 \tValidation Loss: 1.479770\n",
      "Validation loss decreased (1.479772 --> 1.479770).         Saving model ...\n",
      "Epoch: 2842 \tTraining Loss: 1.079032 \tValidation Loss: 1.479769\n",
      "Validation loss decreased (1.479770 --> 1.479769).         Saving model ...\n",
      "Epoch: 2843 \tTraining Loss: 1.079029 \tValidation Loss: 1.479767\n",
      "Validation loss decreased (1.479769 --> 1.479767).         Saving model ...\n",
      "Epoch: 2844 \tTraining Loss: 1.079027 \tValidation Loss: 1.479766\n",
      "Validation loss decreased (1.479767 --> 1.479766).         Saving model ...\n",
      "Epoch: 2845 \tTraining Loss: 1.079024 \tValidation Loss: 1.479764\n",
      "Validation loss decreased (1.479766 --> 1.479764).         Saving model ...\n",
      "Epoch: 2846 \tTraining Loss: 1.079021 \tValidation Loss: 1.479763\n",
      "Validation loss decreased (1.479764 --> 1.479763).         Saving model ...\n",
      "Epoch: 2847 \tTraining Loss: 1.079019 \tValidation Loss: 1.479763\n",
      "Validation loss decreased (1.479763 --> 1.479763).         Saving model ...\n",
      "Epoch: 2848 \tTraining Loss: 1.079016 \tValidation Loss: 1.479761\n",
      "Validation loss decreased (1.479763 --> 1.479761).         Saving model ...\n",
      "Epoch: 2849 \tTraining Loss: 1.079014 \tValidation Loss: 1.479761\n",
      "Validation loss decreased (1.479761 --> 1.479761).         Saving model ...\n",
      "Epoch: 2850 \tTraining Loss: 1.079011 \tValidation Loss: 1.479759\n",
      "Validation loss decreased (1.479761 --> 1.479759).         Saving model ...\n",
      "Epoch: 2851 \tTraining Loss: 1.079009 \tValidation Loss: 1.479758\n",
      "Validation loss decreased (1.479759 --> 1.479758).         Saving model ...\n",
      "Epoch: 2852 \tTraining Loss: 1.079006 \tValidation Loss: 1.479756\n",
      "Validation loss decreased (1.479758 --> 1.479756).         Saving model ...\n",
      "Epoch: 2853 \tTraining Loss: 1.079004 \tValidation Loss: 1.479755\n",
      "Validation loss decreased (1.479756 --> 1.479755).         Saving model ...\n",
      "Epoch: 2854 \tTraining Loss: 1.079001 \tValidation Loss: 1.479753\n",
      "Validation loss decreased (1.479755 --> 1.479753).         Saving model ...\n",
      "Epoch: 2855 \tTraining Loss: 1.078999 \tValidation Loss: 1.479752\n",
      "Validation loss decreased (1.479753 --> 1.479752).         Saving model ...\n",
      "Epoch: 2856 \tTraining Loss: 1.078996 \tValidation Loss: 1.479751\n",
      "Validation loss decreased (1.479752 --> 1.479751).         Saving model ...\n",
      "Epoch: 2857 \tTraining Loss: 1.078994 \tValidation Loss: 1.479749\n",
      "Validation loss decreased (1.479751 --> 1.479749).         Saving model ...\n",
      "Epoch: 2858 \tTraining Loss: 1.078991 \tValidation Loss: 1.479748\n",
      "Validation loss decreased (1.479749 --> 1.479748).         Saving model ...\n",
      "Epoch: 2859 \tTraining Loss: 1.078989 \tValidation Loss: 1.479748\n",
      "Validation loss decreased (1.479748 --> 1.479748).         Saving model ...\n",
      "Epoch: 2860 \tTraining Loss: 1.078986 \tValidation Loss: 1.479746\n",
      "Validation loss decreased (1.479748 --> 1.479746).         Saving model ...\n",
      "Epoch: 2861 \tTraining Loss: 1.078984 \tValidation Loss: 1.479744\n",
      "Validation loss decreased (1.479746 --> 1.479744).         Saving model ...\n",
      "Epoch: 2862 \tTraining Loss: 1.078981 \tValidation Loss: 1.479742\n",
      "Validation loss decreased (1.479744 --> 1.479742).         Saving model ...\n",
      "Epoch: 2863 \tTraining Loss: 1.078979 \tValidation Loss: 1.479742\n",
      "Validation loss decreased (1.479742 --> 1.479742).         Saving model ...\n",
      "Epoch: 2864 \tTraining Loss: 1.078976 \tValidation Loss: 1.479741\n",
      "Validation loss decreased (1.479742 --> 1.479741).         Saving model ...\n",
      "Epoch: 2865 \tTraining Loss: 1.078974 \tValidation Loss: 1.479740\n",
      "Validation loss decreased (1.479741 --> 1.479740).         Saving model ...\n",
      "Epoch: 2866 \tTraining Loss: 1.078971 \tValidation Loss: 1.479738\n",
      "Validation loss decreased (1.479740 --> 1.479738).         Saving model ...\n",
      "Epoch: 2867 \tTraining Loss: 1.078969 \tValidation Loss: 1.479737\n",
      "Validation loss decreased (1.479738 --> 1.479737).         Saving model ...\n",
      "Epoch: 2868 \tTraining Loss: 1.078966 \tValidation Loss: 1.479736\n",
      "Validation loss decreased (1.479737 --> 1.479736).         Saving model ...\n",
      "Epoch: 2869 \tTraining Loss: 1.078964 \tValidation Loss: 1.479734\n",
      "Validation loss decreased (1.479736 --> 1.479734).         Saving model ...\n",
      "Epoch: 2870 \tTraining Loss: 1.078961 \tValidation Loss: 1.479733\n",
      "Validation loss decreased (1.479734 --> 1.479733).         Saving model ...\n",
      "Epoch: 2871 \tTraining Loss: 1.078959 \tValidation Loss: 1.479732\n",
      "Validation loss decreased (1.479733 --> 1.479732).         Saving model ...\n",
      "Epoch: 2872 \tTraining Loss: 1.078956 \tValidation Loss: 1.479730\n",
      "Validation loss decreased (1.479732 --> 1.479730).         Saving model ...\n",
      "Epoch: 2873 \tTraining Loss: 1.078954 \tValidation Loss: 1.479729\n",
      "Validation loss decreased (1.479730 --> 1.479729).         Saving model ...\n",
      "Epoch: 2874 \tTraining Loss: 1.078951 \tValidation Loss: 1.479727\n",
      "Validation loss decreased (1.479729 --> 1.479727).         Saving model ...\n",
      "Epoch: 2875 \tTraining Loss: 1.078949 \tValidation Loss: 1.479725\n",
      "Validation loss decreased (1.479727 --> 1.479725).         Saving model ...\n",
      "Epoch: 2876 \tTraining Loss: 1.078946 \tValidation Loss: 1.479723\n",
      "Validation loss decreased (1.479725 --> 1.479723).         Saving model ...\n",
      "Epoch: 2877 \tTraining Loss: 1.078944 \tValidation Loss: 1.479721\n",
      "Validation loss decreased (1.479723 --> 1.479721).         Saving model ...\n",
      "Epoch: 2878 \tTraining Loss: 1.078941 \tValidation Loss: 1.479719\n",
      "Validation loss decreased (1.479721 --> 1.479719).         Saving model ...\n",
      "Epoch: 2879 \tTraining Loss: 1.078939 \tValidation Loss: 1.479718\n",
      "Validation loss decreased (1.479719 --> 1.479718).         Saving model ...\n",
      "Epoch: 2880 \tTraining Loss: 1.078936 \tValidation Loss: 1.479716\n",
      "Validation loss decreased (1.479718 --> 1.479716).         Saving model ...\n",
      "Epoch: 2881 \tTraining Loss: 1.078934 \tValidation Loss: 1.479715\n",
      "Validation loss decreased (1.479716 --> 1.479715).         Saving model ...\n",
      "Epoch: 2882 \tTraining Loss: 1.078931 \tValidation Loss: 1.479714\n",
      "Validation loss decreased (1.479715 --> 1.479714).         Saving model ...\n",
      "Epoch: 2883 \tTraining Loss: 1.078929 \tValidation Loss: 1.479712\n",
      "Validation loss decreased (1.479714 --> 1.479712).         Saving model ...\n",
      "Epoch: 2884 \tTraining Loss: 1.078926 \tValidation Loss: 1.479710\n",
      "Validation loss decreased (1.479712 --> 1.479710).         Saving model ...\n",
      "Epoch: 2885 \tTraining Loss: 1.078924 \tValidation Loss: 1.479709\n",
      "Validation loss decreased (1.479710 --> 1.479709).         Saving model ...\n",
      "Epoch: 2886 \tTraining Loss: 1.078922 \tValidation Loss: 1.479707\n",
      "Validation loss decreased (1.479709 --> 1.479707).         Saving model ...\n",
      "Epoch: 2887 \tTraining Loss: 1.078919 \tValidation Loss: 1.479706\n",
      "Validation loss decreased (1.479707 --> 1.479706).         Saving model ...\n",
      "Epoch: 2888 \tTraining Loss: 1.078917 \tValidation Loss: 1.479704\n",
      "Validation loss decreased (1.479706 --> 1.479704).         Saving model ...\n",
      "Epoch: 2889 \tTraining Loss: 1.078914 \tValidation Loss: 1.479702\n",
      "Validation loss decreased (1.479704 --> 1.479702).         Saving model ...\n",
      "Epoch: 2890 \tTraining Loss: 1.078912 \tValidation Loss: 1.479701\n",
      "Validation loss decreased (1.479702 --> 1.479701).         Saving model ...\n",
      "Epoch: 2891 \tTraining Loss: 1.078909 \tValidation Loss: 1.479699\n",
      "Validation loss decreased (1.479701 --> 1.479699).         Saving model ...\n",
      "Epoch: 2892 \tTraining Loss: 1.078907 \tValidation Loss: 1.479697\n",
      "Validation loss decreased (1.479699 --> 1.479697).         Saving model ...\n",
      "Epoch: 2893 \tTraining Loss: 1.078904 \tValidation Loss: 1.479696\n",
      "Validation loss decreased (1.479697 --> 1.479696).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2894 \tTraining Loss: 1.078902 \tValidation Loss: 1.479694\n",
      "Validation loss decreased (1.479696 --> 1.479694).         Saving model ...\n",
      "Epoch: 2895 \tTraining Loss: 1.078899 \tValidation Loss: 1.479692\n",
      "Validation loss decreased (1.479694 --> 1.479692).         Saving model ...\n",
      "Epoch: 2896 \tTraining Loss: 1.078897 \tValidation Loss: 1.479692\n",
      "Validation loss decreased (1.479692 --> 1.479692).         Saving model ...\n",
      "Epoch: 2897 \tTraining Loss: 1.078894 \tValidation Loss: 1.479690\n",
      "Validation loss decreased (1.479692 --> 1.479690).         Saving model ...\n",
      "Epoch: 2898 \tTraining Loss: 1.078892 \tValidation Loss: 1.479688\n",
      "Validation loss decreased (1.479690 --> 1.479688).         Saving model ...\n",
      "Epoch: 2899 \tTraining Loss: 1.078889 \tValidation Loss: 1.479687\n",
      "Validation loss decreased (1.479688 --> 1.479687).         Saving model ...\n",
      "Epoch: 2900 \tTraining Loss: 1.078887 \tValidation Loss: 1.479686\n",
      "Validation loss decreased (1.479687 --> 1.479686).         Saving model ...\n",
      "Epoch: 2901 \tTraining Loss: 1.078885 \tValidation Loss: 1.479684\n",
      "Validation loss decreased (1.479686 --> 1.479684).         Saving model ...\n",
      "Epoch: 2902 \tTraining Loss: 1.078882 \tValidation Loss: 1.479683\n",
      "Validation loss decreased (1.479684 --> 1.479683).         Saving model ...\n",
      "Epoch: 2903 \tTraining Loss: 1.078880 \tValidation Loss: 1.479681\n",
      "Validation loss decreased (1.479683 --> 1.479681).         Saving model ...\n",
      "Epoch: 2904 \tTraining Loss: 1.078877 \tValidation Loss: 1.479680\n",
      "Validation loss decreased (1.479681 --> 1.479680).         Saving model ...\n",
      "Epoch: 2905 \tTraining Loss: 1.078875 \tValidation Loss: 1.479680\n",
      "Validation loss decreased (1.479680 --> 1.479680).         Saving model ...\n",
      "Epoch: 2906 \tTraining Loss: 1.078872 \tValidation Loss: 1.479679\n",
      "Validation loss decreased (1.479680 --> 1.479679).         Saving model ...\n",
      "Epoch: 2907 \tTraining Loss: 1.078870 \tValidation Loss: 1.479678\n",
      "Validation loss decreased (1.479679 --> 1.479678).         Saving model ...\n",
      "Epoch: 2908 \tTraining Loss: 1.078867 \tValidation Loss: 1.479678\n",
      "Validation loss decreased (1.479678 --> 1.479678).         Saving model ...\n",
      "Epoch: 2909 \tTraining Loss: 1.078865 \tValidation Loss: 1.479676\n",
      "Validation loss decreased (1.479678 --> 1.479676).         Saving model ...\n",
      "Epoch: 2910 \tTraining Loss: 1.078863 \tValidation Loss: 1.479675\n",
      "Validation loss decreased (1.479676 --> 1.479675).         Saving model ...\n",
      "Epoch: 2911 \tTraining Loss: 1.078860 \tValidation Loss: 1.479674\n",
      "Validation loss decreased (1.479675 --> 1.479674).         Saving model ...\n",
      "Epoch: 2912 \tTraining Loss: 1.078858 \tValidation Loss: 1.479672\n",
      "Validation loss decreased (1.479674 --> 1.479672).         Saving model ...\n",
      "Epoch: 2913 \tTraining Loss: 1.078855 \tValidation Loss: 1.479671\n",
      "Validation loss decreased (1.479672 --> 1.479671).         Saving model ...\n",
      "Epoch: 2914 \tTraining Loss: 1.078853 \tValidation Loss: 1.479670\n",
      "Validation loss decreased (1.479671 --> 1.479670).         Saving model ...\n",
      "Epoch: 2915 \tTraining Loss: 1.078850 \tValidation Loss: 1.479668\n",
      "Validation loss decreased (1.479670 --> 1.479668).         Saving model ...\n",
      "Epoch: 2916 \tTraining Loss: 1.078848 \tValidation Loss: 1.479667\n",
      "Validation loss decreased (1.479668 --> 1.479667).         Saving model ...\n",
      "Epoch: 2917 \tTraining Loss: 1.078845 \tValidation Loss: 1.479665\n",
      "Validation loss decreased (1.479667 --> 1.479665).         Saving model ...\n",
      "Epoch: 2918 \tTraining Loss: 1.078843 \tValidation Loss: 1.479662\n",
      "Validation loss decreased (1.479665 --> 1.479662).         Saving model ...\n",
      "Epoch: 2919 \tTraining Loss: 1.078841 \tValidation Loss: 1.479660\n",
      "Validation loss decreased (1.479662 --> 1.479660).         Saving model ...\n",
      "Epoch: 2920 \tTraining Loss: 1.078838 \tValidation Loss: 1.479659\n",
      "Validation loss decreased (1.479660 --> 1.479659).         Saving model ...\n",
      "Epoch: 2921 \tTraining Loss: 1.078836 \tValidation Loss: 1.479658\n",
      "Validation loss decreased (1.479659 --> 1.479658).         Saving model ...\n",
      "Epoch: 2922 \tTraining Loss: 1.078833 \tValidation Loss: 1.479656\n",
      "Validation loss decreased (1.479658 --> 1.479656).         Saving model ...\n",
      "Epoch: 2923 \tTraining Loss: 1.078831 \tValidation Loss: 1.479654\n",
      "Validation loss decreased (1.479656 --> 1.479654).         Saving model ...\n",
      "Epoch: 2924 \tTraining Loss: 1.078828 \tValidation Loss: 1.479652\n",
      "Validation loss decreased (1.479654 --> 1.479652).         Saving model ...\n",
      "Epoch: 2925 \tTraining Loss: 1.078826 \tValidation Loss: 1.479651\n",
      "Validation loss decreased (1.479652 --> 1.479651).         Saving model ...\n",
      "Epoch: 2926 \tTraining Loss: 1.078824 \tValidation Loss: 1.479649\n",
      "Validation loss decreased (1.479651 --> 1.479649).         Saving model ...\n",
      "Epoch: 2927 \tTraining Loss: 1.078821 \tValidation Loss: 1.479647\n",
      "Validation loss decreased (1.479649 --> 1.479647).         Saving model ...\n",
      "Epoch: 2928 \tTraining Loss: 1.078819 \tValidation Loss: 1.479647\n",
      "Validation loss decreased (1.479647 --> 1.479647).         Saving model ...\n",
      "Epoch: 2929 \tTraining Loss: 1.078816 \tValidation Loss: 1.479645\n",
      "Validation loss decreased (1.479647 --> 1.479645).         Saving model ...\n",
      "Epoch: 2930 \tTraining Loss: 1.078814 \tValidation Loss: 1.479643\n",
      "Validation loss decreased (1.479645 --> 1.479643).         Saving model ...\n",
      "Epoch: 2931 \tTraining Loss: 1.078812 \tValidation Loss: 1.479642\n",
      "Validation loss decreased (1.479643 --> 1.479642).         Saving model ...\n",
      "Epoch: 2932 \tTraining Loss: 1.078809 \tValidation Loss: 1.479641\n",
      "Validation loss decreased (1.479642 --> 1.479641).         Saving model ...\n",
      "Epoch: 2933 \tTraining Loss: 1.078807 \tValidation Loss: 1.479639\n",
      "Validation loss decreased (1.479641 --> 1.479639).         Saving model ...\n",
      "Epoch: 2934 \tTraining Loss: 1.078804 \tValidation Loss: 1.479638\n",
      "Validation loss decreased (1.479639 --> 1.479638).         Saving model ...\n",
      "Epoch: 2935 \tTraining Loss: 1.078802 \tValidation Loss: 1.479637\n",
      "Validation loss decreased (1.479638 --> 1.479637).         Saving model ...\n",
      "Epoch: 2936 \tTraining Loss: 1.078799 \tValidation Loss: 1.479635\n",
      "Validation loss decreased (1.479637 --> 1.479635).         Saving model ...\n",
      "Epoch: 2937 \tTraining Loss: 1.078797 \tValidation Loss: 1.479634\n",
      "Validation loss decreased (1.479635 --> 1.479634).         Saving model ...\n",
      "Epoch: 2938 \tTraining Loss: 1.078795 \tValidation Loss: 1.479633\n",
      "Validation loss decreased (1.479634 --> 1.479633).         Saving model ...\n",
      "Epoch: 2939 \tTraining Loss: 1.078792 \tValidation Loss: 1.479631\n",
      "Validation loss decreased (1.479633 --> 1.479631).         Saving model ...\n",
      "Epoch: 2940 \tTraining Loss: 1.078790 \tValidation Loss: 1.479630\n",
      "Validation loss decreased (1.479631 --> 1.479630).         Saving model ...\n",
      "Epoch: 2941 \tTraining Loss: 1.078787 \tValidation Loss: 1.479629\n",
      "Validation loss decreased (1.479630 --> 1.479629).         Saving model ...\n",
      "Epoch: 2942 \tTraining Loss: 1.078785 \tValidation Loss: 1.479627\n",
      "Validation loss decreased (1.479629 --> 1.479627).         Saving model ...\n",
      "Epoch: 2943 \tTraining Loss: 1.078783 \tValidation Loss: 1.479625\n",
      "Validation loss decreased (1.479627 --> 1.479625).         Saving model ...\n",
      "Epoch: 2944 \tTraining Loss: 1.078780 \tValidation Loss: 1.479623\n",
      "Validation loss decreased (1.479625 --> 1.479623).         Saving model ...\n",
      "Epoch: 2945 \tTraining Loss: 1.078778 \tValidation Loss: 1.479621\n",
      "Validation loss decreased (1.479623 --> 1.479621).         Saving model ...\n",
      "Epoch: 2946 \tTraining Loss: 1.078775 \tValidation Loss: 1.479620\n",
      "Validation loss decreased (1.479621 --> 1.479620).         Saving model ...\n",
      "Epoch: 2947 \tTraining Loss: 1.078773 \tValidation Loss: 1.479618\n",
      "Validation loss decreased (1.479620 --> 1.479618).         Saving model ...\n",
      "Epoch: 2948 \tTraining Loss: 1.078771 \tValidation Loss: 1.479616\n",
      "Validation loss decreased (1.479618 --> 1.479616).         Saving model ...\n",
      "Epoch: 2949 \tTraining Loss: 1.078768 \tValidation Loss: 1.479615\n",
      "Validation loss decreased (1.479616 --> 1.479615).         Saving model ...\n",
      "Epoch: 2950 \tTraining Loss: 1.078766 \tValidation Loss: 1.479614\n",
      "Validation loss decreased (1.479615 --> 1.479614).         Saving model ...\n",
      "Epoch: 2951 \tTraining Loss: 1.078763 \tValidation Loss: 1.479612\n",
      "Validation loss decreased (1.479614 --> 1.479612).         Saving model ...\n",
      "Epoch: 2952 \tTraining Loss: 1.078761 \tValidation Loss: 1.479611\n",
      "Validation loss decreased (1.479612 --> 1.479611).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2953 \tTraining Loss: 1.078759 \tValidation Loss: 1.479610\n",
      "Validation loss decreased (1.479611 --> 1.479610).         Saving model ...\n",
      "Epoch: 2954 \tTraining Loss: 1.078756 \tValidation Loss: 1.479609\n",
      "Validation loss decreased (1.479610 --> 1.479609).         Saving model ...\n",
      "Epoch: 2955 \tTraining Loss: 1.078754 \tValidation Loss: 1.479607\n",
      "Validation loss decreased (1.479609 --> 1.479607).         Saving model ...\n",
      "Epoch: 2956 \tTraining Loss: 1.078751 \tValidation Loss: 1.479606\n",
      "Validation loss decreased (1.479607 --> 1.479606).         Saving model ...\n",
      "Epoch: 2957 \tTraining Loss: 1.078749 \tValidation Loss: 1.479605\n",
      "Validation loss decreased (1.479606 --> 1.479605).         Saving model ...\n",
      "Epoch: 2958 \tTraining Loss: 1.078747 \tValidation Loss: 1.479603\n",
      "Validation loss decreased (1.479605 --> 1.479603).         Saving model ...\n",
      "Epoch: 2959 \tTraining Loss: 1.078744 \tValidation Loss: 1.479601\n",
      "Validation loss decreased (1.479603 --> 1.479601).         Saving model ...\n",
      "Epoch: 2960 \tTraining Loss: 1.078742 \tValidation Loss: 1.479599\n",
      "Validation loss decreased (1.479601 --> 1.479599).         Saving model ...\n",
      "Epoch: 2961 \tTraining Loss: 1.078739 \tValidation Loss: 1.479598\n",
      "Validation loss decreased (1.479599 --> 1.479598).         Saving model ...\n",
      "Epoch: 2962 \tTraining Loss: 1.078737 \tValidation Loss: 1.479596\n",
      "Validation loss decreased (1.479598 --> 1.479596).         Saving model ...\n",
      "Epoch: 2963 \tTraining Loss: 1.078735 \tValidation Loss: 1.479595\n",
      "Validation loss decreased (1.479596 --> 1.479595).         Saving model ...\n",
      "Epoch: 2964 \tTraining Loss: 1.078732 \tValidation Loss: 1.479593\n",
      "Validation loss decreased (1.479595 --> 1.479593).         Saving model ...\n",
      "Epoch: 2965 \tTraining Loss: 1.078730 \tValidation Loss: 1.479592\n",
      "Validation loss decreased (1.479593 --> 1.479592).         Saving model ...\n",
      "Epoch: 2966 \tTraining Loss: 1.078728 \tValidation Loss: 1.479590\n",
      "Validation loss decreased (1.479592 --> 1.479590).         Saving model ...\n",
      "Epoch: 2967 \tTraining Loss: 1.078725 \tValidation Loss: 1.479589\n",
      "Validation loss decreased (1.479590 --> 1.479589).         Saving model ...\n",
      "Epoch: 2968 \tTraining Loss: 1.078723 \tValidation Loss: 1.479587\n",
      "Validation loss decreased (1.479589 --> 1.479587).         Saving model ...\n",
      "Epoch: 2969 \tTraining Loss: 1.078720 \tValidation Loss: 1.479586\n",
      "Validation loss decreased (1.479587 --> 1.479586).         Saving model ...\n",
      "Epoch: 2970 \tTraining Loss: 1.078718 \tValidation Loss: 1.479585\n",
      "Validation loss decreased (1.479586 --> 1.479585).         Saving model ...\n",
      "Epoch: 2971 \tTraining Loss: 1.078716 \tValidation Loss: 1.479583\n",
      "Validation loss decreased (1.479585 --> 1.479583).         Saving model ...\n",
      "Epoch: 2972 \tTraining Loss: 1.078713 \tValidation Loss: 1.479581\n",
      "Validation loss decreased (1.479583 --> 1.479581).         Saving model ...\n",
      "Epoch: 2973 \tTraining Loss: 1.078711 \tValidation Loss: 1.479580\n",
      "Validation loss decreased (1.479581 --> 1.479580).         Saving model ...\n",
      "Epoch: 2974 \tTraining Loss: 1.078709 \tValidation Loss: 1.479578\n",
      "Validation loss decreased (1.479580 --> 1.479578).         Saving model ...\n",
      "Epoch: 2975 \tTraining Loss: 1.078706 \tValidation Loss: 1.479577\n",
      "Validation loss decreased (1.479578 --> 1.479577).         Saving model ...\n",
      "Epoch: 2976 \tTraining Loss: 1.078704 \tValidation Loss: 1.479576\n",
      "Validation loss decreased (1.479577 --> 1.479576).         Saving model ...\n",
      "Epoch: 2977 \tTraining Loss: 1.078702 \tValidation Loss: 1.479574\n",
      "Validation loss decreased (1.479576 --> 1.479574).         Saving model ...\n",
      "Epoch: 2978 \tTraining Loss: 1.078699 \tValidation Loss: 1.479573\n",
      "Validation loss decreased (1.479574 --> 1.479573).         Saving model ...\n",
      "Epoch: 2979 \tTraining Loss: 1.078697 \tValidation Loss: 1.479571\n",
      "Validation loss decreased (1.479573 --> 1.479571).         Saving model ...\n",
      "Epoch: 2980 \tTraining Loss: 1.078694 \tValidation Loss: 1.479571\n",
      "Validation loss decreased (1.479571 --> 1.479571).         Saving model ...\n",
      "Epoch: 2981 \tTraining Loss: 1.078692 \tValidation Loss: 1.479570\n",
      "Validation loss decreased (1.479571 --> 1.479570).         Saving model ...\n",
      "Epoch: 2982 \tTraining Loss: 1.078690 \tValidation Loss: 1.479568\n",
      "Validation loss decreased (1.479570 --> 1.479568).         Saving model ...\n",
      "Epoch: 2983 \tTraining Loss: 1.078687 \tValidation Loss: 1.479568\n",
      "Validation loss decreased (1.479568 --> 1.479568).         Saving model ...\n",
      "Epoch: 2984 \tTraining Loss: 1.078685 \tValidation Loss: 1.479566\n",
      "Validation loss decreased (1.479568 --> 1.479566).         Saving model ...\n",
      "Epoch: 2985 \tTraining Loss: 1.078683 \tValidation Loss: 1.479564\n",
      "Validation loss decreased (1.479566 --> 1.479564).         Saving model ...\n",
      "Epoch: 2986 \tTraining Loss: 1.078680 \tValidation Loss: 1.479563\n",
      "Validation loss decreased (1.479564 --> 1.479563).         Saving model ...\n",
      "Epoch: 2987 \tTraining Loss: 1.078678 \tValidation Loss: 1.479561\n",
      "Validation loss decreased (1.479563 --> 1.479561).         Saving model ...\n",
      "Epoch: 2988 \tTraining Loss: 1.078676 \tValidation Loss: 1.479559\n",
      "Validation loss decreased (1.479561 --> 1.479559).         Saving model ...\n",
      "Epoch: 2989 \tTraining Loss: 1.078673 \tValidation Loss: 1.479558\n",
      "Validation loss decreased (1.479559 --> 1.479558).         Saving model ...\n",
      "Epoch: 2990 \tTraining Loss: 1.078671 \tValidation Loss: 1.479555\n",
      "Validation loss decreased (1.479558 --> 1.479555).         Saving model ...\n",
      "Epoch: 2991 \tTraining Loss: 1.078669 \tValidation Loss: 1.479554\n",
      "Validation loss decreased (1.479555 --> 1.479554).         Saving model ...\n",
      "Epoch: 2992 \tTraining Loss: 1.078666 \tValidation Loss: 1.479553\n",
      "Validation loss decreased (1.479554 --> 1.479553).         Saving model ...\n",
      "Epoch: 2993 \tTraining Loss: 1.078664 \tValidation Loss: 1.479551\n",
      "Validation loss decreased (1.479553 --> 1.479551).         Saving model ...\n",
      "Epoch: 2994 \tTraining Loss: 1.078661 \tValidation Loss: 1.479549\n",
      "Validation loss decreased (1.479551 --> 1.479549).         Saving model ...\n",
      "Epoch: 2995 \tTraining Loss: 1.078659 \tValidation Loss: 1.479548\n",
      "Validation loss decreased (1.479549 --> 1.479548).         Saving model ...\n",
      "Epoch: 2996 \tTraining Loss: 1.078657 \tValidation Loss: 1.479546\n",
      "Validation loss decreased (1.479548 --> 1.479546).         Saving model ...\n",
      "Epoch: 2997 \tTraining Loss: 1.078654 \tValidation Loss: 1.479545\n",
      "Validation loss decreased (1.479546 --> 1.479545).         Saving model ...\n",
      "Epoch: 2998 \tTraining Loss: 1.078652 \tValidation Loss: 1.479543\n",
      "Validation loss decreased (1.479545 --> 1.479543).         Saving model ...\n",
      "Epoch: 2999 \tTraining Loss: 1.078650 \tValidation Loss: 1.479542\n",
      "Validation loss decreased (1.479543 --> 1.479542).         Saving model ...\n",
      "Epoch: 3000 \tTraining Loss: 1.078647 \tValidation Loss: 1.479540\n",
      "Validation loss decreased (1.479542 --> 1.479540).         Saving model ...\n",
      "Epoch: 3001 \tTraining Loss: 1.078645 \tValidation Loss: 1.479539\n",
      "Validation loss decreased (1.479540 --> 1.479539).         Saving model ...\n",
      "Epoch: 3002 \tTraining Loss: 1.078643 \tValidation Loss: 1.479537\n",
      "Validation loss decreased (1.479539 --> 1.479537).         Saving model ...\n",
      "Epoch: 3003 \tTraining Loss: 1.078640 \tValidation Loss: 1.479534\n",
      "Validation loss decreased (1.479537 --> 1.479534).         Saving model ...\n",
      "Epoch: 3004 \tTraining Loss: 1.078638 \tValidation Loss: 1.479533\n",
      "Validation loss decreased (1.479534 --> 1.479533).         Saving model ...\n",
      "Epoch: 3005 \tTraining Loss: 1.078636 \tValidation Loss: 1.479532\n",
      "Validation loss decreased (1.479533 --> 1.479532).         Saving model ...\n",
      "Epoch: 3006 \tTraining Loss: 1.078633 \tValidation Loss: 1.479530\n",
      "Validation loss decreased (1.479532 --> 1.479530).         Saving model ...\n",
      "Epoch: 3007 \tTraining Loss: 1.078631 \tValidation Loss: 1.479528\n",
      "Validation loss decreased (1.479530 --> 1.479528).         Saving model ...\n",
      "Epoch: 3008 \tTraining Loss: 1.078629 \tValidation Loss: 1.479527\n",
      "Validation loss decreased (1.479528 --> 1.479527).         Saving model ...\n",
      "Epoch: 3009 \tTraining Loss: 1.078626 \tValidation Loss: 1.479526\n",
      "Validation loss decreased (1.479527 --> 1.479526).         Saving model ...\n",
      "Epoch: 3010 \tTraining Loss: 1.078624 \tValidation Loss: 1.479524\n",
      "Validation loss decreased (1.479526 --> 1.479524).         Saving model ...\n",
      "Epoch: 3011 \tTraining Loss: 1.078622 \tValidation Loss: 1.479523\n",
      "Validation loss decreased (1.479524 --> 1.479523).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3012 \tTraining Loss: 1.078619 \tValidation Loss: 1.479522\n",
      "Validation loss decreased (1.479523 --> 1.479522).         Saving model ...\n",
      "Epoch: 3013 \tTraining Loss: 1.078617 \tValidation Loss: 1.479521\n",
      "Validation loss decreased (1.479522 --> 1.479521).         Saving model ...\n",
      "Epoch: 3014 \tTraining Loss: 1.078615 \tValidation Loss: 1.479520\n",
      "Validation loss decreased (1.479521 --> 1.479520).         Saving model ...\n",
      "Epoch: 3015 \tTraining Loss: 1.078613 \tValidation Loss: 1.479519\n",
      "Validation loss decreased (1.479520 --> 1.479519).         Saving model ...\n",
      "Epoch: 3016 \tTraining Loss: 1.078610 \tValidation Loss: 1.479518\n",
      "Validation loss decreased (1.479519 --> 1.479518).         Saving model ...\n",
      "Epoch: 3017 \tTraining Loss: 1.078608 \tValidation Loss: 1.479517\n",
      "Validation loss decreased (1.479518 --> 1.479517).         Saving model ...\n",
      "Epoch: 3018 \tTraining Loss: 1.078606 \tValidation Loss: 1.479515\n",
      "Validation loss decreased (1.479517 --> 1.479515).         Saving model ...\n",
      "Epoch: 3019 \tTraining Loss: 1.078603 \tValidation Loss: 1.479514\n",
      "Validation loss decreased (1.479515 --> 1.479514).         Saving model ...\n",
      "Epoch: 3020 \tTraining Loss: 1.078601 \tValidation Loss: 1.479513\n",
      "Validation loss decreased (1.479514 --> 1.479513).         Saving model ...\n",
      "Epoch: 3021 \tTraining Loss: 1.078599 \tValidation Loss: 1.479513\n",
      "Validation loss decreased (1.479513 --> 1.479513).         Saving model ...\n",
      "Epoch: 3022 \tTraining Loss: 1.078596 \tValidation Loss: 1.479511\n",
      "Validation loss decreased (1.479513 --> 1.479511).         Saving model ...\n",
      "Epoch: 3023 \tTraining Loss: 1.078594 \tValidation Loss: 1.479511\n",
      "Validation loss decreased (1.479511 --> 1.479511).         Saving model ...\n",
      "Epoch: 3024 \tTraining Loss: 1.078592 \tValidation Loss: 1.479510\n",
      "Validation loss decreased (1.479511 --> 1.479510).         Saving model ...\n",
      "Epoch: 3025 \tTraining Loss: 1.078589 \tValidation Loss: 1.479508\n",
      "Validation loss decreased (1.479510 --> 1.479508).         Saving model ...\n",
      "Epoch: 3026 \tTraining Loss: 1.078587 \tValidation Loss: 1.479507\n",
      "Validation loss decreased (1.479508 --> 1.479507).         Saving model ...\n",
      "Epoch: 3027 \tTraining Loss: 1.078585 \tValidation Loss: 1.479506\n",
      "Validation loss decreased (1.479507 --> 1.479506).         Saving model ...\n",
      "Epoch: 3028 \tTraining Loss: 1.078582 \tValidation Loss: 1.479505\n",
      "Validation loss decreased (1.479506 --> 1.479505).         Saving model ...\n",
      "Epoch: 3029 \tTraining Loss: 1.078580 \tValidation Loss: 1.479504\n",
      "Validation loss decreased (1.479505 --> 1.479504).         Saving model ...\n",
      "Epoch: 3030 \tTraining Loss: 1.078578 \tValidation Loss: 1.479502\n",
      "Validation loss decreased (1.479504 --> 1.479502).         Saving model ...\n",
      "Epoch: 3031 \tTraining Loss: 1.078576 \tValidation Loss: 1.479501\n",
      "Validation loss decreased (1.479502 --> 1.479501).         Saving model ...\n",
      "Epoch: 3032 \tTraining Loss: 1.078573 \tValidation Loss: 1.479501\n",
      "Validation loss decreased (1.479501 --> 1.479501).         Saving model ...\n",
      "Epoch: 3033 \tTraining Loss: 1.078571 \tValidation Loss: 1.479500\n",
      "Validation loss decreased (1.479501 --> 1.479500).         Saving model ...\n",
      "Epoch: 3034 \tTraining Loss: 1.078569 \tValidation Loss: 1.479498\n",
      "Validation loss decreased (1.479500 --> 1.479498).         Saving model ...\n",
      "Epoch: 3035 \tTraining Loss: 1.078566 \tValidation Loss: 1.479498\n",
      "Validation loss decreased (1.479498 --> 1.479498).         Saving model ...\n",
      "Epoch: 3036 \tTraining Loss: 1.078564 \tValidation Loss: 1.479497\n",
      "Validation loss decreased (1.479498 --> 1.479497).         Saving model ...\n",
      "Epoch: 3037 \tTraining Loss: 1.078562 \tValidation Loss: 1.479496\n",
      "Validation loss decreased (1.479497 --> 1.479496).         Saving model ...\n",
      "Epoch: 3038 \tTraining Loss: 1.078560 \tValidation Loss: 1.479495\n",
      "Validation loss decreased (1.479496 --> 1.479495).         Saving model ...\n",
      "Epoch: 3039 \tTraining Loss: 1.078557 \tValidation Loss: 1.479493\n",
      "Validation loss decreased (1.479495 --> 1.479493).         Saving model ...\n",
      "Epoch: 3040 \tTraining Loss: 1.078555 \tValidation Loss: 1.479492\n",
      "Validation loss decreased (1.479493 --> 1.479492).         Saving model ...\n",
      "Epoch: 3041 \tTraining Loss: 1.078553 \tValidation Loss: 1.479491\n",
      "Validation loss decreased (1.479492 --> 1.479491).         Saving model ...\n",
      "Epoch: 3042 \tTraining Loss: 1.078550 \tValidation Loss: 1.479490\n",
      "Validation loss decreased (1.479491 --> 1.479490).         Saving model ...\n",
      "Epoch: 3043 \tTraining Loss: 1.078548 \tValidation Loss: 1.479489\n",
      "Validation loss decreased (1.479490 --> 1.479489).         Saving model ...\n",
      "Epoch: 3044 \tTraining Loss: 1.078546 \tValidation Loss: 1.479488\n",
      "Validation loss decreased (1.479489 --> 1.479488).         Saving model ...\n",
      "Epoch: 3045 \tTraining Loss: 1.078543 \tValidation Loss: 1.479488\n",
      "Epoch: 3046 \tTraining Loss: 1.078541 \tValidation Loss: 1.479487\n",
      "Validation loss decreased (1.479488 --> 1.479487).         Saving model ...\n",
      "Epoch: 3047 \tTraining Loss: 1.078539 \tValidation Loss: 1.479486\n",
      "Validation loss decreased (1.479487 --> 1.479486).         Saving model ...\n",
      "Epoch: 3048 \tTraining Loss: 1.078537 \tValidation Loss: 1.479485\n",
      "Validation loss decreased (1.479486 --> 1.479485).         Saving model ...\n",
      "Epoch: 3049 \tTraining Loss: 1.078534 \tValidation Loss: 1.479483\n",
      "Validation loss decreased (1.479485 --> 1.479483).         Saving model ...\n",
      "Epoch: 3050 \tTraining Loss: 1.078532 \tValidation Loss: 1.479482\n",
      "Validation loss decreased (1.479483 --> 1.479482).         Saving model ...\n",
      "Epoch: 3051 \tTraining Loss: 1.078530 \tValidation Loss: 1.479481\n",
      "Validation loss decreased (1.479482 --> 1.479481).         Saving model ...\n",
      "Epoch: 3052 \tTraining Loss: 1.078528 \tValidation Loss: 1.479481\n",
      "Validation loss decreased (1.479481 --> 1.479481).         Saving model ...\n",
      "Epoch: 3053 \tTraining Loss: 1.078525 \tValidation Loss: 1.479479\n",
      "Validation loss decreased (1.479481 --> 1.479479).         Saving model ...\n",
      "Epoch: 3054 \tTraining Loss: 1.078523 \tValidation Loss: 1.479478\n",
      "Validation loss decreased (1.479479 --> 1.479478).         Saving model ...\n",
      "Epoch: 3055 \tTraining Loss: 1.078521 \tValidation Loss: 1.479476\n",
      "Validation loss decreased (1.479478 --> 1.479476).         Saving model ...\n",
      "Epoch: 3056 \tTraining Loss: 1.078518 \tValidation Loss: 1.479474\n",
      "Validation loss decreased (1.479476 --> 1.479474).         Saving model ...\n",
      "Epoch: 3057 \tTraining Loss: 1.078516 \tValidation Loss: 1.479473\n",
      "Validation loss decreased (1.479474 --> 1.479473).         Saving model ...\n",
      "Epoch: 3058 \tTraining Loss: 1.078514 \tValidation Loss: 1.479471\n",
      "Validation loss decreased (1.479473 --> 1.479471).         Saving model ...\n",
      "Epoch: 3059 \tTraining Loss: 1.078512 \tValidation Loss: 1.479470\n",
      "Validation loss decreased (1.479471 --> 1.479470).         Saving model ...\n",
      "Epoch: 3060 \tTraining Loss: 1.078509 \tValidation Loss: 1.479468\n",
      "Validation loss decreased (1.479470 --> 1.479468).         Saving model ...\n",
      "Epoch: 3061 \tTraining Loss: 1.078507 \tValidation Loss: 1.479467\n",
      "Validation loss decreased (1.479468 --> 1.479467).         Saving model ...\n",
      "Epoch: 3062 \tTraining Loss: 1.078505 \tValidation Loss: 1.479466\n",
      "Validation loss decreased (1.479467 --> 1.479466).         Saving model ...\n",
      "Epoch: 3063 \tTraining Loss: 1.078503 \tValidation Loss: 1.479464\n",
      "Validation loss decreased (1.479466 --> 1.479464).         Saving model ...\n",
      "Epoch: 3064 \tTraining Loss: 1.078500 \tValidation Loss: 1.479462\n",
      "Validation loss decreased (1.479464 --> 1.479462).         Saving model ...\n",
      "Epoch: 3065 \tTraining Loss: 1.078498 \tValidation Loss: 1.479461\n",
      "Validation loss decreased (1.479462 --> 1.479461).         Saving model ...\n",
      "Epoch: 3066 \tTraining Loss: 1.078496 \tValidation Loss: 1.479460\n",
      "Validation loss decreased (1.479461 --> 1.479460).         Saving model ...\n",
      "Epoch: 3067 \tTraining Loss: 1.078493 \tValidation Loss: 1.479459\n",
      "Validation loss decreased (1.479460 --> 1.479459).         Saving model ...\n",
      "Epoch: 3068 \tTraining Loss: 1.078491 \tValidation Loss: 1.479458\n",
      "Validation loss decreased (1.479459 --> 1.479458).         Saving model ...\n",
      "Epoch: 3069 \tTraining Loss: 1.078489 \tValidation Loss: 1.479456\n",
      "Validation loss decreased (1.479458 --> 1.479456).         Saving model ...\n",
      "Epoch: 3070 \tTraining Loss: 1.078487 \tValidation Loss: 1.479456\n",
      "Validation loss decreased (1.479456 --> 1.479456).         Saving model ...\n",
      "Epoch: 3071 \tTraining Loss: 1.078484 \tValidation Loss: 1.479455\n",
      "Validation loss decreased (1.479456 --> 1.479455).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3072 \tTraining Loss: 1.078482 \tValidation Loss: 1.479454\n",
      "Validation loss decreased (1.479455 --> 1.479454).         Saving model ...\n",
      "Epoch: 3073 \tTraining Loss: 1.078480 \tValidation Loss: 1.479453\n",
      "Validation loss decreased (1.479454 --> 1.479453).         Saving model ...\n",
      "Epoch: 3074 \tTraining Loss: 1.078478 \tValidation Loss: 1.479451\n",
      "Validation loss decreased (1.479453 --> 1.479451).         Saving model ...\n",
      "Epoch: 3075 \tTraining Loss: 1.078475 \tValidation Loss: 1.479451\n",
      "Validation loss decreased (1.479451 --> 1.479451).         Saving model ...\n",
      "Epoch: 3076 \tTraining Loss: 1.078473 \tValidation Loss: 1.479450\n",
      "Validation loss decreased (1.479451 --> 1.479450).         Saving model ...\n",
      "Epoch: 3077 \tTraining Loss: 1.078471 \tValidation Loss: 1.479449\n",
      "Validation loss decreased (1.479450 --> 1.479449).         Saving model ...\n",
      "Epoch: 3078 \tTraining Loss: 1.078469 \tValidation Loss: 1.479448\n",
      "Validation loss decreased (1.479449 --> 1.479448).         Saving model ...\n",
      "Epoch: 3079 \tTraining Loss: 1.078466 \tValidation Loss: 1.479447\n",
      "Validation loss decreased (1.479448 --> 1.479447).         Saving model ...\n",
      "Epoch: 3080 \tTraining Loss: 1.078464 \tValidation Loss: 1.479445\n",
      "Validation loss decreased (1.479447 --> 1.479445).         Saving model ...\n",
      "Epoch: 3081 \tTraining Loss: 1.078462 \tValidation Loss: 1.479445\n",
      "Validation loss decreased (1.479445 --> 1.479445).         Saving model ...\n",
      "Epoch: 3082 \tTraining Loss: 1.078460 \tValidation Loss: 1.479443\n",
      "Validation loss decreased (1.479445 --> 1.479443).         Saving model ...\n",
      "Epoch: 3083 \tTraining Loss: 1.078457 \tValidation Loss: 1.479441\n",
      "Validation loss decreased (1.479443 --> 1.479441).         Saving model ...\n",
      "Epoch: 3084 \tTraining Loss: 1.078455 \tValidation Loss: 1.479440\n",
      "Validation loss decreased (1.479441 --> 1.479440).         Saving model ...\n",
      "Epoch: 3085 \tTraining Loss: 1.078453 \tValidation Loss: 1.479438\n",
      "Validation loss decreased (1.479440 --> 1.479438).         Saving model ...\n",
      "Epoch: 3086 \tTraining Loss: 1.078451 \tValidation Loss: 1.479437\n",
      "Validation loss decreased (1.479438 --> 1.479437).         Saving model ...\n",
      "Epoch: 3087 \tTraining Loss: 1.078448 \tValidation Loss: 1.479436\n",
      "Validation loss decreased (1.479437 --> 1.479436).         Saving model ...\n",
      "Epoch: 3088 \tTraining Loss: 1.078446 \tValidation Loss: 1.479434\n",
      "Validation loss decreased (1.479436 --> 1.479434).         Saving model ...\n",
      "Epoch: 3089 \tTraining Loss: 1.078444 \tValidation Loss: 1.479434\n",
      "Validation loss decreased (1.479434 --> 1.479434).         Saving model ...\n",
      "Epoch: 3090 \tTraining Loss: 1.078442 \tValidation Loss: 1.479432\n",
      "Validation loss decreased (1.479434 --> 1.479432).         Saving model ...\n",
      "Epoch: 3091 \tTraining Loss: 1.078440 \tValidation Loss: 1.479431\n",
      "Validation loss decreased (1.479432 --> 1.479431).         Saving model ...\n",
      "Epoch: 3092 \tTraining Loss: 1.078437 \tValidation Loss: 1.479429\n",
      "Validation loss decreased (1.479431 --> 1.479429).         Saving model ...\n",
      "Epoch: 3093 \tTraining Loss: 1.078435 \tValidation Loss: 1.479428\n",
      "Validation loss decreased (1.479429 --> 1.479428).         Saving model ...\n",
      "Epoch: 3094 \tTraining Loss: 1.078433 \tValidation Loss: 1.479426\n",
      "Validation loss decreased (1.479428 --> 1.479426).         Saving model ...\n",
      "Epoch: 3095 \tTraining Loss: 1.078431 \tValidation Loss: 1.479425\n",
      "Validation loss decreased (1.479426 --> 1.479425).         Saving model ...\n",
      "Epoch: 3096 \tTraining Loss: 1.078428 \tValidation Loss: 1.479424\n",
      "Validation loss decreased (1.479425 --> 1.479424).         Saving model ...\n",
      "Epoch: 3097 \tTraining Loss: 1.078426 \tValidation Loss: 1.479422\n",
      "Validation loss decreased (1.479424 --> 1.479422).         Saving model ...\n",
      "Epoch: 3098 \tTraining Loss: 1.078424 \tValidation Loss: 1.479421\n",
      "Validation loss decreased (1.479422 --> 1.479421).         Saving model ...\n",
      "Epoch: 3099 \tTraining Loss: 1.078422 \tValidation Loss: 1.479420\n",
      "Validation loss decreased (1.479421 --> 1.479420).         Saving model ...\n",
      "Epoch: 3100 \tTraining Loss: 1.078419 \tValidation Loss: 1.479419\n",
      "Validation loss decreased (1.479420 --> 1.479419).         Saving model ...\n",
      "Epoch: 3101 \tTraining Loss: 1.078417 \tValidation Loss: 1.479418\n",
      "Validation loss decreased (1.479419 --> 1.479418).         Saving model ...\n",
      "Epoch: 3102 \tTraining Loss: 1.078415 \tValidation Loss: 1.479418\n",
      "Validation loss decreased (1.479418 --> 1.479418).         Saving model ...\n",
      "Epoch: 3103 \tTraining Loss: 1.078413 \tValidation Loss: 1.479417\n",
      "Validation loss decreased (1.479418 --> 1.479417).         Saving model ...\n",
      "Epoch: 3104 \tTraining Loss: 1.078411 \tValidation Loss: 1.479417\n",
      "Validation loss decreased (1.479417 --> 1.479417).         Saving model ...\n",
      "Epoch: 3105 \tTraining Loss: 1.078408 \tValidation Loss: 1.479416\n",
      "Validation loss decreased (1.479417 --> 1.479416).         Saving model ...\n",
      "Epoch: 3106 \tTraining Loss: 1.078406 \tValidation Loss: 1.479415\n",
      "Validation loss decreased (1.479416 --> 1.479415).         Saving model ...\n",
      "Epoch: 3107 \tTraining Loss: 1.078404 \tValidation Loss: 1.479414\n",
      "Validation loss decreased (1.479415 --> 1.479414).         Saving model ...\n",
      "Epoch: 3108 \tTraining Loss: 1.078402 \tValidation Loss: 1.479412\n",
      "Validation loss decreased (1.479414 --> 1.479412).         Saving model ...\n",
      "Epoch: 3109 \tTraining Loss: 1.078399 \tValidation Loss: 1.479412\n",
      "Validation loss decreased (1.479412 --> 1.479412).         Saving model ...\n",
      "Epoch: 3110 \tTraining Loss: 1.078397 \tValidation Loss: 1.479410\n",
      "Validation loss decreased (1.479412 --> 1.479410).         Saving model ...\n",
      "Epoch: 3111 \tTraining Loss: 1.078395 \tValidation Loss: 1.479409\n",
      "Validation loss decreased (1.479410 --> 1.479409).         Saving model ...\n",
      "Epoch: 3112 \tTraining Loss: 1.078393 \tValidation Loss: 1.479408\n",
      "Validation loss decreased (1.479409 --> 1.479408).         Saving model ...\n",
      "Epoch: 3113 \tTraining Loss: 1.078391 \tValidation Loss: 1.479407\n",
      "Validation loss decreased (1.479408 --> 1.479407).         Saving model ...\n",
      "Epoch: 3114 \tTraining Loss: 1.078388 \tValidation Loss: 1.479405\n",
      "Validation loss decreased (1.479407 --> 1.479405).         Saving model ...\n",
      "Epoch: 3115 \tTraining Loss: 1.078386 \tValidation Loss: 1.479404\n",
      "Validation loss decreased (1.479405 --> 1.479404).         Saving model ...\n",
      "Epoch: 3116 \tTraining Loss: 1.078384 \tValidation Loss: 1.479403\n",
      "Validation loss decreased (1.479404 --> 1.479403).         Saving model ...\n",
      "Epoch: 3117 \tTraining Loss: 1.078382 \tValidation Loss: 1.479402\n",
      "Validation loss decreased (1.479403 --> 1.479402).         Saving model ...\n",
      "Epoch: 3118 \tTraining Loss: 1.078380 \tValidation Loss: 1.479401\n",
      "Validation loss decreased (1.479402 --> 1.479401).         Saving model ...\n",
      "Epoch: 3119 \tTraining Loss: 1.078377 \tValidation Loss: 1.479401\n",
      "Validation loss decreased (1.479401 --> 1.479401).         Saving model ...\n",
      "Epoch: 3120 \tTraining Loss: 1.078375 \tValidation Loss: 1.479400\n",
      "Validation loss decreased (1.479401 --> 1.479400).         Saving model ...\n",
      "Epoch: 3121 \tTraining Loss: 1.078373 \tValidation Loss: 1.479398\n",
      "Validation loss decreased (1.479400 --> 1.479398).         Saving model ...\n",
      "Epoch: 3122 \tTraining Loss: 1.078371 \tValidation Loss: 1.479398\n",
      "Validation loss decreased (1.479398 --> 1.479398).         Saving model ...\n",
      "Epoch: 3123 \tTraining Loss: 1.078368 \tValidation Loss: 1.479396\n",
      "Validation loss decreased (1.479398 --> 1.479396).         Saving model ...\n",
      "Epoch: 3124 \tTraining Loss: 1.078366 \tValidation Loss: 1.479395\n",
      "Validation loss decreased (1.479396 --> 1.479395).         Saving model ...\n",
      "Epoch: 3125 \tTraining Loss: 1.078364 \tValidation Loss: 1.479394\n",
      "Validation loss decreased (1.479395 --> 1.479394).         Saving model ...\n",
      "Epoch: 3126 \tTraining Loss: 1.078362 \tValidation Loss: 1.479393\n",
      "Validation loss decreased (1.479394 --> 1.479393).         Saving model ...\n",
      "Epoch: 3127 \tTraining Loss: 1.078360 \tValidation Loss: 1.479392\n",
      "Validation loss decreased (1.479393 --> 1.479392).         Saving model ...\n",
      "Epoch: 3128 \tTraining Loss: 1.078357 \tValidation Loss: 1.479391\n",
      "Validation loss decreased (1.479392 --> 1.479391).         Saving model ...\n",
      "Epoch: 3129 \tTraining Loss: 1.078355 \tValidation Loss: 1.479390\n",
      "Validation loss decreased (1.479391 --> 1.479390).         Saving model ...\n",
      "Epoch: 3130 \tTraining Loss: 1.078353 \tValidation Loss: 1.479389\n",
      "Validation loss decreased (1.479390 --> 1.479389).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3131 \tTraining Loss: 1.078351 \tValidation Loss: 1.479388\n",
      "Validation loss decreased (1.479389 --> 1.479388).         Saving model ...\n",
      "Epoch: 3132 \tTraining Loss: 1.078349 \tValidation Loss: 1.479386\n",
      "Validation loss decreased (1.479388 --> 1.479386).         Saving model ...\n",
      "Epoch: 3133 \tTraining Loss: 1.078347 \tValidation Loss: 1.479385\n",
      "Validation loss decreased (1.479386 --> 1.479385).         Saving model ...\n",
      "Epoch: 3134 \tTraining Loss: 1.078344 \tValidation Loss: 1.479384\n",
      "Validation loss decreased (1.479385 --> 1.479384).         Saving model ...\n",
      "Epoch: 3135 \tTraining Loss: 1.078342 \tValidation Loss: 1.479383\n",
      "Validation loss decreased (1.479384 --> 1.479383).         Saving model ...\n",
      "Epoch: 3136 \tTraining Loss: 1.078340 \tValidation Loss: 1.479383\n",
      "Validation loss decreased (1.479383 --> 1.479383).         Saving model ...\n",
      "Epoch: 3137 \tTraining Loss: 1.078338 \tValidation Loss: 1.479381\n",
      "Validation loss decreased (1.479383 --> 1.479381).         Saving model ...\n",
      "Epoch: 3138 \tTraining Loss: 1.078336 \tValidation Loss: 1.479380\n",
      "Validation loss decreased (1.479381 --> 1.479380).         Saving model ...\n",
      "Epoch: 3139 \tTraining Loss: 1.078333 \tValidation Loss: 1.479379\n",
      "Validation loss decreased (1.479380 --> 1.479379).         Saving model ...\n",
      "Epoch: 3140 \tTraining Loss: 1.078331 \tValidation Loss: 1.479378\n",
      "Validation loss decreased (1.479379 --> 1.479378).         Saving model ...\n",
      "Epoch: 3141 \tTraining Loss: 1.078329 \tValidation Loss: 1.479377\n",
      "Validation loss decreased (1.479378 --> 1.479377).         Saving model ...\n",
      "Epoch: 3142 \tTraining Loss: 1.078327 \tValidation Loss: 1.479376\n",
      "Validation loss decreased (1.479377 --> 1.479376).         Saving model ...\n",
      "Epoch: 3143 \tTraining Loss: 1.078325 \tValidation Loss: 1.479375\n",
      "Validation loss decreased (1.479376 --> 1.479375).         Saving model ...\n",
      "Epoch: 3144 \tTraining Loss: 1.078322 \tValidation Loss: 1.479374\n",
      "Validation loss decreased (1.479375 --> 1.479374).         Saving model ...\n",
      "Epoch: 3145 \tTraining Loss: 1.078320 \tValidation Loss: 1.479374\n",
      "Validation loss decreased (1.479374 --> 1.479374).         Saving model ...\n",
      "Epoch: 3146 \tTraining Loss: 1.078318 \tValidation Loss: 1.479372\n",
      "Validation loss decreased (1.479374 --> 1.479372).         Saving model ...\n",
      "Epoch: 3147 \tTraining Loss: 1.078316 \tValidation Loss: 1.479372\n",
      "Validation loss decreased (1.479372 --> 1.479372).         Saving model ...\n",
      "Epoch: 3148 \tTraining Loss: 1.078314 \tValidation Loss: 1.479372\n",
      "Validation loss decreased (1.479372 --> 1.479372).         Saving model ...\n",
      "Epoch: 3149 \tTraining Loss: 1.078312 \tValidation Loss: 1.479372\n",
      "Validation loss decreased (1.479372 --> 1.479372).         Saving model ...\n",
      "Epoch: 3150 \tTraining Loss: 1.078309 \tValidation Loss: 1.479372\n",
      "Validation loss decreased (1.479372 --> 1.479372).         Saving model ...\n",
      "Epoch: 3151 \tTraining Loss: 1.078307 \tValidation Loss: 1.479370\n",
      "Validation loss decreased (1.479372 --> 1.479370).         Saving model ...\n",
      "Epoch: 3152 \tTraining Loss: 1.078305 \tValidation Loss: 1.479369\n",
      "Validation loss decreased (1.479370 --> 1.479369).         Saving model ...\n",
      "Epoch: 3153 \tTraining Loss: 1.078303 \tValidation Loss: 1.479369\n",
      "Validation loss decreased (1.479369 --> 1.479369).         Saving model ...\n",
      "Epoch: 3154 \tTraining Loss: 1.078301 \tValidation Loss: 1.479368\n",
      "Validation loss decreased (1.479369 --> 1.479368).         Saving model ...\n",
      "Epoch: 3155 \tTraining Loss: 1.078299 \tValidation Loss: 1.479367\n",
      "Validation loss decreased (1.479368 --> 1.479367).         Saving model ...\n",
      "Epoch: 3156 \tTraining Loss: 1.078296 \tValidation Loss: 1.479367\n",
      "Validation loss decreased (1.479367 --> 1.479367).         Saving model ...\n",
      "Epoch: 3157 \tTraining Loss: 1.078294 \tValidation Loss: 1.479366\n",
      "Validation loss decreased (1.479367 --> 1.479366).         Saving model ...\n",
      "Epoch: 3158 \tTraining Loss: 1.078292 \tValidation Loss: 1.479365\n",
      "Validation loss decreased (1.479366 --> 1.479365).         Saving model ...\n",
      "Epoch: 3159 \tTraining Loss: 1.078290 \tValidation Loss: 1.479365\n",
      "Validation loss decreased (1.479365 --> 1.479365).         Saving model ...\n",
      "Epoch: 3160 \tTraining Loss: 1.078288 \tValidation Loss: 1.479363\n",
      "Validation loss decreased (1.479365 --> 1.479363).         Saving model ...\n",
      "Epoch: 3161 \tTraining Loss: 1.078285 \tValidation Loss: 1.479363\n",
      "Validation loss decreased (1.479363 --> 1.479363).         Saving model ...\n",
      "Epoch: 3162 \tTraining Loss: 1.078283 \tValidation Loss: 1.479363\n",
      "Validation loss decreased (1.479363 --> 1.479363).         Saving model ...\n",
      "Epoch: 3163 \tTraining Loss: 1.078281 \tValidation Loss: 1.479362\n",
      "Validation loss decreased (1.479363 --> 1.479362).         Saving model ...\n",
      "Epoch: 3164 \tTraining Loss: 1.078279 \tValidation Loss: 1.479362\n",
      "Validation loss decreased (1.479362 --> 1.479362).         Saving model ...\n",
      "Epoch: 3165 \tTraining Loss: 1.078277 \tValidation Loss: 1.479361\n",
      "Validation loss decreased (1.479362 --> 1.479361).         Saving model ...\n",
      "Epoch: 3166 \tTraining Loss: 1.078275 \tValidation Loss: 1.479360\n",
      "Validation loss decreased (1.479361 --> 1.479360).         Saving model ...\n",
      "Epoch: 3167 \tTraining Loss: 1.078273 \tValidation Loss: 1.479359\n",
      "Validation loss decreased (1.479360 --> 1.479359).         Saving model ...\n",
      "Epoch: 3168 \tTraining Loss: 1.078270 \tValidation Loss: 1.479358\n",
      "Validation loss decreased (1.479359 --> 1.479358).         Saving model ...\n",
      "Epoch: 3169 \tTraining Loss: 1.078268 \tValidation Loss: 1.479358\n",
      "Validation loss decreased (1.479358 --> 1.479358).         Saving model ...\n",
      "Epoch: 3170 \tTraining Loss: 1.078266 \tValidation Loss: 1.479356\n",
      "Validation loss decreased (1.479358 --> 1.479356).         Saving model ...\n",
      "Epoch: 3171 \tTraining Loss: 1.078264 \tValidation Loss: 1.479356\n",
      "Validation loss decreased (1.479356 --> 1.479356).         Saving model ...\n",
      "Epoch: 3172 \tTraining Loss: 1.078262 \tValidation Loss: 1.479355\n",
      "Validation loss decreased (1.479356 --> 1.479355).         Saving model ...\n",
      "Epoch: 3173 \tTraining Loss: 1.078260 \tValidation Loss: 1.479355\n",
      "Validation loss decreased (1.479355 --> 1.479355).         Saving model ...\n",
      "Epoch: 3174 \tTraining Loss: 1.078257 \tValidation Loss: 1.479354\n",
      "Validation loss decreased (1.479355 --> 1.479354).         Saving model ...\n",
      "Epoch: 3175 \tTraining Loss: 1.078255 \tValidation Loss: 1.479352\n",
      "Validation loss decreased (1.479354 --> 1.479352).         Saving model ...\n",
      "Epoch: 3176 \tTraining Loss: 1.078253 \tValidation Loss: 1.479352\n",
      "Validation loss decreased (1.479352 --> 1.479352).         Saving model ...\n",
      "Epoch: 3177 \tTraining Loss: 1.078251 \tValidation Loss: 1.479351\n",
      "Validation loss decreased (1.479352 --> 1.479351).         Saving model ...\n",
      "Epoch: 3178 \tTraining Loss: 1.078249 \tValidation Loss: 1.479350\n",
      "Validation loss decreased (1.479351 --> 1.479350).         Saving model ...\n",
      "Epoch: 3179 \tTraining Loss: 1.078247 \tValidation Loss: 1.479349\n",
      "Validation loss decreased (1.479350 --> 1.479349).         Saving model ...\n",
      "Epoch: 3180 \tTraining Loss: 1.078245 \tValidation Loss: 1.479347\n",
      "Validation loss decreased (1.479349 --> 1.479347).         Saving model ...\n",
      "Epoch: 3181 \tTraining Loss: 1.078242 \tValidation Loss: 1.479346\n",
      "Validation loss decreased (1.479347 --> 1.479346).         Saving model ...\n",
      "Epoch: 3182 \tTraining Loss: 1.078240 \tValidation Loss: 1.479346\n",
      "Validation loss decreased (1.479346 --> 1.479346).         Saving model ...\n",
      "Epoch: 3183 \tTraining Loss: 1.078238 \tValidation Loss: 1.479345\n",
      "Validation loss decreased (1.479346 --> 1.479345).         Saving model ...\n",
      "Epoch: 3184 \tTraining Loss: 1.078236 \tValidation Loss: 1.479343\n",
      "Validation loss decreased (1.479345 --> 1.479343).         Saving model ...\n",
      "Epoch: 3185 \tTraining Loss: 1.078234 \tValidation Loss: 1.479342\n",
      "Validation loss decreased (1.479343 --> 1.479342).         Saving model ...\n",
      "Epoch: 3186 \tTraining Loss: 1.078232 \tValidation Loss: 1.479341\n",
      "Validation loss decreased (1.479342 --> 1.479341).         Saving model ...\n",
      "Epoch: 3187 \tTraining Loss: 1.078230 \tValidation Loss: 1.479339\n",
      "Validation loss decreased (1.479341 --> 1.479339).         Saving model ...\n",
      "Epoch: 3188 \tTraining Loss: 1.078227 \tValidation Loss: 1.479338\n",
      "Validation loss decreased (1.479339 --> 1.479338).         Saving model ...\n",
      "Epoch: 3189 \tTraining Loss: 1.078225 \tValidation Loss: 1.479337\n",
      "Validation loss decreased (1.479338 --> 1.479337).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3190 \tTraining Loss: 1.078223 \tValidation Loss: 1.479336\n",
      "Validation loss decreased (1.479337 --> 1.479336).         Saving model ...\n",
      "Epoch: 3191 \tTraining Loss: 1.078221 \tValidation Loss: 1.479334\n",
      "Validation loss decreased (1.479336 --> 1.479334).         Saving model ...\n",
      "Epoch: 3192 \tTraining Loss: 1.078219 \tValidation Loss: 1.479334\n",
      "Validation loss decreased (1.479334 --> 1.479334).         Saving model ...\n",
      "Epoch: 3193 \tTraining Loss: 1.078217 \tValidation Loss: 1.479332\n",
      "Validation loss decreased (1.479334 --> 1.479332).         Saving model ...\n",
      "Epoch: 3194 \tTraining Loss: 1.078215 \tValidation Loss: 1.479331\n",
      "Validation loss decreased (1.479332 --> 1.479331).         Saving model ...\n",
      "Epoch: 3195 \tTraining Loss: 1.078213 \tValidation Loss: 1.479330\n",
      "Validation loss decreased (1.479331 --> 1.479330).         Saving model ...\n",
      "Epoch: 3196 \tTraining Loss: 1.078210 \tValidation Loss: 1.479329\n",
      "Validation loss decreased (1.479330 --> 1.479329).         Saving model ...\n",
      "Epoch: 3197 \tTraining Loss: 1.078208 \tValidation Loss: 1.479327\n",
      "Validation loss decreased (1.479329 --> 1.479327).         Saving model ...\n",
      "Epoch: 3198 \tTraining Loss: 1.078206 \tValidation Loss: 1.479326\n",
      "Validation loss decreased (1.479327 --> 1.479326).         Saving model ...\n",
      "Epoch: 3199 \tTraining Loss: 1.078204 \tValidation Loss: 1.479324\n",
      "Validation loss decreased (1.479326 --> 1.479324).         Saving model ...\n",
      "Epoch: 3200 \tTraining Loss: 1.078202 \tValidation Loss: 1.479324\n",
      "Validation loss decreased (1.479324 --> 1.479324).         Saving model ...\n",
      "Epoch: 3201 \tTraining Loss: 1.078200 \tValidation Loss: 1.479322\n",
      "Validation loss decreased (1.479324 --> 1.479322).         Saving model ...\n",
      "Epoch: 3202 \tTraining Loss: 1.078198 \tValidation Loss: 1.479322\n",
      "Validation loss decreased (1.479322 --> 1.479322).         Saving model ...\n",
      "Epoch: 3203 \tTraining Loss: 1.078196 \tValidation Loss: 1.479321\n",
      "Validation loss decreased (1.479322 --> 1.479321).         Saving model ...\n",
      "Epoch: 3204 \tTraining Loss: 1.078193 \tValidation Loss: 1.479321\n",
      "Validation loss decreased (1.479321 --> 1.479321).         Saving model ...\n",
      "Epoch: 3205 \tTraining Loss: 1.078191 \tValidation Loss: 1.479320\n",
      "Validation loss decreased (1.479321 --> 1.479320).         Saving model ...\n",
      "Epoch: 3206 \tTraining Loss: 1.078189 \tValidation Loss: 1.479320\n",
      "Validation loss decreased (1.479320 --> 1.479320).         Saving model ...\n",
      "Epoch: 3207 \tTraining Loss: 1.078187 \tValidation Loss: 1.479319\n",
      "Validation loss decreased (1.479320 --> 1.479319).         Saving model ...\n",
      "Epoch: 3208 \tTraining Loss: 1.078185 \tValidation Loss: 1.479317\n",
      "Validation loss decreased (1.479319 --> 1.479317).         Saving model ...\n",
      "Epoch: 3209 \tTraining Loss: 1.078183 \tValidation Loss: 1.479316\n",
      "Validation loss decreased (1.479317 --> 1.479316).         Saving model ...\n",
      "Epoch: 3210 \tTraining Loss: 1.078181 \tValidation Loss: 1.479316\n",
      "Validation loss decreased (1.479316 --> 1.479316).         Saving model ...\n",
      "Epoch: 3211 \tTraining Loss: 1.078179 \tValidation Loss: 1.479315\n",
      "Validation loss decreased (1.479316 --> 1.479315).         Saving model ...\n",
      "Epoch: 3212 \tTraining Loss: 1.078176 \tValidation Loss: 1.479315\n",
      "Validation loss decreased (1.479315 --> 1.479315).         Saving model ...\n",
      "Epoch: 3213 \tTraining Loss: 1.078174 \tValidation Loss: 1.479314\n",
      "Validation loss decreased (1.479315 --> 1.479314).         Saving model ...\n",
      "Epoch: 3214 \tTraining Loss: 1.078172 \tValidation Loss: 1.479314\n",
      "Validation loss decreased (1.479314 --> 1.479314).         Saving model ...\n",
      "Epoch: 3215 \tTraining Loss: 1.078170 \tValidation Loss: 1.479313\n",
      "Validation loss decreased (1.479314 --> 1.479313).         Saving model ...\n",
      "Epoch: 3216 \tTraining Loss: 1.078168 \tValidation Loss: 1.479312\n",
      "Validation loss decreased (1.479313 --> 1.479312).         Saving model ...\n",
      "Epoch: 3217 \tTraining Loss: 1.078166 \tValidation Loss: 1.479312\n",
      "Validation loss decreased (1.479312 --> 1.479312).         Saving model ...\n",
      "Epoch: 3218 \tTraining Loss: 1.078164 \tValidation Loss: 1.479311\n",
      "Validation loss decreased (1.479312 --> 1.479311).         Saving model ...\n",
      "Epoch: 3219 \tTraining Loss: 1.078162 \tValidation Loss: 1.479310\n",
      "Validation loss decreased (1.479311 --> 1.479310).         Saving model ...\n",
      "Epoch: 3220 \tTraining Loss: 1.078160 \tValidation Loss: 1.479309\n",
      "Validation loss decreased (1.479310 --> 1.479309).         Saving model ...\n",
      "Epoch: 3221 \tTraining Loss: 1.078158 \tValidation Loss: 1.479309\n",
      "Validation loss decreased (1.479309 --> 1.479309).         Saving model ...\n",
      "Epoch: 3222 \tTraining Loss: 1.078155 \tValidation Loss: 1.479308\n",
      "Validation loss decreased (1.479309 --> 1.479308).         Saving model ...\n",
      "Epoch: 3223 \tTraining Loss: 1.078153 \tValidation Loss: 1.479307\n",
      "Validation loss decreased (1.479308 --> 1.479307).         Saving model ...\n",
      "Epoch: 3224 \tTraining Loss: 1.078151 \tValidation Loss: 1.479306\n",
      "Validation loss decreased (1.479307 --> 1.479306).         Saving model ...\n",
      "Epoch: 3225 \tTraining Loss: 1.078149 \tValidation Loss: 1.479305\n",
      "Validation loss decreased (1.479306 --> 1.479305).         Saving model ...\n",
      "Epoch: 3226 \tTraining Loss: 1.078147 \tValidation Loss: 1.479304\n",
      "Validation loss decreased (1.479305 --> 1.479304).         Saving model ...\n",
      "Epoch: 3227 \tTraining Loss: 1.078145 \tValidation Loss: 1.479304\n",
      "Validation loss decreased (1.479304 --> 1.479304).         Saving model ...\n",
      "Epoch: 3228 \tTraining Loss: 1.078143 \tValidation Loss: 1.479303\n",
      "Validation loss decreased (1.479304 --> 1.479303).         Saving model ...\n",
      "Epoch: 3229 \tTraining Loss: 1.078141 \tValidation Loss: 1.479303\n",
      "Validation loss decreased (1.479303 --> 1.479303).         Saving model ...\n",
      "Epoch: 3230 \tTraining Loss: 1.078139 \tValidation Loss: 1.479302\n",
      "Validation loss decreased (1.479303 --> 1.479302).         Saving model ...\n",
      "Epoch: 3231 \tTraining Loss: 1.078137 \tValidation Loss: 1.479301\n",
      "Validation loss decreased (1.479302 --> 1.479301).         Saving model ...\n",
      "Epoch: 3232 \tTraining Loss: 1.078134 \tValidation Loss: 1.479300\n",
      "Validation loss decreased (1.479301 --> 1.479300).         Saving model ...\n",
      "Epoch: 3233 \tTraining Loss: 1.078132 \tValidation Loss: 1.479299\n",
      "Validation loss decreased (1.479300 --> 1.479299).         Saving model ...\n",
      "Epoch: 3234 \tTraining Loss: 1.078130 \tValidation Loss: 1.479298\n",
      "Validation loss decreased (1.479299 --> 1.479298).         Saving model ...\n",
      "Epoch: 3235 \tTraining Loss: 1.078128 \tValidation Loss: 1.479296\n",
      "Validation loss decreased (1.479298 --> 1.479296).         Saving model ...\n",
      "Epoch: 3236 \tTraining Loss: 1.078126 \tValidation Loss: 1.479296\n",
      "Validation loss decreased (1.479296 --> 1.479296).         Saving model ...\n",
      "Epoch: 3237 \tTraining Loss: 1.078124 \tValidation Loss: 1.479295\n",
      "Validation loss decreased (1.479296 --> 1.479295).         Saving model ...\n",
      "Epoch: 3238 \tTraining Loss: 1.078122 \tValidation Loss: 1.479294\n",
      "Validation loss decreased (1.479295 --> 1.479294).         Saving model ...\n",
      "Epoch: 3239 \tTraining Loss: 1.078120 \tValidation Loss: 1.479294\n",
      "Validation loss decreased (1.479294 --> 1.479294).         Saving model ...\n",
      "Epoch: 3240 \tTraining Loss: 1.078118 \tValidation Loss: 1.479292\n",
      "Validation loss decreased (1.479294 --> 1.479292).         Saving model ...\n",
      "Epoch: 3241 \tTraining Loss: 1.078116 \tValidation Loss: 1.479292\n",
      "Validation loss decreased (1.479292 --> 1.479292).         Saving model ...\n",
      "Epoch: 3242 \tTraining Loss: 1.078114 \tValidation Loss: 1.479291\n",
      "Validation loss decreased (1.479292 --> 1.479291).         Saving model ...\n",
      "Epoch: 3243 \tTraining Loss: 1.078111 \tValidation Loss: 1.479291\n",
      "Validation loss decreased (1.479291 --> 1.479291).         Saving model ...\n",
      "Epoch: 3244 \tTraining Loss: 1.078109 \tValidation Loss: 1.479290\n",
      "Validation loss decreased (1.479291 --> 1.479290).         Saving model ...\n",
      "Epoch: 3245 \tTraining Loss: 1.078107 \tValidation Loss: 1.479289\n",
      "Validation loss decreased (1.479290 --> 1.479289).         Saving model ...\n",
      "Epoch: 3246 \tTraining Loss: 1.078105 \tValidation Loss: 1.479288\n",
      "Validation loss decreased (1.479289 --> 1.479288).         Saving model ...\n",
      "Epoch: 3247 \tTraining Loss: 1.078103 \tValidation Loss: 1.479287\n",
      "Validation loss decreased (1.479288 --> 1.479287).         Saving model ...\n",
      "Epoch: 3248 \tTraining Loss: 1.078101 \tValidation Loss: 1.479286\n",
      "Validation loss decreased (1.479287 --> 1.479286).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3249 \tTraining Loss: 1.078099 \tValidation Loss: 1.479286\n",
      "Validation loss decreased (1.479286 --> 1.479286).         Saving model ...\n",
      "Epoch: 3250 \tTraining Loss: 1.078097 \tValidation Loss: 1.479285\n",
      "Validation loss decreased (1.479286 --> 1.479285).         Saving model ...\n",
      "Epoch: 3251 \tTraining Loss: 1.078095 \tValidation Loss: 1.479284\n",
      "Validation loss decreased (1.479285 --> 1.479284).         Saving model ...\n",
      "Epoch: 3252 \tTraining Loss: 1.078093 \tValidation Loss: 1.479283\n",
      "Validation loss decreased (1.479284 --> 1.479283).         Saving model ...\n",
      "Epoch: 3253 \tTraining Loss: 1.078091 \tValidation Loss: 1.479283\n",
      "Validation loss decreased (1.479283 --> 1.479283).         Saving model ...\n",
      "Epoch: 3254 \tTraining Loss: 1.078089 \tValidation Loss: 1.479282\n",
      "Validation loss decreased (1.479283 --> 1.479282).         Saving model ...\n",
      "Epoch: 3255 \tTraining Loss: 1.078087 \tValidation Loss: 1.479282\n",
      "Epoch: 3256 \tTraining Loss: 1.078084 \tValidation Loss: 1.479280\n",
      "Validation loss decreased (1.479282 --> 1.479280).         Saving model ...\n",
      "Epoch: 3257 \tTraining Loss: 1.078082 \tValidation Loss: 1.479280\n",
      "Validation loss decreased (1.479280 --> 1.479280).         Saving model ...\n",
      "Epoch: 3258 \tTraining Loss: 1.078080 \tValidation Loss: 1.479279\n",
      "Validation loss decreased (1.479280 --> 1.479279).         Saving model ...\n",
      "Epoch: 3259 \tTraining Loss: 1.078078 \tValidation Loss: 1.479279\n",
      "Validation loss decreased (1.479279 --> 1.479279).         Saving model ...\n",
      "Epoch: 3260 \tTraining Loss: 1.078076 \tValidation Loss: 1.479278\n",
      "Validation loss decreased (1.479279 --> 1.479278).         Saving model ...\n",
      "Epoch: 3261 \tTraining Loss: 1.078074 \tValidation Loss: 1.479278\n",
      "Validation loss decreased (1.479278 --> 1.479278).         Saving model ...\n",
      "Epoch: 3262 \tTraining Loss: 1.078072 \tValidation Loss: 1.479277\n",
      "Validation loss decreased (1.479278 --> 1.479277).         Saving model ...\n",
      "Epoch: 3263 \tTraining Loss: 1.078070 \tValidation Loss: 1.479276\n",
      "Validation loss decreased (1.479277 --> 1.479276).         Saving model ...\n",
      "Epoch: 3264 \tTraining Loss: 1.078068 \tValidation Loss: 1.479276\n",
      "Validation loss decreased (1.479276 --> 1.479276).         Saving model ...\n",
      "Epoch: 3265 \tTraining Loss: 1.078066 \tValidation Loss: 1.479275\n",
      "Validation loss decreased (1.479276 --> 1.479275).         Saving model ...\n",
      "Epoch: 3266 \tTraining Loss: 1.078064 \tValidation Loss: 1.479274\n",
      "Validation loss decreased (1.479275 --> 1.479274).         Saving model ...\n",
      "Epoch: 3267 \tTraining Loss: 1.078062 \tValidation Loss: 1.479274\n",
      "Validation loss decreased (1.479274 --> 1.479274).         Saving model ...\n",
      "Epoch: 3268 \tTraining Loss: 1.078060 \tValidation Loss: 1.479273\n",
      "Validation loss decreased (1.479274 --> 1.479273).         Saving model ...\n",
      "Epoch: 3269 \tTraining Loss: 1.078058 \tValidation Loss: 1.479272\n",
      "Validation loss decreased (1.479273 --> 1.479272).         Saving model ...\n",
      "Epoch: 3270 \tTraining Loss: 1.078056 \tValidation Loss: 1.479270\n",
      "Validation loss decreased (1.479272 --> 1.479270).         Saving model ...\n",
      "Epoch: 3271 \tTraining Loss: 1.078053 \tValidation Loss: 1.479269\n",
      "Validation loss decreased (1.479270 --> 1.479269).         Saving model ...\n",
      "Epoch: 3272 \tTraining Loss: 1.078051 \tValidation Loss: 1.479268\n",
      "Validation loss decreased (1.479269 --> 1.479268).         Saving model ...\n",
      "Epoch: 3273 \tTraining Loss: 1.078049 \tValidation Loss: 1.479267\n",
      "Validation loss decreased (1.479268 --> 1.479267).         Saving model ...\n",
      "Epoch: 3274 \tTraining Loss: 1.078047 \tValidation Loss: 1.479265\n",
      "Validation loss decreased (1.479267 --> 1.479265).         Saving model ...\n",
      "Epoch: 3275 \tTraining Loss: 1.078045 \tValidation Loss: 1.479264\n",
      "Validation loss decreased (1.479265 --> 1.479264).         Saving model ...\n",
      "Epoch: 3276 \tTraining Loss: 1.078043 \tValidation Loss: 1.479263\n",
      "Validation loss decreased (1.479264 --> 1.479263).         Saving model ...\n",
      "Epoch: 3277 \tTraining Loss: 1.078041 \tValidation Loss: 1.479262\n",
      "Validation loss decreased (1.479263 --> 1.479262).         Saving model ...\n",
      "Epoch: 3278 \tTraining Loss: 1.078039 \tValidation Loss: 1.479260\n",
      "Validation loss decreased (1.479262 --> 1.479260).         Saving model ...\n",
      "Epoch: 3279 \tTraining Loss: 1.078037 \tValidation Loss: 1.479260\n",
      "Validation loss decreased (1.479260 --> 1.479260).         Saving model ...\n",
      "Epoch: 3280 \tTraining Loss: 1.078035 \tValidation Loss: 1.479259\n",
      "Validation loss decreased (1.479260 --> 1.479259).         Saving model ...\n",
      "Epoch: 3281 \tTraining Loss: 1.078033 \tValidation Loss: 1.479258\n",
      "Validation loss decreased (1.479259 --> 1.479258).         Saving model ...\n",
      "Epoch: 3282 \tTraining Loss: 1.078031 \tValidation Loss: 1.479258\n",
      "Validation loss decreased (1.479258 --> 1.479258).         Saving model ...\n",
      "Epoch: 3283 \tTraining Loss: 1.078029 \tValidation Loss: 1.479257\n",
      "Validation loss decreased (1.479258 --> 1.479257).         Saving model ...\n",
      "Epoch: 3284 \tTraining Loss: 1.078027 \tValidation Loss: 1.479257\n",
      "Validation loss decreased (1.479257 --> 1.479257).         Saving model ...\n",
      "Epoch: 3285 \tTraining Loss: 1.078025 \tValidation Loss: 1.479256\n",
      "Validation loss decreased (1.479257 --> 1.479256).         Saving model ...\n",
      "Epoch: 3286 \tTraining Loss: 1.078023 \tValidation Loss: 1.479256\n",
      "Validation loss decreased (1.479256 --> 1.479256).         Saving model ...\n",
      "Epoch: 3287 \tTraining Loss: 1.078021 \tValidation Loss: 1.479255\n",
      "Validation loss decreased (1.479256 --> 1.479255).         Saving model ...\n",
      "Epoch: 3288 \tTraining Loss: 1.078019 \tValidation Loss: 1.479256\n",
      "Epoch: 3289 \tTraining Loss: 1.078017 \tValidation Loss: 1.479256\n",
      "Epoch: 3290 \tTraining Loss: 1.078015 \tValidation Loss: 1.479255\n",
      "Validation loss decreased (1.479255 --> 1.479255).         Saving model ...\n",
      "Epoch: 3291 \tTraining Loss: 1.078013 \tValidation Loss: 1.479255\n",
      "Validation loss decreased (1.479255 --> 1.479255).         Saving model ...\n",
      "Epoch: 3292 \tTraining Loss: 1.078010 \tValidation Loss: 1.479255\n",
      "Validation loss decreased (1.479255 --> 1.479255).         Saving model ...\n",
      "Epoch: 3293 \tTraining Loss: 1.078008 \tValidation Loss: 1.479254\n",
      "Validation loss decreased (1.479255 --> 1.479254).         Saving model ...\n",
      "Epoch: 3294 \tTraining Loss: 1.078006 \tValidation Loss: 1.479254\n",
      "Validation loss decreased (1.479254 --> 1.479254).         Saving model ...\n",
      "Epoch: 3295 \tTraining Loss: 1.078004 \tValidation Loss: 1.479252\n",
      "Validation loss decreased (1.479254 --> 1.479252).         Saving model ...\n",
      "Epoch: 3296 \tTraining Loss: 1.078002 \tValidation Loss: 1.479252\n",
      "Validation loss decreased (1.479252 --> 1.479252).         Saving model ...\n",
      "Epoch: 3297 \tTraining Loss: 1.078000 \tValidation Loss: 1.479251\n",
      "Validation loss decreased (1.479252 --> 1.479251).         Saving model ...\n",
      "Epoch: 3298 \tTraining Loss: 1.077998 \tValidation Loss: 1.479250\n",
      "Validation loss decreased (1.479251 --> 1.479250).         Saving model ...\n",
      "Epoch: 3299 \tTraining Loss: 1.077996 \tValidation Loss: 1.479249\n",
      "Validation loss decreased (1.479250 --> 1.479249).         Saving model ...\n",
      "Epoch: 3300 \tTraining Loss: 1.077994 \tValidation Loss: 1.479249\n",
      "Validation loss decreased (1.479249 --> 1.479249).         Saving model ...\n",
      "Epoch: 3301 \tTraining Loss: 1.077992 \tValidation Loss: 1.479248\n",
      "Validation loss decreased (1.479249 --> 1.479248).         Saving model ...\n",
      "Epoch: 3302 \tTraining Loss: 1.077990 \tValidation Loss: 1.479247\n",
      "Validation loss decreased (1.479248 --> 1.479247).         Saving model ...\n",
      "Epoch: 3303 \tTraining Loss: 1.077988 \tValidation Loss: 1.479246\n",
      "Validation loss decreased (1.479247 --> 1.479246).         Saving model ...\n",
      "Epoch: 3304 \tTraining Loss: 1.077986 \tValidation Loss: 1.479246\n",
      "Validation loss decreased (1.479246 --> 1.479246).         Saving model ...\n",
      "Epoch: 3305 \tTraining Loss: 1.077984 \tValidation Loss: 1.479246\n",
      "Validation loss decreased (1.479246 --> 1.479246).         Saving model ...\n",
      "Epoch: 3306 \tTraining Loss: 1.077982 \tValidation Loss: 1.479245\n",
      "Validation loss decreased (1.479246 --> 1.479245).         Saving model ...\n",
      "Epoch: 3307 \tTraining Loss: 1.077980 \tValidation Loss: 1.479245\n",
      "Validation loss decreased (1.479245 --> 1.479245).         Saving model ...\n",
      "Epoch: 3308 \tTraining Loss: 1.077978 \tValidation Loss: 1.479244\n",
      "Validation loss decreased (1.479245 --> 1.479244).         Saving model ...\n",
      "Epoch: 3309 \tTraining Loss: 1.077976 \tValidation Loss: 1.479244\n",
      "Validation loss decreased (1.479244 --> 1.479244).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3310 \tTraining Loss: 1.077974 \tValidation Loss: 1.479243\n",
      "Validation loss decreased (1.479244 --> 1.479243).         Saving model ...\n",
      "Epoch: 3311 \tTraining Loss: 1.077972 \tValidation Loss: 1.479242\n",
      "Validation loss decreased (1.479243 --> 1.479242).         Saving model ...\n",
      "Epoch: 3312 \tTraining Loss: 1.077970 \tValidation Loss: 1.479242\n",
      "Epoch: 3313 \tTraining Loss: 1.077968 \tValidation Loss: 1.479241\n",
      "Validation loss decreased (1.479242 --> 1.479241).         Saving model ...\n",
      "Epoch: 3314 \tTraining Loss: 1.077966 \tValidation Loss: 1.479240\n",
      "Validation loss decreased (1.479241 --> 1.479240).         Saving model ...\n",
      "Epoch: 3315 \tTraining Loss: 1.077964 \tValidation Loss: 1.479239\n",
      "Validation loss decreased (1.479240 --> 1.479239).         Saving model ...\n",
      "Epoch: 3316 \tTraining Loss: 1.077962 \tValidation Loss: 1.479238\n",
      "Validation loss decreased (1.479239 --> 1.479238).         Saving model ...\n",
      "Epoch: 3317 \tTraining Loss: 1.077960 \tValidation Loss: 1.479238\n",
      "Validation loss decreased (1.479238 --> 1.479238).         Saving model ...\n",
      "Epoch: 3318 \tTraining Loss: 1.077958 \tValidation Loss: 1.479237\n",
      "Validation loss decreased (1.479238 --> 1.479237).         Saving model ...\n",
      "Epoch: 3319 \tTraining Loss: 1.077956 \tValidation Loss: 1.479236\n",
      "Validation loss decreased (1.479237 --> 1.479236).         Saving model ...\n",
      "Epoch: 3320 \tTraining Loss: 1.077954 \tValidation Loss: 1.479235\n",
      "Validation loss decreased (1.479236 --> 1.479235).         Saving model ...\n",
      "Epoch: 3321 \tTraining Loss: 1.077952 \tValidation Loss: 1.479235\n",
      "Validation loss decreased (1.479235 --> 1.479235).         Saving model ...\n",
      "Epoch: 3322 \tTraining Loss: 1.077950 \tValidation Loss: 1.479235\n",
      "Epoch: 3323 \tTraining Loss: 1.077948 \tValidation Loss: 1.479234\n",
      "Validation loss decreased (1.479235 --> 1.479234).         Saving model ...\n",
      "Epoch: 3324 \tTraining Loss: 1.077946 \tValidation Loss: 1.479233\n",
      "Validation loss decreased (1.479234 --> 1.479233).         Saving model ...\n",
      "Epoch: 3325 \tTraining Loss: 1.077944 \tValidation Loss: 1.479233\n",
      "Epoch: 3326 \tTraining Loss: 1.077942 \tValidation Loss: 1.479232\n",
      "Validation loss decreased (1.479233 --> 1.479232).         Saving model ...\n",
      "Epoch: 3327 \tTraining Loss: 1.077940 \tValidation Loss: 1.479232\n",
      "Validation loss decreased (1.479232 --> 1.479232).         Saving model ...\n",
      "Epoch: 3328 \tTraining Loss: 1.077938 \tValidation Loss: 1.479232\n",
      "Validation loss decreased (1.479232 --> 1.479232).         Saving model ...\n",
      "Epoch: 3329 \tTraining Loss: 1.077936 \tValidation Loss: 1.479231\n",
      "Validation loss decreased (1.479232 --> 1.479231).         Saving model ...\n",
      "Epoch: 3330 \tTraining Loss: 1.077934 \tValidation Loss: 1.479231\n",
      "Validation loss decreased (1.479231 --> 1.479231).         Saving model ...\n",
      "Epoch: 3331 \tTraining Loss: 1.077932 \tValidation Loss: 1.479231\n",
      "Epoch: 3332 \tTraining Loss: 1.077930 \tValidation Loss: 1.479230\n",
      "Validation loss decreased (1.479231 --> 1.479230).         Saving model ...\n",
      "Epoch: 3333 \tTraining Loss: 1.077928 \tValidation Loss: 1.479230\n",
      "Validation loss decreased (1.479230 --> 1.479230).         Saving model ...\n",
      "Epoch: 3334 \tTraining Loss: 1.077926 \tValidation Loss: 1.479230\n",
      "Epoch: 3335 \tTraining Loss: 1.077924 \tValidation Loss: 1.479230\n",
      "Validation loss decreased (1.479230 --> 1.479230).         Saving model ...\n",
      "Epoch: 3336 \tTraining Loss: 1.077922 \tValidation Loss: 1.479229\n",
      "Validation loss decreased (1.479230 --> 1.479229).         Saving model ...\n",
      "Epoch: 3337 \tTraining Loss: 1.077920 \tValidation Loss: 1.479228\n",
      "Validation loss decreased (1.479229 --> 1.479228).         Saving model ...\n",
      "Epoch: 3338 \tTraining Loss: 1.077918 \tValidation Loss: 1.479229\n",
      "Epoch: 3339 \tTraining Loss: 1.077916 \tValidation Loss: 1.479228\n",
      "Epoch: 3340 \tTraining Loss: 1.077914 \tValidation Loss: 1.479228\n",
      "Epoch: 3341 \tTraining Loss: 1.077912 \tValidation Loss: 1.479228\n",
      "Epoch: 3342 \tTraining Loss: 1.077910 \tValidation Loss: 1.479228\n",
      "Validation loss decreased (1.479228 --> 1.479228).         Saving model ...\n",
      "Epoch: 3343 \tTraining Loss: 1.077908 \tValidation Loss: 1.479227\n",
      "Validation loss decreased (1.479228 --> 1.479227).         Saving model ...\n",
      "Epoch: 3344 \tTraining Loss: 1.077906 \tValidation Loss: 1.479227\n",
      "Epoch: 3345 \tTraining Loss: 1.077904 \tValidation Loss: 1.479227\n",
      "Validation loss decreased (1.479227 --> 1.479227).         Saving model ...\n",
      "Epoch: 3346 \tTraining Loss: 1.077902 \tValidation Loss: 1.479226\n",
      "Validation loss decreased (1.479227 --> 1.479226).         Saving model ...\n",
      "Epoch: 3347 \tTraining Loss: 1.077900 \tValidation Loss: 1.479227\n",
      "Epoch: 3348 \tTraining Loss: 1.077898 \tValidation Loss: 1.479226\n",
      "Validation loss decreased (1.479226 --> 1.479226).         Saving model ...\n",
      "Epoch: 3349 \tTraining Loss: 1.077896 \tValidation Loss: 1.479226\n",
      "Epoch: 3350 \tTraining Loss: 1.077894 \tValidation Loss: 1.479225\n",
      "Validation loss decreased (1.479226 --> 1.479225).         Saving model ...\n",
      "Epoch: 3351 \tTraining Loss: 1.077892 \tValidation Loss: 1.479224\n",
      "Validation loss decreased (1.479225 --> 1.479224).         Saving model ...\n",
      "Epoch: 3352 \tTraining Loss: 1.077890 \tValidation Loss: 1.479224\n",
      "Validation loss decreased (1.479224 --> 1.479224).         Saving model ...\n",
      "Epoch: 3353 \tTraining Loss: 1.077888 \tValidation Loss: 1.479224\n",
      "Validation loss decreased (1.479224 --> 1.479224).         Saving model ...\n",
      "Epoch: 3354 \tTraining Loss: 1.077886 \tValidation Loss: 1.479223\n",
      "Validation loss decreased (1.479224 --> 1.479223).         Saving model ...\n",
      "Epoch: 3355 \tTraining Loss: 1.077884 \tValidation Loss: 1.479223\n",
      "Validation loss decreased (1.479223 --> 1.479223).         Saving model ...\n",
      "Epoch: 3356 \tTraining Loss: 1.077882 \tValidation Loss: 1.479222\n",
      "Validation loss decreased (1.479223 --> 1.479222).         Saving model ...\n",
      "Epoch: 3357 \tTraining Loss: 1.077880 \tValidation Loss: 1.479222\n",
      "Validation loss decreased (1.479222 --> 1.479222).         Saving model ...\n",
      "Epoch: 3358 \tTraining Loss: 1.077878 \tValidation Loss: 1.479221\n",
      "Validation loss decreased (1.479222 --> 1.479221).         Saving model ...\n",
      "Epoch: 3359 \tTraining Loss: 1.077876 \tValidation Loss: 1.479222\n",
      "Epoch: 3360 \tTraining Loss: 1.077874 \tValidation Loss: 1.479222\n",
      "Epoch: 3361 \tTraining Loss: 1.077872 \tValidation Loss: 1.479221\n",
      "Validation loss decreased (1.479221 --> 1.479221).         Saving model ...\n",
      "Epoch: 3362 \tTraining Loss: 1.077870 \tValidation Loss: 1.479222\n",
      "Epoch: 3363 \tTraining Loss: 1.077868 \tValidation Loss: 1.479222\n",
      "Epoch: 3364 \tTraining Loss: 1.077866 \tValidation Loss: 1.479221\n",
      "Validation loss decreased (1.479221 --> 1.479221).         Saving model ...\n",
      "Epoch: 3365 \tTraining Loss: 1.077864 \tValidation Loss: 1.479221\n",
      "Validation loss decreased (1.479221 --> 1.479221).         Saving model ...\n",
      "Epoch: 3366 \tTraining Loss: 1.077862 \tValidation Loss: 1.479221\n",
      "Epoch: 3367 \tTraining Loss: 1.077860 \tValidation Loss: 1.479221\n",
      "Epoch: 3368 \tTraining Loss: 1.077858 \tValidation Loss: 1.479221\n",
      "Validation loss decreased (1.479221 --> 1.479221).         Saving model ...\n",
      "Epoch: 3369 \tTraining Loss: 1.077856 \tValidation Loss: 1.479221\n",
      "Validation loss decreased (1.479221 --> 1.479221).         Saving model ...\n",
      "Epoch: 3370 \tTraining Loss: 1.077854 \tValidation Loss: 1.479220\n",
      "Validation loss decreased (1.479221 --> 1.479220).         Saving model ...\n",
      "Epoch: 3371 \tTraining Loss: 1.077852 \tValidation Loss: 1.479220\n",
      "Epoch: 3372 \tTraining Loss: 1.077850 \tValidation Loss: 1.479220\n",
      "Validation loss decreased (1.479220 --> 1.479220).         Saving model ...\n",
      "Epoch: 3373 \tTraining Loss: 1.077848 \tValidation Loss: 1.479220\n",
      "Validation loss decreased (1.479220 --> 1.479220).         Saving model ...\n",
      "Epoch: 3374 \tTraining Loss: 1.077846 \tValidation Loss: 1.479219\n",
      "Validation loss decreased (1.479220 --> 1.479219).         Saving model ...\n",
      "Epoch: 3375 \tTraining Loss: 1.077844 \tValidation Loss: 1.479220\n",
      "Epoch: 3376 \tTraining Loss: 1.077842 \tValidation Loss: 1.479220\n",
      "Epoch: 3377 \tTraining Loss: 1.077840 \tValidation Loss: 1.479218\n",
      "Validation loss decreased (1.479219 --> 1.479218).         Saving model ...\n",
      "Epoch: 3378 \tTraining Loss: 1.077839 \tValidation Loss: 1.479218\n",
      "Validation loss decreased (1.479218 --> 1.479218).         Saving model ...\n",
      "Epoch: 3379 \tTraining Loss: 1.077837 \tValidation Loss: 1.479218\n",
      "Epoch: 3380 \tTraining Loss: 1.077835 \tValidation Loss: 1.479217\n",
      "Validation loss decreased (1.479218 --> 1.479217).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3381 \tTraining Loss: 1.077833 \tValidation Loss: 1.479217\n",
      "Validation loss decreased (1.479217 --> 1.479217).         Saving model ...\n",
      "Epoch: 3382 \tTraining Loss: 1.077831 \tValidation Loss: 1.479215\n",
      "Validation loss decreased (1.479217 --> 1.479215).         Saving model ...\n",
      "Epoch: 3383 \tTraining Loss: 1.077829 \tValidation Loss: 1.479214\n",
      "Validation loss decreased (1.479215 --> 1.479214).         Saving model ...\n",
      "Epoch: 3384 \tTraining Loss: 1.077827 \tValidation Loss: 1.479213\n",
      "Validation loss decreased (1.479214 --> 1.479213).         Saving model ...\n",
      "Epoch: 3385 \tTraining Loss: 1.077825 \tValidation Loss: 1.479212\n",
      "Validation loss decreased (1.479213 --> 1.479212).         Saving model ...\n",
      "Epoch: 3386 \tTraining Loss: 1.077823 \tValidation Loss: 1.479211\n",
      "Validation loss decreased (1.479212 --> 1.479211).         Saving model ...\n",
      "Epoch: 3387 \tTraining Loss: 1.077821 \tValidation Loss: 1.479210\n",
      "Validation loss decreased (1.479211 --> 1.479210).         Saving model ...\n",
      "Epoch: 3388 \tTraining Loss: 1.077819 \tValidation Loss: 1.479210\n",
      "Validation loss decreased (1.479210 --> 1.479210).         Saving model ...\n",
      "Epoch: 3389 \tTraining Loss: 1.077817 \tValidation Loss: 1.479208\n",
      "Validation loss decreased (1.479210 --> 1.479208).         Saving model ...\n",
      "Epoch: 3390 \tTraining Loss: 1.077815 \tValidation Loss: 1.479207\n",
      "Validation loss decreased (1.479208 --> 1.479207).         Saving model ...\n",
      "Epoch: 3391 \tTraining Loss: 1.077813 \tValidation Loss: 1.479206\n",
      "Validation loss decreased (1.479207 --> 1.479206).         Saving model ...\n",
      "Epoch: 3392 \tTraining Loss: 1.077811 \tValidation Loss: 1.479206\n",
      "Validation loss decreased (1.479206 --> 1.479206).         Saving model ...\n",
      "Epoch: 3393 \tTraining Loss: 1.077809 \tValidation Loss: 1.479205\n",
      "Validation loss decreased (1.479206 --> 1.479205).         Saving model ...\n",
      "Epoch: 3394 \tTraining Loss: 1.077807 \tValidation Loss: 1.479204\n",
      "Validation loss decreased (1.479205 --> 1.479204).         Saving model ...\n",
      "Epoch: 3395 \tTraining Loss: 1.077805 \tValidation Loss: 1.479202\n",
      "Validation loss decreased (1.479204 --> 1.479202).         Saving model ...\n",
      "Epoch: 3396 \tTraining Loss: 1.077803 \tValidation Loss: 1.479201\n",
      "Validation loss decreased (1.479202 --> 1.479201).         Saving model ...\n",
      "Epoch: 3397 \tTraining Loss: 1.077801 \tValidation Loss: 1.479201\n",
      "Validation loss decreased (1.479201 --> 1.479201).         Saving model ...\n",
      "Epoch: 3398 \tTraining Loss: 1.077799 \tValidation Loss: 1.479199\n",
      "Validation loss decreased (1.479201 --> 1.479199).         Saving model ...\n",
      "Epoch: 3399 \tTraining Loss: 1.077798 \tValidation Loss: 1.479198\n",
      "Validation loss decreased (1.479199 --> 1.479198).         Saving model ...\n",
      "Epoch: 3400 \tTraining Loss: 1.077796 \tValidation Loss: 1.479198\n",
      "Validation loss decreased (1.479198 --> 1.479198).         Saving model ...\n",
      "Epoch: 3401 \tTraining Loss: 1.077794 \tValidation Loss: 1.479196\n",
      "Validation loss decreased (1.479198 --> 1.479196).         Saving model ...\n",
      "Epoch: 3402 \tTraining Loss: 1.077792 \tValidation Loss: 1.479195\n",
      "Validation loss decreased (1.479196 --> 1.479195).         Saving model ...\n",
      "Epoch: 3403 \tTraining Loss: 1.077790 \tValidation Loss: 1.479194\n",
      "Validation loss decreased (1.479195 --> 1.479194).         Saving model ...\n",
      "Epoch: 3404 \tTraining Loss: 1.077788 \tValidation Loss: 1.479193\n",
      "Validation loss decreased (1.479194 --> 1.479193).         Saving model ...\n",
      "Epoch: 3405 \tTraining Loss: 1.077786 \tValidation Loss: 1.479193\n",
      "Validation loss decreased (1.479193 --> 1.479193).         Saving model ...\n",
      "Epoch: 3406 \tTraining Loss: 1.077784 \tValidation Loss: 1.479192\n",
      "Validation loss decreased (1.479193 --> 1.479192).         Saving model ...\n",
      "Epoch: 3407 \tTraining Loss: 1.077782 \tValidation Loss: 1.479191\n",
      "Validation loss decreased (1.479192 --> 1.479191).         Saving model ...\n",
      "Epoch: 3408 \tTraining Loss: 1.077780 \tValidation Loss: 1.479190\n",
      "Validation loss decreased (1.479191 --> 1.479190).         Saving model ...\n",
      "Epoch: 3409 \tTraining Loss: 1.077778 \tValidation Loss: 1.479189\n",
      "Validation loss decreased (1.479190 --> 1.479189).         Saving model ...\n",
      "Epoch: 3410 \tTraining Loss: 1.077776 \tValidation Loss: 1.479189\n",
      "Epoch: 3411 \tTraining Loss: 1.077774 \tValidation Loss: 1.479188\n",
      "Validation loss decreased (1.479189 --> 1.479188).         Saving model ...\n",
      "Epoch: 3412 \tTraining Loss: 1.077772 \tValidation Loss: 1.479187\n",
      "Validation loss decreased (1.479188 --> 1.479187).         Saving model ...\n",
      "Epoch: 3413 \tTraining Loss: 1.077770 \tValidation Loss: 1.479186\n",
      "Validation loss decreased (1.479187 --> 1.479186).         Saving model ...\n",
      "Epoch: 3414 \tTraining Loss: 1.077768 \tValidation Loss: 1.479186\n",
      "Validation loss decreased (1.479186 --> 1.479186).         Saving model ...\n",
      "Epoch: 3415 \tTraining Loss: 1.077767 \tValidation Loss: 1.479185\n",
      "Validation loss decreased (1.479186 --> 1.479185).         Saving model ...\n",
      "Epoch: 3416 \tTraining Loss: 1.077765 \tValidation Loss: 1.479186\n",
      "Epoch: 3417 \tTraining Loss: 1.077763 \tValidation Loss: 1.479185\n",
      "Validation loss decreased (1.479185 --> 1.479185).         Saving model ...\n",
      "Epoch: 3418 \tTraining Loss: 1.077761 \tValidation Loss: 1.479184\n",
      "Validation loss decreased (1.479185 --> 1.479184).         Saving model ...\n",
      "Epoch: 3419 \tTraining Loss: 1.077759 \tValidation Loss: 1.479185\n",
      "Epoch: 3420 \tTraining Loss: 1.077757 \tValidation Loss: 1.479184\n",
      "Validation loss decreased (1.479184 --> 1.479184).         Saving model ...\n",
      "Epoch: 3421 \tTraining Loss: 1.077755 \tValidation Loss: 1.479184\n",
      "Validation loss decreased (1.479184 --> 1.479184).         Saving model ...\n",
      "Epoch: 3422 \tTraining Loss: 1.077753 \tValidation Loss: 1.479182\n",
      "Validation loss decreased (1.479184 --> 1.479182).         Saving model ...\n",
      "Epoch: 3423 \tTraining Loss: 1.077751 \tValidation Loss: 1.479182\n",
      "Validation loss decreased (1.479182 --> 1.479182).         Saving model ...\n",
      "Epoch: 3424 \tTraining Loss: 1.077749 \tValidation Loss: 1.479181\n",
      "Validation loss decreased (1.479182 --> 1.479181).         Saving model ...\n",
      "Epoch: 3425 \tTraining Loss: 1.077747 \tValidation Loss: 1.479181\n",
      "Validation loss decreased (1.479181 --> 1.479181).         Saving model ...\n",
      "Epoch: 3426 \tTraining Loss: 1.077745 \tValidation Loss: 1.479180\n",
      "Validation loss decreased (1.479181 --> 1.479180).         Saving model ...\n",
      "Epoch: 3427 \tTraining Loss: 1.077744 \tValidation Loss: 1.479180\n",
      "Epoch: 3428 \tTraining Loss: 1.077742 \tValidation Loss: 1.479179\n",
      "Validation loss decreased (1.479180 --> 1.479179).         Saving model ...\n",
      "Epoch: 3429 \tTraining Loss: 1.077740 \tValidation Loss: 1.479177\n",
      "Validation loss decreased (1.479179 --> 1.479177).         Saving model ...\n",
      "Epoch: 3430 \tTraining Loss: 1.077738 \tValidation Loss: 1.479177\n",
      "Validation loss decreased (1.479177 --> 1.479177).         Saving model ...\n",
      "Epoch: 3431 \tTraining Loss: 1.077736 \tValidation Loss: 1.479176\n",
      "Validation loss decreased (1.479177 --> 1.479176).         Saving model ...\n",
      "Epoch: 3432 \tTraining Loss: 1.077734 \tValidation Loss: 1.479175\n",
      "Validation loss decreased (1.479176 --> 1.479175).         Saving model ...\n",
      "Epoch: 3433 \tTraining Loss: 1.077732 \tValidation Loss: 1.479175\n",
      "Validation loss decreased (1.479175 --> 1.479175).         Saving model ...\n",
      "Epoch: 3434 \tTraining Loss: 1.077730 \tValidation Loss: 1.479174\n",
      "Validation loss decreased (1.479175 --> 1.479174).         Saving model ...\n",
      "Epoch: 3435 \tTraining Loss: 1.077728 \tValidation Loss: 1.479174\n",
      "Epoch: 3436 \tTraining Loss: 1.077726 \tValidation Loss: 1.479174\n",
      "Validation loss decreased (1.479174 --> 1.479174).         Saving model ...\n",
      "Epoch: 3437 \tTraining Loss: 1.077724 \tValidation Loss: 1.479173\n",
      "Validation loss decreased (1.479174 --> 1.479173).         Saving model ...\n",
      "Epoch: 3438 \tTraining Loss: 1.077722 \tValidation Loss: 1.479174\n",
      "Epoch: 3439 \tTraining Loss: 1.077721 \tValidation Loss: 1.479173\n",
      "Epoch: 3440 \tTraining Loss: 1.077719 \tValidation Loss: 1.479173\n",
      "Validation loss decreased (1.479173 --> 1.479173).         Saving model ...\n",
      "Epoch: 3441 \tTraining Loss: 1.077717 \tValidation Loss: 1.479173\n",
      "Validation loss decreased (1.479173 --> 1.479173).         Saving model ...\n",
      "Epoch: 3442 \tTraining Loss: 1.077715 \tValidation Loss: 1.479172\n",
      "Validation loss decreased (1.479173 --> 1.479172).         Saving model ...\n",
      "Epoch: 3443 \tTraining Loss: 1.077713 \tValidation Loss: 1.479172\n",
      "Validation loss decreased (1.479172 --> 1.479172).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3444 \tTraining Loss: 1.077711 \tValidation Loss: 1.479171\n",
      "Validation loss decreased (1.479172 --> 1.479171).         Saving model ...\n",
      "Epoch: 3445 \tTraining Loss: 1.077709 \tValidation Loss: 1.479171\n",
      "Validation loss decreased (1.479171 --> 1.479171).         Saving model ...\n",
      "Epoch: 3446 \tTraining Loss: 1.077707 \tValidation Loss: 1.479170\n",
      "Validation loss decreased (1.479171 --> 1.479170).         Saving model ...\n",
      "Epoch: 3447 \tTraining Loss: 1.077705 \tValidation Loss: 1.479169\n",
      "Validation loss decreased (1.479170 --> 1.479169).         Saving model ...\n",
      "Epoch: 3448 \tTraining Loss: 1.077703 \tValidation Loss: 1.479169\n",
      "Validation loss decreased (1.479169 --> 1.479169).         Saving model ...\n",
      "Epoch: 3449 \tTraining Loss: 1.077701 \tValidation Loss: 1.479169\n",
      "Epoch: 3450 \tTraining Loss: 1.077700 \tValidation Loss: 1.479167\n",
      "Validation loss decreased (1.479169 --> 1.479167).         Saving model ...\n",
      "Epoch: 3451 \tTraining Loss: 1.077698 \tValidation Loss: 1.479167\n",
      "Validation loss decreased (1.479167 --> 1.479167).         Saving model ...\n",
      "Epoch: 3452 \tTraining Loss: 1.077696 \tValidation Loss: 1.479167\n",
      "Epoch: 3453 \tTraining Loss: 1.077694 \tValidation Loss: 1.479166\n",
      "Validation loss decreased (1.479167 --> 1.479166).         Saving model ...\n",
      "Epoch: 3454 \tTraining Loss: 1.077692 \tValidation Loss: 1.479166\n",
      "Epoch: 3455 \tTraining Loss: 1.077690 \tValidation Loss: 1.479165\n",
      "Validation loss decreased (1.479166 --> 1.479165).         Saving model ...\n",
      "Epoch: 3456 \tTraining Loss: 1.077688 \tValidation Loss: 1.479164\n",
      "Validation loss decreased (1.479165 --> 1.479164).         Saving model ...\n",
      "Epoch: 3457 \tTraining Loss: 1.077686 \tValidation Loss: 1.479163\n",
      "Validation loss decreased (1.479164 --> 1.479163).         Saving model ...\n",
      "Epoch: 3458 \tTraining Loss: 1.077684 \tValidation Loss: 1.479162\n",
      "Validation loss decreased (1.479163 --> 1.479162).         Saving model ...\n",
      "Epoch: 3459 \tTraining Loss: 1.077682 \tValidation Loss: 1.479160\n",
      "Validation loss decreased (1.479162 --> 1.479160).         Saving model ...\n",
      "Epoch: 3460 \tTraining Loss: 1.077681 \tValidation Loss: 1.479159\n",
      "Validation loss decreased (1.479160 --> 1.479159).         Saving model ...\n",
      "Epoch: 3461 \tTraining Loss: 1.077679 \tValidation Loss: 1.479158\n",
      "Validation loss decreased (1.479159 --> 1.479158).         Saving model ...\n",
      "Epoch: 3462 \tTraining Loss: 1.077677 \tValidation Loss: 1.479156\n",
      "Validation loss decreased (1.479158 --> 1.479156).         Saving model ...\n",
      "Epoch: 3463 \tTraining Loss: 1.077675 \tValidation Loss: 1.479155\n",
      "Validation loss decreased (1.479156 --> 1.479155).         Saving model ...\n",
      "Epoch: 3464 \tTraining Loss: 1.077673 \tValidation Loss: 1.479154\n",
      "Validation loss decreased (1.479155 --> 1.479154).         Saving model ...\n",
      "Epoch: 3465 \tTraining Loss: 1.077671 \tValidation Loss: 1.479152\n",
      "Validation loss decreased (1.479154 --> 1.479152).         Saving model ...\n",
      "Epoch: 3466 \tTraining Loss: 1.077669 \tValidation Loss: 1.479151\n",
      "Validation loss decreased (1.479152 --> 1.479151).         Saving model ...\n",
      "Epoch: 3467 \tTraining Loss: 1.077667 \tValidation Loss: 1.479150\n",
      "Validation loss decreased (1.479151 --> 1.479150).         Saving model ...\n",
      "Epoch: 3468 \tTraining Loss: 1.077665 \tValidation Loss: 1.479148\n",
      "Validation loss decreased (1.479150 --> 1.479148).         Saving model ...\n",
      "Epoch: 3469 \tTraining Loss: 1.077664 \tValidation Loss: 1.479147\n",
      "Validation loss decreased (1.479148 --> 1.479147).         Saving model ...\n",
      "Epoch: 3470 \tTraining Loss: 1.077662 \tValidation Loss: 1.479146\n",
      "Validation loss decreased (1.479147 --> 1.479146).         Saving model ...\n",
      "Epoch: 3471 \tTraining Loss: 1.077660 \tValidation Loss: 1.479145\n",
      "Validation loss decreased (1.479146 --> 1.479145).         Saving model ...\n",
      "Epoch: 3472 \tTraining Loss: 1.077658 \tValidation Loss: 1.479144\n",
      "Validation loss decreased (1.479145 --> 1.479144).         Saving model ...\n",
      "Epoch: 3473 \tTraining Loss: 1.077656 \tValidation Loss: 1.479142\n",
      "Validation loss decreased (1.479144 --> 1.479142).         Saving model ...\n",
      "Epoch: 3474 \tTraining Loss: 1.077654 \tValidation Loss: 1.479141\n",
      "Validation loss decreased (1.479142 --> 1.479141).         Saving model ...\n",
      "Epoch: 3475 \tTraining Loss: 1.077652 \tValidation Loss: 1.479140\n",
      "Validation loss decreased (1.479141 --> 1.479140).         Saving model ...\n",
      "Epoch: 3476 \tTraining Loss: 1.077650 \tValidation Loss: 1.479139\n",
      "Validation loss decreased (1.479140 --> 1.479139).         Saving model ...\n",
      "Epoch: 3477 \tTraining Loss: 1.077649 \tValidation Loss: 1.479138\n",
      "Validation loss decreased (1.479139 --> 1.479138).         Saving model ...\n",
      "Epoch: 3478 \tTraining Loss: 1.077647 \tValidation Loss: 1.479137\n",
      "Validation loss decreased (1.479138 --> 1.479137).         Saving model ...\n",
      "Epoch: 3479 \tTraining Loss: 1.077645 \tValidation Loss: 1.479137\n",
      "Validation loss decreased (1.479137 --> 1.479137).         Saving model ...\n",
      "Epoch: 3480 \tTraining Loss: 1.077643 \tValidation Loss: 1.479136\n",
      "Validation loss decreased (1.479137 --> 1.479136).         Saving model ...\n",
      "Epoch: 3481 \tTraining Loss: 1.077641 \tValidation Loss: 1.479135\n",
      "Validation loss decreased (1.479136 --> 1.479135).         Saving model ...\n",
      "Epoch: 3482 \tTraining Loss: 1.077639 \tValidation Loss: 1.479134\n",
      "Validation loss decreased (1.479135 --> 1.479134).         Saving model ...\n",
      "Epoch: 3483 \tTraining Loss: 1.077637 \tValidation Loss: 1.479133\n",
      "Validation loss decreased (1.479134 --> 1.479133).         Saving model ...\n",
      "Epoch: 3484 \tTraining Loss: 1.077635 \tValidation Loss: 1.479132\n",
      "Validation loss decreased (1.479133 --> 1.479132).         Saving model ...\n",
      "Epoch: 3485 \tTraining Loss: 1.077634 \tValidation Loss: 1.479132\n",
      "Validation loss decreased (1.479132 --> 1.479132).         Saving model ...\n",
      "Epoch: 3486 \tTraining Loss: 1.077632 \tValidation Loss: 1.479131\n",
      "Validation loss decreased (1.479132 --> 1.479131).         Saving model ...\n",
      "Epoch: 3487 \tTraining Loss: 1.077630 \tValidation Loss: 1.479130\n",
      "Validation loss decreased (1.479131 --> 1.479130).         Saving model ...\n",
      "Epoch: 3488 \tTraining Loss: 1.077628 \tValidation Loss: 1.479130\n",
      "Validation loss decreased (1.479130 --> 1.479130).         Saving model ...\n",
      "Epoch: 3489 \tTraining Loss: 1.077626 \tValidation Loss: 1.479129\n",
      "Validation loss decreased (1.479130 --> 1.479129).         Saving model ...\n",
      "Epoch: 3490 \tTraining Loss: 1.077624 \tValidation Loss: 1.479128\n",
      "Validation loss decreased (1.479129 --> 1.479128).         Saving model ...\n",
      "Epoch: 3491 \tTraining Loss: 1.077622 \tValidation Loss: 1.479128\n",
      "Validation loss decreased (1.479128 --> 1.479128).         Saving model ...\n",
      "Epoch: 3492 \tTraining Loss: 1.077620 \tValidation Loss: 1.479128\n",
      "Validation loss decreased (1.479128 --> 1.479128).         Saving model ...\n",
      "Epoch: 3493 \tTraining Loss: 1.077619 \tValidation Loss: 1.479127\n",
      "Validation loss decreased (1.479128 --> 1.479127).         Saving model ...\n",
      "Epoch: 3494 \tTraining Loss: 1.077617 \tValidation Loss: 1.479125\n",
      "Validation loss decreased (1.479127 --> 1.479125).         Saving model ...\n",
      "Epoch: 3495 \tTraining Loss: 1.077615 \tValidation Loss: 1.479125\n",
      "Validation loss decreased (1.479125 --> 1.479125).         Saving model ...\n",
      "Epoch: 3496 \tTraining Loss: 1.077613 \tValidation Loss: 1.479125\n",
      "Validation loss decreased (1.479125 --> 1.479125).         Saving model ...\n",
      "Epoch: 3497 \tTraining Loss: 1.077611 \tValidation Loss: 1.479123\n",
      "Validation loss decreased (1.479125 --> 1.479123).         Saving model ...\n",
      "Epoch: 3498 \tTraining Loss: 1.077609 \tValidation Loss: 1.479123\n",
      "Validation loss decreased (1.479123 --> 1.479123).         Saving model ...\n",
      "Epoch: 3499 \tTraining Loss: 1.077607 \tValidation Loss: 1.479122\n",
      "Validation loss decreased (1.479123 --> 1.479122).         Saving model ...\n",
      "Epoch: 3500 \tTraining Loss: 1.077606 \tValidation Loss: 1.479121\n",
      "Validation loss decreased (1.479122 --> 1.479121).         Saving model ...\n",
      "Epoch: 3501 \tTraining Loss: 1.077604 \tValidation Loss: 1.479121\n",
      "Validation loss decreased (1.479121 --> 1.479121).         Saving model ...\n",
      "Epoch: 3502 \tTraining Loss: 1.077602 \tValidation Loss: 1.479120\n",
      "Validation loss decreased (1.479121 --> 1.479120).         Saving model ...\n",
      "Epoch: 3503 \tTraining Loss: 1.077600 \tValidation Loss: 1.479120\n",
      "Validation loss decreased (1.479120 --> 1.479120).         Saving model ...\n",
      "Epoch: 3504 \tTraining Loss: 1.077598 \tValidation Loss: 1.479119\n",
      "Validation loss decreased (1.479120 --> 1.479119).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3505 \tTraining Loss: 1.077596 \tValidation Loss: 1.479118\n",
      "Validation loss decreased (1.479119 --> 1.479118).         Saving model ...\n",
      "Epoch: 3506 \tTraining Loss: 1.077594 \tValidation Loss: 1.479117\n",
      "Validation loss decreased (1.479118 --> 1.479117).         Saving model ...\n",
      "Epoch: 3507 \tTraining Loss: 1.077592 \tValidation Loss: 1.479117\n",
      "Validation loss decreased (1.479117 --> 1.479117).         Saving model ...\n",
      "Epoch: 3508 \tTraining Loss: 1.077591 \tValidation Loss: 1.479116\n",
      "Validation loss decreased (1.479117 --> 1.479116).         Saving model ...\n",
      "Epoch: 3509 \tTraining Loss: 1.077589 \tValidation Loss: 1.479114\n",
      "Validation loss decreased (1.479116 --> 1.479114).         Saving model ...\n",
      "Epoch: 3510 \tTraining Loss: 1.077587 \tValidation Loss: 1.479113\n",
      "Validation loss decreased (1.479114 --> 1.479113).         Saving model ...\n",
      "Epoch: 3511 \tTraining Loss: 1.077585 \tValidation Loss: 1.479113\n",
      "Validation loss decreased (1.479113 --> 1.479113).         Saving model ...\n",
      "Epoch: 3512 \tTraining Loss: 1.077583 \tValidation Loss: 1.479112\n",
      "Validation loss decreased (1.479113 --> 1.479112).         Saving model ...\n",
      "Epoch: 3513 \tTraining Loss: 1.077581 \tValidation Loss: 1.479111\n",
      "Validation loss decreased (1.479112 --> 1.479111).         Saving model ...\n",
      "Epoch: 3514 \tTraining Loss: 1.077580 \tValidation Loss: 1.479110\n",
      "Validation loss decreased (1.479111 --> 1.479110).         Saving model ...\n",
      "Epoch: 3515 \tTraining Loss: 1.077578 \tValidation Loss: 1.479109\n",
      "Validation loss decreased (1.479110 --> 1.479109).         Saving model ...\n",
      "Epoch: 3516 \tTraining Loss: 1.077576 \tValidation Loss: 1.479108\n",
      "Validation loss decreased (1.479109 --> 1.479108).         Saving model ...\n",
      "Epoch: 3517 \tTraining Loss: 1.077574 \tValidation Loss: 1.479107\n",
      "Validation loss decreased (1.479108 --> 1.479107).         Saving model ...\n",
      "Epoch: 3518 \tTraining Loss: 1.077572 \tValidation Loss: 1.479107\n",
      "Validation loss decreased (1.479107 --> 1.479107).         Saving model ...\n",
      "Epoch: 3519 \tTraining Loss: 1.077570 \tValidation Loss: 1.479105\n",
      "Validation loss decreased (1.479107 --> 1.479105).         Saving model ...\n",
      "Epoch: 3520 \tTraining Loss: 1.077568 \tValidation Loss: 1.479105\n",
      "Validation loss decreased (1.479105 --> 1.479105).         Saving model ...\n",
      "Epoch: 3521 \tTraining Loss: 1.077567 \tValidation Loss: 1.479104\n",
      "Validation loss decreased (1.479105 --> 1.479104).         Saving model ...\n",
      "Epoch: 3522 \tTraining Loss: 1.077565 \tValidation Loss: 1.479103\n",
      "Validation loss decreased (1.479104 --> 1.479103).         Saving model ...\n",
      "Epoch: 3523 \tTraining Loss: 1.077563 \tValidation Loss: 1.479102\n",
      "Validation loss decreased (1.479103 --> 1.479102).         Saving model ...\n",
      "Epoch: 3524 \tTraining Loss: 1.077561 \tValidation Loss: 1.479102\n",
      "Validation loss decreased (1.479102 --> 1.479102).         Saving model ...\n",
      "Epoch: 3525 \tTraining Loss: 1.077559 \tValidation Loss: 1.479101\n",
      "Validation loss decreased (1.479102 --> 1.479101).         Saving model ...\n",
      "Epoch: 3526 \tTraining Loss: 1.077557 \tValidation Loss: 1.479101\n",
      "Validation loss decreased (1.479101 --> 1.479101).         Saving model ...\n",
      "Epoch: 3527 \tTraining Loss: 1.077556 \tValidation Loss: 1.479100\n",
      "Validation loss decreased (1.479101 --> 1.479100).         Saving model ...\n",
      "Epoch: 3528 \tTraining Loss: 1.077554 \tValidation Loss: 1.479100\n",
      "Validation loss decreased (1.479100 --> 1.479100).         Saving model ...\n",
      "Epoch: 3529 \tTraining Loss: 1.077552 \tValidation Loss: 1.479098\n",
      "Validation loss decreased (1.479100 --> 1.479098).         Saving model ...\n",
      "Epoch: 3530 \tTraining Loss: 1.077550 \tValidation Loss: 1.479097\n",
      "Validation loss decreased (1.479098 --> 1.479097).         Saving model ...\n",
      "Epoch: 3531 \tTraining Loss: 1.077548 \tValidation Loss: 1.479096\n",
      "Validation loss decreased (1.479097 --> 1.479096).         Saving model ...\n",
      "Epoch: 3532 \tTraining Loss: 1.077546 \tValidation Loss: 1.479095\n",
      "Validation loss decreased (1.479096 --> 1.479095).         Saving model ...\n",
      "Epoch: 3533 \tTraining Loss: 1.077545 \tValidation Loss: 1.479094\n",
      "Validation loss decreased (1.479095 --> 1.479094).         Saving model ...\n",
      "Epoch: 3534 \tTraining Loss: 1.077543 \tValidation Loss: 1.479093\n",
      "Validation loss decreased (1.479094 --> 1.479093).         Saving model ...\n",
      "Epoch: 3535 \tTraining Loss: 1.077541 \tValidation Loss: 1.479092\n",
      "Validation loss decreased (1.479093 --> 1.479092).         Saving model ...\n",
      "Epoch: 3536 \tTraining Loss: 1.077539 \tValidation Loss: 1.479091\n",
      "Validation loss decreased (1.479092 --> 1.479091).         Saving model ...\n",
      "Epoch: 3537 \tTraining Loss: 1.077537 \tValidation Loss: 1.479090\n",
      "Validation loss decreased (1.479091 --> 1.479090).         Saving model ...\n",
      "Epoch: 3538 \tTraining Loss: 1.077535 \tValidation Loss: 1.479090\n",
      "Validation loss decreased (1.479090 --> 1.479090).         Saving model ...\n",
      "Epoch: 3539 \tTraining Loss: 1.077534 \tValidation Loss: 1.479089\n",
      "Validation loss decreased (1.479090 --> 1.479089).         Saving model ...\n",
      "Epoch: 3540 \tTraining Loss: 1.077532 \tValidation Loss: 1.479088\n",
      "Validation loss decreased (1.479089 --> 1.479088).         Saving model ...\n",
      "Epoch: 3541 \tTraining Loss: 1.077530 \tValidation Loss: 1.479087\n",
      "Validation loss decreased (1.479088 --> 1.479087).         Saving model ...\n",
      "Epoch: 3542 \tTraining Loss: 1.077528 \tValidation Loss: 1.479087\n",
      "Validation loss decreased (1.479087 --> 1.479087).         Saving model ...\n",
      "Epoch: 3543 \tTraining Loss: 1.077526 \tValidation Loss: 1.479086\n",
      "Validation loss decreased (1.479087 --> 1.479086).         Saving model ...\n",
      "Epoch: 3544 \tTraining Loss: 1.077524 \tValidation Loss: 1.479085\n",
      "Validation loss decreased (1.479086 --> 1.479085).         Saving model ...\n",
      "Epoch: 3545 \tTraining Loss: 1.077523 \tValidation Loss: 1.479084\n",
      "Validation loss decreased (1.479085 --> 1.479084).         Saving model ...\n",
      "Epoch: 3546 \tTraining Loss: 1.077521 \tValidation Loss: 1.479083\n",
      "Validation loss decreased (1.479084 --> 1.479083).         Saving model ...\n",
      "Epoch: 3547 \tTraining Loss: 1.077519 \tValidation Loss: 1.479082\n",
      "Validation loss decreased (1.479083 --> 1.479082).         Saving model ...\n",
      "Epoch: 3548 \tTraining Loss: 1.077517 \tValidation Loss: 1.479082\n",
      "Validation loss decreased (1.479082 --> 1.479082).         Saving model ...\n",
      "Epoch: 3549 \tTraining Loss: 1.077515 \tValidation Loss: 1.479081\n",
      "Validation loss decreased (1.479082 --> 1.479081).         Saving model ...\n",
      "Epoch: 3550 \tTraining Loss: 1.077513 \tValidation Loss: 1.479080\n",
      "Validation loss decreased (1.479081 --> 1.479080).         Saving model ...\n",
      "Epoch: 3551 \tTraining Loss: 1.077512 \tValidation Loss: 1.479078\n",
      "Validation loss decreased (1.479080 --> 1.479078).         Saving model ...\n",
      "Epoch: 3552 \tTraining Loss: 1.077510 \tValidation Loss: 1.479077\n",
      "Validation loss decreased (1.479078 --> 1.479077).         Saving model ...\n",
      "Epoch: 3553 \tTraining Loss: 1.077508 \tValidation Loss: 1.479076\n",
      "Validation loss decreased (1.479077 --> 1.479076).         Saving model ...\n",
      "Epoch: 3554 \tTraining Loss: 1.077506 \tValidation Loss: 1.479076\n",
      "Validation loss decreased (1.479076 --> 1.479076).         Saving model ...\n",
      "Epoch: 3555 \tTraining Loss: 1.077504 \tValidation Loss: 1.479075\n",
      "Validation loss decreased (1.479076 --> 1.479075).         Saving model ...\n",
      "Epoch: 3556 \tTraining Loss: 1.077503 \tValidation Loss: 1.479073\n",
      "Validation loss decreased (1.479075 --> 1.479073).         Saving model ...\n",
      "Epoch: 3557 \tTraining Loss: 1.077501 \tValidation Loss: 1.479073\n",
      "Validation loss decreased (1.479073 --> 1.479073).         Saving model ...\n",
      "Epoch: 3558 \tTraining Loss: 1.077499 \tValidation Loss: 1.479073\n",
      "Validation loss decreased (1.479073 --> 1.479073).         Saving model ...\n",
      "Epoch: 3559 \tTraining Loss: 1.077497 \tValidation Loss: 1.479072\n",
      "Validation loss decreased (1.479073 --> 1.479072).         Saving model ...\n",
      "Epoch: 3560 \tTraining Loss: 1.077495 \tValidation Loss: 1.479071\n",
      "Validation loss decreased (1.479072 --> 1.479071).         Saving model ...\n",
      "Epoch: 3561 \tTraining Loss: 1.077493 \tValidation Loss: 1.479070\n",
      "Validation loss decreased (1.479071 --> 1.479070).         Saving model ...\n",
      "Epoch: 3562 \tTraining Loss: 1.077492 \tValidation Loss: 1.479069\n",
      "Validation loss decreased (1.479070 --> 1.479069).         Saving model ...\n",
      "Epoch: 3563 \tTraining Loss: 1.077490 \tValidation Loss: 1.479068\n",
      "Validation loss decreased (1.479069 --> 1.479068).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3564 \tTraining Loss: 1.077488 \tValidation Loss: 1.479067\n",
      "Validation loss decreased (1.479068 --> 1.479067).         Saving model ...\n",
      "Epoch: 3565 \tTraining Loss: 1.077486 \tValidation Loss: 1.479066\n",
      "Validation loss decreased (1.479067 --> 1.479066).         Saving model ...\n",
      "Epoch: 3566 \tTraining Loss: 1.077484 \tValidation Loss: 1.479066\n",
      "Validation loss decreased (1.479066 --> 1.479066).         Saving model ...\n",
      "Epoch: 3567 \tTraining Loss: 1.077483 \tValidation Loss: 1.479065\n",
      "Validation loss decreased (1.479066 --> 1.479065).         Saving model ...\n",
      "Epoch: 3568 \tTraining Loss: 1.077481 \tValidation Loss: 1.479064\n",
      "Validation loss decreased (1.479065 --> 1.479064).         Saving model ...\n",
      "Epoch: 3569 \tTraining Loss: 1.077479 \tValidation Loss: 1.479064\n",
      "Validation loss decreased (1.479064 --> 1.479064).         Saving model ...\n",
      "Epoch: 3570 \tTraining Loss: 1.077477 \tValidation Loss: 1.479063\n",
      "Validation loss decreased (1.479064 --> 1.479063).         Saving model ...\n",
      "Epoch: 3571 \tTraining Loss: 1.077475 \tValidation Loss: 1.479063\n",
      "Validation loss decreased (1.479063 --> 1.479063).         Saving model ...\n",
      "Epoch: 3572 \tTraining Loss: 1.077474 \tValidation Loss: 1.479062\n",
      "Validation loss decreased (1.479063 --> 1.479062).         Saving model ...\n",
      "Epoch: 3573 \tTraining Loss: 1.077472 \tValidation Loss: 1.479061\n",
      "Validation loss decreased (1.479062 --> 1.479061).         Saving model ...\n",
      "Epoch: 3574 \tTraining Loss: 1.077470 \tValidation Loss: 1.479061\n",
      "Validation loss decreased (1.479061 --> 1.479061).         Saving model ...\n",
      "Epoch: 3575 \tTraining Loss: 1.077468 \tValidation Loss: 1.479059\n",
      "Validation loss decreased (1.479061 --> 1.479059).         Saving model ...\n",
      "Epoch: 3576 \tTraining Loss: 1.077466 \tValidation Loss: 1.479057\n",
      "Validation loss decreased (1.479059 --> 1.479057).         Saving model ...\n",
      "Epoch: 3577 \tTraining Loss: 1.077465 \tValidation Loss: 1.479056\n",
      "Validation loss decreased (1.479057 --> 1.479056).         Saving model ...\n",
      "Epoch: 3578 \tTraining Loss: 1.077463 \tValidation Loss: 1.479054\n",
      "Validation loss decreased (1.479056 --> 1.479054).         Saving model ...\n",
      "Epoch: 3579 \tTraining Loss: 1.077461 \tValidation Loss: 1.479054\n",
      "Validation loss decreased (1.479054 --> 1.479054).         Saving model ...\n",
      "Epoch: 3580 \tTraining Loss: 1.077459 \tValidation Loss: 1.479052\n",
      "Validation loss decreased (1.479054 --> 1.479052).         Saving model ...\n",
      "Epoch: 3581 \tTraining Loss: 1.077457 \tValidation Loss: 1.479051\n",
      "Validation loss decreased (1.479052 --> 1.479051).         Saving model ...\n",
      "Epoch: 3582 \tTraining Loss: 1.077456 \tValidation Loss: 1.479050\n",
      "Validation loss decreased (1.479051 --> 1.479050).         Saving model ...\n",
      "Epoch: 3583 \tTraining Loss: 1.077454 \tValidation Loss: 1.479049\n",
      "Validation loss decreased (1.479050 --> 1.479049).         Saving model ...\n",
      "Epoch: 3584 \tTraining Loss: 1.077452 \tValidation Loss: 1.479047\n",
      "Validation loss decreased (1.479049 --> 1.479047).         Saving model ...\n",
      "Epoch: 3585 \tTraining Loss: 1.077450 \tValidation Loss: 1.479047\n",
      "Validation loss decreased (1.479047 --> 1.479047).         Saving model ...\n",
      "Epoch: 3586 \tTraining Loss: 1.077448 \tValidation Loss: 1.479045\n",
      "Validation loss decreased (1.479047 --> 1.479045).         Saving model ...\n",
      "Epoch: 3587 \tTraining Loss: 1.077447 \tValidation Loss: 1.479043\n",
      "Validation loss decreased (1.479045 --> 1.479043).         Saving model ...\n",
      "Epoch: 3588 \tTraining Loss: 1.077445 \tValidation Loss: 1.479043\n",
      "Validation loss decreased (1.479043 --> 1.479043).         Saving model ...\n",
      "Epoch: 3589 \tTraining Loss: 1.077443 \tValidation Loss: 1.479042\n",
      "Validation loss decreased (1.479043 --> 1.479042).         Saving model ...\n",
      "Epoch: 3590 \tTraining Loss: 1.077441 \tValidation Loss: 1.479041\n",
      "Validation loss decreased (1.479042 --> 1.479041).         Saving model ...\n",
      "Epoch: 3591 \tTraining Loss: 1.077439 \tValidation Loss: 1.479039\n",
      "Validation loss decreased (1.479041 --> 1.479039).         Saving model ...\n",
      "Epoch: 3592 \tTraining Loss: 1.077438 \tValidation Loss: 1.479039\n",
      "Validation loss decreased (1.479039 --> 1.479039).         Saving model ...\n",
      "Epoch: 3593 \tTraining Loss: 1.077436 \tValidation Loss: 1.479038\n",
      "Validation loss decreased (1.479039 --> 1.479038).         Saving model ...\n",
      "Epoch: 3594 \tTraining Loss: 1.077434 \tValidation Loss: 1.479036\n",
      "Validation loss decreased (1.479038 --> 1.479036).         Saving model ...\n",
      "Epoch: 3595 \tTraining Loss: 1.077432 \tValidation Loss: 1.479036\n",
      "Validation loss decreased (1.479036 --> 1.479036).         Saving model ...\n",
      "Epoch: 3596 \tTraining Loss: 1.077430 \tValidation Loss: 1.479034\n",
      "Validation loss decreased (1.479036 --> 1.479034).         Saving model ...\n",
      "Epoch: 3597 \tTraining Loss: 1.077429 \tValidation Loss: 1.479035\n",
      "Epoch: 3598 \tTraining Loss: 1.077427 \tValidation Loss: 1.479033\n",
      "Validation loss decreased (1.479034 --> 1.479033).         Saving model ...\n",
      "Epoch: 3599 \tTraining Loss: 1.077425 \tValidation Loss: 1.479032\n",
      "Validation loss decreased (1.479033 --> 1.479032).         Saving model ...\n",
      "Epoch: 3600 \tTraining Loss: 1.077423 \tValidation Loss: 1.479032\n",
      "Validation loss decreased (1.479032 --> 1.479032).         Saving model ...\n",
      "Epoch: 3601 \tTraining Loss: 1.077422 \tValidation Loss: 1.479031\n",
      "Validation loss decreased (1.479032 --> 1.479031).         Saving model ...\n",
      "Epoch: 3602 \tTraining Loss: 1.077420 \tValidation Loss: 1.479030\n",
      "Validation loss decreased (1.479031 --> 1.479030).         Saving model ...\n",
      "Epoch: 3603 \tTraining Loss: 1.077418 \tValidation Loss: 1.479028\n",
      "Validation loss decreased (1.479030 --> 1.479028).         Saving model ...\n",
      "Epoch: 3604 \tTraining Loss: 1.077416 \tValidation Loss: 1.479028\n",
      "Validation loss decreased (1.479028 --> 1.479028).         Saving model ...\n",
      "Epoch: 3605 \tTraining Loss: 1.077414 \tValidation Loss: 1.479027\n",
      "Validation loss decreased (1.479028 --> 1.479027).         Saving model ...\n",
      "Epoch: 3606 \tTraining Loss: 1.077413 \tValidation Loss: 1.479026\n",
      "Validation loss decreased (1.479027 --> 1.479026).         Saving model ...\n",
      "Epoch: 3607 \tTraining Loss: 1.077411 \tValidation Loss: 1.479025\n",
      "Validation loss decreased (1.479026 --> 1.479025).         Saving model ...\n",
      "Epoch: 3608 \tTraining Loss: 1.077409 \tValidation Loss: 1.479025\n",
      "Validation loss decreased (1.479025 --> 1.479025).         Saving model ...\n",
      "Epoch: 3609 \tTraining Loss: 1.077407 \tValidation Loss: 1.479024\n",
      "Validation loss decreased (1.479025 --> 1.479024).         Saving model ...\n",
      "Epoch: 3610 \tTraining Loss: 1.077406 \tValidation Loss: 1.479024\n",
      "Validation loss decreased (1.479024 --> 1.479024).         Saving model ...\n",
      "Epoch: 3611 \tTraining Loss: 1.077404 \tValidation Loss: 1.479023\n",
      "Validation loss decreased (1.479024 --> 1.479023).         Saving model ...\n",
      "Epoch: 3612 \tTraining Loss: 1.077402 \tValidation Loss: 1.479023\n",
      "Validation loss decreased (1.479023 --> 1.479023).         Saving model ...\n",
      "Epoch: 3613 \tTraining Loss: 1.077400 \tValidation Loss: 1.479022\n",
      "Validation loss decreased (1.479023 --> 1.479022).         Saving model ...\n",
      "Epoch: 3614 \tTraining Loss: 1.077398 \tValidation Loss: 1.479021\n",
      "Validation loss decreased (1.479022 --> 1.479021).         Saving model ...\n",
      "Epoch: 3615 \tTraining Loss: 1.077397 \tValidation Loss: 1.479021\n",
      "Validation loss decreased (1.479021 --> 1.479021).         Saving model ...\n",
      "Epoch: 3616 \tTraining Loss: 1.077395 \tValidation Loss: 1.479020\n",
      "Validation loss decreased (1.479021 --> 1.479020).         Saving model ...\n",
      "Epoch: 3617 \tTraining Loss: 1.077393 \tValidation Loss: 1.479020\n",
      "Validation loss decreased (1.479020 --> 1.479020).         Saving model ...\n",
      "Epoch: 3618 \tTraining Loss: 1.077391 \tValidation Loss: 1.479019\n",
      "Validation loss decreased (1.479020 --> 1.479019).         Saving model ...\n",
      "Epoch: 3619 \tTraining Loss: 1.077390 \tValidation Loss: 1.479019\n",
      "Epoch: 3620 \tTraining Loss: 1.077388 \tValidation Loss: 1.479018\n",
      "Validation loss decreased (1.479019 --> 1.479018).         Saving model ...\n",
      "Epoch: 3621 \tTraining Loss: 1.077386 \tValidation Loss: 1.479018\n",
      "Validation loss decreased (1.479018 --> 1.479018).         Saving model ...\n",
      "Epoch: 3622 \tTraining Loss: 1.077384 \tValidation Loss: 1.479017\n",
      "Validation loss decreased (1.479018 --> 1.479017).         Saving model ...\n",
      "Epoch: 3623 \tTraining Loss: 1.077382 \tValidation Loss: 1.479015\n",
      "Validation loss decreased (1.479017 --> 1.479015).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3624 \tTraining Loss: 1.077381 \tValidation Loss: 1.479015\n",
      "Validation loss decreased (1.479015 --> 1.479015).         Saving model ...\n",
      "Epoch: 3625 \tTraining Loss: 1.077379 \tValidation Loss: 1.479014\n",
      "Validation loss decreased (1.479015 --> 1.479014).         Saving model ...\n",
      "Epoch: 3626 \tTraining Loss: 1.077377 \tValidation Loss: 1.479013\n",
      "Validation loss decreased (1.479014 --> 1.479013).         Saving model ...\n",
      "Epoch: 3627 \tTraining Loss: 1.077375 \tValidation Loss: 1.479013\n",
      "Validation loss decreased (1.479013 --> 1.479013).         Saving model ...\n",
      "Epoch: 3628 \tTraining Loss: 1.077374 \tValidation Loss: 1.479012\n",
      "Validation loss decreased (1.479013 --> 1.479012).         Saving model ...\n",
      "Epoch: 3629 \tTraining Loss: 1.077372 \tValidation Loss: 1.479011\n",
      "Validation loss decreased (1.479012 --> 1.479011).         Saving model ...\n",
      "Epoch: 3630 \tTraining Loss: 1.077370 \tValidation Loss: 1.479010\n",
      "Validation loss decreased (1.479011 --> 1.479010).         Saving model ...\n",
      "Epoch: 3631 \tTraining Loss: 1.077368 \tValidation Loss: 1.479009\n",
      "Validation loss decreased (1.479010 --> 1.479009).         Saving model ...\n",
      "Epoch: 3632 \tTraining Loss: 1.077367 \tValidation Loss: 1.479008\n",
      "Validation loss decreased (1.479009 --> 1.479008).         Saving model ...\n",
      "Epoch: 3633 \tTraining Loss: 1.077365 \tValidation Loss: 1.479008\n",
      "Validation loss decreased (1.479008 --> 1.479008).         Saving model ...\n",
      "Epoch: 3634 \tTraining Loss: 1.077363 \tValidation Loss: 1.479007\n",
      "Validation loss decreased (1.479008 --> 1.479007).         Saving model ...\n",
      "Epoch: 3635 \tTraining Loss: 1.077361 \tValidation Loss: 1.479006\n",
      "Validation loss decreased (1.479007 --> 1.479006).         Saving model ...\n",
      "Epoch: 3636 \tTraining Loss: 1.077360 \tValidation Loss: 1.479005\n",
      "Validation loss decreased (1.479006 --> 1.479005).         Saving model ...\n",
      "Epoch: 3637 \tTraining Loss: 1.077358 \tValidation Loss: 1.479004\n",
      "Validation loss decreased (1.479005 --> 1.479004).         Saving model ...\n",
      "Epoch: 3638 \tTraining Loss: 1.077356 \tValidation Loss: 1.479003\n",
      "Validation loss decreased (1.479004 --> 1.479003).         Saving model ...\n",
      "Epoch: 3639 \tTraining Loss: 1.077354 \tValidation Loss: 1.479003\n",
      "Validation loss decreased (1.479003 --> 1.479003).         Saving model ...\n",
      "Epoch: 3640 \tTraining Loss: 1.077353 \tValidation Loss: 1.479002\n",
      "Validation loss decreased (1.479003 --> 1.479002).         Saving model ...\n",
      "Epoch: 3641 \tTraining Loss: 1.077351 \tValidation Loss: 1.479001\n",
      "Validation loss decreased (1.479002 --> 1.479001).         Saving model ...\n",
      "Epoch: 3642 \tTraining Loss: 1.077349 \tValidation Loss: 1.479000\n",
      "Validation loss decreased (1.479001 --> 1.479000).         Saving model ...\n",
      "Epoch: 3643 \tTraining Loss: 1.077347 \tValidation Loss: 1.478999\n",
      "Validation loss decreased (1.479000 --> 1.478999).         Saving model ...\n",
      "Epoch: 3644 \tTraining Loss: 1.077346 \tValidation Loss: 1.478998\n",
      "Validation loss decreased (1.478999 --> 1.478998).         Saving model ...\n",
      "Epoch: 3645 \tTraining Loss: 1.077344 \tValidation Loss: 1.478997\n",
      "Validation loss decreased (1.478998 --> 1.478997).         Saving model ...\n",
      "Epoch: 3646 \tTraining Loss: 1.077342 \tValidation Loss: 1.478996\n",
      "Validation loss decreased (1.478997 --> 1.478996).         Saving model ...\n",
      "Epoch: 3647 \tTraining Loss: 1.077340 \tValidation Loss: 1.478996\n",
      "Validation loss decreased (1.478996 --> 1.478996).         Saving model ...\n",
      "Epoch: 3648 \tTraining Loss: 1.077339 \tValidation Loss: 1.478994\n",
      "Validation loss decreased (1.478996 --> 1.478994).         Saving model ...\n",
      "Epoch: 3649 \tTraining Loss: 1.077337 \tValidation Loss: 1.478993\n",
      "Validation loss decreased (1.478994 --> 1.478993).         Saving model ...\n",
      "Epoch: 3650 \tTraining Loss: 1.077335 \tValidation Loss: 1.478992\n",
      "Validation loss decreased (1.478993 --> 1.478992).         Saving model ...\n",
      "Epoch: 3651 \tTraining Loss: 1.077333 \tValidation Loss: 1.478991\n",
      "Validation loss decreased (1.478992 --> 1.478991).         Saving model ...\n",
      "Epoch: 3652 \tTraining Loss: 1.077332 \tValidation Loss: 1.478991\n",
      "Validation loss decreased (1.478991 --> 1.478991).         Saving model ...\n",
      "Epoch: 3653 \tTraining Loss: 1.077330 \tValidation Loss: 1.478990\n",
      "Validation loss decreased (1.478991 --> 1.478990).         Saving model ...\n",
      "Epoch: 3654 \tTraining Loss: 1.077328 \tValidation Loss: 1.478990\n",
      "Validation loss decreased (1.478990 --> 1.478990).         Saving model ...\n",
      "Epoch: 3655 \tTraining Loss: 1.077326 \tValidation Loss: 1.478990\n",
      "Epoch: 3656 \tTraining Loss: 1.077325 \tValidation Loss: 1.478989\n",
      "Validation loss decreased (1.478990 --> 1.478989).         Saving model ...\n",
      "Epoch: 3657 \tTraining Loss: 1.077323 \tValidation Loss: 1.478988\n",
      "Validation loss decreased (1.478989 --> 1.478988).         Saving model ...\n",
      "Epoch: 3658 \tTraining Loss: 1.077321 \tValidation Loss: 1.478988\n",
      "Validation loss decreased (1.478988 --> 1.478988).         Saving model ...\n",
      "Epoch: 3659 \tTraining Loss: 1.077319 \tValidation Loss: 1.478987\n",
      "Validation loss decreased (1.478988 --> 1.478987).         Saving model ...\n",
      "Epoch: 3660 \tTraining Loss: 1.077318 \tValidation Loss: 1.478986\n",
      "Validation loss decreased (1.478987 --> 1.478986).         Saving model ...\n",
      "Epoch: 3661 \tTraining Loss: 1.077316 \tValidation Loss: 1.478986\n",
      "Validation loss decreased (1.478986 --> 1.478986).         Saving model ...\n",
      "Epoch: 3662 \tTraining Loss: 1.077314 \tValidation Loss: 1.478985\n",
      "Validation loss decreased (1.478986 --> 1.478985).         Saving model ...\n",
      "Epoch: 3663 \tTraining Loss: 1.077312 \tValidation Loss: 1.478985\n",
      "Validation loss decreased (1.478985 --> 1.478985).         Saving model ...\n",
      "Epoch: 3664 \tTraining Loss: 1.077311 \tValidation Loss: 1.478984\n",
      "Validation loss decreased (1.478985 --> 1.478984).         Saving model ...\n",
      "Epoch: 3665 \tTraining Loss: 1.077309 \tValidation Loss: 1.478983\n",
      "Validation loss decreased (1.478984 --> 1.478983).         Saving model ...\n",
      "Epoch: 3666 \tTraining Loss: 1.077307 \tValidation Loss: 1.478983\n",
      "Validation loss decreased (1.478983 --> 1.478983).         Saving model ...\n",
      "Epoch: 3667 \tTraining Loss: 1.077305 \tValidation Loss: 1.478982\n",
      "Validation loss decreased (1.478983 --> 1.478982).         Saving model ...\n",
      "Epoch: 3668 \tTraining Loss: 1.077304 \tValidation Loss: 1.478981\n",
      "Validation loss decreased (1.478982 --> 1.478981).         Saving model ...\n",
      "Epoch: 3669 \tTraining Loss: 1.077302 \tValidation Loss: 1.478980\n",
      "Validation loss decreased (1.478981 --> 1.478980).         Saving model ...\n",
      "Epoch: 3670 \tTraining Loss: 1.077300 \tValidation Loss: 1.478980\n",
      "Validation loss decreased (1.478980 --> 1.478980).         Saving model ...\n",
      "Epoch: 3671 \tTraining Loss: 1.077298 \tValidation Loss: 1.478979\n",
      "Validation loss decreased (1.478980 --> 1.478979).         Saving model ...\n",
      "Epoch: 3672 \tTraining Loss: 1.077297 \tValidation Loss: 1.478978\n",
      "Validation loss decreased (1.478979 --> 1.478978).         Saving model ...\n",
      "Epoch: 3673 \tTraining Loss: 1.077295 \tValidation Loss: 1.478977\n",
      "Validation loss decreased (1.478978 --> 1.478977).         Saving model ...\n",
      "Epoch: 3674 \tTraining Loss: 1.077293 \tValidation Loss: 1.478976\n",
      "Validation loss decreased (1.478977 --> 1.478976).         Saving model ...\n",
      "Epoch: 3675 \tTraining Loss: 1.077292 \tValidation Loss: 1.478975\n",
      "Validation loss decreased (1.478976 --> 1.478975).         Saving model ...\n",
      "Epoch: 3676 \tTraining Loss: 1.077290 \tValidation Loss: 1.478975\n",
      "Validation loss decreased (1.478975 --> 1.478975).         Saving model ...\n",
      "Epoch: 3677 \tTraining Loss: 1.077288 \tValidation Loss: 1.478973\n",
      "Validation loss decreased (1.478975 --> 1.478973).         Saving model ...\n",
      "Epoch: 3678 \tTraining Loss: 1.077286 \tValidation Loss: 1.478972\n",
      "Validation loss decreased (1.478973 --> 1.478972).         Saving model ...\n",
      "Epoch: 3679 \tTraining Loss: 1.077285 \tValidation Loss: 1.478972\n",
      "Validation loss decreased (1.478972 --> 1.478972).         Saving model ...\n",
      "Epoch: 3680 \tTraining Loss: 1.077283 \tValidation Loss: 1.478971\n",
      "Validation loss decreased (1.478972 --> 1.478971).         Saving model ...\n",
      "Epoch: 3681 \tTraining Loss: 1.077281 \tValidation Loss: 1.478970\n",
      "Validation loss decreased (1.478971 --> 1.478970).         Saving model ...\n",
      "Epoch: 3682 \tTraining Loss: 1.077279 \tValidation Loss: 1.478969\n",
      "Validation loss decreased (1.478970 --> 1.478969).         Saving model ...\n",
      "Epoch: 3683 \tTraining Loss: 1.077278 \tValidation Loss: 1.478967\n",
      "Validation loss decreased (1.478969 --> 1.478967).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3684 \tTraining Loss: 1.077276 \tValidation Loss: 1.478967\n",
      "Validation loss decreased (1.478967 --> 1.478967).         Saving model ...\n",
      "Epoch: 3685 \tTraining Loss: 1.077274 \tValidation Loss: 1.478964\n",
      "Validation loss decreased (1.478967 --> 1.478964).         Saving model ...\n",
      "Epoch: 3686 \tTraining Loss: 1.077273 \tValidation Loss: 1.478964\n",
      "Validation loss decreased (1.478964 --> 1.478964).         Saving model ...\n",
      "Epoch: 3687 \tTraining Loss: 1.077271 \tValidation Loss: 1.478962\n",
      "Validation loss decreased (1.478964 --> 1.478962).         Saving model ...\n",
      "Epoch: 3688 \tTraining Loss: 1.077269 \tValidation Loss: 1.478961\n",
      "Validation loss decreased (1.478962 --> 1.478961).         Saving model ...\n",
      "Epoch: 3689 \tTraining Loss: 1.077267 \tValidation Loss: 1.478960\n",
      "Validation loss decreased (1.478961 --> 1.478960).         Saving model ...\n",
      "Epoch: 3690 \tTraining Loss: 1.077266 \tValidation Loss: 1.478959\n",
      "Validation loss decreased (1.478960 --> 1.478959).         Saving model ...\n",
      "Epoch: 3691 \tTraining Loss: 1.077264 \tValidation Loss: 1.478957\n",
      "Validation loss decreased (1.478959 --> 1.478957).         Saving model ...\n",
      "Epoch: 3692 \tTraining Loss: 1.077262 \tValidation Loss: 1.478956\n",
      "Validation loss decreased (1.478957 --> 1.478956).         Saving model ...\n",
      "Epoch: 3693 \tTraining Loss: 1.077261 \tValidation Loss: 1.478955\n",
      "Validation loss decreased (1.478956 --> 1.478955).         Saving model ...\n",
      "Epoch: 3694 \tTraining Loss: 1.077259 \tValidation Loss: 1.478954\n",
      "Validation loss decreased (1.478955 --> 1.478954).         Saving model ...\n",
      "Epoch: 3695 \tTraining Loss: 1.077257 \tValidation Loss: 1.478953\n",
      "Validation loss decreased (1.478954 --> 1.478953).         Saving model ...\n",
      "Epoch: 3696 \tTraining Loss: 1.077255 \tValidation Loss: 1.478951\n",
      "Validation loss decreased (1.478953 --> 1.478951).         Saving model ...\n",
      "Epoch: 3697 \tTraining Loss: 1.077254 \tValidation Loss: 1.478951\n",
      "Validation loss decreased (1.478951 --> 1.478951).         Saving model ...\n",
      "Epoch: 3698 \tTraining Loss: 1.077252 \tValidation Loss: 1.478949\n",
      "Validation loss decreased (1.478951 --> 1.478949).         Saving model ...\n",
      "Epoch: 3699 \tTraining Loss: 1.077250 \tValidation Loss: 1.478948\n",
      "Validation loss decreased (1.478949 --> 1.478948).         Saving model ...\n",
      "Epoch: 3700 \tTraining Loss: 1.077249 \tValidation Loss: 1.478947\n",
      "Validation loss decreased (1.478948 --> 1.478947).         Saving model ...\n",
      "Epoch: 3701 \tTraining Loss: 1.077247 \tValidation Loss: 1.478946\n",
      "Validation loss decreased (1.478947 --> 1.478946).         Saving model ...\n",
      "Epoch: 3702 \tTraining Loss: 1.077245 \tValidation Loss: 1.478945\n",
      "Validation loss decreased (1.478946 --> 1.478945).         Saving model ...\n",
      "Epoch: 3703 \tTraining Loss: 1.077243 \tValidation Loss: 1.478944\n",
      "Validation loss decreased (1.478945 --> 1.478944).         Saving model ...\n",
      "Epoch: 3704 \tTraining Loss: 1.077242 \tValidation Loss: 1.478943\n",
      "Validation loss decreased (1.478944 --> 1.478943).         Saving model ...\n",
      "Epoch: 3705 \tTraining Loss: 1.077240 \tValidation Loss: 1.478943\n",
      "Validation loss decreased (1.478943 --> 1.478943).         Saving model ...\n",
      "Epoch: 3706 \tTraining Loss: 1.077238 \tValidation Loss: 1.478943\n",
      "Validation loss decreased (1.478943 --> 1.478943).         Saving model ...\n",
      "Epoch: 3707 \tTraining Loss: 1.077237 \tValidation Loss: 1.478942\n",
      "Validation loss decreased (1.478943 --> 1.478942).         Saving model ...\n",
      "Epoch: 3708 \tTraining Loss: 1.077235 \tValidation Loss: 1.478942\n",
      "Validation loss decreased (1.478942 --> 1.478942).         Saving model ...\n",
      "Epoch: 3709 \tTraining Loss: 1.077233 \tValidation Loss: 1.478942\n",
      "Epoch: 3710 \tTraining Loss: 1.077231 \tValidation Loss: 1.478942\n",
      "Epoch: 3711 \tTraining Loss: 1.077230 \tValidation Loss: 1.478942\n",
      "Epoch: 3712 \tTraining Loss: 1.077228 \tValidation Loss: 1.478942\n",
      "Validation loss decreased (1.478942 --> 1.478942).         Saving model ...\n",
      "Epoch: 3713 \tTraining Loss: 1.077226 \tValidation Loss: 1.478942\n",
      "Epoch: 3714 \tTraining Loss: 1.077225 \tValidation Loss: 1.478942\n",
      "Epoch: 3715 \tTraining Loss: 1.077223 \tValidation Loss: 1.478942\n",
      "Epoch: 3716 \tTraining Loss: 1.077221 \tValidation Loss: 1.478941\n",
      "Validation loss decreased (1.478942 --> 1.478941).         Saving model ...\n",
      "Epoch: 3717 \tTraining Loss: 1.077220 \tValidation Loss: 1.478941\n",
      "Epoch: 3718 \tTraining Loss: 1.077218 \tValidation Loss: 1.478940\n",
      "Validation loss decreased (1.478941 --> 1.478940).         Saving model ...\n",
      "Epoch: 3719 \tTraining Loss: 1.077216 \tValidation Loss: 1.478940\n",
      "Validation loss decreased (1.478940 --> 1.478940).         Saving model ...\n",
      "Epoch: 3720 \tTraining Loss: 1.077214 \tValidation Loss: 1.478939\n",
      "Validation loss decreased (1.478940 --> 1.478939).         Saving model ...\n",
      "Epoch: 3721 \tTraining Loss: 1.077213 \tValidation Loss: 1.478939\n",
      "Epoch: 3722 \tTraining Loss: 1.077211 \tValidation Loss: 1.478939\n",
      "Validation loss decreased (1.478939 --> 1.478939).         Saving model ...\n",
      "Epoch: 3723 \tTraining Loss: 1.077209 \tValidation Loss: 1.478940\n",
      "Epoch: 3724 \tTraining Loss: 1.077208 \tValidation Loss: 1.478939\n",
      "Validation loss decreased (1.478939 --> 1.478939).         Saving model ...\n",
      "Epoch: 3725 \tTraining Loss: 1.077206 \tValidation Loss: 1.478938\n",
      "Validation loss decreased (1.478939 --> 1.478938).         Saving model ...\n",
      "Epoch: 3726 \tTraining Loss: 1.077204 \tValidation Loss: 1.478937\n",
      "Validation loss decreased (1.478938 --> 1.478937).         Saving model ...\n",
      "Epoch: 3727 \tTraining Loss: 1.077203 \tValidation Loss: 1.478936\n",
      "Validation loss decreased (1.478937 --> 1.478936).         Saving model ...\n",
      "Epoch: 3728 \tTraining Loss: 1.077201 \tValidation Loss: 1.478935\n",
      "Validation loss decreased (1.478936 --> 1.478935).         Saving model ...\n",
      "Epoch: 3729 \tTraining Loss: 1.077199 \tValidation Loss: 1.478934\n",
      "Validation loss decreased (1.478935 --> 1.478934).         Saving model ...\n",
      "Epoch: 3730 \tTraining Loss: 1.077198 \tValidation Loss: 1.478933\n",
      "Validation loss decreased (1.478934 --> 1.478933).         Saving model ...\n",
      "Epoch: 3731 \tTraining Loss: 1.077196 \tValidation Loss: 1.478933\n",
      "Validation loss decreased (1.478933 --> 1.478933).         Saving model ...\n",
      "Epoch: 3732 \tTraining Loss: 1.077194 \tValidation Loss: 1.478932\n",
      "Validation loss decreased (1.478933 --> 1.478932).         Saving model ...\n",
      "Epoch: 3733 \tTraining Loss: 1.077192 \tValidation Loss: 1.478931\n",
      "Validation loss decreased (1.478932 --> 1.478931).         Saving model ...\n",
      "Epoch: 3734 \tTraining Loss: 1.077191 \tValidation Loss: 1.478931\n",
      "Validation loss decreased (1.478931 --> 1.478931).         Saving model ...\n",
      "Epoch: 3735 \tTraining Loss: 1.077189 \tValidation Loss: 1.478930\n",
      "Validation loss decreased (1.478931 --> 1.478930).         Saving model ...\n",
      "Epoch: 3736 \tTraining Loss: 1.077187 \tValidation Loss: 1.478929\n",
      "Validation loss decreased (1.478930 --> 1.478929).         Saving model ...\n",
      "Epoch: 3737 \tTraining Loss: 1.077186 \tValidation Loss: 1.478929\n",
      "Validation loss decreased (1.478929 --> 1.478929).         Saving model ...\n",
      "Epoch: 3738 \tTraining Loss: 1.077184 \tValidation Loss: 1.478929\n",
      "Validation loss decreased (1.478929 --> 1.478929).         Saving model ...\n",
      "Epoch: 3739 \tTraining Loss: 1.077182 \tValidation Loss: 1.478928\n",
      "Validation loss decreased (1.478929 --> 1.478928).         Saving model ...\n",
      "Epoch: 3740 \tTraining Loss: 1.077181 \tValidation Loss: 1.478928\n",
      "Validation loss decreased (1.478928 --> 1.478928).         Saving model ...\n",
      "Epoch: 3741 \tTraining Loss: 1.077179 \tValidation Loss: 1.478926\n",
      "Validation loss decreased (1.478928 --> 1.478926).         Saving model ...\n",
      "Epoch: 3742 \tTraining Loss: 1.077177 \tValidation Loss: 1.478925\n",
      "Validation loss decreased (1.478926 --> 1.478925).         Saving model ...\n",
      "Epoch: 3743 \tTraining Loss: 1.077176 \tValidation Loss: 1.478925\n",
      "Validation loss decreased (1.478925 --> 1.478925).         Saving model ...\n",
      "Epoch: 3744 \tTraining Loss: 1.077174 \tValidation Loss: 1.478924\n",
      "Validation loss decreased (1.478925 --> 1.478924).         Saving model ...\n",
      "Epoch: 3745 \tTraining Loss: 1.077172 \tValidation Loss: 1.478924\n",
      "Validation loss decreased (1.478924 --> 1.478924).         Saving model ...\n",
      "Epoch: 3746 \tTraining Loss: 1.077171 \tValidation Loss: 1.478923\n",
      "Validation loss decreased (1.478924 --> 1.478923).         Saving model ...\n",
      "Epoch: 3747 \tTraining Loss: 1.077169 \tValidation Loss: 1.478922\n",
      "Validation loss decreased (1.478923 --> 1.478922).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3748 \tTraining Loss: 1.077167 \tValidation Loss: 1.478920\n",
      "Validation loss decreased (1.478922 --> 1.478920).         Saving model ...\n",
      "Epoch: 3749 \tTraining Loss: 1.077166 \tValidation Loss: 1.478919\n",
      "Validation loss decreased (1.478920 --> 1.478919).         Saving model ...\n",
      "Epoch: 3750 \tTraining Loss: 1.077164 \tValidation Loss: 1.478919\n",
      "Validation loss decreased (1.478919 --> 1.478919).         Saving model ...\n",
      "Epoch: 3751 \tTraining Loss: 1.077162 \tValidation Loss: 1.478918\n",
      "Validation loss decreased (1.478919 --> 1.478918).         Saving model ...\n",
      "Epoch: 3752 \tTraining Loss: 1.077161 \tValidation Loss: 1.478917\n",
      "Validation loss decreased (1.478918 --> 1.478917).         Saving model ...\n",
      "Epoch: 3753 \tTraining Loss: 1.077159 \tValidation Loss: 1.478916\n",
      "Validation loss decreased (1.478917 --> 1.478916).         Saving model ...\n",
      "Epoch: 3754 \tTraining Loss: 1.077157 \tValidation Loss: 1.478915\n",
      "Validation loss decreased (1.478916 --> 1.478915).         Saving model ...\n",
      "Epoch: 3755 \tTraining Loss: 1.077155 \tValidation Loss: 1.478914\n",
      "Validation loss decreased (1.478915 --> 1.478914).         Saving model ...\n",
      "Epoch: 3756 \tTraining Loss: 1.077154 \tValidation Loss: 1.478913\n",
      "Validation loss decreased (1.478914 --> 1.478913).         Saving model ...\n",
      "Epoch: 3757 \tTraining Loss: 1.077152 \tValidation Loss: 1.478913\n",
      "Validation loss decreased (1.478913 --> 1.478913).         Saving model ...\n",
      "Epoch: 3758 \tTraining Loss: 1.077150 \tValidation Loss: 1.478912\n",
      "Validation loss decreased (1.478913 --> 1.478912).         Saving model ...\n",
      "Epoch: 3759 \tTraining Loss: 1.077149 \tValidation Loss: 1.478911\n",
      "Validation loss decreased (1.478912 --> 1.478911).         Saving model ...\n",
      "Epoch: 3760 \tTraining Loss: 1.077147 \tValidation Loss: 1.478910\n",
      "Validation loss decreased (1.478911 --> 1.478910).         Saving model ...\n",
      "Epoch: 3761 \tTraining Loss: 1.077145 \tValidation Loss: 1.478909\n",
      "Validation loss decreased (1.478910 --> 1.478909).         Saving model ...\n",
      "Epoch: 3762 \tTraining Loss: 1.077144 \tValidation Loss: 1.478909\n",
      "Epoch: 3763 \tTraining Loss: 1.077142 \tValidation Loss: 1.478908\n",
      "Validation loss decreased (1.478909 --> 1.478908).         Saving model ...\n",
      "Epoch: 3764 \tTraining Loss: 1.077140 \tValidation Loss: 1.478907\n",
      "Validation loss decreased (1.478908 --> 1.478907).         Saving model ...\n",
      "Epoch: 3765 \tTraining Loss: 1.077139 \tValidation Loss: 1.478906\n",
      "Validation loss decreased (1.478907 --> 1.478906).         Saving model ...\n",
      "Epoch: 3766 \tTraining Loss: 1.077137 \tValidation Loss: 1.478906\n",
      "Validation loss decreased (1.478906 --> 1.478906).         Saving model ...\n",
      "Epoch: 3767 \tTraining Loss: 1.077135 \tValidation Loss: 1.478905\n",
      "Validation loss decreased (1.478906 --> 1.478905).         Saving model ...\n",
      "Epoch: 3768 \tTraining Loss: 1.077134 \tValidation Loss: 1.478904\n",
      "Validation loss decreased (1.478905 --> 1.478904).         Saving model ...\n",
      "Epoch: 3769 \tTraining Loss: 1.077132 \tValidation Loss: 1.478904\n",
      "Validation loss decreased (1.478904 --> 1.478904).         Saving model ...\n",
      "Epoch: 3770 \tTraining Loss: 1.077130 \tValidation Loss: 1.478903\n",
      "Validation loss decreased (1.478904 --> 1.478903).         Saving model ...\n",
      "Epoch: 3771 \tTraining Loss: 1.077129 \tValidation Loss: 1.478902\n",
      "Validation loss decreased (1.478903 --> 1.478902).         Saving model ...\n",
      "Epoch: 3772 \tTraining Loss: 1.077127 \tValidation Loss: 1.478902\n",
      "Validation loss decreased (1.478902 --> 1.478902).         Saving model ...\n",
      "Epoch: 3773 \tTraining Loss: 1.077125 \tValidation Loss: 1.478901\n",
      "Validation loss decreased (1.478902 --> 1.478901).         Saving model ...\n",
      "Epoch: 3774 \tTraining Loss: 1.077124 \tValidation Loss: 1.478901\n",
      "Validation loss decreased (1.478901 --> 1.478901).         Saving model ...\n",
      "Epoch: 3775 \tTraining Loss: 1.077122 \tValidation Loss: 1.478900\n",
      "Validation loss decreased (1.478901 --> 1.478900).         Saving model ...\n",
      "Epoch: 3776 \tTraining Loss: 1.077121 \tValidation Loss: 1.478900\n",
      "Validation loss decreased (1.478900 --> 1.478900).         Saving model ...\n",
      "Epoch: 3777 \tTraining Loss: 1.077119 \tValidation Loss: 1.478900\n",
      "Validation loss decreased (1.478900 --> 1.478900).         Saving model ...\n",
      "Epoch: 3778 \tTraining Loss: 1.077117 \tValidation Loss: 1.478900\n",
      "Validation loss decreased (1.478900 --> 1.478900).         Saving model ...\n",
      "Epoch: 3779 \tTraining Loss: 1.077116 \tValidation Loss: 1.478899\n",
      "Validation loss decreased (1.478900 --> 1.478899).         Saving model ...\n",
      "Epoch: 3780 \tTraining Loss: 1.077114 \tValidation Loss: 1.478898\n",
      "Validation loss decreased (1.478899 --> 1.478898).         Saving model ...\n",
      "Epoch: 3781 \tTraining Loss: 1.077112 \tValidation Loss: 1.478897\n",
      "Validation loss decreased (1.478898 --> 1.478897).         Saving model ...\n",
      "Epoch: 3782 \tTraining Loss: 1.077111 \tValidation Loss: 1.478896\n",
      "Validation loss decreased (1.478897 --> 1.478896).         Saving model ...\n",
      "Epoch: 3783 \tTraining Loss: 1.077109 \tValidation Loss: 1.478895\n",
      "Validation loss decreased (1.478896 --> 1.478895).         Saving model ...\n",
      "Epoch: 3784 \tTraining Loss: 1.077107 \tValidation Loss: 1.478894\n",
      "Validation loss decreased (1.478895 --> 1.478894).         Saving model ...\n",
      "Epoch: 3785 \tTraining Loss: 1.077106 \tValidation Loss: 1.478892\n",
      "Validation loss decreased (1.478894 --> 1.478892).         Saving model ...\n",
      "Epoch: 3786 \tTraining Loss: 1.077104 \tValidation Loss: 1.478892\n",
      "Validation loss decreased (1.478892 --> 1.478892).         Saving model ...\n",
      "Epoch: 3787 \tTraining Loss: 1.077102 \tValidation Loss: 1.478891\n",
      "Validation loss decreased (1.478892 --> 1.478891).         Saving model ...\n",
      "Epoch: 3788 \tTraining Loss: 1.077101 \tValidation Loss: 1.478890\n",
      "Validation loss decreased (1.478891 --> 1.478890).         Saving model ...\n",
      "Epoch: 3789 \tTraining Loss: 1.077099 \tValidation Loss: 1.478889\n",
      "Validation loss decreased (1.478890 --> 1.478889).         Saving model ...\n",
      "Epoch: 3790 \tTraining Loss: 1.077097 \tValidation Loss: 1.478887\n",
      "Validation loss decreased (1.478889 --> 1.478887).         Saving model ...\n",
      "Epoch: 3791 \tTraining Loss: 1.077096 \tValidation Loss: 1.478886\n",
      "Validation loss decreased (1.478887 --> 1.478886).         Saving model ...\n",
      "Epoch: 3792 \tTraining Loss: 1.077094 \tValidation Loss: 1.478886\n",
      "Validation loss decreased (1.478886 --> 1.478886).         Saving model ...\n",
      "Epoch: 3793 \tTraining Loss: 1.077092 \tValidation Loss: 1.478884\n",
      "Validation loss decreased (1.478886 --> 1.478884).         Saving model ...\n",
      "Epoch: 3794 \tTraining Loss: 1.077091 \tValidation Loss: 1.478883\n",
      "Validation loss decreased (1.478884 --> 1.478883).         Saving model ...\n",
      "Epoch: 3795 \tTraining Loss: 1.077089 \tValidation Loss: 1.478881\n",
      "Validation loss decreased (1.478883 --> 1.478881).         Saving model ...\n",
      "Epoch: 3796 \tTraining Loss: 1.077087 \tValidation Loss: 1.478880\n",
      "Validation loss decreased (1.478881 --> 1.478880).         Saving model ...\n",
      "Epoch: 3797 \tTraining Loss: 1.077086 \tValidation Loss: 1.478880\n",
      "Validation loss decreased (1.478880 --> 1.478880).         Saving model ...\n",
      "Epoch: 3798 \tTraining Loss: 1.077084 \tValidation Loss: 1.478878\n",
      "Validation loss decreased (1.478880 --> 1.478878).         Saving model ...\n",
      "Epoch: 3799 \tTraining Loss: 1.077083 \tValidation Loss: 1.478877\n",
      "Validation loss decreased (1.478878 --> 1.478877).         Saving model ...\n",
      "Epoch: 3800 \tTraining Loss: 1.077081 \tValidation Loss: 1.478876\n",
      "Validation loss decreased (1.478877 --> 1.478876).         Saving model ...\n",
      "Epoch: 3801 \tTraining Loss: 1.077079 \tValidation Loss: 1.478875\n",
      "Validation loss decreased (1.478876 --> 1.478875).         Saving model ...\n",
      "Epoch: 3802 \tTraining Loss: 1.077078 \tValidation Loss: 1.478874\n",
      "Validation loss decreased (1.478875 --> 1.478874).         Saving model ...\n",
      "Epoch: 3803 \tTraining Loss: 1.077076 \tValidation Loss: 1.478873\n",
      "Validation loss decreased (1.478874 --> 1.478873).         Saving model ...\n",
      "Epoch: 3804 \tTraining Loss: 1.077074 \tValidation Loss: 1.478872\n",
      "Validation loss decreased (1.478873 --> 1.478872).         Saving model ...\n",
      "Epoch: 3805 \tTraining Loss: 1.077073 \tValidation Loss: 1.478871\n",
      "Validation loss decreased (1.478872 --> 1.478871).         Saving model ...\n",
      "Epoch: 3806 \tTraining Loss: 1.077071 \tValidation Loss: 1.478869\n",
      "Validation loss decreased (1.478871 --> 1.478869).         Saving model ...\n",
      "Epoch: 3807 \tTraining Loss: 1.077069 \tValidation Loss: 1.478868\n",
      "Validation loss decreased (1.478869 --> 1.478868).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3808 \tTraining Loss: 1.077068 \tValidation Loss: 1.478868\n",
      "Validation loss decreased (1.478868 --> 1.478868).         Saving model ...\n",
      "Epoch: 3809 \tTraining Loss: 1.077066 \tValidation Loss: 1.478866\n",
      "Validation loss decreased (1.478868 --> 1.478866).         Saving model ...\n",
      "Epoch: 3810 \tTraining Loss: 1.077064 \tValidation Loss: 1.478865\n",
      "Validation loss decreased (1.478866 --> 1.478865).         Saving model ...\n",
      "Epoch: 3811 \tTraining Loss: 1.077063 \tValidation Loss: 1.478863\n",
      "Validation loss decreased (1.478865 --> 1.478863).         Saving model ...\n",
      "Epoch: 3812 \tTraining Loss: 1.077061 \tValidation Loss: 1.478862\n",
      "Validation loss decreased (1.478863 --> 1.478862).         Saving model ...\n",
      "Epoch: 3813 \tTraining Loss: 1.077060 \tValidation Loss: 1.478860\n",
      "Validation loss decreased (1.478862 --> 1.478860).         Saving model ...\n",
      "Epoch: 3814 \tTraining Loss: 1.077058 \tValidation Loss: 1.478860\n",
      "Validation loss decreased (1.478860 --> 1.478860).         Saving model ...\n",
      "Epoch: 3815 \tTraining Loss: 1.077056 \tValidation Loss: 1.478859\n",
      "Validation loss decreased (1.478860 --> 1.478859).         Saving model ...\n",
      "Epoch: 3816 \tTraining Loss: 1.077055 \tValidation Loss: 1.478858\n",
      "Validation loss decreased (1.478859 --> 1.478858).         Saving model ...\n",
      "Epoch: 3817 \tTraining Loss: 1.077053 \tValidation Loss: 1.478856\n",
      "Validation loss decreased (1.478858 --> 1.478856).         Saving model ...\n",
      "Epoch: 3818 \tTraining Loss: 1.077051 \tValidation Loss: 1.478855\n",
      "Validation loss decreased (1.478856 --> 1.478855).         Saving model ...\n",
      "Epoch: 3819 \tTraining Loss: 1.077050 \tValidation Loss: 1.478855\n",
      "Validation loss decreased (1.478855 --> 1.478855).         Saving model ...\n",
      "Epoch: 3820 \tTraining Loss: 1.077048 \tValidation Loss: 1.478854\n",
      "Validation loss decreased (1.478855 --> 1.478854).         Saving model ...\n",
      "Epoch: 3821 \tTraining Loss: 1.077046 \tValidation Loss: 1.478854\n",
      "Epoch: 3822 \tTraining Loss: 1.077045 \tValidation Loss: 1.478854\n",
      "Validation loss decreased (1.478854 --> 1.478854).         Saving model ...\n",
      "Epoch: 3823 \tTraining Loss: 1.077043 \tValidation Loss: 1.478853\n",
      "Validation loss decreased (1.478854 --> 1.478853).         Saving model ...\n",
      "Epoch: 3824 \tTraining Loss: 1.077042 \tValidation Loss: 1.478853\n",
      "Validation loss decreased (1.478853 --> 1.478853).         Saving model ...\n",
      "Epoch: 3825 \tTraining Loss: 1.077040 \tValidation Loss: 1.478853\n",
      "Validation loss decreased (1.478853 --> 1.478853).         Saving model ...\n",
      "Epoch: 3826 \tTraining Loss: 1.077038 \tValidation Loss: 1.478852\n",
      "Validation loss decreased (1.478853 --> 1.478852).         Saving model ...\n",
      "Epoch: 3827 \tTraining Loss: 1.077037 \tValidation Loss: 1.478852\n",
      "Validation loss decreased (1.478852 --> 1.478852).         Saving model ...\n",
      "Epoch: 3828 \tTraining Loss: 1.077035 \tValidation Loss: 1.478851\n",
      "Validation loss decreased (1.478852 --> 1.478851).         Saving model ...\n",
      "Epoch: 3829 \tTraining Loss: 1.077033 \tValidation Loss: 1.478851\n",
      "Validation loss decreased (1.478851 --> 1.478851).         Saving model ...\n",
      "Epoch: 3830 \tTraining Loss: 1.077032 \tValidation Loss: 1.478850\n",
      "Validation loss decreased (1.478851 --> 1.478850).         Saving model ...\n",
      "Epoch: 3831 \tTraining Loss: 1.077030 \tValidation Loss: 1.478850\n",
      "Validation loss decreased (1.478850 --> 1.478850).         Saving model ...\n",
      "Epoch: 3832 \tTraining Loss: 1.077029 \tValidation Loss: 1.478849\n",
      "Validation loss decreased (1.478850 --> 1.478849).         Saving model ...\n",
      "Epoch: 3833 \tTraining Loss: 1.077027 \tValidation Loss: 1.478849\n",
      "Validation loss decreased (1.478849 --> 1.478849).         Saving model ...\n",
      "Epoch: 3834 \tTraining Loss: 1.077025 \tValidation Loss: 1.478847\n",
      "Validation loss decreased (1.478849 --> 1.478847).         Saving model ...\n",
      "Epoch: 3835 \tTraining Loss: 1.077024 \tValidation Loss: 1.478847\n",
      "Validation loss decreased (1.478847 --> 1.478847).         Saving model ...\n",
      "Epoch: 3836 \tTraining Loss: 1.077022 \tValidation Loss: 1.478846\n",
      "Validation loss decreased (1.478847 --> 1.478846).         Saving model ...\n",
      "Epoch: 3837 \tTraining Loss: 1.077020 \tValidation Loss: 1.478845\n",
      "Validation loss decreased (1.478846 --> 1.478845).         Saving model ...\n",
      "Epoch: 3838 \tTraining Loss: 1.077019 \tValidation Loss: 1.478844\n",
      "Validation loss decreased (1.478845 --> 1.478844).         Saving model ...\n",
      "Epoch: 3839 \tTraining Loss: 1.077017 \tValidation Loss: 1.478843\n",
      "Validation loss decreased (1.478844 --> 1.478843).         Saving model ...\n",
      "Epoch: 3840 \tTraining Loss: 1.077016 \tValidation Loss: 1.478842\n",
      "Validation loss decreased (1.478843 --> 1.478842).         Saving model ...\n",
      "Epoch: 3841 \tTraining Loss: 1.077014 \tValidation Loss: 1.478841\n",
      "Validation loss decreased (1.478842 --> 1.478841).         Saving model ...\n",
      "Epoch: 3842 \tTraining Loss: 1.077012 \tValidation Loss: 1.478840\n",
      "Validation loss decreased (1.478841 --> 1.478840).         Saving model ...\n",
      "Epoch: 3843 \tTraining Loss: 1.077011 \tValidation Loss: 1.478839\n",
      "Validation loss decreased (1.478840 --> 1.478839).         Saving model ...\n",
      "Epoch: 3844 \tTraining Loss: 1.077009 \tValidation Loss: 1.478839\n",
      "Validation loss decreased (1.478839 --> 1.478839).         Saving model ...\n",
      "Epoch: 3845 \tTraining Loss: 1.077008 \tValidation Loss: 1.478838\n",
      "Validation loss decreased (1.478839 --> 1.478838).         Saving model ...\n",
      "Epoch: 3846 \tTraining Loss: 1.077006 \tValidation Loss: 1.478837\n",
      "Validation loss decreased (1.478838 --> 1.478837).         Saving model ...\n",
      "Epoch: 3847 \tTraining Loss: 1.077004 \tValidation Loss: 1.478836\n",
      "Validation loss decreased (1.478837 --> 1.478836).         Saving model ...\n",
      "Epoch: 3848 \tTraining Loss: 1.077003 \tValidation Loss: 1.478835\n",
      "Validation loss decreased (1.478836 --> 1.478835).         Saving model ...\n",
      "Epoch: 3849 \tTraining Loss: 1.077001 \tValidation Loss: 1.478834\n",
      "Validation loss decreased (1.478835 --> 1.478834).         Saving model ...\n",
      "Epoch: 3850 \tTraining Loss: 1.077000 \tValidation Loss: 1.478833\n",
      "Validation loss decreased (1.478834 --> 1.478833).         Saving model ...\n",
      "Epoch: 3851 \tTraining Loss: 1.076998 \tValidation Loss: 1.478832\n",
      "Validation loss decreased (1.478833 --> 1.478832).         Saving model ...\n",
      "Epoch: 3852 \tTraining Loss: 1.076996 \tValidation Loss: 1.478831\n",
      "Validation loss decreased (1.478832 --> 1.478831).         Saving model ...\n",
      "Epoch: 3853 \tTraining Loss: 1.076995 \tValidation Loss: 1.478830\n",
      "Validation loss decreased (1.478831 --> 1.478830).         Saving model ...\n",
      "Epoch: 3854 \tTraining Loss: 1.076993 \tValidation Loss: 1.478829\n",
      "Validation loss decreased (1.478830 --> 1.478829).         Saving model ...\n",
      "Epoch: 3855 \tTraining Loss: 1.076991 \tValidation Loss: 1.478829\n",
      "Validation loss decreased (1.478829 --> 1.478829).         Saving model ...\n",
      "Epoch: 3856 \tTraining Loss: 1.076990 \tValidation Loss: 1.478828\n",
      "Validation loss decreased (1.478829 --> 1.478828).         Saving model ...\n",
      "Epoch: 3857 \tTraining Loss: 1.076988 \tValidation Loss: 1.478827\n",
      "Validation loss decreased (1.478828 --> 1.478827).         Saving model ...\n",
      "Epoch: 3858 \tTraining Loss: 1.076987 \tValidation Loss: 1.478827\n",
      "Validation loss decreased (1.478827 --> 1.478827).         Saving model ...\n",
      "Epoch: 3859 \tTraining Loss: 1.076985 \tValidation Loss: 1.478826\n",
      "Validation loss decreased (1.478827 --> 1.478826).         Saving model ...\n",
      "Epoch: 3860 \tTraining Loss: 1.076983 \tValidation Loss: 1.478826\n",
      "Validation loss decreased (1.478826 --> 1.478826).         Saving model ...\n",
      "Epoch: 3861 \tTraining Loss: 1.076982 \tValidation Loss: 1.478825\n",
      "Validation loss decreased (1.478826 --> 1.478825).         Saving model ...\n",
      "Epoch: 3862 \tTraining Loss: 1.076980 \tValidation Loss: 1.478824\n",
      "Validation loss decreased (1.478825 --> 1.478824).         Saving model ...\n",
      "Epoch: 3863 \tTraining Loss: 1.076979 \tValidation Loss: 1.478823\n",
      "Validation loss decreased (1.478824 --> 1.478823).         Saving model ...\n",
      "Epoch: 3864 \tTraining Loss: 1.076977 \tValidation Loss: 1.478823\n",
      "Validation loss decreased (1.478823 --> 1.478823).         Saving model ...\n",
      "Epoch: 3865 \tTraining Loss: 1.076975 \tValidation Loss: 1.478823\n",
      "Validation loss decreased (1.478823 --> 1.478823).         Saving model ...\n",
      "Epoch: 3866 \tTraining Loss: 1.076974 \tValidation Loss: 1.478822\n",
      "Validation loss decreased (1.478823 --> 1.478822).         Saving model ...\n",
      "Epoch: 3867 \tTraining Loss: 1.076972 \tValidation Loss: 1.478822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3868 \tTraining Loss: 1.076971 \tValidation Loss: 1.478821\n",
      "Validation loss decreased (1.478822 --> 1.478821).         Saving model ...\n",
      "Epoch: 3869 \tTraining Loss: 1.076969 \tValidation Loss: 1.478821\n",
      "Validation loss decreased (1.478821 --> 1.478821).         Saving model ...\n",
      "Epoch: 3870 \tTraining Loss: 1.076967 \tValidation Loss: 1.478819\n",
      "Validation loss decreased (1.478821 --> 1.478819).         Saving model ...\n",
      "Epoch: 3871 \tTraining Loss: 1.076966 \tValidation Loss: 1.478818\n",
      "Validation loss decreased (1.478819 --> 1.478818).         Saving model ...\n",
      "Epoch: 3872 \tTraining Loss: 1.076964 \tValidation Loss: 1.478817\n",
      "Validation loss decreased (1.478818 --> 1.478817).         Saving model ...\n",
      "Epoch: 3873 \tTraining Loss: 1.076963 \tValidation Loss: 1.478817\n",
      "Validation loss decreased (1.478817 --> 1.478817).         Saving model ...\n",
      "Epoch: 3874 \tTraining Loss: 1.076961 \tValidation Loss: 1.478816\n",
      "Validation loss decreased (1.478817 --> 1.478816).         Saving model ...\n",
      "Epoch: 3875 \tTraining Loss: 1.076959 \tValidation Loss: 1.478815\n",
      "Validation loss decreased (1.478816 --> 1.478815).         Saving model ...\n",
      "Epoch: 3876 \tTraining Loss: 1.076958 \tValidation Loss: 1.478815\n",
      "Validation loss decreased (1.478815 --> 1.478815).         Saving model ...\n",
      "Epoch: 3877 \tTraining Loss: 1.076956 \tValidation Loss: 1.478814\n",
      "Validation loss decreased (1.478815 --> 1.478814).         Saving model ...\n",
      "Epoch: 3878 \tTraining Loss: 1.076955 \tValidation Loss: 1.478814\n",
      "Validation loss decreased (1.478814 --> 1.478814).         Saving model ...\n",
      "Epoch: 3879 \tTraining Loss: 1.076953 \tValidation Loss: 1.478813\n",
      "Validation loss decreased (1.478814 --> 1.478813).         Saving model ...\n",
      "Epoch: 3880 \tTraining Loss: 1.076951 \tValidation Loss: 1.478812\n",
      "Validation loss decreased (1.478813 --> 1.478812).         Saving model ...\n",
      "Epoch: 3881 \tTraining Loss: 1.076950 \tValidation Loss: 1.478812\n",
      "Validation loss decreased (1.478812 --> 1.478812).         Saving model ...\n",
      "Epoch: 3882 \tTraining Loss: 1.076948 \tValidation Loss: 1.478812\n",
      "Validation loss decreased (1.478812 --> 1.478812).         Saving model ...\n",
      "Epoch: 3883 \tTraining Loss: 1.076947 \tValidation Loss: 1.478811\n",
      "Validation loss decreased (1.478812 --> 1.478811).         Saving model ...\n",
      "Epoch: 3884 \tTraining Loss: 1.076945 \tValidation Loss: 1.478811\n",
      "Validation loss decreased (1.478811 --> 1.478811).         Saving model ...\n",
      "Epoch: 3885 \tTraining Loss: 1.076943 \tValidation Loss: 1.478810\n",
      "Validation loss decreased (1.478811 --> 1.478810).         Saving model ...\n",
      "Epoch: 3886 \tTraining Loss: 1.076942 \tValidation Loss: 1.478810\n",
      "Validation loss decreased (1.478810 --> 1.478810).         Saving model ...\n",
      "Epoch: 3887 \tTraining Loss: 1.076940 \tValidation Loss: 1.478809\n",
      "Validation loss decreased (1.478810 --> 1.478809).         Saving model ...\n",
      "Epoch: 3888 \tTraining Loss: 1.076939 \tValidation Loss: 1.478808\n",
      "Validation loss decreased (1.478809 --> 1.478808).         Saving model ...\n",
      "Epoch: 3889 \tTraining Loss: 1.076937 \tValidation Loss: 1.478807\n",
      "Validation loss decreased (1.478808 --> 1.478807).         Saving model ...\n",
      "Epoch: 3890 \tTraining Loss: 1.076936 \tValidation Loss: 1.478806\n",
      "Validation loss decreased (1.478807 --> 1.478806).         Saving model ...\n",
      "Epoch: 3891 \tTraining Loss: 1.076934 \tValidation Loss: 1.478805\n",
      "Validation loss decreased (1.478806 --> 1.478805).         Saving model ...\n",
      "Epoch: 3892 \tTraining Loss: 1.076932 \tValidation Loss: 1.478805\n",
      "Validation loss decreased (1.478805 --> 1.478805).         Saving model ...\n",
      "Epoch: 3893 \tTraining Loss: 1.076931 \tValidation Loss: 1.478804\n",
      "Validation loss decreased (1.478805 --> 1.478804).         Saving model ...\n",
      "Epoch: 3894 \tTraining Loss: 1.076929 \tValidation Loss: 1.478803\n",
      "Validation loss decreased (1.478804 --> 1.478803).         Saving model ...\n",
      "Epoch: 3895 \tTraining Loss: 1.076928 \tValidation Loss: 1.478803\n",
      "Validation loss decreased (1.478803 --> 1.478803).         Saving model ...\n",
      "Epoch: 3896 \tTraining Loss: 1.076926 \tValidation Loss: 1.478802\n",
      "Validation loss decreased (1.478803 --> 1.478802).         Saving model ...\n",
      "Epoch: 3897 \tTraining Loss: 1.076924 \tValidation Loss: 1.478802\n",
      "Epoch: 3898 \tTraining Loss: 1.076923 \tValidation Loss: 1.478801\n",
      "Validation loss decreased (1.478802 --> 1.478801).         Saving model ...\n",
      "Epoch: 3899 \tTraining Loss: 1.076921 \tValidation Loss: 1.478801\n",
      "Validation loss decreased (1.478801 --> 1.478801).         Saving model ...\n",
      "Epoch: 3900 \tTraining Loss: 1.076920 \tValidation Loss: 1.478800\n",
      "Validation loss decreased (1.478801 --> 1.478800).         Saving model ...\n",
      "Epoch: 3901 \tTraining Loss: 1.076918 \tValidation Loss: 1.478799\n",
      "Validation loss decreased (1.478800 --> 1.478799).         Saving model ...\n",
      "Epoch: 3902 \tTraining Loss: 1.076917 \tValidation Loss: 1.478799\n",
      "Validation loss decreased (1.478799 --> 1.478799).         Saving model ...\n",
      "Epoch: 3903 \tTraining Loss: 1.076915 \tValidation Loss: 1.478798\n",
      "Validation loss decreased (1.478799 --> 1.478798).         Saving model ...\n",
      "Epoch: 3904 \tTraining Loss: 1.076913 \tValidation Loss: 1.478797\n",
      "Validation loss decreased (1.478798 --> 1.478797).         Saving model ...\n",
      "Epoch: 3905 \tTraining Loss: 1.076912 \tValidation Loss: 1.478796\n",
      "Validation loss decreased (1.478797 --> 1.478796).         Saving model ...\n",
      "Epoch: 3906 \tTraining Loss: 1.076910 \tValidation Loss: 1.478795\n",
      "Validation loss decreased (1.478796 --> 1.478795).         Saving model ...\n",
      "Epoch: 3907 \tTraining Loss: 1.076909 \tValidation Loss: 1.478794\n",
      "Validation loss decreased (1.478795 --> 1.478794).         Saving model ...\n",
      "Epoch: 3908 \tTraining Loss: 1.076907 \tValidation Loss: 1.478794\n",
      "Validation loss decreased (1.478794 --> 1.478794).         Saving model ...\n",
      "Epoch: 3909 \tTraining Loss: 1.076906 \tValidation Loss: 1.478792\n",
      "Validation loss decreased (1.478794 --> 1.478792).         Saving model ...\n",
      "Epoch: 3910 \tTraining Loss: 1.076904 \tValidation Loss: 1.478791\n",
      "Validation loss decreased (1.478792 --> 1.478791).         Saving model ...\n",
      "Epoch: 3911 \tTraining Loss: 1.076902 \tValidation Loss: 1.478790\n",
      "Validation loss decreased (1.478791 --> 1.478790).         Saving model ...\n",
      "Epoch: 3912 \tTraining Loss: 1.076901 \tValidation Loss: 1.478789\n",
      "Validation loss decreased (1.478790 --> 1.478789).         Saving model ...\n",
      "Epoch: 3913 \tTraining Loss: 1.076899 \tValidation Loss: 1.478788\n",
      "Validation loss decreased (1.478789 --> 1.478788).         Saving model ...\n",
      "Epoch: 3914 \tTraining Loss: 1.076898 \tValidation Loss: 1.478787\n",
      "Validation loss decreased (1.478788 --> 1.478787).         Saving model ...\n",
      "Epoch: 3915 \tTraining Loss: 1.076896 \tValidation Loss: 1.478786\n",
      "Validation loss decreased (1.478787 --> 1.478786).         Saving model ...\n",
      "Epoch: 3916 \tTraining Loss: 1.076895 \tValidation Loss: 1.478786\n",
      "Validation loss decreased (1.478786 --> 1.478786).         Saving model ...\n",
      "Epoch: 3917 \tTraining Loss: 1.076893 \tValidation Loss: 1.478786\n",
      "Epoch: 3918 \tTraining Loss: 1.076891 \tValidation Loss: 1.478785\n",
      "Validation loss decreased (1.478786 --> 1.478785).         Saving model ...\n",
      "Epoch: 3919 \tTraining Loss: 1.076890 \tValidation Loss: 1.478784\n",
      "Validation loss decreased (1.478785 --> 1.478784).         Saving model ...\n",
      "Epoch: 3920 \tTraining Loss: 1.076888 \tValidation Loss: 1.478784\n",
      "Epoch: 3921 \tTraining Loss: 1.076887 \tValidation Loss: 1.478783\n",
      "Validation loss decreased (1.478784 --> 1.478783).         Saving model ...\n",
      "Epoch: 3922 \tTraining Loss: 1.076885 \tValidation Loss: 1.478782\n",
      "Validation loss decreased (1.478783 --> 1.478782).         Saving model ...\n",
      "Epoch: 3923 \tTraining Loss: 1.076884 \tValidation Loss: 1.478781\n",
      "Validation loss decreased (1.478782 --> 1.478781).         Saving model ...\n",
      "Epoch: 3924 \tTraining Loss: 1.076882 \tValidation Loss: 1.478781\n",
      "Validation loss decreased (1.478781 --> 1.478781).         Saving model ...\n",
      "Epoch: 3925 \tTraining Loss: 1.076880 \tValidation Loss: 1.478779\n",
      "Validation loss decreased (1.478781 --> 1.478779).         Saving model ...\n",
      "Epoch: 3926 \tTraining Loss: 1.076879 \tValidation Loss: 1.478778\n",
      "Validation loss decreased (1.478779 --> 1.478778).         Saving model ...\n",
      "Epoch: 3927 \tTraining Loss: 1.076877 \tValidation Loss: 1.478777\n",
      "Validation loss decreased (1.478778 --> 1.478777).         Saving model ...\n",
      "Epoch: 3928 \tTraining Loss: 1.076876 \tValidation Loss: 1.478776\n",
      "Validation loss decreased (1.478777 --> 1.478776).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3929 \tTraining Loss: 1.076874 \tValidation Loss: 1.478775\n",
      "Validation loss decreased (1.478776 --> 1.478775).         Saving model ...\n",
      "Epoch: 3930 \tTraining Loss: 1.076873 \tValidation Loss: 1.478773\n",
      "Validation loss decreased (1.478775 --> 1.478773).         Saving model ...\n",
      "Epoch: 3931 \tTraining Loss: 1.076871 \tValidation Loss: 1.478772\n",
      "Validation loss decreased (1.478773 --> 1.478772).         Saving model ...\n",
      "Epoch: 3932 \tTraining Loss: 1.076869 \tValidation Loss: 1.478770\n",
      "Validation loss decreased (1.478772 --> 1.478770).         Saving model ...\n",
      "Epoch: 3933 \tTraining Loss: 1.076868 \tValidation Loss: 1.478769\n",
      "Validation loss decreased (1.478770 --> 1.478769).         Saving model ...\n",
      "Epoch: 3934 \tTraining Loss: 1.076866 \tValidation Loss: 1.478769\n",
      "Validation loss decreased (1.478769 --> 1.478769).         Saving model ...\n",
      "Epoch: 3935 \tTraining Loss: 1.076865 \tValidation Loss: 1.478767\n",
      "Validation loss decreased (1.478769 --> 1.478767).         Saving model ...\n",
      "Epoch: 3936 \tTraining Loss: 1.076863 \tValidation Loss: 1.478767\n",
      "Validation loss decreased (1.478767 --> 1.478767).         Saving model ...\n",
      "Epoch: 3937 \tTraining Loss: 1.076862 \tValidation Loss: 1.478766\n",
      "Validation loss decreased (1.478767 --> 1.478766).         Saving model ...\n",
      "Epoch: 3938 \tTraining Loss: 1.076860 \tValidation Loss: 1.478765\n",
      "Validation loss decreased (1.478766 --> 1.478765).         Saving model ...\n",
      "Epoch: 3939 \tTraining Loss: 1.076859 \tValidation Loss: 1.478764\n",
      "Validation loss decreased (1.478765 --> 1.478764).         Saving model ...\n",
      "Epoch: 3940 \tTraining Loss: 1.076857 \tValidation Loss: 1.478763\n",
      "Validation loss decreased (1.478764 --> 1.478763).         Saving model ...\n",
      "Epoch: 3941 \tTraining Loss: 1.076855 \tValidation Loss: 1.478762\n",
      "Validation loss decreased (1.478763 --> 1.478762).         Saving model ...\n",
      "Epoch: 3942 \tTraining Loss: 1.076854 \tValidation Loss: 1.478761\n",
      "Validation loss decreased (1.478762 --> 1.478761).         Saving model ...\n",
      "Epoch: 3943 \tTraining Loss: 1.076852 \tValidation Loss: 1.478760\n",
      "Validation loss decreased (1.478761 --> 1.478760).         Saving model ...\n",
      "Epoch: 3944 \tTraining Loss: 1.076851 \tValidation Loss: 1.478759\n",
      "Validation loss decreased (1.478760 --> 1.478759).         Saving model ...\n",
      "Epoch: 3945 \tTraining Loss: 1.076849 \tValidation Loss: 1.478758\n",
      "Validation loss decreased (1.478759 --> 1.478758).         Saving model ...\n",
      "Epoch: 3946 \tTraining Loss: 1.076848 \tValidation Loss: 1.478757\n",
      "Validation loss decreased (1.478758 --> 1.478757).         Saving model ...\n",
      "Epoch: 3947 \tTraining Loss: 1.076846 \tValidation Loss: 1.478756\n",
      "Validation loss decreased (1.478757 --> 1.478756).         Saving model ...\n",
      "Epoch: 3948 \tTraining Loss: 1.076845 \tValidation Loss: 1.478755\n",
      "Validation loss decreased (1.478756 --> 1.478755).         Saving model ...\n",
      "Epoch: 3949 \tTraining Loss: 1.076843 \tValidation Loss: 1.478755\n",
      "Validation loss decreased (1.478755 --> 1.478755).         Saving model ...\n",
      "Epoch: 3950 \tTraining Loss: 1.076841 \tValidation Loss: 1.478753\n",
      "Validation loss decreased (1.478755 --> 1.478753).         Saving model ...\n",
      "Epoch: 3951 \tTraining Loss: 1.076840 \tValidation Loss: 1.478752\n",
      "Validation loss decreased (1.478753 --> 1.478752).         Saving model ...\n",
      "Epoch: 3952 \tTraining Loss: 1.076838 \tValidation Loss: 1.478751\n",
      "Validation loss decreased (1.478752 --> 1.478751).         Saving model ...\n",
      "Epoch: 3953 \tTraining Loss: 1.076837 \tValidation Loss: 1.478751\n",
      "Validation loss decreased (1.478751 --> 1.478751).         Saving model ...\n",
      "Epoch: 3954 \tTraining Loss: 1.076835 \tValidation Loss: 1.478750\n",
      "Validation loss decreased (1.478751 --> 1.478750).         Saving model ...\n",
      "Epoch: 3955 \tTraining Loss: 1.076834 \tValidation Loss: 1.478748\n",
      "Validation loss decreased (1.478750 --> 1.478748).         Saving model ...\n",
      "Epoch: 3956 \tTraining Loss: 1.076832 \tValidation Loss: 1.478749\n",
      "Epoch: 3957 \tTraining Loss: 1.076831 \tValidation Loss: 1.478747\n",
      "Validation loss decreased (1.478748 --> 1.478747).         Saving model ...\n",
      "Epoch: 3958 \tTraining Loss: 1.076829 \tValidation Loss: 1.478746\n",
      "Validation loss decreased (1.478747 --> 1.478746).         Saving model ...\n",
      "Epoch: 3959 \tTraining Loss: 1.076828 \tValidation Loss: 1.478745\n",
      "Validation loss decreased (1.478746 --> 1.478745).         Saving model ...\n",
      "Epoch: 3960 \tTraining Loss: 1.076826 \tValidation Loss: 1.478745\n",
      "Validation loss decreased (1.478745 --> 1.478745).         Saving model ...\n",
      "Epoch: 3961 \tTraining Loss: 1.076824 \tValidation Loss: 1.478745\n",
      "Validation loss decreased (1.478745 --> 1.478745).         Saving model ...\n",
      "Epoch: 3962 \tTraining Loss: 1.076823 \tValidation Loss: 1.478744\n",
      "Validation loss decreased (1.478745 --> 1.478744).         Saving model ...\n",
      "Epoch: 3963 \tTraining Loss: 1.076821 \tValidation Loss: 1.478744\n",
      "Validation loss decreased (1.478744 --> 1.478744).         Saving model ...\n",
      "Epoch: 3964 \tTraining Loss: 1.076820 \tValidation Loss: 1.478743\n",
      "Validation loss decreased (1.478744 --> 1.478743).         Saving model ...\n",
      "Epoch: 3965 \tTraining Loss: 1.076818 \tValidation Loss: 1.478743\n",
      "Validation loss decreased (1.478743 --> 1.478743).         Saving model ...\n",
      "Epoch: 3966 \tTraining Loss: 1.076817 \tValidation Loss: 1.478743\n",
      "Validation loss decreased (1.478743 --> 1.478743).         Saving model ...\n",
      "Epoch: 3967 \tTraining Loss: 1.076815 \tValidation Loss: 1.478741\n",
      "Validation loss decreased (1.478743 --> 1.478741).         Saving model ...\n",
      "Epoch: 3968 \tTraining Loss: 1.076814 \tValidation Loss: 1.478741\n",
      "Epoch: 3969 \tTraining Loss: 1.076812 \tValidation Loss: 1.478741\n",
      "Validation loss decreased (1.478741 --> 1.478741).         Saving model ...\n",
      "Epoch: 3970 \tTraining Loss: 1.076811 \tValidation Loss: 1.478740\n",
      "Validation loss decreased (1.478741 --> 1.478740).         Saving model ...\n",
      "Epoch: 3971 \tTraining Loss: 1.076809 \tValidation Loss: 1.478740\n",
      "Validation loss decreased (1.478740 --> 1.478740).         Saving model ...\n",
      "Epoch: 3972 \tTraining Loss: 1.076807 \tValidation Loss: 1.478739\n",
      "Validation loss decreased (1.478740 --> 1.478739).         Saving model ...\n",
      "Epoch: 3973 \tTraining Loss: 1.076806 \tValidation Loss: 1.478739\n",
      "Validation loss decreased (1.478739 --> 1.478739).         Saving model ...\n",
      "Epoch: 3974 \tTraining Loss: 1.076804 \tValidation Loss: 1.478739\n",
      "Epoch: 3975 \tTraining Loss: 1.076803 \tValidation Loss: 1.478739\n",
      "Epoch: 3976 \tTraining Loss: 1.076801 \tValidation Loss: 1.478738\n",
      "Validation loss decreased (1.478739 --> 1.478738).         Saving model ...\n",
      "Epoch: 3977 \tTraining Loss: 1.076800 \tValidation Loss: 1.478738\n",
      "Validation loss decreased (1.478738 --> 1.478738).         Saving model ...\n",
      "Epoch: 3978 \tTraining Loss: 1.076798 \tValidation Loss: 1.478737\n",
      "Validation loss decreased (1.478738 --> 1.478737).         Saving model ...\n",
      "Epoch: 3979 \tTraining Loss: 1.076797 \tValidation Loss: 1.478736\n",
      "Validation loss decreased (1.478737 --> 1.478736).         Saving model ...\n",
      "Epoch: 3980 \tTraining Loss: 1.076795 \tValidation Loss: 1.478735\n",
      "Validation loss decreased (1.478736 --> 1.478735).         Saving model ...\n",
      "Epoch: 3981 \tTraining Loss: 1.076794 \tValidation Loss: 1.478734\n",
      "Validation loss decreased (1.478735 --> 1.478734).         Saving model ...\n",
      "Epoch: 3982 \tTraining Loss: 1.076792 \tValidation Loss: 1.478734\n",
      "Validation loss decreased (1.478734 --> 1.478734).         Saving model ...\n",
      "Epoch: 3983 \tTraining Loss: 1.076791 \tValidation Loss: 1.478733\n",
      "Validation loss decreased (1.478734 --> 1.478733).         Saving model ...\n",
      "Epoch: 3984 \tTraining Loss: 1.076789 \tValidation Loss: 1.478731\n",
      "Validation loss decreased (1.478733 --> 1.478731).         Saving model ...\n",
      "Epoch: 3985 \tTraining Loss: 1.076788 \tValidation Loss: 1.478731\n",
      "Validation loss decreased (1.478731 --> 1.478731).         Saving model ...\n",
      "Epoch: 3986 \tTraining Loss: 1.076786 \tValidation Loss: 1.478730\n",
      "Validation loss decreased (1.478731 --> 1.478730).         Saving model ...\n",
      "Epoch: 3987 \tTraining Loss: 1.076784 \tValidation Loss: 1.478730\n",
      "Validation loss decreased (1.478730 --> 1.478730).         Saving model ...\n",
      "Epoch: 3988 \tTraining Loss: 1.076783 \tValidation Loss: 1.478729\n",
      "Validation loss decreased (1.478730 --> 1.478729).         Saving model ...\n",
      "Epoch: 3989 \tTraining Loss: 1.076781 \tValidation Loss: 1.478728\n",
      "Validation loss decreased (1.478729 --> 1.478728).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3990 \tTraining Loss: 1.076780 \tValidation Loss: 1.478728\n",
      "Validation loss decreased (1.478728 --> 1.478728).         Saving model ...\n",
      "Epoch: 3991 \tTraining Loss: 1.076778 \tValidation Loss: 1.478727\n",
      "Validation loss decreased (1.478728 --> 1.478727).         Saving model ...\n",
      "Epoch: 3992 \tTraining Loss: 1.076777 \tValidation Loss: 1.478726\n",
      "Validation loss decreased (1.478727 --> 1.478726).         Saving model ...\n",
      "Epoch: 3993 \tTraining Loss: 1.076775 \tValidation Loss: 1.478725\n",
      "Validation loss decreased (1.478726 --> 1.478725).         Saving model ...\n",
      "Epoch: 3994 \tTraining Loss: 1.076774 \tValidation Loss: 1.478725\n",
      "Validation loss decreased (1.478725 --> 1.478725).         Saving model ...\n",
      "Epoch: 3995 \tTraining Loss: 1.076772 \tValidation Loss: 1.478724\n",
      "Validation loss decreased (1.478725 --> 1.478724).         Saving model ...\n",
      "Epoch: 3996 \tTraining Loss: 1.076771 \tValidation Loss: 1.478723\n",
      "Validation loss decreased (1.478724 --> 1.478723).         Saving model ...\n",
      "Epoch: 3997 \tTraining Loss: 1.076769 \tValidation Loss: 1.478723\n",
      "Validation loss decreased (1.478723 --> 1.478723).         Saving model ...\n",
      "Epoch: 3998 \tTraining Loss: 1.076768 \tValidation Loss: 1.478722\n",
      "Validation loss decreased (1.478723 --> 1.478722).         Saving model ...\n",
      "Epoch: 3999 \tTraining Loss: 1.076766 \tValidation Loss: 1.478722\n",
      "Epoch: 4000 \tTraining Loss: 1.076765 \tValidation Loss: 1.478721\n",
      "Validation loss decreased (1.478722 --> 1.478721).         Saving model ...\n",
      "Epoch: 4001 \tTraining Loss: 1.076763 \tValidation Loss: 1.478721\n",
      "Validation loss decreased (1.478721 --> 1.478721).         Saving model ...\n",
      "Epoch: 4002 \tTraining Loss: 1.076762 \tValidation Loss: 1.478720\n",
      "Validation loss decreased (1.478721 --> 1.478720).         Saving model ...\n",
      "Epoch: 4003 \tTraining Loss: 1.076760 \tValidation Loss: 1.478720\n",
      "Validation loss decreased (1.478720 --> 1.478720).         Saving model ...\n",
      "Epoch: 4004 \tTraining Loss: 1.076759 \tValidation Loss: 1.478719\n",
      "Validation loss decreased (1.478720 --> 1.478719).         Saving model ...\n",
      "Epoch: 4005 \tTraining Loss: 1.076757 \tValidation Loss: 1.478719\n",
      "Validation loss decreased (1.478719 --> 1.478719).         Saving model ...\n",
      "Epoch: 4006 \tTraining Loss: 1.076755 \tValidation Loss: 1.478719\n",
      "Validation loss decreased (1.478719 --> 1.478719).         Saving model ...\n",
      "Epoch: 4007 \tTraining Loss: 1.076754 \tValidation Loss: 1.478718\n",
      "Validation loss decreased (1.478719 --> 1.478718).         Saving model ...\n",
      "Epoch: 4008 \tTraining Loss: 1.076752 \tValidation Loss: 1.478717\n",
      "Validation loss decreased (1.478718 --> 1.478717).         Saving model ...\n",
      "Epoch: 4009 \tTraining Loss: 1.076751 \tValidation Loss: 1.478716\n",
      "Validation loss decreased (1.478717 --> 1.478716).         Saving model ...\n",
      "Epoch: 4010 \tTraining Loss: 1.076749 \tValidation Loss: 1.478715\n",
      "Validation loss decreased (1.478716 --> 1.478715).         Saving model ...\n",
      "Epoch: 4011 \tTraining Loss: 1.076748 \tValidation Loss: 1.478715\n",
      "Validation loss decreased (1.478715 --> 1.478715).         Saving model ...\n",
      "Epoch: 4012 \tTraining Loss: 1.076746 \tValidation Loss: 1.478713\n",
      "Validation loss decreased (1.478715 --> 1.478713).         Saving model ...\n",
      "Epoch: 4013 \tTraining Loss: 1.076745 \tValidation Loss: 1.478713\n",
      "Validation loss decreased (1.478713 --> 1.478713).         Saving model ...\n",
      "Epoch: 4014 \tTraining Loss: 1.076743 \tValidation Loss: 1.478712\n",
      "Validation loss decreased (1.478713 --> 1.478712).         Saving model ...\n",
      "Epoch: 4015 \tTraining Loss: 1.076742 \tValidation Loss: 1.478711\n",
      "Validation loss decreased (1.478712 --> 1.478711).         Saving model ...\n",
      "Epoch: 4016 \tTraining Loss: 1.076740 \tValidation Loss: 1.478710\n",
      "Validation loss decreased (1.478711 --> 1.478710).         Saving model ...\n",
      "Epoch: 4017 \tTraining Loss: 1.076739 \tValidation Loss: 1.478709\n",
      "Validation loss decreased (1.478710 --> 1.478709).         Saving model ...\n",
      "Epoch: 4018 \tTraining Loss: 1.076737 \tValidation Loss: 1.478708\n",
      "Validation loss decreased (1.478709 --> 1.478708).         Saving model ...\n",
      "Epoch: 4019 \tTraining Loss: 1.076736 \tValidation Loss: 1.478708\n",
      "Validation loss decreased (1.478708 --> 1.478708).         Saving model ...\n",
      "Epoch: 4020 \tTraining Loss: 1.076734 \tValidation Loss: 1.478707\n",
      "Validation loss decreased (1.478708 --> 1.478707).         Saving model ...\n",
      "Epoch: 4021 \tTraining Loss: 1.076733 \tValidation Loss: 1.478706\n",
      "Validation loss decreased (1.478707 --> 1.478706).         Saving model ...\n",
      "Epoch: 4022 \tTraining Loss: 1.076731 \tValidation Loss: 1.478705\n",
      "Validation loss decreased (1.478706 --> 1.478705).         Saving model ...\n",
      "Epoch: 4023 \tTraining Loss: 1.076730 \tValidation Loss: 1.478705\n",
      "Validation loss decreased (1.478705 --> 1.478705).         Saving model ...\n",
      "Epoch: 4024 \tTraining Loss: 1.076728 \tValidation Loss: 1.478705\n",
      "Validation loss decreased (1.478705 --> 1.478705).         Saving model ...\n",
      "Epoch: 4025 \tTraining Loss: 1.076727 \tValidation Loss: 1.478704\n",
      "Validation loss decreased (1.478705 --> 1.478704).         Saving model ...\n",
      "Epoch: 4026 \tTraining Loss: 1.076725 \tValidation Loss: 1.478704\n",
      "Epoch: 4027 \tTraining Loss: 1.076724 \tValidation Loss: 1.478704\n",
      "Validation loss decreased (1.478704 --> 1.478704).         Saving model ...\n",
      "Epoch: 4028 \tTraining Loss: 1.076722 \tValidation Loss: 1.478703\n",
      "Validation loss decreased (1.478704 --> 1.478703).         Saving model ...\n",
      "Epoch: 4029 \tTraining Loss: 1.076721 \tValidation Loss: 1.478702\n",
      "Validation loss decreased (1.478703 --> 1.478702).         Saving model ...\n",
      "Epoch: 4030 \tTraining Loss: 1.076719 \tValidation Loss: 1.478701\n",
      "Validation loss decreased (1.478702 --> 1.478701).         Saving model ...\n",
      "Epoch: 4031 \tTraining Loss: 1.076718 \tValidation Loss: 1.478700\n",
      "Validation loss decreased (1.478701 --> 1.478700).         Saving model ...\n",
      "Epoch: 4032 \tTraining Loss: 1.076716 \tValidation Loss: 1.478699\n",
      "Validation loss decreased (1.478700 --> 1.478699).         Saving model ...\n",
      "Epoch: 4033 \tTraining Loss: 1.076715 \tValidation Loss: 1.478699\n",
      "Validation loss decreased (1.478699 --> 1.478699).         Saving model ...\n",
      "Epoch: 4034 \tTraining Loss: 1.076713 \tValidation Loss: 1.478698\n",
      "Validation loss decreased (1.478699 --> 1.478698).         Saving model ...\n",
      "Epoch: 4035 \tTraining Loss: 1.076712 \tValidation Loss: 1.478697\n",
      "Validation loss decreased (1.478698 --> 1.478697).         Saving model ...\n",
      "Epoch: 4036 \tTraining Loss: 1.076710 \tValidation Loss: 1.478696\n",
      "Validation loss decreased (1.478697 --> 1.478696).         Saving model ...\n",
      "Epoch: 4037 \tTraining Loss: 1.076709 \tValidation Loss: 1.478696\n",
      "Validation loss decreased (1.478696 --> 1.478696).         Saving model ...\n",
      "Epoch: 4038 \tTraining Loss: 1.076707 \tValidation Loss: 1.478695\n",
      "Validation loss decreased (1.478696 --> 1.478695).         Saving model ...\n",
      "Epoch: 4039 \tTraining Loss: 1.076706 \tValidation Loss: 1.478694\n",
      "Validation loss decreased (1.478695 --> 1.478694).         Saving model ...\n",
      "Epoch: 4040 \tTraining Loss: 1.076704 \tValidation Loss: 1.478693\n",
      "Validation loss decreased (1.478694 --> 1.478693).         Saving model ...\n",
      "Epoch: 4041 \tTraining Loss: 1.076703 \tValidation Loss: 1.478692\n",
      "Validation loss decreased (1.478693 --> 1.478692).         Saving model ...\n",
      "Epoch: 4042 \tTraining Loss: 1.076701 \tValidation Loss: 1.478691\n",
      "Validation loss decreased (1.478692 --> 1.478691).         Saving model ...\n",
      "Epoch: 4043 \tTraining Loss: 1.076700 \tValidation Loss: 1.478690\n",
      "Validation loss decreased (1.478691 --> 1.478690).         Saving model ...\n",
      "Epoch: 4044 \tTraining Loss: 1.076698 \tValidation Loss: 1.478690\n",
      "Validation loss decreased (1.478690 --> 1.478690).         Saving model ...\n",
      "Epoch: 4045 \tTraining Loss: 1.076697 \tValidation Loss: 1.478688\n",
      "Validation loss decreased (1.478690 --> 1.478688).         Saving model ...\n",
      "Epoch: 4046 \tTraining Loss: 1.076695 \tValidation Loss: 1.478687\n",
      "Validation loss decreased (1.478688 --> 1.478687).         Saving model ...\n",
      "Epoch: 4047 \tTraining Loss: 1.076694 \tValidation Loss: 1.478686\n",
      "Validation loss decreased (1.478687 --> 1.478686).         Saving model ...\n",
      "Epoch: 4048 \tTraining Loss: 1.076692 \tValidation Loss: 1.478685\n",
      "Validation loss decreased (1.478686 --> 1.478685).         Saving model ...\n",
      "Epoch: 4049 \tTraining Loss: 1.076691 \tValidation Loss: 1.478684\n",
      "Validation loss decreased (1.478685 --> 1.478684).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4050 \tTraining Loss: 1.076689 \tValidation Loss: 1.478683\n",
      "Validation loss decreased (1.478684 --> 1.478683).         Saving model ...\n",
      "Epoch: 4051 \tTraining Loss: 1.076688 \tValidation Loss: 1.478682\n",
      "Validation loss decreased (1.478683 --> 1.478682).         Saving model ...\n",
      "Epoch: 4052 \tTraining Loss: 1.076686 \tValidation Loss: 1.478680\n",
      "Validation loss decreased (1.478682 --> 1.478680).         Saving model ...\n",
      "Epoch: 4053 \tTraining Loss: 1.076685 \tValidation Loss: 1.478679\n",
      "Validation loss decreased (1.478680 --> 1.478679).         Saving model ...\n",
      "Epoch: 4054 \tTraining Loss: 1.076683 \tValidation Loss: 1.478678\n",
      "Validation loss decreased (1.478679 --> 1.478678).         Saving model ...\n",
      "Epoch: 4055 \tTraining Loss: 1.076682 \tValidation Loss: 1.478677\n",
      "Validation loss decreased (1.478678 --> 1.478677).         Saving model ...\n",
      "Epoch: 4056 \tTraining Loss: 1.076680 \tValidation Loss: 1.478677\n",
      "Validation loss decreased (1.478677 --> 1.478677).         Saving model ...\n",
      "Epoch: 4057 \tTraining Loss: 1.076679 \tValidation Loss: 1.478676\n",
      "Validation loss decreased (1.478677 --> 1.478676).         Saving model ...\n",
      "Epoch: 4058 \tTraining Loss: 1.076677 \tValidation Loss: 1.478675\n",
      "Validation loss decreased (1.478676 --> 1.478675).         Saving model ...\n",
      "Epoch: 4059 \tTraining Loss: 1.076676 \tValidation Loss: 1.478674\n",
      "Validation loss decreased (1.478675 --> 1.478674).         Saving model ...\n",
      "Epoch: 4060 \tTraining Loss: 1.076674 \tValidation Loss: 1.478673\n",
      "Validation loss decreased (1.478674 --> 1.478673).         Saving model ...\n",
      "Epoch: 4061 \tTraining Loss: 1.076673 \tValidation Loss: 1.478671\n",
      "Validation loss decreased (1.478673 --> 1.478671).         Saving model ...\n",
      "Epoch: 4062 \tTraining Loss: 1.076671 \tValidation Loss: 1.478671\n",
      "Validation loss decreased (1.478671 --> 1.478671).         Saving model ...\n",
      "Epoch: 4063 \tTraining Loss: 1.076670 \tValidation Loss: 1.478670\n",
      "Validation loss decreased (1.478671 --> 1.478670).         Saving model ...\n",
      "Epoch: 4064 \tTraining Loss: 1.076668 \tValidation Loss: 1.478669\n",
      "Validation loss decreased (1.478670 --> 1.478669).         Saving model ...\n",
      "Epoch: 4065 \tTraining Loss: 1.076667 \tValidation Loss: 1.478668\n",
      "Validation loss decreased (1.478669 --> 1.478668).         Saving model ...\n",
      "Epoch: 4066 \tTraining Loss: 1.076665 \tValidation Loss: 1.478667\n",
      "Validation loss decreased (1.478668 --> 1.478667).         Saving model ...\n",
      "Epoch: 4067 \tTraining Loss: 1.076664 \tValidation Loss: 1.478666\n",
      "Validation loss decreased (1.478667 --> 1.478666).         Saving model ...\n",
      "Epoch: 4068 \tTraining Loss: 1.076663 \tValidation Loss: 1.478665\n",
      "Validation loss decreased (1.478666 --> 1.478665).         Saving model ...\n",
      "Epoch: 4069 \tTraining Loss: 1.076661 \tValidation Loss: 1.478664\n",
      "Validation loss decreased (1.478665 --> 1.478664).         Saving model ...\n",
      "Epoch: 4070 \tTraining Loss: 1.076660 \tValidation Loss: 1.478663\n",
      "Validation loss decreased (1.478664 --> 1.478663).         Saving model ...\n",
      "Epoch: 4071 \tTraining Loss: 1.076658 \tValidation Loss: 1.478663\n",
      "Validation loss decreased (1.478663 --> 1.478663).         Saving model ...\n",
      "Epoch: 4072 \tTraining Loss: 1.076657 \tValidation Loss: 1.478661\n",
      "Validation loss decreased (1.478663 --> 1.478661).         Saving model ...\n",
      "Epoch: 4073 \tTraining Loss: 1.076655 \tValidation Loss: 1.478661\n",
      "Epoch: 4074 \tTraining Loss: 1.076654 \tValidation Loss: 1.478660\n",
      "Validation loss decreased (1.478661 --> 1.478660).         Saving model ...\n",
      "Epoch: 4075 \tTraining Loss: 1.076652 \tValidation Loss: 1.478659\n",
      "Validation loss decreased (1.478660 --> 1.478659).         Saving model ...\n",
      "Epoch: 4076 \tTraining Loss: 1.076651 \tValidation Loss: 1.478659\n",
      "Validation loss decreased (1.478659 --> 1.478659).         Saving model ...\n",
      "Epoch: 4077 \tTraining Loss: 1.076649 \tValidation Loss: 1.478658\n",
      "Validation loss decreased (1.478659 --> 1.478658).         Saving model ...\n",
      "Epoch: 4078 \tTraining Loss: 1.076648 \tValidation Loss: 1.478658\n",
      "Validation loss decreased (1.478658 --> 1.478658).         Saving model ...\n",
      "Epoch: 4079 \tTraining Loss: 1.076646 \tValidation Loss: 1.478658\n",
      "Validation loss decreased (1.478658 --> 1.478658).         Saving model ...\n",
      "Epoch: 4080 \tTraining Loss: 1.076645 \tValidation Loss: 1.478657\n",
      "Validation loss decreased (1.478658 --> 1.478657).         Saving model ...\n",
      "Epoch: 4081 \tTraining Loss: 1.076643 \tValidation Loss: 1.478657\n",
      "Validation loss decreased (1.478657 --> 1.478657).         Saving model ...\n",
      "Epoch: 4082 \tTraining Loss: 1.076642 \tValidation Loss: 1.478656\n",
      "Validation loss decreased (1.478657 --> 1.478656).         Saving model ...\n",
      "Epoch: 4083 \tTraining Loss: 1.076640 \tValidation Loss: 1.478655\n",
      "Validation loss decreased (1.478656 --> 1.478655).         Saving model ...\n",
      "Epoch: 4084 \tTraining Loss: 1.076639 \tValidation Loss: 1.478654\n",
      "Validation loss decreased (1.478655 --> 1.478654).         Saving model ...\n",
      "Epoch: 4085 \tTraining Loss: 1.076637 \tValidation Loss: 1.478654\n",
      "Validation loss decreased (1.478654 --> 1.478654).         Saving model ...\n",
      "Epoch: 4086 \tTraining Loss: 1.076636 \tValidation Loss: 1.478653\n",
      "Validation loss decreased (1.478654 --> 1.478653).         Saving model ...\n",
      "Epoch: 4087 \tTraining Loss: 1.076634 \tValidation Loss: 1.478652\n",
      "Validation loss decreased (1.478653 --> 1.478652).         Saving model ...\n",
      "Epoch: 4088 \tTraining Loss: 1.076633 \tValidation Loss: 1.478651\n",
      "Validation loss decreased (1.478652 --> 1.478651).         Saving model ...\n",
      "Epoch: 4089 \tTraining Loss: 1.076632 \tValidation Loss: 1.478651\n",
      "Validation loss decreased (1.478651 --> 1.478651).         Saving model ...\n",
      "Epoch: 4090 \tTraining Loss: 1.076630 \tValidation Loss: 1.478650\n",
      "Validation loss decreased (1.478651 --> 1.478650).         Saving model ...\n",
      "Epoch: 4091 \tTraining Loss: 1.076629 \tValidation Loss: 1.478649\n",
      "Validation loss decreased (1.478650 --> 1.478649).         Saving model ...\n",
      "Epoch: 4092 \tTraining Loss: 1.076627 \tValidation Loss: 1.478649\n",
      "Validation loss decreased (1.478649 --> 1.478649).         Saving model ...\n",
      "Epoch: 4093 \tTraining Loss: 1.076626 \tValidation Loss: 1.478648\n",
      "Validation loss decreased (1.478649 --> 1.478648).         Saving model ...\n",
      "Epoch: 4094 \tTraining Loss: 1.076624 \tValidation Loss: 1.478648\n",
      "Validation loss decreased (1.478648 --> 1.478648).         Saving model ...\n",
      "Epoch: 4095 \tTraining Loss: 1.076623 \tValidation Loss: 1.478647\n",
      "Validation loss decreased (1.478648 --> 1.478647).         Saving model ...\n",
      "Epoch: 4096 \tTraining Loss: 1.076621 \tValidation Loss: 1.478645\n",
      "Validation loss decreased (1.478647 --> 1.478645).         Saving model ...\n",
      "Epoch: 4097 \tTraining Loss: 1.076620 \tValidation Loss: 1.478644\n",
      "Validation loss decreased (1.478645 --> 1.478644).         Saving model ...\n",
      "Epoch: 4098 \tTraining Loss: 1.076618 \tValidation Loss: 1.478644\n",
      "Validation loss decreased (1.478644 --> 1.478644).         Saving model ...\n",
      "Epoch: 4099 \tTraining Loss: 1.076617 \tValidation Loss: 1.478643\n",
      "Validation loss decreased (1.478644 --> 1.478643).         Saving model ...\n",
      "Epoch: 4100 \tTraining Loss: 1.076615 \tValidation Loss: 1.478642\n",
      "Validation loss decreased (1.478643 --> 1.478642).         Saving model ...\n",
      "Epoch: 4101 \tTraining Loss: 1.076614 \tValidation Loss: 1.478642\n",
      "Validation loss decreased (1.478642 --> 1.478642).         Saving model ...\n",
      "Epoch: 4102 \tTraining Loss: 1.076613 \tValidation Loss: 1.478641\n",
      "Validation loss decreased (1.478642 --> 1.478641).         Saving model ...\n",
      "Epoch: 4103 \tTraining Loss: 1.076611 \tValidation Loss: 1.478640\n",
      "Validation loss decreased (1.478641 --> 1.478640).         Saving model ...\n",
      "Epoch: 4104 \tTraining Loss: 1.076610 \tValidation Loss: 1.478639\n",
      "Validation loss decreased (1.478640 --> 1.478639).         Saving model ...\n",
      "Epoch: 4105 \tTraining Loss: 1.076608 \tValidation Loss: 1.478639\n",
      "Validation loss decreased (1.478639 --> 1.478639).         Saving model ...\n",
      "Epoch: 4106 \tTraining Loss: 1.076607 \tValidation Loss: 1.478638\n",
      "Validation loss decreased (1.478639 --> 1.478638).         Saving model ...\n",
      "Epoch: 4107 \tTraining Loss: 1.076605 \tValidation Loss: 1.478637\n",
      "Validation loss decreased (1.478638 --> 1.478637).         Saving model ...\n",
      "Epoch: 4108 \tTraining Loss: 1.076604 \tValidation Loss: 1.478637\n",
      "Validation loss decreased (1.478637 --> 1.478637).         Saving model ...\n",
      "Epoch: 4109 \tTraining Loss: 1.076602 \tValidation Loss: 1.478636\n",
      "Validation loss decreased (1.478637 --> 1.478636).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4110 \tTraining Loss: 1.076601 \tValidation Loss: 1.478635\n",
      "Validation loss decreased (1.478636 --> 1.478635).         Saving model ...\n",
      "Epoch: 4111 \tTraining Loss: 1.076599 \tValidation Loss: 1.478634\n",
      "Validation loss decreased (1.478635 --> 1.478634).         Saving model ...\n",
      "Epoch: 4112 \tTraining Loss: 1.076598 \tValidation Loss: 1.478634\n",
      "Validation loss decreased (1.478634 --> 1.478634).         Saving model ...\n",
      "Epoch: 4113 \tTraining Loss: 1.076596 \tValidation Loss: 1.478633\n",
      "Validation loss decreased (1.478634 --> 1.478633).         Saving model ...\n",
      "Epoch: 4114 \tTraining Loss: 1.076595 \tValidation Loss: 1.478631\n",
      "Validation loss decreased (1.478633 --> 1.478631).         Saving model ...\n",
      "Epoch: 4115 \tTraining Loss: 1.076594 \tValidation Loss: 1.478631\n",
      "Validation loss decreased (1.478631 --> 1.478631).         Saving model ...\n",
      "Epoch: 4116 \tTraining Loss: 1.076592 \tValidation Loss: 1.478630\n",
      "Validation loss decreased (1.478631 --> 1.478630).         Saving model ...\n",
      "Epoch: 4117 \tTraining Loss: 1.076591 \tValidation Loss: 1.478630\n",
      "Validation loss decreased (1.478630 --> 1.478630).         Saving model ...\n",
      "Epoch: 4118 \tTraining Loss: 1.076589 \tValidation Loss: 1.478630\n",
      "Epoch: 4119 \tTraining Loss: 1.076588 \tValidation Loss: 1.478630\n",
      "Validation loss decreased (1.478630 --> 1.478630).         Saving model ...\n",
      "Epoch: 4120 \tTraining Loss: 1.076586 \tValidation Loss: 1.478630\n",
      "Validation loss decreased (1.478630 --> 1.478630).         Saving model ...\n",
      "Epoch: 4121 \tTraining Loss: 1.076585 \tValidation Loss: 1.478629\n",
      "Validation loss decreased (1.478630 --> 1.478629).         Saving model ...\n",
      "Epoch: 4122 \tTraining Loss: 1.076583 \tValidation Loss: 1.478629\n",
      "Validation loss decreased (1.478629 --> 1.478629).         Saving model ...\n",
      "Epoch: 4123 \tTraining Loss: 1.076582 \tValidation Loss: 1.478628\n",
      "Validation loss decreased (1.478629 --> 1.478628).         Saving model ...\n",
      "Epoch: 4124 \tTraining Loss: 1.076580 \tValidation Loss: 1.478628\n",
      "Validation loss decreased (1.478628 --> 1.478628).         Saving model ...\n",
      "Epoch: 4125 \tTraining Loss: 1.076579 \tValidation Loss: 1.478628\n",
      "Validation loss decreased (1.478628 --> 1.478628).         Saving model ...\n",
      "Epoch: 4126 \tTraining Loss: 1.076578 \tValidation Loss: 1.478627\n",
      "Validation loss decreased (1.478628 --> 1.478627).         Saving model ...\n",
      "Epoch: 4127 \tTraining Loss: 1.076576 \tValidation Loss: 1.478627\n",
      "Validation loss decreased (1.478627 --> 1.478627).         Saving model ...\n",
      "Epoch: 4128 \tTraining Loss: 1.076575 \tValidation Loss: 1.478626\n",
      "Validation loss decreased (1.478627 --> 1.478626).         Saving model ...\n",
      "Epoch: 4129 \tTraining Loss: 1.076573 \tValidation Loss: 1.478625\n",
      "Validation loss decreased (1.478626 --> 1.478625).         Saving model ...\n",
      "Epoch: 4130 \tTraining Loss: 1.076572 \tValidation Loss: 1.478625\n",
      "Validation loss decreased (1.478625 --> 1.478625).         Saving model ...\n",
      "Epoch: 4131 \tTraining Loss: 1.076570 \tValidation Loss: 1.478624\n",
      "Validation loss decreased (1.478625 --> 1.478624).         Saving model ...\n",
      "Epoch: 4132 \tTraining Loss: 1.076569 \tValidation Loss: 1.478624\n",
      "Validation loss decreased (1.478624 --> 1.478624).         Saving model ...\n",
      "Epoch: 4133 \tTraining Loss: 1.076567 \tValidation Loss: 1.478622\n",
      "Validation loss decreased (1.478624 --> 1.478622).         Saving model ...\n",
      "Epoch: 4134 \tTraining Loss: 1.076566 \tValidation Loss: 1.478622\n",
      "Validation loss decreased (1.478622 --> 1.478622).         Saving model ...\n",
      "Epoch: 4135 \tTraining Loss: 1.076565 \tValidation Loss: 1.478621\n",
      "Validation loss decreased (1.478622 --> 1.478621).         Saving model ...\n",
      "Epoch: 4136 \tTraining Loss: 1.076563 \tValidation Loss: 1.478620\n",
      "Validation loss decreased (1.478621 --> 1.478620).         Saving model ...\n",
      "Epoch: 4137 \tTraining Loss: 1.076562 \tValidation Loss: 1.478619\n",
      "Validation loss decreased (1.478620 --> 1.478619).         Saving model ...\n",
      "Epoch: 4138 \tTraining Loss: 1.076560 \tValidation Loss: 1.478619\n",
      "Validation loss decreased (1.478619 --> 1.478619).         Saving model ...\n",
      "Epoch: 4139 \tTraining Loss: 1.076559 \tValidation Loss: 1.478618\n",
      "Validation loss decreased (1.478619 --> 1.478618).         Saving model ...\n",
      "Epoch: 4140 \tTraining Loss: 1.076557 \tValidation Loss: 1.478617\n",
      "Validation loss decreased (1.478618 --> 1.478617).         Saving model ...\n",
      "Epoch: 4141 \tTraining Loss: 1.076556 \tValidation Loss: 1.478616\n",
      "Validation loss decreased (1.478617 --> 1.478616).         Saving model ...\n",
      "Epoch: 4142 \tTraining Loss: 1.076554 \tValidation Loss: 1.478616\n",
      "Validation loss decreased (1.478616 --> 1.478616).         Saving model ...\n",
      "Epoch: 4143 \tTraining Loss: 1.076553 \tValidation Loss: 1.478615\n",
      "Validation loss decreased (1.478616 --> 1.478615).         Saving model ...\n",
      "Epoch: 4144 \tTraining Loss: 1.076552 \tValidation Loss: 1.478614\n",
      "Validation loss decreased (1.478615 --> 1.478614).         Saving model ...\n",
      "Epoch: 4145 \tTraining Loss: 1.076550 \tValidation Loss: 1.478613\n",
      "Validation loss decreased (1.478614 --> 1.478613).         Saving model ...\n",
      "Epoch: 4146 \tTraining Loss: 1.076549 \tValidation Loss: 1.478612\n",
      "Validation loss decreased (1.478613 --> 1.478612).         Saving model ...\n",
      "Epoch: 4147 \tTraining Loss: 1.076547 \tValidation Loss: 1.478612\n",
      "Validation loss decreased (1.478612 --> 1.478612).         Saving model ...\n",
      "Epoch: 4148 \tTraining Loss: 1.076546 \tValidation Loss: 1.478611\n",
      "Validation loss decreased (1.478612 --> 1.478611).         Saving model ...\n",
      "Epoch: 4149 \tTraining Loss: 1.076544 \tValidation Loss: 1.478610\n",
      "Validation loss decreased (1.478611 --> 1.478610).         Saving model ...\n",
      "Epoch: 4150 \tTraining Loss: 1.076543 \tValidation Loss: 1.478609\n",
      "Validation loss decreased (1.478610 --> 1.478609).         Saving model ...\n",
      "Epoch: 4151 \tTraining Loss: 1.076541 \tValidation Loss: 1.478609\n",
      "Validation loss decreased (1.478609 --> 1.478609).         Saving model ...\n",
      "Epoch: 4152 \tTraining Loss: 1.076540 \tValidation Loss: 1.478608\n",
      "Validation loss decreased (1.478609 --> 1.478608).         Saving model ...\n",
      "Epoch: 4153 \tTraining Loss: 1.076539 \tValidation Loss: 1.478607\n",
      "Validation loss decreased (1.478608 --> 1.478607).         Saving model ...\n",
      "Epoch: 4154 \tTraining Loss: 1.076537 \tValidation Loss: 1.478607\n",
      "Validation loss decreased (1.478607 --> 1.478607).         Saving model ...\n",
      "Epoch: 4155 \tTraining Loss: 1.076536 \tValidation Loss: 1.478605\n",
      "Validation loss decreased (1.478607 --> 1.478605).         Saving model ...\n",
      "Epoch: 4156 \tTraining Loss: 1.076534 \tValidation Loss: 1.478605\n",
      "Validation loss decreased (1.478605 --> 1.478605).         Saving model ...\n",
      "Epoch: 4157 \tTraining Loss: 1.076533 \tValidation Loss: 1.478604\n",
      "Validation loss decreased (1.478605 --> 1.478604).         Saving model ...\n",
      "Epoch: 4158 \tTraining Loss: 1.076531 \tValidation Loss: 1.478604\n",
      "Validation loss decreased (1.478604 --> 1.478604).         Saving model ...\n",
      "Epoch: 4159 \tTraining Loss: 1.076530 \tValidation Loss: 1.478602\n",
      "Validation loss decreased (1.478604 --> 1.478602).         Saving model ...\n",
      "Epoch: 4160 \tTraining Loss: 1.076529 \tValidation Loss: 1.478602\n",
      "Validation loss decreased (1.478602 --> 1.478602).         Saving model ...\n",
      "Epoch: 4161 \tTraining Loss: 1.076527 \tValidation Loss: 1.478600\n",
      "Validation loss decreased (1.478602 --> 1.478600).         Saving model ...\n",
      "Epoch: 4162 \tTraining Loss: 1.076526 \tValidation Loss: 1.478599\n",
      "Validation loss decreased (1.478600 --> 1.478599).         Saving model ...\n",
      "Epoch: 4163 \tTraining Loss: 1.076524 \tValidation Loss: 1.478597\n",
      "Validation loss decreased (1.478599 --> 1.478597).         Saving model ...\n",
      "Epoch: 4164 \tTraining Loss: 1.076523 \tValidation Loss: 1.478596\n",
      "Validation loss decreased (1.478597 --> 1.478596).         Saving model ...\n",
      "Epoch: 4165 \tTraining Loss: 1.076521 \tValidation Loss: 1.478594\n",
      "Validation loss decreased (1.478596 --> 1.478594).         Saving model ...\n",
      "Epoch: 4166 \tTraining Loss: 1.076520 \tValidation Loss: 1.478592\n",
      "Validation loss decreased (1.478594 --> 1.478592).         Saving model ...\n",
      "Epoch: 4167 \tTraining Loss: 1.076519 \tValidation Loss: 1.478591\n",
      "Validation loss decreased (1.478592 --> 1.478591).         Saving model ...\n",
      "Epoch: 4168 \tTraining Loss: 1.076517 \tValidation Loss: 1.478590\n",
      "Validation loss decreased (1.478591 --> 1.478590).         Saving model ...\n",
      "Epoch: 4169 \tTraining Loss: 1.076516 \tValidation Loss: 1.478589\n",
      "Validation loss decreased (1.478590 --> 1.478589).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4170 \tTraining Loss: 1.076514 \tValidation Loss: 1.478587\n",
      "Validation loss decreased (1.478589 --> 1.478587).         Saving model ...\n",
      "Epoch: 4171 \tTraining Loss: 1.076513 \tValidation Loss: 1.478585\n",
      "Validation loss decreased (1.478587 --> 1.478585).         Saving model ...\n",
      "Epoch: 4172 \tTraining Loss: 1.076511 \tValidation Loss: 1.478584\n",
      "Validation loss decreased (1.478585 --> 1.478584).         Saving model ...\n",
      "Epoch: 4173 \tTraining Loss: 1.076510 \tValidation Loss: 1.478583\n",
      "Validation loss decreased (1.478584 --> 1.478583).         Saving model ...\n",
      "Epoch: 4174 \tTraining Loss: 1.076509 \tValidation Loss: 1.478581\n",
      "Validation loss decreased (1.478583 --> 1.478581).         Saving model ...\n",
      "Epoch: 4175 \tTraining Loss: 1.076507 \tValidation Loss: 1.478579\n",
      "Validation loss decreased (1.478581 --> 1.478579).         Saving model ...\n",
      "Epoch: 4176 \tTraining Loss: 1.076506 \tValidation Loss: 1.478579\n",
      "Validation loss decreased (1.478579 --> 1.478579).         Saving model ...\n",
      "Epoch: 4177 \tTraining Loss: 1.076504 \tValidation Loss: 1.478578\n",
      "Validation loss decreased (1.478579 --> 1.478578).         Saving model ...\n",
      "Epoch: 4178 \tTraining Loss: 1.076503 \tValidation Loss: 1.478578\n",
      "Validation loss decreased (1.478578 --> 1.478578).         Saving model ...\n",
      "Epoch: 4179 \tTraining Loss: 1.076501 \tValidation Loss: 1.478577\n",
      "Validation loss decreased (1.478578 --> 1.478577).         Saving model ...\n",
      "Epoch: 4180 \tTraining Loss: 1.076500 \tValidation Loss: 1.478575\n",
      "Validation loss decreased (1.478577 --> 1.478575).         Saving model ...\n",
      "Epoch: 4181 \tTraining Loss: 1.076499 \tValidation Loss: 1.478574\n",
      "Validation loss decreased (1.478575 --> 1.478574).         Saving model ...\n",
      "Epoch: 4182 \tTraining Loss: 1.076497 \tValidation Loss: 1.478574\n",
      "Validation loss decreased (1.478574 --> 1.478574).         Saving model ...\n",
      "Epoch: 4183 \tTraining Loss: 1.076496 \tValidation Loss: 1.478573\n",
      "Validation loss decreased (1.478574 --> 1.478573).         Saving model ...\n",
      "Epoch: 4184 \tTraining Loss: 1.076494 \tValidation Loss: 1.478572\n",
      "Validation loss decreased (1.478573 --> 1.478572).         Saving model ...\n",
      "Epoch: 4185 \tTraining Loss: 1.076493 \tValidation Loss: 1.478570\n",
      "Validation loss decreased (1.478572 --> 1.478570).         Saving model ...\n",
      "Epoch: 4186 \tTraining Loss: 1.076491 \tValidation Loss: 1.478570\n",
      "Validation loss decreased (1.478570 --> 1.478570).         Saving model ...\n",
      "Epoch: 4187 \tTraining Loss: 1.076490 \tValidation Loss: 1.478568\n",
      "Validation loss decreased (1.478570 --> 1.478568).         Saving model ...\n",
      "Epoch: 4188 \tTraining Loss: 1.076489 \tValidation Loss: 1.478568\n",
      "Validation loss decreased (1.478568 --> 1.478568).         Saving model ...\n",
      "Epoch: 4189 \tTraining Loss: 1.076487 \tValidation Loss: 1.478567\n",
      "Validation loss decreased (1.478568 --> 1.478567).         Saving model ...\n",
      "Epoch: 4190 \tTraining Loss: 1.076486 \tValidation Loss: 1.478566\n",
      "Validation loss decreased (1.478567 --> 1.478566).         Saving model ...\n",
      "Epoch: 4191 \tTraining Loss: 1.076484 \tValidation Loss: 1.478565\n",
      "Validation loss decreased (1.478566 --> 1.478565).         Saving model ...\n",
      "Epoch: 4192 \tTraining Loss: 1.076483 \tValidation Loss: 1.478565\n",
      "Validation loss decreased (1.478565 --> 1.478565).         Saving model ...\n",
      "Epoch: 4193 \tTraining Loss: 1.076482 \tValidation Loss: 1.478564\n",
      "Validation loss decreased (1.478565 --> 1.478564).         Saving model ...\n",
      "Epoch: 4194 \tTraining Loss: 1.076480 \tValidation Loss: 1.478563\n",
      "Validation loss decreased (1.478564 --> 1.478563).         Saving model ...\n",
      "Epoch: 4195 \tTraining Loss: 1.076479 \tValidation Loss: 1.478563\n",
      "Validation loss decreased (1.478563 --> 1.478563).         Saving model ...\n",
      "Epoch: 4196 \tTraining Loss: 1.076477 \tValidation Loss: 1.478562\n",
      "Validation loss decreased (1.478563 --> 1.478562).         Saving model ...\n",
      "Epoch: 4197 \tTraining Loss: 1.076476 \tValidation Loss: 1.478561\n",
      "Validation loss decreased (1.478562 --> 1.478561).         Saving model ...\n",
      "Epoch: 4198 \tTraining Loss: 1.076475 \tValidation Loss: 1.478560\n",
      "Validation loss decreased (1.478561 --> 1.478560).         Saving model ...\n",
      "Epoch: 4199 \tTraining Loss: 1.076473 \tValidation Loss: 1.478559\n",
      "Validation loss decreased (1.478560 --> 1.478559).         Saving model ...\n",
      "Epoch: 4200 \tTraining Loss: 1.076472 \tValidation Loss: 1.478558\n",
      "Validation loss decreased (1.478559 --> 1.478558).         Saving model ...\n",
      "Epoch: 4201 \tTraining Loss: 1.076470 \tValidation Loss: 1.478557\n",
      "Validation loss decreased (1.478558 --> 1.478557).         Saving model ...\n",
      "Epoch: 4202 \tTraining Loss: 1.076469 \tValidation Loss: 1.478557\n",
      "Validation loss decreased (1.478557 --> 1.478557).         Saving model ...\n",
      "Epoch: 4203 \tTraining Loss: 1.076467 \tValidation Loss: 1.478556\n",
      "Validation loss decreased (1.478557 --> 1.478556).         Saving model ...\n",
      "Epoch: 4204 \tTraining Loss: 1.076466 \tValidation Loss: 1.478555\n",
      "Validation loss decreased (1.478556 --> 1.478555).         Saving model ...\n",
      "Epoch: 4205 \tTraining Loss: 1.076465 \tValidation Loss: 1.478554\n",
      "Validation loss decreased (1.478555 --> 1.478554).         Saving model ...\n",
      "Epoch: 4206 \tTraining Loss: 1.076463 \tValidation Loss: 1.478554\n",
      "Validation loss decreased (1.478554 --> 1.478554).         Saving model ...\n",
      "Epoch: 4207 \tTraining Loss: 1.076462 \tValidation Loss: 1.478552\n",
      "Validation loss decreased (1.478554 --> 1.478552).         Saving model ...\n",
      "Epoch: 4208 \tTraining Loss: 1.076460 \tValidation Loss: 1.478552\n",
      "Validation loss decreased (1.478552 --> 1.478552).         Saving model ...\n",
      "Epoch: 4209 \tTraining Loss: 1.076459 \tValidation Loss: 1.478550\n",
      "Validation loss decreased (1.478552 --> 1.478550).         Saving model ...\n",
      "Epoch: 4210 \tTraining Loss: 1.076458 \tValidation Loss: 1.478549\n",
      "Validation loss decreased (1.478550 --> 1.478549).         Saving model ...\n",
      "Epoch: 4211 \tTraining Loss: 1.076456 \tValidation Loss: 1.478548\n",
      "Validation loss decreased (1.478549 --> 1.478548).         Saving model ...\n",
      "Epoch: 4212 \tTraining Loss: 1.076455 \tValidation Loss: 1.478547\n",
      "Validation loss decreased (1.478548 --> 1.478547).         Saving model ...\n",
      "Epoch: 4213 \tTraining Loss: 1.076453 \tValidation Loss: 1.478546\n",
      "Validation loss decreased (1.478547 --> 1.478546).         Saving model ...\n",
      "Epoch: 4214 \tTraining Loss: 1.076452 \tValidation Loss: 1.478545\n",
      "Validation loss decreased (1.478546 --> 1.478545).         Saving model ...\n",
      "Epoch: 4215 \tTraining Loss: 1.076451 \tValidation Loss: 1.478544\n",
      "Validation loss decreased (1.478545 --> 1.478544).         Saving model ...\n",
      "Epoch: 4216 \tTraining Loss: 1.076449 \tValidation Loss: 1.478544\n",
      "Validation loss decreased (1.478544 --> 1.478544).         Saving model ...\n",
      "Epoch: 4217 \tTraining Loss: 1.076448 \tValidation Loss: 1.478543\n",
      "Validation loss decreased (1.478544 --> 1.478543).         Saving model ...\n",
      "Epoch: 4218 \tTraining Loss: 1.076446 \tValidation Loss: 1.478542\n",
      "Validation loss decreased (1.478543 --> 1.478542).         Saving model ...\n",
      "Epoch: 4219 \tTraining Loss: 1.076445 \tValidation Loss: 1.478542\n",
      "Validation loss decreased (1.478542 --> 1.478542).         Saving model ...\n",
      "Epoch: 4220 \tTraining Loss: 1.076444 \tValidation Loss: 1.478541\n",
      "Validation loss decreased (1.478542 --> 1.478541).         Saving model ...\n",
      "Epoch: 4221 \tTraining Loss: 1.076442 \tValidation Loss: 1.478541\n",
      "Validation loss decreased (1.478541 --> 1.478541).         Saving model ...\n",
      "Epoch: 4222 \tTraining Loss: 1.076441 \tValidation Loss: 1.478541\n",
      "Validation loss decreased (1.478541 --> 1.478541).         Saving model ...\n",
      "Epoch: 4223 \tTraining Loss: 1.076439 \tValidation Loss: 1.478540\n",
      "Validation loss decreased (1.478541 --> 1.478540).         Saving model ...\n",
      "Epoch: 4224 \tTraining Loss: 1.076438 \tValidation Loss: 1.478539\n",
      "Validation loss decreased (1.478540 --> 1.478539).         Saving model ...\n",
      "Epoch: 4225 \tTraining Loss: 1.076437 \tValidation Loss: 1.478538\n",
      "Validation loss decreased (1.478539 --> 1.478538).         Saving model ...\n",
      "Epoch: 4226 \tTraining Loss: 1.076435 \tValidation Loss: 1.478537\n",
      "Validation loss decreased (1.478538 --> 1.478537).         Saving model ...\n",
      "Epoch: 4227 \tTraining Loss: 1.076434 \tValidation Loss: 1.478537\n",
      "Validation loss decreased (1.478537 --> 1.478537).         Saving model ...\n",
      "Epoch: 4228 \tTraining Loss: 1.076432 \tValidation Loss: 1.478536\n",
      "Validation loss decreased (1.478537 --> 1.478536).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4229 \tTraining Loss: 1.076431 \tValidation Loss: 1.478535\n",
      "Validation loss decreased (1.478536 --> 1.478535).         Saving model ...\n",
      "Epoch: 4230 \tTraining Loss: 1.076430 \tValidation Loss: 1.478534\n",
      "Validation loss decreased (1.478535 --> 1.478534).         Saving model ...\n",
      "Epoch: 4231 \tTraining Loss: 1.076428 \tValidation Loss: 1.478533\n",
      "Validation loss decreased (1.478534 --> 1.478533).         Saving model ...\n",
      "Epoch: 4232 \tTraining Loss: 1.076427 \tValidation Loss: 1.478532\n",
      "Validation loss decreased (1.478533 --> 1.478532).         Saving model ...\n",
      "Epoch: 4233 \tTraining Loss: 1.076425 \tValidation Loss: 1.478531\n",
      "Validation loss decreased (1.478532 --> 1.478531).         Saving model ...\n",
      "Epoch: 4234 \tTraining Loss: 1.076424 \tValidation Loss: 1.478529\n",
      "Validation loss decreased (1.478531 --> 1.478529).         Saving model ...\n",
      "Epoch: 4235 \tTraining Loss: 1.076423 \tValidation Loss: 1.478528\n",
      "Validation loss decreased (1.478529 --> 1.478528).         Saving model ...\n",
      "Epoch: 4236 \tTraining Loss: 1.076421 \tValidation Loss: 1.478527\n",
      "Validation loss decreased (1.478528 --> 1.478527).         Saving model ...\n",
      "Epoch: 4237 \tTraining Loss: 1.076420 \tValidation Loss: 1.478526\n",
      "Validation loss decreased (1.478527 --> 1.478526).         Saving model ...\n",
      "Epoch: 4238 \tTraining Loss: 1.076418 \tValidation Loss: 1.478525\n",
      "Validation loss decreased (1.478526 --> 1.478525).         Saving model ...\n",
      "Epoch: 4239 \tTraining Loss: 1.076417 \tValidation Loss: 1.478524\n",
      "Validation loss decreased (1.478525 --> 1.478524).         Saving model ...\n",
      "Epoch: 4240 \tTraining Loss: 1.076416 \tValidation Loss: 1.478525\n",
      "Epoch: 4241 \tTraining Loss: 1.076414 \tValidation Loss: 1.478523\n",
      "Validation loss decreased (1.478524 --> 1.478523).         Saving model ...\n",
      "Epoch: 4242 \tTraining Loss: 1.076413 \tValidation Loss: 1.478523\n",
      "Validation loss decreased (1.478523 --> 1.478523).         Saving model ...\n",
      "Epoch: 4243 \tTraining Loss: 1.076411 \tValidation Loss: 1.478522\n",
      "Validation loss decreased (1.478523 --> 1.478522).         Saving model ...\n",
      "Epoch: 4244 \tTraining Loss: 1.076410 \tValidation Loss: 1.478521\n",
      "Validation loss decreased (1.478522 --> 1.478521).         Saving model ...\n",
      "Epoch: 4245 \tTraining Loss: 1.076409 \tValidation Loss: 1.478520\n",
      "Validation loss decreased (1.478521 --> 1.478520).         Saving model ...\n",
      "Epoch: 4246 \tTraining Loss: 1.076407 \tValidation Loss: 1.478519\n",
      "Validation loss decreased (1.478520 --> 1.478519).         Saving model ...\n",
      "Epoch: 4247 \tTraining Loss: 1.076406 \tValidation Loss: 1.478517\n",
      "Validation loss decreased (1.478519 --> 1.478517).         Saving model ...\n",
      "Epoch: 4248 \tTraining Loss: 1.076405 \tValidation Loss: 1.478517\n",
      "Validation loss decreased (1.478517 --> 1.478517).         Saving model ...\n",
      "Epoch: 4249 \tTraining Loss: 1.076403 \tValidation Loss: 1.478516\n",
      "Validation loss decreased (1.478517 --> 1.478516).         Saving model ...\n",
      "Epoch: 4250 \tTraining Loss: 1.076402 \tValidation Loss: 1.478515\n",
      "Validation loss decreased (1.478516 --> 1.478515).         Saving model ...\n",
      "Epoch: 4251 \tTraining Loss: 1.076400 \tValidation Loss: 1.478514\n",
      "Validation loss decreased (1.478515 --> 1.478514).         Saving model ...\n",
      "Epoch: 4252 \tTraining Loss: 1.076399 \tValidation Loss: 1.478512\n",
      "Validation loss decreased (1.478514 --> 1.478512).         Saving model ...\n",
      "Epoch: 4253 \tTraining Loss: 1.076398 \tValidation Loss: 1.478511\n",
      "Validation loss decreased (1.478512 --> 1.478511).         Saving model ...\n",
      "Epoch: 4254 \tTraining Loss: 1.076396 \tValidation Loss: 1.478509\n",
      "Validation loss decreased (1.478511 --> 1.478509).         Saving model ...\n",
      "Epoch: 4255 \tTraining Loss: 1.076395 \tValidation Loss: 1.478508\n",
      "Validation loss decreased (1.478509 --> 1.478508).         Saving model ...\n",
      "Epoch: 4256 \tTraining Loss: 1.076393 \tValidation Loss: 1.478507\n",
      "Validation loss decreased (1.478508 --> 1.478507).         Saving model ...\n",
      "Epoch: 4257 \tTraining Loss: 1.076392 \tValidation Loss: 1.478506\n",
      "Validation loss decreased (1.478507 --> 1.478506).         Saving model ...\n",
      "Epoch: 4258 \tTraining Loss: 1.076391 \tValidation Loss: 1.478506\n",
      "Validation loss decreased (1.478506 --> 1.478506).         Saving model ...\n",
      "Epoch: 4259 \tTraining Loss: 1.076389 \tValidation Loss: 1.478504\n",
      "Validation loss decreased (1.478506 --> 1.478504).         Saving model ...\n",
      "Epoch: 4260 \tTraining Loss: 1.076388 \tValidation Loss: 1.478504\n",
      "Validation loss decreased (1.478504 --> 1.478504).         Saving model ...\n",
      "Epoch: 4261 \tTraining Loss: 1.076387 \tValidation Loss: 1.478504\n",
      "Validation loss decreased (1.478504 --> 1.478504).         Saving model ...\n",
      "Epoch: 4262 \tTraining Loss: 1.076385 \tValidation Loss: 1.478502\n",
      "Validation loss decreased (1.478504 --> 1.478502).         Saving model ...\n",
      "Epoch: 4263 \tTraining Loss: 1.076384 \tValidation Loss: 1.478502\n",
      "Validation loss decreased (1.478502 --> 1.478502).         Saving model ...\n",
      "Epoch: 4264 \tTraining Loss: 1.076382 \tValidation Loss: 1.478501\n",
      "Validation loss decreased (1.478502 --> 1.478501).         Saving model ...\n",
      "Epoch: 4265 \tTraining Loss: 1.076381 \tValidation Loss: 1.478500\n",
      "Validation loss decreased (1.478501 --> 1.478500).         Saving model ...\n",
      "Epoch: 4266 \tTraining Loss: 1.076380 \tValidation Loss: 1.478499\n",
      "Validation loss decreased (1.478500 --> 1.478499).         Saving model ...\n",
      "Epoch: 4267 \tTraining Loss: 1.076378 \tValidation Loss: 1.478498\n",
      "Validation loss decreased (1.478499 --> 1.478498).         Saving model ...\n",
      "Epoch: 4268 \tTraining Loss: 1.076377 \tValidation Loss: 1.478496\n",
      "Validation loss decreased (1.478498 --> 1.478496).         Saving model ...\n",
      "Epoch: 4269 \tTraining Loss: 1.076375 \tValidation Loss: 1.478494\n",
      "Validation loss decreased (1.478496 --> 1.478494).         Saving model ...\n",
      "Epoch: 4270 \tTraining Loss: 1.076374 \tValidation Loss: 1.478493\n",
      "Validation loss decreased (1.478494 --> 1.478493).         Saving model ...\n",
      "Epoch: 4271 \tTraining Loss: 1.076373 \tValidation Loss: 1.478491\n",
      "Validation loss decreased (1.478493 --> 1.478491).         Saving model ...\n",
      "Epoch: 4272 \tTraining Loss: 1.076371 \tValidation Loss: 1.478490\n",
      "Validation loss decreased (1.478491 --> 1.478490).         Saving model ...\n",
      "Epoch: 4273 \tTraining Loss: 1.076370 \tValidation Loss: 1.478489\n",
      "Validation loss decreased (1.478490 --> 1.478489).         Saving model ...\n",
      "Epoch: 4274 \tTraining Loss: 1.076369 \tValidation Loss: 1.478488\n",
      "Validation loss decreased (1.478489 --> 1.478488).         Saving model ...\n",
      "Epoch: 4275 \tTraining Loss: 1.076367 \tValidation Loss: 1.478487\n",
      "Validation loss decreased (1.478488 --> 1.478487).         Saving model ...\n",
      "Epoch: 4276 \tTraining Loss: 1.076366 \tValidation Loss: 1.478486\n",
      "Validation loss decreased (1.478487 --> 1.478486).         Saving model ...\n",
      "Epoch: 4277 \tTraining Loss: 1.076365 \tValidation Loss: 1.478485\n",
      "Validation loss decreased (1.478486 --> 1.478485).         Saving model ...\n",
      "Epoch: 4278 \tTraining Loss: 1.076363 \tValidation Loss: 1.478484\n",
      "Validation loss decreased (1.478485 --> 1.478484).         Saving model ...\n",
      "Epoch: 4279 \tTraining Loss: 1.076362 \tValidation Loss: 1.478483\n",
      "Validation loss decreased (1.478484 --> 1.478483).         Saving model ...\n",
      "Epoch: 4280 \tTraining Loss: 1.076360 \tValidation Loss: 1.478482\n",
      "Validation loss decreased (1.478483 --> 1.478482).         Saving model ...\n",
      "Epoch: 4281 \tTraining Loss: 1.076359 \tValidation Loss: 1.478481\n",
      "Validation loss decreased (1.478482 --> 1.478481).         Saving model ...\n",
      "Epoch: 4282 \tTraining Loss: 1.076358 \tValidation Loss: 1.478480\n",
      "Validation loss decreased (1.478481 --> 1.478480).         Saving model ...\n",
      "Epoch: 4283 \tTraining Loss: 1.076356 \tValidation Loss: 1.478478\n",
      "Validation loss decreased (1.478480 --> 1.478478).         Saving model ...\n",
      "Epoch: 4284 \tTraining Loss: 1.076355 \tValidation Loss: 1.478478\n",
      "Validation loss decreased (1.478478 --> 1.478478).         Saving model ...\n",
      "Epoch: 4285 \tTraining Loss: 1.076354 \tValidation Loss: 1.478477\n",
      "Validation loss decreased (1.478478 --> 1.478477).         Saving model ...\n",
      "Epoch: 4286 \tTraining Loss: 1.076352 \tValidation Loss: 1.478476\n",
      "Validation loss decreased (1.478477 --> 1.478476).         Saving model ...\n",
      "Epoch: 4287 \tTraining Loss: 1.076351 \tValidation Loss: 1.478475\n",
      "Validation loss decreased (1.478476 --> 1.478475).         Saving model ...\n",
      "Epoch: 4288 \tTraining Loss: 1.076349 \tValidation Loss: 1.478474\n",
      "Validation loss decreased (1.478475 --> 1.478474).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4289 \tTraining Loss: 1.076348 \tValidation Loss: 1.478472\n",
      "Validation loss decreased (1.478474 --> 1.478472).         Saving model ...\n",
      "Epoch: 4290 \tTraining Loss: 1.076347 \tValidation Loss: 1.478471\n",
      "Validation loss decreased (1.478472 --> 1.478471).         Saving model ...\n",
      "Epoch: 4291 \tTraining Loss: 1.076345 \tValidation Loss: 1.478469\n",
      "Validation loss decreased (1.478471 --> 1.478469).         Saving model ...\n",
      "Epoch: 4292 \tTraining Loss: 1.076344 \tValidation Loss: 1.478468\n",
      "Validation loss decreased (1.478469 --> 1.478468).         Saving model ...\n",
      "Epoch: 4293 \tTraining Loss: 1.076343 \tValidation Loss: 1.478467\n",
      "Validation loss decreased (1.478468 --> 1.478467).         Saving model ...\n",
      "Epoch: 4294 \tTraining Loss: 1.076341 \tValidation Loss: 1.478465\n",
      "Validation loss decreased (1.478467 --> 1.478465).         Saving model ...\n",
      "Epoch: 4295 \tTraining Loss: 1.076340 \tValidation Loss: 1.478463\n",
      "Validation loss decreased (1.478465 --> 1.478463).         Saving model ...\n",
      "Epoch: 4296 \tTraining Loss: 1.076339 \tValidation Loss: 1.478462\n",
      "Validation loss decreased (1.478463 --> 1.478462).         Saving model ...\n",
      "Epoch: 4297 \tTraining Loss: 1.076337 \tValidation Loss: 1.478460\n",
      "Validation loss decreased (1.478462 --> 1.478460).         Saving model ...\n",
      "Epoch: 4298 \tTraining Loss: 1.076336 \tValidation Loss: 1.478459\n",
      "Validation loss decreased (1.478460 --> 1.478459).         Saving model ...\n",
      "Epoch: 4299 \tTraining Loss: 1.076334 \tValidation Loss: 1.478457\n",
      "Validation loss decreased (1.478459 --> 1.478457).         Saving model ...\n",
      "Epoch: 4300 \tTraining Loss: 1.076333 \tValidation Loss: 1.478456\n",
      "Validation loss decreased (1.478457 --> 1.478456).         Saving model ...\n",
      "Epoch: 4301 \tTraining Loss: 1.076332 \tValidation Loss: 1.478455\n",
      "Validation loss decreased (1.478456 --> 1.478455).         Saving model ...\n",
      "Epoch: 4302 \tTraining Loss: 1.076330 \tValidation Loss: 1.478455\n",
      "Validation loss decreased (1.478455 --> 1.478455).         Saving model ...\n",
      "Epoch: 4303 \tTraining Loss: 1.076329 \tValidation Loss: 1.478454\n",
      "Validation loss decreased (1.478455 --> 1.478454).         Saving model ...\n",
      "Epoch: 4304 \tTraining Loss: 1.076328 \tValidation Loss: 1.478453\n",
      "Validation loss decreased (1.478454 --> 1.478453).         Saving model ...\n",
      "Epoch: 4305 \tTraining Loss: 1.076326 \tValidation Loss: 1.478453\n",
      "Validation loss decreased (1.478453 --> 1.478453).         Saving model ...\n",
      "Epoch: 4306 \tTraining Loss: 1.076325 \tValidation Loss: 1.478452\n",
      "Validation loss decreased (1.478453 --> 1.478452).         Saving model ...\n",
      "Epoch: 4307 \tTraining Loss: 1.076324 \tValidation Loss: 1.478452\n",
      "Validation loss decreased (1.478452 --> 1.478452).         Saving model ...\n",
      "Epoch: 4308 \tTraining Loss: 1.076322 \tValidation Loss: 1.478451\n",
      "Validation loss decreased (1.478452 --> 1.478451).         Saving model ...\n",
      "Epoch: 4309 \tTraining Loss: 1.076321 \tValidation Loss: 1.478449\n",
      "Validation loss decreased (1.478451 --> 1.478449).         Saving model ...\n",
      "Epoch: 4310 \tTraining Loss: 1.076320 \tValidation Loss: 1.478449\n",
      "Validation loss decreased (1.478449 --> 1.478449).         Saving model ...\n",
      "Epoch: 4311 \tTraining Loss: 1.076318 \tValidation Loss: 1.478448\n",
      "Validation loss decreased (1.478449 --> 1.478448).         Saving model ...\n",
      "Epoch: 4312 \tTraining Loss: 1.076317 \tValidation Loss: 1.478446\n",
      "Validation loss decreased (1.478448 --> 1.478446).         Saving model ...\n",
      "Epoch: 4313 \tTraining Loss: 1.076315 \tValidation Loss: 1.478445\n",
      "Validation loss decreased (1.478446 --> 1.478445).         Saving model ...\n",
      "Epoch: 4314 \tTraining Loss: 1.076314 \tValidation Loss: 1.478444\n",
      "Validation loss decreased (1.478445 --> 1.478444).         Saving model ...\n",
      "Epoch: 4315 \tTraining Loss: 1.076313 \tValidation Loss: 1.478443\n",
      "Validation loss decreased (1.478444 --> 1.478443).         Saving model ...\n",
      "Epoch: 4316 \tTraining Loss: 1.076311 \tValidation Loss: 1.478442\n",
      "Validation loss decreased (1.478443 --> 1.478442).         Saving model ...\n",
      "Epoch: 4317 \tTraining Loss: 1.076310 \tValidation Loss: 1.478441\n",
      "Validation loss decreased (1.478442 --> 1.478441).         Saving model ...\n",
      "Epoch: 4318 \tTraining Loss: 1.076309 \tValidation Loss: 1.478439\n",
      "Validation loss decreased (1.478441 --> 1.478439).         Saving model ...\n",
      "Epoch: 4319 \tTraining Loss: 1.076307 \tValidation Loss: 1.478438\n",
      "Validation loss decreased (1.478439 --> 1.478438).         Saving model ...\n",
      "Epoch: 4320 \tTraining Loss: 1.076306 \tValidation Loss: 1.478436\n",
      "Validation loss decreased (1.478438 --> 1.478436).         Saving model ...\n",
      "Epoch: 4321 \tTraining Loss: 1.076305 \tValidation Loss: 1.478435\n",
      "Validation loss decreased (1.478436 --> 1.478435).         Saving model ...\n",
      "Epoch: 4322 \tTraining Loss: 1.076303 \tValidation Loss: 1.478434\n",
      "Validation loss decreased (1.478435 --> 1.478434).         Saving model ...\n",
      "Epoch: 4323 \tTraining Loss: 1.076302 \tValidation Loss: 1.478433\n",
      "Validation loss decreased (1.478434 --> 1.478433).         Saving model ...\n",
      "Epoch: 4324 \tTraining Loss: 1.076301 \tValidation Loss: 1.478431\n",
      "Validation loss decreased (1.478433 --> 1.478431).         Saving model ...\n",
      "Epoch: 4325 \tTraining Loss: 1.076299 \tValidation Loss: 1.478430\n",
      "Validation loss decreased (1.478431 --> 1.478430).         Saving model ...\n",
      "Epoch: 4326 \tTraining Loss: 1.076298 \tValidation Loss: 1.478429\n",
      "Validation loss decreased (1.478430 --> 1.478429).         Saving model ...\n",
      "Epoch: 4327 \tTraining Loss: 1.076297 \tValidation Loss: 1.478428\n",
      "Validation loss decreased (1.478429 --> 1.478428).         Saving model ...\n",
      "Epoch: 4328 \tTraining Loss: 1.076295 \tValidation Loss: 1.478426\n",
      "Validation loss decreased (1.478428 --> 1.478426).         Saving model ...\n",
      "Epoch: 4329 \tTraining Loss: 1.076294 \tValidation Loss: 1.478425\n",
      "Validation loss decreased (1.478426 --> 1.478425).         Saving model ...\n",
      "Epoch: 4330 \tTraining Loss: 1.076292 \tValidation Loss: 1.478424\n",
      "Validation loss decreased (1.478425 --> 1.478424).         Saving model ...\n",
      "Epoch: 4331 \tTraining Loss: 1.076291 \tValidation Loss: 1.478424\n",
      "Validation loss decreased (1.478424 --> 1.478424).         Saving model ...\n",
      "Epoch: 4332 \tTraining Loss: 1.076290 \tValidation Loss: 1.478422\n",
      "Validation loss decreased (1.478424 --> 1.478422).         Saving model ...\n",
      "Epoch: 4333 \tTraining Loss: 1.076288 \tValidation Loss: 1.478420\n",
      "Validation loss decreased (1.478422 --> 1.478420).         Saving model ...\n",
      "Epoch: 4334 \tTraining Loss: 1.076287 \tValidation Loss: 1.478419\n",
      "Validation loss decreased (1.478420 --> 1.478419).         Saving model ...\n",
      "Epoch: 4335 \tTraining Loss: 1.076286 \tValidation Loss: 1.478418\n",
      "Validation loss decreased (1.478419 --> 1.478418).         Saving model ...\n",
      "Epoch: 4336 \tTraining Loss: 1.076284 \tValidation Loss: 1.478416\n",
      "Validation loss decreased (1.478418 --> 1.478416).         Saving model ...\n",
      "Epoch: 4337 \tTraining Loss: 1.076283 \tValidation Loss: 1.478415\n",
      "Validation loss decreased (1.478416 --> 1.478415).         Saving model ...\n",
      "Epoch: 4338 \tTraining Loss: 1.076282 \tValidation Loss: 1.478414\n",
      "Validation loss decreased (1.478415 --> 1.478414).         Saving model ...\n",
      "Epoch: 4339 \tTraining Loss: 1.076280 \tValidation Loss: 1.478412\n",
      "Validation loss decreased (1.478414 --> 1.478412).         Saving model ...\n",
      "Epoch: 4340 \tTraining Loss: 1.076279 \tValidation Loss: 1.478410\n",
      "Validation loss decreased (1.478412 --> 1.478410).         Saving model ...\n",
      "Epoch: 4341 \tTraining Loss: 1.076278 \tValidation Loss: 1.478409\n",
      "Validation loss decreased (1.478410 --> 1.478409).         Saving model ...\n",
      "Epoch: 4342 \tTraining Loss: 1.076276 \tValidation Loss: 1.478407\n",
      "Validation loss decreased (1.478409 --> 1.478407).         Saving model ...\n",
      "Epoch: 4343 \tTraining Loss: 1.076275 \tValidation Loss: 1.478405\n",
      "Validation loss decreased (1.478407 --> 1.478405).         Saving model ...\n",
      "Epoch: 4344 \tTraining Loss: 1.076274 \tValidation Loss: 1.478403\n",
      "Validation loss decreased (1.478405 --> 1.478403).         Saving model ...\n",
      "Epoch: 4345 \tTraining Loss: 1.076272 \tValidation Loss: 1.478402\n",
      "Validation loss decreased (1.478403 --> 1.478402).         Saving model ...\n",
      "Epoch: 4346 \tTraining Loss: 1.076271 \tValidation Loss: 1.478401\n",
      "Validation loss decreased (1.478402 --> 1.478401).         Saving model ...\n",
      "Epoch: 4347 \tTraining Loss: 1.076270 \tValidation Loss: 1.478399\n",
      "Validation loss decreased (1.478401 --> 1.478399).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4348 \tTraining Loss: 1.076268 \tValidation Loss: 1.478398\n",
      "Validation loss decreased (1.478399 --> 1.478398).         Saving model ...\n",
      "Epoch: 4349 \tTraining Loss: 1.076267 \tValidation Loss: 1.478396\n",
      "Validation loss decreased (1.478398 --> 1.478396).         Saving model ...\n",
      "Epoch: 4350 \tTraining Loss: 1.076266 \tValidation Loss: 1.478396\n",
      "Validation loss decreased (1.478396 --> 1.478396).         Saving model ...\n",
      "Epoch: 4351 \tTraining Loss: 1.076264 \tValidation Loss: 1.478395\n",
      "Validation loss decreased (1.478396 --> 1.478395).         Saving model ...\n",
      "Epoch: 4352 \tTraining Loss: 1.076263 \tValidation Loss: 1.478394\n",
      "Validation loss decreased (1.478395 --> 1.478394).         Saving model ...\n",
      "Epoch: 4353 \tTraining Loss: 1.076262 \tValidation Loss: 1.478393\n",
      "Validation loss decreased (1.478394 --> 1.478393).         Saving model ...\n",
      "Epoch: 4354 \tTraining Loss: 1.076260 \tValidation Loss: 1.478392\n",
      "Validation loss decreased (1.478393 --> 1.478392).         Saving model ...\n",
      "Epoch: 4355 \tTraining Loss: 1.076259 \tValidation Loss: 1.478391\n",
      "Validation loss decreased (1.478392 --> 1.478391).         Saving model ...\n",
      "Epoch: 4356 \tTraining Loss: 1.076258 \tValidation Loss: 1.478389\n",
      "Validation loss decreased (1.478391 --> 1.478389).         Saving model ...\n",
      "Epoch: 4357 \tTraining Loss: 1.076256 \tValidation Loss: 1.478388\n",
      "Validation loss decreased (1.478389 --> 1.478388).         Saving model ...\n",
      "Epoch: 4358 \tTraining Loss: 1.076255 \tValidation Loss: 1.478386\n",
      "Validation loss decreased (1.478388 --> 1.478386).         Saving model ...\n",
      "Epoch: 4359 \tTraining Loss: 1.076254 \tValidation Loss: 1.478385\n",
      "Validation loss decreased (1.478386 --> 1.478385).         Saving model ...\n",
      "Epoch: 4360 \tTraining Loss: 1.076252 \tValidation Loss: 1.478384\n",
      "Validation loss decreased (1.478385 --> 1.478384).         Saving model ...\n",
      "Epoch: 4361 \tTraining Loss: 1.076251 \tValidation Loss: 1.478382\n",
      "Validation loss decreased (1.478384 --> 1.478382).         Saving model ...\n",
      "Epoch: 4362 \tTraining Loss: 1.076250 \tValidation Loss: 1.478381\n",
      "Validation loss decreased (1.478382 --> 1.478381).         Saving model ...\n",
      "Epoch: 4363 \tTraining Loss: 1.076248 \tValidation Loss: 1.478380\n",
      "Validation loss decreased (1.478381 --> 1.478380).         Saving model ...\n",
      "Epoch: 4364 \tTraining Loss: 1.076247 \tValidation Loss: 1.478380\n",
      "Validation loss decreased (1.478380 --> 1.478380).         Saving model ...\n",
      "Epoch: 4365 \tTraining Loss: 1.076246 \tValidation Loss: 1.478378\n",
      "Validation loss decreased (1.478380 --> 1.478378).         Saving model ...\n",
      "Epoch: 4366 \tTraining Loss: 1.076244 \tValidation Loss: 1.478378\n",
      "Validation loss decreased (1.478378 --> 1.478378).         Saving model ...\n",
      "Epoch: 4367 \tTraining Loss: 1.076243 \tValidation Loss: 1.478377\n",
      "Validation loss decreased (1.478378 --> 1.478377).         Saving model ...\n",
      "Epoch: 4368 \tTraining Loss: 1.076242 \tValidation Loss: 1.478376\n",
      "Validation loss decreased (1.478377 --> 1.478376).         Saving model ...\n",
      "Epoch: 4369 \tTraining Loss: 1.076240 \tValidation Loss: 1.478375\n",
      "Validation loss decreased (1.478376 --> 1.478375).         Saving model ...\n",
      "Epoch: 4370 \tTraining Loss: 1.076239 \tValidation Loss: 1.478375\n",
      "Epoch: 4371 \tTraining Loss: 1.076238 \tValidation Loss: 1.478375\n",
      "Validation loss decreased (1.478375 --> 1.478375).         Saving model ...\n",
      "Epoch: 4372 \tTraining Loss: 1.076236 \tValidation Loss: 1.478374\n",
      "Validation loss decreased (1.478375 --> 1.478374).         Saving model ...\n",
      "Epoch: 4373 \tTraining Loss: 1.076235 \tValidation Loss: 1.478373\n",
      "Validation loss decreased (1.478374 --> 1.478373).         Saving model ...\n",
      "Epoch: 4374 \tTraining Loss: 1.076234 \tValidation Loss: 1.478373\n",
      "Validation loss decreased (1.478373 --> 1.478373).         Saving model ...\n",
      "Epoch: 4375 \tTraining Loss: 1.076232 \tValidation Loss: 1.478371\n",
      "Validation loss decreased (1.478373 --> 1.478371).         Saving model ...\n",
      "Epoch: 4376 \tTraining Loss: 1.076231 \tValidation Loss: 1.478371\n",
      "Validation loss decreased (1.478371 --> 1.478371).         Saving model ...\n",
      "Epoch: 4377 \tTraining Loss: 1.076230 \tValidation Loss: 1.478369\n",
      "Validation loss decreased (1.478371 --> 1.478369).         Saving model ...\n",
      "Epoch: 4378 \tTraining Loss: 1.076228 \tValidation Loss: 1.478368\n",
      "Validation loss decreased (1.478369 --> 1.478368).         Saving model ...\n",
      "Epoch: 4379 \tTraining Loss: 1.076227 \tValidation Loss: 1.478367\n",
      "Validation loss decreased (1.478368 --> 1.478367).         Saving model ...\n",
      "Epoch: 4380 \tTraining Loss: 1.076226 \tValidation Loss: 1.478366\n",
      "Validation loss decreased (1.478367 --> 1.478366).         Saving model ...\n",
      "Epoch: 4381 \tTraining Loss: 1.076224 \tValidation Loss: 1.478365\n",
      "Validation loss decreased (1.478366 --> 1.478365).         Saving model ...\n",
      "Epoch: 4382 \tTraining Loss: 1.076223 \tValidation Loss: 1.478364\n",
      "Validation loss decreased (1.478365 --> 1.478364).         Saving model ...\n",
      "Epoch: 4383 \tTraining Loss: 1.076222 \tValidation Loss: 1.478363\n",
      "Validation loss decreased (1.478364 --> 1.478363).         Saving model ...\n",
      "Epoch: 4384 \tTraining Loss: 1.076220 \tValidation Loss: 1.478363\n",
      "Validation loss decreased (1.478363 --> 1.478363).         Saving model ...\n",
      "Epoch: 4385 \tTraining Loss: 1.076219 \tValidation Loss: 1.478362\n",
      "Validation loss decreased (1.478363 --> 1.478362).         Saving model ...\n",
      "Epoch: 4386 \tTraining Loss: 1.076218 \tValidation Loss: 1.478361\n",
      "Validation loss decreased (1.478362 --> 1.478361).         Saving model ...\n",
      "Epoch: 4387 \tTraining Loss: 1.076216 \tValidation Loss: 1.478360\n",
      "Validation loss decreased (1.478361 --> 1.478360).         Saving model ...\n",
      "Epoch: 4388 \tTraining Loss: 1.076215 \tValidation Loss: 1.478359\n",
      "Validation loss decreased (1.478360 --> 1.478359).         Saving model ...\n",
      "Epoch: 4389 \tTraining Loss: 1.076214 \tValidation Loss: 1.478359\n",
      "Validation loss decreased (1.478359 --> 1.478359).         Saving model ...\n",
      "Epoch: 4390 \tTraining Loss: 1.076212 \tValidation Loss: 1.478357\n",
      "Validation loss decreased (1.478359 --> 1.478357).         Saving model ...\n",
      "Epoch: 4391 \tTraining Loss: 1.076211 \tValidation Loss: 1.478357\n",
      "Validation loss decreased (1.478357 --> 1.478357).         Saving model ...\n",
      "Epoch: 4392 \tTraining Loss: 1.076210 \tValidation Loss: 1.478355\n",
      "Validation loss decreased (1.478357 --> 1.478355).         Saving model ...\n",
      "Epoch: 4393 \tTraining Loss: 1.076209 \tValidation Loss: 1.478355\n",
      "Validation loss decreased (1.478355 --> 1.478355).         Saving model ...\n",
      "Epoch: 4394 \tTraining Loss: 1.076207 \tValidation Loss: 1.478354\n",
      "Validation loss decreased (1.478355 --> 1.478354).         Saving model ...\n",
      "Epoch: 4395 \tTraining Loss: 1.076206 \tValidation Loss: 1.478353\n",
      "Validation loss decreased (1.478354 --> 1.478353).         Saving model ...\n",
      "Epoch: 4396 \tTraining Loss: 1.076205 \tValidation Loss: 1.478352\n",
      "Validation loss decreased (1.478353 --> 1.478352).         Saving model ...\n",
      "Epoch: 4397 \tTraining Loss: 1.076203 \tValidation Loss: 1.478352\n",
      "Validation loss decreased (1.478352 --> 1.478352).         Saving model ...\n",
      "Epoch: 4398 \tTraining Loss: 1.076202 \tValidation Loss: 1.478350\n",
      "Validation loss decreased (1.478352 --> 1.478350).         Saving model ...\n",
      "Epoch: 4399 \tTraining Loss: 1.076201 \tValidation Loss: 1.478350\n",
      "Validation loss decreased (1.478350 --> 1.478350).         Saving model ...\n",
      "Epoch: 4400 \tTraining Loss: 1.076199 \tValidation Loss: 1.478350\n",
      "Validation loss decreased (1.478350 --> 1.478350).         Saving model ...\n",
      "Epoch: 4401 \tTraining Loss: 1.076198 \tValidation Loss: 1.478349\n",
      "Validation loss decreased (1.478350 --> 1.478349).         Saving model ...\n",
      "Epoch: 4402 \tTraining Loss: 1.076197 \tValidation Loss: 1.478347\n",
      "Validation loss decreased (1.478349 --> 1.478347).         Saving model ...\n",
      "Epoch: 4403 \tTraining Loss: 1.076195 \tValidation Loss: 1.478346\n",
      "Validation loss decreased (1.478347 --> 1.478346).         Saving model ...\n",
      "Epoch: 4404 \tTraining Loss: 1.076194 \tValidation Loss: 1.478345\n",
      "Validation loss decreased (1.478346 --> 1.478345).         Saving model ...\n",
      "Epoch: 4405 \tTraining Loss: 1.076193 \tValidation Loss: 1.478345\n",
      "Validation loss decreased (1.478345 --> 1.478345).         Saving model ...\n",
      "Epoch: 4406 \tTraining Loss: 1.076191 \tValidation Loss: 1.478343\n",
      "Validation loss decreased (1.478345 --> 1.478343).         Saving model ...\n",
      "Epoch: 4407 \tTraining Loss: 1.076190 \tValidation Loss: 1.478343\n",
      "Validation loss decreased (1.478343 --> 1.478343).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4408 \tTraining Loss: 1.076189 \tValidation Loss: 1.478341\n",
      "Validation loss decreased (1.478343 --> 1.478341).         Saving model ...\n",
      "Epoch: 4409 \tTraining Loss: 1.076187 \tValidation Loss: 1.478340\n",
      "Validation loss decreased (1.478341 --> 1.478340).         Saving model ...\n",
      "Epoch: 4410 \tTraining Loss: 1.076186 \tValidation Loss: 1.478339\n",
      "Validation loss decreased (1.478340 --> 1.478339).         Saving model ...\n",
      "Epoch: 4411 \tTraining Loss: 1.076185 \tValidation Loss: 1.478338\n",
      "Validation loss decreased (1.478339 --> 1.478338).         Saving model ...\n",
      "Epoch: 4412 \tTraining Loss: 1.076184 \tValidation Loss: 1.478338\n",
      "Validation loss decreased (1.478338 --> 1.478338).         Saving model ...\n",
      "Epoch: 4413 \tTraining Loss: 1.076182 \tValidation Loss: 1.478336\n",
      "Validation loss decreased (1.478338 --> 1.478336).         Saving model ...\n",
      "Epoch: 4414 \tTraining Loss: 1.076181 \tValidation Loss: 1.478336\n",
      "Validation loss decreased (1.478336 --> 1.478336).         Saving model ...\n",
      "Epoch: 4415 \tTraining Loss: 1.076180 \tValidation Loss: 1.478335\n",
      "Validation loss decreased (1.478336 --> 1.478335).         Saving model ...\n",
      "Epoch: 4416 \tTraining Loss: 1.076178 \tValidation Loss: 1.478333\n",
      "Validation loss decreased (1.478335 --> 1.478333).         Saving model ...\n",
      "Epoch: 4417 \tTraining Loss: 1.076177 \tValidation Loss: 1.478332\n",
      "Validation loss decreased (1.478333 --> 1.478332).         Saving model ...\n",
      "Epoch: 4418 \tTraining Loss: 1.076176 \tValidation Loss: 1.478331\n",
      "Validation loss decreased (1.478332 --> 1.478331).         Saving model ...\n",
      "Epoch: 4419 \tTraining Loss: 1.076174 \tValidation Loss: 1.478330\n",
      "Validation loss decreased (1.478331 --> 1.478330).         Saving model ...\n",
      "Epoch: 4420 \tTraining Loss: 1.076173 \tValidation Loss: 1.478328\n",
      "Validation loss decreased (1.478330 --> 1.478328).         Saving model ...\n",
      "Epoch: 4421 \tTraining Loss: 1.076172 \tValidation Loss: 1.478327\n",
      "Validation loss decreased (1.478328 --> 1.478327).         Saving model ...\n",
      "Epoch: 4422 \tTraining Loss: 1.076171 \tValidation Loss: 1.478325\n",
      "Validation loss decreased (1.478327 --> 1.478325).         Saving model ...\n",
      "Epoch: 4423 \tTraining Loss: 1.076169 \tValidation Loss: 1.478324\n",
      "Validation loss decreased (1.478325 --> 1.478324).         Saving model ...\n",
      "Epoch: 4424 \tTraining Loss: 1.076168 \tValidation Loss: 1.478322\n",
      "Validation loss decreased (1.478324 --> 1.478322).         Saving model ...\n",
      "Epoch: 4425 \tTraining Loss: 1.076167 \tValidation Loss: 1.478322\n",
      "Validation loss decreased (1.478322 --> 1.478322).         Saving model ...\n",
      "Epoch: 4426 \tTraining Loss: 1.076165 \tValidation Loss: 1.478321\n",
      "Validation loss decreased (1.478322 --> 1.478321).         Saving model ...\n",
      "Epoch: 4427 \tTraining Loss: 1.076164 \tValidation Loss: 1.478319\n",
      "Validation loss decreased (1.478321 --> 1.478319).         Saving model ...\n",
      "Epoch: 4428 \tTraining Loss: 1.076163 \tValidation Loss: 1.478319\n",
      "Validation loss decreased (1.478319 --> 1.478319).         Saving model ...\n",
      "Epoch: 4429 \tTraining Loss: 1.076161 \tValidation Loss: 1.478317\n",
      "Validation loss decreased (1.478319 --> 1.478317).         Saving model ...\n",
      "Epoch: 4430 \tTraining Loss: 1.076160 \tValidation Loss: 1.478316\n",
      "Validation loss decreased (1.478317 --> 1.478316).         Saving model ...\n",
      "Epoch: 4431 \tTraining Loss: 1.076159 \tValidation Loss: 1.478315\n",
      "Validation loss decreased (1.478316 --> 1.478315).         Saving model ...\n",
      "Epoch: 4432 \tTraining Loss: 1.076157 \tValidation Loss: 1.478314\n",
      "Validation loss decreased (1.478315 --> 1.478314).         Saving model ...\n",
      "Epoch: 4433 \tTraining Loss: 1.076156 \tValidation Loss: 1.478314\n",
      "Validation loss decreased (1.478314 --> 1.478314).         Saving model ...\n",
      "Epoch: 4434 \tTraining Loss: 1.076155 \tValidation Loss: 1.478313\n",
      "Validation loss decreased (1.478314 --> 1.478313).         Saving model ...\n",
      "Epoch: 4435 \tTraining Loss: 1.076154 \tValidation Loss: 1.478312\n",
      "Validation loss decreased (1.478313 --> 1.478312).         Saving model ...\n",
      "Epoch: 4436 \tTraining Loss: 1.076152 \tValidation Loss: 1.478311\n",
      "Validation loss decreased (1.478312 --> 1.478311).         Saving model ...\n",
      "Epoch: 4437 \tTraining Loss: 1.076151 \tValidation Loss: 1.478311\n",
      "Validation loss decreased (1.478311 --> 1.478311).         Saving model ...\n",
      "Epoch: 4438 \tTraining Loss: 1.076150 \tValidation Loss: 1.478311\n",
      "Validation loss decreased (1.478311 --> 1.478311).         Saving model ...\n",
      "Epoch: 4439 \tTraining Loss: 1.076148 \tValidation Loss: 1.478311\n",
      "Validation loss decreased (1.478311 --> 1.478311).         Saving model ...\n",
      "Epoch: 4440 \tTraining Loss: 1.076147 \tValidation Loss: 1.478309\n",
      "Validation loss decreased (1.478311 --> 1.478309).         Saving model ...\n",
      "Epoch: 4441 \tTraining Loss: 1.076146 \tValidation Loss: 1.478308\n",
      "Validation loss decreased (1.478309 --> 1.478308).         Saving model ...\n",
      "Epoch: 4442 \tTraining Loss: 1.076145 \tValidation Loss: 1.478307\n",
      "Validation loss decreased (1.478308 --> 1.478307).         Saving model ...\n",
      "Epoch: 4443 \tTraining Loss: 1.076143 \tValidation Loss: 1.478306\n",
      "Validation loss decreased (1.478307 --> 1.478306).         Saving model ...\n",
      "Epoch: 4444 \tTraining Loss: 1.076142 \tValidation Loss: 1.478305\n",
      "Validation loss decreased (1.478306 --> 1.478305).         Saving model ...\n",
      "Epoch: 4445 \tTraining Loss: 1.076141 \tValidation Loss: 1.478304\n",
      "Validation loss decreased (1.478305 --> 1.478304).         Saving model ...\n",
      "Epoch: 4446 \tTraining Loss: 1.076139 \tValidation Loss: 1.478302\n",
      "Validation loss decreased (1.478304 --> 1.478302).         Saving model ...\n",
      "Epoch: 4447 \tTraining Loss: 1.076138 \tValidation Loss: 1.478301\n",
      "Validation loss decreased (1.478302 --> 1.478301).         Saving model ...\n",
      "Epoch: 4448 \tTraining Loss: 1.076137 \tValidation Loss: 1.478300\n",
      "Validation loss decreased (1.478301 --> 1.478300).         Saving model ...\n",
      "Epoch: 4449 \tTraining Loss: 1.076136 \tValidation Loss: 1.478298\n",
      "Validation loss decreased (1.478300 --> 1.478298).         Saving model ...\n",
      "Epoch: 4450 \tTraining Loss: 1.076134 \tValidation Loss: 1.478297\n",
      "Validation loss decreased (1.478298 --> 1.478297).         Saving model ...\n",
      "Epoch: 4451 \tTraining Loss: 1.076133 \tValidation Loss: 1.478296\n",
      "Validation loss decreased (1.478297 --> 1.478296).         Saving model ...\n",
      "Epoch: 4452 \tTraining Loss: 1.076132 \tValidation Loss: 1.478295\n",
      "Validation loss decreased (1.478296 --> 1.478295).         Saving model ...\n",
      "Epoch: 4453 \tTraining Loss: 1.076130 \tValidation Loss: 1.478293\n",
      "Validation loss decreased (1.478295 --> 1.478293).         Saving model ...\n",
      "Epoch: 4454 \tTraining Loss: 1.076129 \tValidation Loss: 1.478291\n",
      "Validation loss decreased (1.478293 --> 1.478291).         Saving model ...\n",
      "Epoch: 4455 \tTraining Loss: 1.076128 \tValidation Loss: 1.478290\n",
      "Validation loss decreased (1.478291 --> 1.478290).         Saving model ...\n",
      "Epoch: 4456 \tTraining Loss: 1.076127 \tValidation Loss: 1.478289\n",
      "Validation loss decreased (1.478290 --> 1.478289).         Saving model ...\n",
      "Epoch: 4457 \tTraining Loss: 1.076125 \tValidation Loss: 1.478288\n",
      "Validation loss decreased (1.478289 --> 1.478288).         Saving model ...\n",
      "Epoch: 4458 \tTraining Loss: 1.076124 \tValidation Loss: 1.478286\n",
      "Validation loss decreased (1.478288 --> 1.478286).         Saving model ...\n",
      "Epoch: 4459 \tTraining Loss: 1.076123 \tValidation Loss: 1.478286\n",
      "Validation loss decreased (1.478286 --> 1.478286).         Saving model ...\n",
      "Epoch: 4460 \tTraining Loss: 1.076121 \tValidation Loss: 1.478284\n",
      "Validation loss decreased (1.478286 --> 1.478284).         Saving model ...\n",
      "Epoch: 4461 \tTraining Loss: 1.076120 \tValidation Loss: 1.478284\n",
      "Validation loss decreased (1.478284 --> 1.478284).         Saving model ...\n",
      "Epoch: 4462 \tTraining Loss: 1.076119 \tValidation Loss: 1.478283\n",
      "Validation loss decreased (1.478284 --> 1.478283).         Saving model ...\n",
      "Epoch: 4463 \tTraining Loss: 1.076118 \tValidation Loss: 1.478282\n",
      "Validation loss decreased (1.478283 --> 1.478282).         Saving model ...\n",
      "Epoch: 4464 \tTraining Loss: 1.076116 \tValidation Loss: 1.478281\n",
      "Validation loss decreased (1.478282 --> 1.478281).         Saving model ...\n",
      "Epoch: 4465 \tTraining Loss: 1.076115 \tValidation Loss: 1.478280\n",
      "Validation loss decreased (1.478281 --> 1.478280).         Saving model ...\n",
      "Epoch: 4466 \tTraining Loss: 1.076114 \tValidation Loss: 1.478278\n",
      "Validation loss decreased (1.478280 --> 1.478278).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4467 \tTraining Loss: 1.076112 \tValidation Loss: 1.478278\n",
      "Validation loss decreased (1.478278 --> 1.478278).         Saving model ...\n",
      "Epoch: 4468 \tTraining Loss: 1.076111 \tValidation Loss: 1.478276\n",
      "Validation loss decreased (1.478278 --> 1.478276).         Saving model ...\n",
      "Epoch: 4469 \tTraining Loss: 1.076110 \tValidation Loss: 1.478275\n",
      "Validation loss decreased (1.478276 --> 1.478275).         Saving model ...\n",
      "Epoch: 4470 \tTraining Loss: 1.076109 \tValidation Loss: 1.478274\n",
      "Validation loss decreased (1.478275 --> 1.478274).         Saving model ...\n",
      "Epoch: 4471 \tTraining Loss: 1.076107 \tValidation Loss: 1.478273\n",
      "Validation loss decreased (1.478274 --> 1.478273).         Saving model ...\n",
      "Epoch: 4472 \tTraining Loss: 1.076106 \tValidation Loss: 1.478272\n",
      "Validation loss decreased (1.478273 --> 1.478272).         Saving model ...\n",
      "Epoch: 4473 \tTraining Loss: 1.076105 \tValidation Loss: 1.478270\n",
      "Validation loss decreased (1.478272 --> 1.478270).         Saving model ...\n",
      "Epoch: 4474 \tTraining Loss: 1.076103 \tValidation Loss: 1.478269\n",
      "Validation loss decreased (1.478270 --> 1.478269).         Saving model ...\n",
      "Epoch: 4475 \tTraining Loss: 1.076102 \tValidation Loss: 1.478268\n",
      "Validation loss decreased (1.478269 --> 1.478268).         Saving model ...\n",
      "Epoch: 4476 \tTraining Loss: 1.076101 \tValidation Loss: 1.478267\n",
      "Validation loss decreased (1.478268 --> 1.478267).         Saving model ...\n",
      "Epoch: 4477 \tTraining Loss: 1.076100 \tValidation Loss: 1.478266\n",
      "Validation loss decreased (1.478267 --> 1.478266).         Saving model ...\n",
      "Epoch: 4478 \tTraining Loss: 1.076098 \tValidation Loss: 1.478266\n",
      "Validation loss decreased (1.478266 --> 1.478266).         Saving model ...\n",
      "Epoch: 4479 \tTraining Loss: 1.076097 \tValidation Loss: 1.478264\n",
      "Validation loss decreased (1.478266 --> 1.478264).         Saving model ...\n",
      "Epoch: 4480 \tTraining Loss: 1.076096 \tValidation Loss: 1.478262\n",
      "Validation loss decreased (1.478264 --> 1.478262).         Saving model ...\n",
      "Epoch: 4481 \tTraining Loss: 1.076094 \tValidation Loss: 1.478261\n",
      "Validation loss decreased (1.478262 --> 1.478261).         Saving model ...\n",
      "Epoch: 4482 \tTraining Loss: 1.076093 \tValidation Loss: 1.478260\n",
      "Validation loss decreased (1.478261 --> 1.478260).         Saving model ...\n",
      "Epoch: 4483 \tTraining Loss: 1.076092 \tValidation Loss: 1.478259\n",
      "Validation loss decreased (1.478260 --> 1.478259).         Saving model ...\n",
      "Epoch: 4484 \tTraining Loss: 1.076091 \tValidation Loss: 1.478257\n",
      "Validation loss decreased (1.478259 --> 1.478257).         Saving model ...\n",
      "Epoch: 4485 \tTraining Loss: 1.076089 \tValidation Loss: 1.478257\n",
      "Validation loss decreased (1.478257 --> 1.478257).         Saving model ...\n",
      "Epoch: 4486 \tTraining Loss: 1.076088 \tValidation Loss: 1.478255\n",
      "Validation loss decreased (1.478257 --> 1.478255).         Saving model ...\n",
      "Epoch: 4487 \tTraining Loss: 1.076087 \tValidation Loss: 1.478254\n",
      "Validation loss decreased (1.478255 --> 1.478254).         Saving model ...\n",
      "Epoch: 4488 \tTraining Loss: 1.076086 \tValidation Loss: 1.478252\n",
      "Validation loss decreased (1.478254 --> 1.478252).         Saving model ...\n",
      "Epoch: 4489 \tTraining Loss: 1.076084 \tValidation Loss: 1.478251\n",
      "Validation loss decreased (1.478252 --> 1.478251).         Saving model ...\n",
      "Epoch: 4490 \tTraining Loss: 1.076083 \tValidation Loss: 1.478249\n",
      "Validation loss decreased (1.478251 --> 1.478249).         Saving model ...\n",
      "Epoch: 4491 \tTraining Loss: 1.076082 \tValidation Loss: 1.478248\n",
      "Validation loss decreased (1.478249 --> 1.478248).         Saving model ...\n",
      "Epoch: 4492 \tTraining Loss: 1.076080 \tValidation Loss: 1.478247\n",
      "Validation loss decreased (1.478248 --> 1.478247).         Saving model ...\n",
      "Epoch: 4493 \tTraining Loss: 1.076079 \tValidation Loss: 1.478246\n",
      "Validation loss decreased (1.478247 --> 1.478246).         Saving model ...\n",
      "Epoch: 4494 \tTraining Loss: 1.076078 \tValidation Loss: 1.478245\n",
      "Validation loss decreased (1.478246 --> 1.478245).         Saving model ...\n",
      "Epoch: 4495 \tTraining Loss: 1.076077 \tValidation Loss: 1.478244\n",
      "Validation loss decreased (1.478245 --> 1.478244).         Saving model ...\n",
      "Epoch: 4496 \tTraining Loss: 1.076075 \tValidation Loss: 1.478242\n",
      "Validation loss decreased (1.478244 --> 1.478242).         Saving model ...\n",
      "Epoch: 4497 \tTraining Loss: 1.076074 \tValidation Loss: 1.478241\n",
      "Validation loss decreased (1.478242 --> 1.478241).         Saving model ...\n",
      "Epoch: 4498 \tTraining Loss: 1.076073 \tValidation Loss: 1.478239\n",
      "Validation loss decreased (1.478241 --> 1.478239).         Saving model ...\n",
      "Epoch: 4499 \tTraining Loss: 1.076072 \tValidation Loss: 1.478238\n",
      "Validation loss decreased (1.478239 --> 1.478238).         Saving model ...\n",
      "Epoch: 4500 \tTraining Loss: 1.076070 \tValidation Loss: 1.478237\n",
      "Validation loss decreased (1.478238 --> 1.478237).         Saving model ...\n",
      "Epoch: 4501 \tTraining Loss: 1.076069 \tValidation Loss: 1.478236\n",
      "Validation loss decreased (1.478237 --> 1.478236).         Saving model ...\n",
      "Epoch: 4502 \tTraining Loss: 1.076068 \tValidation Loss: 1.478235\n",
      "Validation loss decreased (1.478236 --> 1.478235).         Saving model ...\n",
      "Epoch: 4503 \tTraining Loss: 1.076066 \tValidation Loss: 1.478233\n",
      "Validation loss decreased (1.478235 --> 1.478233).         Saving model ...\n",
      "Epoch: 4504 \tTraining Loss: 1.076065 \tValidation Loss: 1.478232\n",
      "Validation loss decreased (1.478233 --> 1.478232).         Saving model ...\n",
      "Epoch: 4505 \tTraining Loss: 1.076064 \tValidation Loss: 1.478230\n",
      "Validation loss decreased (1.478232 --> 1.478230).         Saving model ...\n",
      "Epoch: 4506 \tTraining Loss: 1.076063 \tValidation Loss: 1.478229\n",
      "Validation loss decreased (1.478230 --> 1.478229).         Saving model ...\n",
      "Epoch: 4507 \tTraining Loss: 1.076061 \tValidation Loss: 1.478228\n",
      "Validation loss decreased (1.478229 --> 1.478228).         Saving model ...\n",
      "Epoch: 4508 \tTraining Loss: 1.076060 \tValidation Loss: 1.478227\n",
      "Validation loss decreased (1.478228 --> 1.478227).         Saving model ...\n",
      "Epoch: 4509 \tTraining Loss: 1.076059 \tValidation Loss: 1.478226\n",
      "Validation loss decreased (1.478227 --> 1.478226).         Saving model ...\n",
      "Epoch: 4510 \tTraining Loss: 1.076058 \tValidation Loss: 1.478224\n",
      "Validation loss decreased (1.478226 --> 1.478224).         Saving model ...\n",
      "Epoch: 4511 \tTraining Loss: 1.076056 \tValidation Loss: 1.478223\n",
      "Validation loss decreased (1.478224 --> 1.478223).         Saving model ...\n",
      "Epoch: 4512 \tTraining Loss: 1.076055 \tValidation Loss: 1.478222\n",
      "Validation loss decreased (1.478223 --> 1.478222).         Saving model ...\n",
      "Epoch: 4513 \tTraining Loss: 1.076054 \tValidation Loss: 1.478221\n",
      "Validation loss decreased (1.478222 --> 1.478221).         Saving model ...\n",
      "Epoch: 4514 \tTraining Loss: 1.076053 \tValidation Loss: 1.478220\n",
      "Validation loss decreased (1.478221 --> 1.478220).         Saving model ...\n",
      "Epoch: 4515 \tTraining Loss: 1.076051 \tValidation Loss: 1.478220\n",
      "Validation loss decreased (1.478220 --> 1.478220).         Saving model ...\n",
      "Epoch: 4516 \tTraining Loss: 1.076050 \tValidation Loss: 1.478219\n",
      "Validation loss decreased (1.478220 --> 1.478219).         Saving model ...\n",
      "Epoch: 4517 \tTraining Loss: 1.076049 \tValidation Loss: 1.478218\n",
      "Validation loss decreased (1.478219 --> 1.478218).         Saving model ...\n",
      "Epoch: 4518 \tTraining Loss: 1.076048 \tValidation Loss: 1.478216\n",
      "Validation loss decreased (1.478218 --> 1.478216).         Saving model ...\n",
      "Epoch: 4519 \tTraining Loss: 1.076046 \tValidation Loss: 1.478216\n",
      "Validation loss decreased (1.478216 --> 1.478216).         Saving model ...\n",
      "Epoch: 4520 \tTraining Loss: 1.076045 \tValidation Loss: 1.478214\n",
      "Validation loss decreased (1.478216 --> 1.478214).         Saving model ...\n",
      "Epoch: 4521 \tTraining Loss: 1.076044 \tValidation Loss: 1.478213\n",
      "Validation loss decreased (1.478214 --> 1.478213).         Saving model ...\n",
      "Epoch: 4522 \tTraining Loss: 1.076042 \tValidation Loss: 1.478211\n",
      "Validation loss decreased (1.478213 --> 1.478211).         Saving model ...\n",
      "Epoch: 4523 \tTraining Loss: 1.076041 \tValidation Loss: 1.478211\n",
      "Validation loss decreased (1.478211 --> 1.478211).         Saving model ...\n",
      "Epoch: 4524 \tTraining Loss: 1.076040 \tValidation Loss: 1.478210\n",
      "Validation loss decreased (1.478211 --> 1.478210).         Saving model ...\n",
      "Epoch: 4525 \tTraining Loss: 1.076039 \tValidation Loss: 1.478209\n",
      "Validation loss decreased (1.478210 --> 1.478209).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4526 \tTraining Loss: 1.076037 \tValidation Loss: 1.478207\n",
      "Validation loss decreased (1.478209 --> 1.478207).         Saving model ...\n",
      "Epoch: 4527 \tTraining Loss: 1.076036 \tValidation Loss: 1.478207\n",
      "Validation loss decreased (1.478207 --> 1.478207).         Saving model ...\n",
      "Epoch: 4528 \tTraining Loss: 1.076035 \tValidation Loss: 1.478206\n",
      "Validation loss decreased (1.478207 --> 1.478206).         Saving model ...\n",
      "Epoch: 4529 \tTraining Loss: 1.076034 \tValidation Loss: 1.478205\n",
      "Validation loss decreased (1.478206 --> 1.478205).         Saving model ...\n",
      "Epoch: 4530 \tTraining Loss: 1.076032 \tValidation Loss: 1.478205\n",
      "Validation loss decreased (1.478205 --> 1.478205).         Saving model ...\n",
      "Epoch: 4531 \tTraining Loss: 1.076031 \tValidation Loss: 1.478203\n",
      "Validation loss decreased (1.478205 --> 1.478203).         Saving model ...\n",
      "Epoch: 4532 \tTraining Loss: 1.076030 \tValidation Loss: 1.478202\n",
      "Validation loss decreased (1.478203 --> 1.478202).         Saving model ...\n",
      "Epoch: 4533 \tTraining Loss: 1.076029 \tValidation Loss: 1.478200\n",
      "Validation loss decreased (1.478202 --> 1.478200).         Saving model ...\n",
      "Epoch: 4534 \tTraining Loss: 1.076027 \tValidation Loss: 1.478199\n",
      "Validation loss decreased (1.478200 --> 1.478199).         Saving model ...\n",
      "Epoch: 4535 \tTraining Loss: 1.076026 \tValidation Loss: 1.478197\n",
      "Validation loss decreased (1.478199 --> 1.478197).         Saving model ...\n",
      "Epoch: 4536 \tTraining Loss: 1.076025 \tValidation Loss: 1.478196\n",
      "Validation loss decreased (1.478197 --> 1.478196).         Saving model ...\n",
      "Epoch: 4537 \tTraining Loss: 1.076024 \tValidation Loss: 1.478194\n",
      "Validation loss decreased (1.478196 --> 1.478194).         Saving model ...\n",
      "Epoch: 4538 \tTraining Loss: 1.076022 \tValidation Loss: 1.478192\n",
      "Validation loss decreased (1.478194 --> 1.478192).         Saving model ...\n",
      "Epoch: 4539 \tTraining Loss: 1.076021 \tValidation Loss: 1.478190\n",
      "Validation loss decreased (1.478192 --> 1.478190).         Saving model ...\n",
      "Epoch: 4540 \tTraining Loss: 1.076020 \tValidation Loss: 1.478189\n",
      "Validation loss decreased (1.478190 --> 1.478189).         Saving model ...\n",
      "Epoch: 4541 \tTraining Loss: 1.076019 \tValidation Loss: 1.478187\n",
      "Validation loss decreased (1.478189 --> 1.478187).         Saving model ...\n",
      "Epoch: 4542 \tTraining Loss: 1.076017 \tValidation Loss: 1.478185\n",
      "Validation loss decreased (1.478187 --> 1.478185).         Saving model ...\n",
      "Epoch: 4543 \tTraining Loss: 1.076016 \tValidation Loss: 1.478184\n",
      "Validation loss decreased (1.478185 --> 1.478184).         Saving model ...\n",
      "Epoch: 4544 \tTraining Loss: 1.076015 \tValidation Loss: 1.478183\n",
      "Validation loss decreased (1.478184 --> 1.478183).         Saving model ...\n",
      "Epoch: 4545 \tTraining Loss: 1.076014 \tValidation Loss: 1.478180\n",
      "Validation loss decreased (1.478183 --> 1.478180).         Saving model ...\n",
      "Epoch: 4546 \tTraining Loss: 1.076012 \tValidation Loss: 1.478180\n",
      "Validation loss decreased (1.478180 --> 1.478180).         Saving model ...\n",
      "Epoch: 4547 \tTraining Loss: 1.076011 \tValidation Loss: 1.478178\n",
      "Validation loss decreased (1.478180 --> 1.478178).         Saving model ...\n",
      "Epoch: 4548 \tTraining Loss: 1.076010 \tValidation Loss: 1.478176\n",
      "Validation loss decreased (1.478178 --> 1.478176).         Saving model ...\n",
      "Epoch: 4549 \tTraining Loss: 1.076009 \tValidation Loss: 1.478175\n",
      "Validation loss decreased (1.478176 --> 1.478175).         Saving model ...\n",
      "Epoch: 4550 \tTraining Loss: 1.076007 \tValidation Loss: 1.478174\n",
      "Validation loss decreased (1.478175 --> 1.478174).         Saving model ...\n",
      "Epoch: 4551 \tTraining Loss: 1.076006 \tValidation Loss: 1.478173\n",
      "Validation loss decreased (1.478174 --> 1.478173).         Saving model ...\n",
      "Epoch: 4552 \tTraining Loss: 1.076005 \tValidation Loss: 1.478171\n",
      "Validation loss decreased (1.478173 --> 1.478171).         Saving model ...\n",
      "Epoch: 4553 \tTraining Loss: 1.076004 \tValidation Loss: 1.478169\n",
      "Validation loss decreased (1.478171 --> 1.478169).         Saving model ...\n",
      "Epoch: 4554 \tTraining Loss: 1.076002 \tValidation Loss: 1.478168\n",
      "Validation loss decreased (1.478169 --> 1.478168).         Saving model ...\n",
      "Epoch: 4555 \tTraining Loss: 1.076001 \tValidation Loss: 1.478167\n",
      "Validation loss decreased (1.478168 --> 1.478167).         Saving model ...\n",
      "Epoch: 4556 \tTraining Loss: 1.076000 \tValidation Loss: 1.478166\n",
      "Validation loss decreased (1.478167 --> 1.478166).         Saving model ...\n",
      "Epoch: 4557 \tTraining Loss: 1.075999 \tValidation Loss: 1.478166\n",
      "Validation loss decreased (1.478166 --> 1.478166).         Saving model ...\n",
      "Epoch: 4558 \tTraining Loss: 1.075997 \tValidation Loss: 1.478165\n",
      "Validation loss decreased (1.478166 --> 1.478165).         Saving model ...\n",
      "Epoch: 4559 \tTraining Loss: 1.075996 \tValidation Loss: 1.478164\n",
      "Validation loss decreased (1.478165 --> 1.478164).         Saving model ...\n",
      "Epoch: 4560 \tTraining Loss: 1.075995 \tValidation Loss: 1.478163\n",
      "Validation loss decreased (1.478164 --> 1.478163).         Saving model ...\n",
      "Epoch: 4561 \tTraining Loss: 1.075994 \tValidation Loss: 1.478162\n",
      "Validation loss decreased (1.478163 --> 1.478162).         Saving model ...\n",
      "Epoch: 4562 \tTraining Loss: 1.075992 \tValidation Loss: 1.478161\n",
      "Validation loss decreased (1.478162 --> 1.478161).         Saving model ...\n",
      "Epoch: 4563 \tTraining Loss: 1.075991 \tValidation Loss: 1.478160\n",
      "Validation loss decreased (1.478161 --> 1.478160).         Saving model ...\n",
      "Epoch: 4564 \tTraining Loss: 1.075990 \tValidation Loss: 1.478160\n",
      "Validation loss decreased (1.478160 --> 1.478160).         Saving model ...\n",
      "Epoch: 4565 \tTraining Loss: 1.075989 \tValidation Loss: 1.478159\n",
      "Validation loss decreased (1.478160 --> 1.478159).         Saving model ...\n",
      "Epoch: 4566 \tTraining Loss: 1.075987 \tValidation Loss: 1.478158\n",
      "Validation loss decreased (1.478159 --> 1.478158).         Saving model ...\n",
      "Epoch: 4567 \tTraining Loss: 1.075986 \tValidation Loss: 1.478157\n",
      "Validation loss decreased (1.478158 --> 1.478157).         Saving model ...\n",
      "Epoch: 4568 \tTraining Loss: 1.075985 \tValidation Loss: 1.478156\n",
      "Validation loss decreased (1.478157 --> 1.478156).         Saving model ...\n",
      "Epoch: 4569 \tTraining Loss: 1.075984 \tValidation Loss: 1.478156\n",
      "Validation loss decreased (1.478156 --> 1.478156).         Saving model ...\n",
      "Epoch: 4570 \tTraining Loss: 1.075983 \tValidation Loss: 1.478155\n",
      "Validation loss decreased (1.478156 --> 1.478155).         Saving model ...\n",
      "Epoch: 4571 \tTraining Loss: 1.075981 \tValidation Loss: 1.478154\n",
      "Validation loss decreased (1.478155 --> 1.478154).         Saving model ...\n",
      "Epoch: 4572 \tTraining Loss: 1.075980 \tValidation Loss: 1.478154\n",
      "Validation loss decreased (1.478154 --> 1.478154).         Saving model ...\n",
      "Epoch: 4573 \tTraining Loss: 1.075979 \tValidation Loss: 1.478153\n",
      "Validation loss decreased (1.478154 --> 1.478153).         Saving model ...\n",
      "Epoch: 4574 \tTraining Loss: 1.075978 \tValidation Loss: 1.478152\n",
      "Validation loss decreased (1.478153 --> 1.478152).         Saving model ...\n",
      "Epoch: 4575 \tTraining Loss: 1.075976 \tValidation Loss: 1.478152\n",
      "Validation loss decreased (1.478152 --> 1.478152).         Saving model ...\n",
      "Epoch: 4576 \tTraining Loss: 1.075975 \tValidation Loss: 1.478152\n",
      "Validation loss decreased (1.478152 --> 1.478152).         Saving model ...\n",
      "Epoch: 4577 \tTraining Loss: 1.075974 \tValidation Loss: 1.478151\n",
      "Validation loss decreased (1.478152 --> 1.478151).         Saving model ...\n",
      "Epoch: 4578 \tTraining Loss: 1.075973 \tValidation Loss: 1.478150\n",
      "Validation loss decreased (1.478151 --> 1.478150).         Saving model ...\n",
      "Epoch: 4579 \tTraining Loss: 1.075971 \tValidation Loss: 1.478149\n",
      "Validation loss decreased (1.478150 --> 1.478149).         Saving model ...\n",
      "Epoch: 4580 \tTraining Loss: 1.075970 \tValidation Loss: 1.478149\n",
      "Validation loss decreased (1.478149 --> 1.478149).         Saving model ...\n",
      "Epoch: 4581 \tTraining Loss: 1.075969 \tValidation Loss: 1.478149\n",
      "Validation loss decreased (1.478149 --> 1.478149).         Saving model ...\n",
      "Epoch: 4582 \tTraining Loss: 1.075968 \tValidation Loss: 1.478149\n",
      "Validation loss decreased (1.478149 --> 1.478149).         Saving model ...\n",
      "Epoch: 4583 \tTraining Loss: 1.075966 \tValidation Loss: 1.478148\n",
      "Validation loss decreased (1.478149 --> 1.478148).         Saving model ...\n",
      "Epoch: 4584 \tTraining Loss: 1.075965 \tValidation Loss: 1.478146\n",
      "Validation loss decreased (1.478148 --> 1.478146).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4585 \tTraining Loss: 1.075964 \tValidation Loss: 1.478145\n",
      "Validation loss decreased (1.478146 --> 1.478145).         Saving model ...\n",
      "Epoch: 4586 \tTraining Loss: 1.075963 \tValidation Loss: 1.478145\n",
      "Validation loss decreased (1.478145 --> 1.478145).         Saving model ...\n",
      "Epoch: 4587 \tTraining Loss: 1.075962 \tValidation Loss: 1.478143\n",
      "Validation loss decreased (1.478145 --> 1.478143).         Saving model ...\n",
      "Epoch: 4588 \tTraining Loss: 1.075960 \tValidation Loss: 1.478142\n",
      "Validation loss decreased (1.478143 --> 1.478142).         Saving model ...\n",
      "Epoch: 4589 \tTraining Loss: 1.075959 \tValidation Loss: 1.478141\n",
      "Validation loss decreased (1.478142 --> 1.478141).         Saving model ...\n",
      "Epoch: 4590 \tTraining Loss: 1.075958 \tValidation Loss: 1.478139\n",
      "Validation loss decreased (1.478141 --> 1.478139).         Saving model ...\n",
      "Epoch: 4591 \tTraining Loss: 1.075957 \tValidation Loss: 1.478138\n",
      "Validation loss decreased (1.478139 --> 1.478138).         Saving model ...\n",
      "Epoch: 4592 \tTraining Loss: 1.075955 \tValidation Loss: 1.478136\n",
      "Validation loss decreased (1.478138 --> 1.478136).         Saving model ...\n",
      "Epoch: 4593 \tTraining Loss: 1.075954 \tValidation Loss: 1.478134\n",
      "Validation loss decreased (1.478136 --> 1.478134).         Saving model ...\n",
      "Epoch: 4594 \tTraining Loss: 1.075953 \tValidation Loss: 1.478133\n",
      "Validation loss decreased (1.478134 --> 1.478133).         Saving model ...\n",
      "Epoch: 4595 \tTraining Loss: 1.075952 \tValidation Loss: 1.478132\n",
      "Validation loss decreased (1.478133 --> 1.478132).         Saving model ...\n",
      "Epoch: 4596 \tTraining Loss: 1.075950 \tValidation Loss: 1.478130\n",
      "Validation loss decreased (1.478132 --> 1.478130).         Saving model ...\n",
      "Epoch: 4597 \tTraining Loss: 1.075949 \tValidation Loss: 1.478128\n",
      "Validation loss decreased (1.478130 --> 1.478128).         Saving model ...\n",
      "Epoch: 4598 \tTraining Loss: 1.075948 \tValidation Loss: 1.478127\n",
      "Validation loss decreased (1.478128 --> 1.478127).         Saving model ...\n",
      "Epoch: 4599 \tTraining Loss: 1.075947 \tValidation Loss: 1.478125\n",
      "Validation loss decreased (1.478127 --> 1.478125).         Saving model ...\n",
      "Epoch: 4600 \tTraining Loss: 1.075946 \tValidation Loss: 1.478124\n",
      "Validation loss decreased (1.478125 --> 1.478124).         Saving model ...\n",
      "Epoch: 4601 \tTraining Loss: 1.075944 \tValidation Loss: 1.478122\n",
      "Validation loss decreased (1.478124 --> 1.478122).         Saving model ...\n",
      "Epoch: 4602 \tTraining Loss: 1.075943 \tValidation Loss: 1.478121\n",
      "Validation loss decreased (1.478122 --> 1.478121).         Saving model ...\n",
      "Epoch: 4603 \tTraining Loss: 1.075942 \tValidation Loss: 1.478120\n",
      "Validation loss decreased (1.478121 --> 1.478120).         Saving model ...\n",
      "Epoch: 4604 \tTraining Loss: 1.075941 \tValidation Loss: 1.478119\n",
      "Validation loss decreased (1.478120 --> 1.478119).         Saving model ...\n",
      "Epoch: 4605 \tTraining Loss: 1.075939 \tValidation Loss: 1.478117\n",
      "Validation loss decreased (1.478119 --> 1.478117).         Saving model ...\n",
      "Epoch: 4606 \tTraining Loss: 1.075938 \tValidation Loss: 1.478116\n",
      "Validation loss decreased (1.478117 --> 1.478116).         Saving model ...\n",
      "Epoch: 4607 \tTraining Loss: 1.075937 \tValidation Loss: 1.478114\n",
      "Validation loss decreased (1.478116 --> 1.478114).         Saving model ...\n",
      "Epoch: 4608 \tTraining Loss: 1.075936 \tValidation Loss: 1.478113\n",
      "Validation loss decreased (1.478114 --> 1.478113).         Saving model ...\n",
      "Epoch: 4609 \tTraining Loss: 1.075935 \tValidation Loss: 1.478113\n",
      "Validation loss decreased (1.478113 --> 1.478113).         Saving model ...\n",
      "Epoch: 4610 \tTraining Loss: 1.075933 \tValidation Loss: 1.478112\n",
      "Validation loss decreased (1.478113 --> 1.478112).         Saving model ...\n",
      "Epoch: 4611 \tTraining Loss: 1.075932 \tValidation Loss: 1.478111\n",
      "Validation loss decreased (1.478112 --> 1.478111).         Saving model ...\n",
      "Epoch: 4612 \tTraining Loss: 1.075931 \tValidation Loss: 1.478111\n",
      "Validation loss decreased (1.478111 --> 1.478111).         Saving model ...\n",
      "Epoch: 4613 \tTraining Loss: 1.075930 \tValidation Loss: 1.478110\n",
      "Validation loss decreased (1.478111 --> 1.478110).         Saving model ...\n",
      "Epoch: 4614 \tTraining Loss: 1.075928 \tValidation Loss: 1.478110\n",
      "Epoch: 4615 \tTraining Loss: 1.075927 \tValidation Loss: 1.478109\n",
      "Validation loss decreased (1.478110 --> 1.478109).         Saving model ...\n",
      "Epoch: 4616 \tTraining Loss: 1.075926 \tValidation Loss: 1.478109\n",
      "Validation loss decreased (1.478109 --> 1.478109).         Saving model ...\n",
      "Epoch: 4617 \tTraining Loss: 1.075925 \tValidation Loss: 1.478108\n",
      "Validation loss decreased (1.478109 --> 1.478108).         Saving model ...\n",
      "Epoch: 4618 \tTraining Loss: 1.075923 \tValidation Loss: 1.478107\n",
      "Validation loss decreased (1.478108 --> 1.478107).         Saving model ...\n",
      "Epoch: 4619 \tTraining Loss: 1.075922 \tValidation Loss: 1.478106\n",
      "Validation loss decreased (1.478107 --> 1.478106).         Saving model ...\n",
      "Epoch: 4620 \tTraining Loss: 1.075921 \tValidation Loss: 1.478105\n",
      "Validation loss decreased (1.478106 --> 1.478105).         Saving model ...\n",
      "Epoch: 4621 \tTraining Loss: 1.075920 \tValidation Loss: 1.478104\n",
      "Validation loss decreased (1.478105 --> 1.478104).         Saving model ...\n",
      "Epoch: 4622 \tTraining Loss: 1.075919 \tValidation Loss: 1.478103\n",
      "Validation loss decreased (1.478104 --> 1.478103).         Saving model ...\n",
      "Epoch: 4623 \tTraining Loss: 1.075917 \tValidation Loss: 1.478103\n",
      "Validation loss decreased (1.478103 --> 1.478103).         Saving model ...\n",
      "Epoch: 4624 \tTraining Loss: 1.075916 \tValidation Loss: 1.478102\n",
      "Validation loss decreased (1.478103 --> 1.478102).         Saving model ...\n",
      "Epoch: 4625 \tTraining Loss: 1.075915 \tValidation Loss: 1.478101\n",
      "Validation loss decreased (1.478102 --> 1.478101).         Saving model ...\n",
      "Epoch: 4626 \tTraining Loss: 1.075914 \tValidation Loss: 1.478101\n",
      "Validation loss decreased (1.478101 --> 1.478101).         Saving model ...\n",
      "Epoch: 4627 \tTraining Loss: 1.075913 \tValidation Loss: 1.478100\n",
      "Validation loss decreased (1.478101 --> 1.478100).         Saving model ...\n",
      "Epoch: 4628 \tTraining Loss: 1.075911 \tValidation Loss: 1.478099\n",
      "Validation loss decreased (1.478100 --> 1.478099).         Saving model ...\n",
      "Epoch: 4629 \tTraining Loss: 1.075910 \tValidation Loss: 1.478097\n",
      "Validation loss decreased (1.478099 --> 1.478097).         Saving model ...\n",
      "Epoch: 4630 \tTraining Loss: 1.075909 \tValidation Loss: 1.478096\n",
      "Validation loss decreased (1.478097 --> 1.478096).         Saving model ...\n",
      "Epoch: 4631 \tTraining Loss: 1.075908 \tValidation Loss: 1.478096\n",
      "Validation loss decreased (1.478096 --> 1.478096).         Saving model ...\n",
      "Epoch: 4632 \tTraining Loss: 1.075906 \tValidation Loss: 1.478095\n",
      "Validation loss decreased (1.478096 --> 1.478095).         Saving model ...\n",
      "Epoch: 4633 \tTraining Loss: 1.075905 \tValidation Loss: 1.478095\n",
      "Validation loss decreased (1.478095 --> 1.478095).         Saving model ...\n",
      "Epoch: 4634 \tTraining Loss: 1.075904 \tValidation Loss: 1.478094\n",
      "Validation loss decreased (1.478095 --> 1.478094).         Saving model ...\n",
      "Epoch: 4635 \tTraining Loss: 1.075903 \tValidation Loss: 1.478093\n",
      "Validation loss decreased (1.478094 --> 1.478093).         Saving model ...\n",
      "Epoch: 4636 \tTraining Loss: 1.075902 \tValidation Loss: 1.478092\n",
      "Validation loss decreased (1.478093 --> 1.478092).         Saving model ...\n",
      "Epoch: 4637 \tTraining Loss: 1.075900 \tValidation Loss: 1.478091\n",
      "Validation loss decreased (1.478092 --> 1.478091).         Saving model ...\n",
      "Epoch: 4638 \tTraining Loss: 1.075899 \tValidation Loss: 1.478090\n",
      "Validation loss decreased (1.478091 --> 1.478090).         Saving model ...\n",
      "Epoch: 4639 \tTraining Loss: 1.075898 \tValidation Loss: 1.478089\n",
      "Validation loss decreased (1.478090 --> 1.478089).         Saving model ...\n",
      "Epoch: 4640 \tTraining Loss: 1.075897 \tValidation Loss: 1.478088\n",
      "Validation loss decreased (1.478089 --> 1.478088).         Saving model ...\n",
      "Epoch: 4641 \tTraining Loss: 1.075896 \tValidation Loss: 1.478087\n",
      "Validation loss decreased (1.478088 --> 1.478087).         Saving model ...\n",
      "Epoch: 4642 \tTraining Loss: 1.075894 \tValidation Loss: 1.478086\n",
      "Validation loss decreased (1.478087 --> 1.478086).         Saving model ...\n",
      "Epoch: 4643 \tTraining Loss: 1.075893 \tValidation Loss: 1.478084\n",
      "Validation loss decreased (1.478086 --> 1.478084).         Saving model ...\n",
      "Epoch: 4644 \tTraining Loss: 1.075892 \tValidation Loss: 1.478082\n",
      "Validation loss decreased (1.478084 --> 1.478082).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4645 \tTraining Loss: 1.075891 \tValidation Loss: 1.478080\n",
      "Validation loss decreased (1.478082 --> 1.478080).         Saving model ...\n",
      "Epoch: 4646 \tTraining Loss: 1.075890 \tValidation Loss: 1.478079\n",
      "Validation loss decreased (1.478080 --> 1.478079).         Saving model ...\n",
      "Epoch: 4647 \tTraining Loss: 1.075888 \tValidation Loss: 1.478078\n",
      "Validation loss decreased (1.478079 --> 1.478078).         Saving model ...\n",
      "Epoch: 4648 \tTraining Loss: 1.075887 \tValidation Loss: 1.478077\n",
      "Validation loss decreased (1.478078 --> 1.478077).         Saving model ...\n",
      "Epoch: 4649 \tTraining Loss: 1.075886 \tValidation Loss: 1.478075\n",
      "Validation loss decreased (1.478077 --> 1.478075).         Saving model ...\n",
      "Epoch: 4650 \tTraining Loss: 1.075885 \tValidation Loss: 1.478074\n",
      "Validation loss decreased (1.478075 --> 1.478074).         Saving model ...\n",
      "Epoch: 4651 \tTraining Loss: 1.075884 \tValidation Loss: 1.478072\n",
      "Validation loss decreased (1.478074 --> 1.478072).         Saving model ...\n",
      "Epoch: 4652 \tTraining Loss: 1.075882 \tValidation Loss: 1.478072\n",
      "Validation loss decreased (1.478072 --> 1.478072).         Saving model ...\n",
      "Epoch: 4653 \tTraining Loss: 1.075881 \tValidation Loss: 1.478070\n",
      "Validation loss decreased (1.478072 --> 1.478070).         Saving model ...\n",
      "Epoch: 4654 \tTraining Loss: 1.075880 \tValidation Loss: 1.478069\n",
      "Validation loss decreased (1.478070 --> 1.478069).         Saving model ...\n",
      "Epoch: 4655 \tTraining Loss: 1.075879 \tValidation Loss: 1.478067\n",
      "Validation loss decreased (1.478069 --> 1.478067).         Saving model ...\n",
      "Epoch: 4656 \tTraining Loss: 1.075878 \tValidation Loss: 1.478065\n",
      "Validation loss decreased (1.478067 --> 1.478065).         Saving model ...\n",
      "Epoch: 4657 \tTraining Loss: 1.075876 \tValidation Loss: 1.478063\n",
      "Validation loss decreased (1.478065 --> 1.478063).         Saving model ...\n",
      "Epoch: 4658 \tTraining Loss: 1.075875 \tValidation Loss: 1.478062\n",
      "Validation loss decreased (1.478063 --> 1.478062).         Saving model ...\n",
      "Epoch: 4659 \tTraining Loss: 1.075874 \tValidation Loss: 1.478060\n",
      "Validation loss decreased (1.478062 --> 1.478060).         Saving model ...\n",
      "Epoch: 4660 \tTraining Loss: 1.075873 \tValidation Loss: 1.478058\n",
      "Validation loss decreased (1.478060 --> 1.478058).         Saving model ...\n",
      "Epoch: 4661 \tTraining Loss: 1.075872 \tValidation Loss: 1.478056\n",
      "Validation loss decreased (1.478058 --> 1.478056).         Saving model ...\n",
      "Epoch: 4662 \tTraining Loss: 1.075870 \tValidation Loss: 1.478054\n",
      "Validation loss decreased (1.478056 --> 1.478054).         Saving model ...\n",
      "Epoch: 4663 \tTraining Loss: 1.075869 \tValidation Loss: 1.478051\n",
      "Validation loss decreased (1.478054 --> 1.478051).         Saving model ...\n",
      "Epoch: 4664 \tTraining Loss: 1.075868 \tValidation Loss: 1.478049\n",
      "Validation loss decreased (1.478051 --> 1.478049).         Saving model ...\n",
      "Epoch: 4665 \tTraining Loss: 1.075867 \tValidation Loss: 1.478048\n",
      "Validation loss decreased (1.478049 --> 1.478048).         Saving model ...\n",
      "Epoch: 4666 \tTraining Loss: 1.075866 \tValidation Loss: 1.478045\n",
      "Validation loss decreased (1.478048 --> 1.478045).         Saving model ...\n",
      "Epoch: 4667 \tTraining Loss: 1.075864 \tValidation Loss: 1.478043\n",
      "Validation loss decreased (1.478045 --> 1.478043).         Saving model ...\n",
      "Epoch: 4668 \tTraining Loss: 1.075863 \tValidation Loss: 1.478042\n",
      "Validation loss decreased (1.478043 --> 1.478042).         Saving model ...\n",
      "Epoch: 4669 \tTraining Loss: 1.075862 \tValidation Loss: 1.478040\n",
      "Validation loss decreased (1.478042 --> 1.478040).         Saving model ...\n",
      "Epoch: 4670 \tTraining Loss: 1.075861 \tValidation Loss: 1.478038\n",
      "Validation loss decreased (1.478040 --> 1.478038).         Saving model ...\n",
      "Epoch: 4671 \tTraining Loss: 1.075860 \tValidation Loss: 1.478036\n",
      "Validation loss decreased (1.478038 --> 1.478036).         Saving model ...\n",
      "Epoch: 4672 \tTraining Loss: 1.075858 \tValidation Loss: 1.478034\n",
      "Validation loss decreased (1.478036 --> 1.478034).         Saving model ...\n",
      "Epoch: 4673 \tTraining Loss: 1.075857 \tValidation Loss: 1.478033\n",
      "Validation loss decreased (1.478034 --> 1.478033).         Saving model ...\n",
      "Epoch: 4674 \tTraining Loss: 1.075856 \tValidation Loss: 1.478031\n",
      "Validation loss decreased (1.478033 --> 1.478031).         Saving model ...\n",
      "Epoch: 4675 \tTraining Loss: 1.075855 \tValidation Loss: 1.478029\n",
      "Validation loss decreased (1.478031 --> 1.478029).         Saving model ...\n",
      "Epoch: 4676 \tTraining Loss: 1.075854 \tValidation Loss: 1.478028\n",
      "Validation loss decreased (1.478029 --> 1.478028).         Saving model ...\n",
      "Epoch: 4677 \tTraining Loss: 1.075852 \tValidation Loss: 1.478025\n",
      "Validation loss decreased (1.478028 --> 1.478025).         Saving model ...\n",
      "Epoch: 4678 \tTraining Loss: 1.075851 \tValidation Loss: 1.478024\n",
      "Validation loss decreased (1.478025 --> 1.478024).         Saving model ...\n",
      "Epoch: 4679 \tTraining Loss: 1.075850 \tValidation Loss: 1.478023\n",
      "Validation loss decreased (1.478024 --> 1.478023).         Saving model ...\n",
      "Epoch: 4680 \tTraining Loss: 1.075849 \tValidation Loss: 1.478021\n",
      "Validation loss decreased (1.478023 --> 1.478021).         Saving model ...\n",
      "Epoch: 4681 \tTraining Loss: 1.075848 \tValidation Loss: 1.478018\n",
      "Validation loss decreased (1.478021 --> 1.478018).         Saving model ...\n",
      "Epoch: 4682 \tTraining Loss: 1.075846 \tValidation Loss: 1.478017\n",
      "Validation loss decreased (1.478018 --> 1.478017).         Saving model ...\n",
      "Epoch: 4683 \tTraining Loss: 1.075845 \tValidation Loss: 1.478015\n",
      "Validation loss decreased (1.478017 --> 1.478015).         Saving model ...\n",
      "Epoch: 4684 \tTraining Loss: 1.075844 \tValidation Loss: 1.478014\n",
      "Validation loss decreased (1.478015 --> 1.478014).         Saving model ...\n",
      "Epoch: 4685 \tTraining Loss: 1.075843 \tValidation Loss: 1.478013\n",
      "Validation loss decreased (1.478014 --> 1.478013).         Saving model ...\n",
      "Epoch: 4686 \tTraining Loss: 1.075842 \tValidation Loss: 1.478011\n",
      "Validation loss decreased (1.478013 --> 1.478011).         Saving model ...\n",
      "Epoch: 4687 \tTraining Loss: 1.075840 \tValidation Loss: 1.478010\n",
      "Validation loss decreased (1.478011 --> 1.478010).         Saving model ...\n",
      "Epoch: 4688 \tTraining Loss: 1.075839 \tValidation Loss: 1.478008\n",
      "Validation loss decreased (1.478010 --> 1.478008).         Saving model ...\n",
      "Epoch: 4689 \tTraining Loss: 1.075838 \tValidation Loss: 1.478007\n",
      "Validation loss decreased (1.478008 --> 1.478007).         Saving model ...\n",
      "Epoch: 4690 \tTraining Loss: 1.075837 \tValidation Loss: 1.478004\n",
      "Validation loss decreased (1.478007 --> 1.478004).         Saving model ...\n",
      "Epoch: 4691 \tTraining Loss: 1.075836 \tValidation Loss: 1.478002\n",
      "Validation loss decreased (1.478004 --> 1.478002).         Saving model ...\n",
      "Epoch: 4692 \tTraining Loss: 1.075834 \tValidation Loss: 1.478001\n",
      "Validation loss decreased (1.478002 --> 1.478001).         Saving model ...\n",
      "Epoch: 4693 \tTraining Loss: 1.075833 \tValidation Loss: 1.477999\n",
      "Validation loss decreased (1.478001 --> 1.477999).         Saving model ...\n",
      "Epoch: 4694 \tTraining Loss: 1.075832 \tValidation Loss: 1.477996\n",
      "Validation loss decreased (1.477999 --> 1.477996).         Saving model ...\n",
      "Epoch: 4695 \tTraining Loss: 1.075831 \tValidation Loss: 1.477995\n",
      "Validation loss decreased (1.477996 --> 1.477995).         Saving model ...\n",
      "Epoch: 4696 \tTraining Loss: 1.075830 \tValidation Loss: 1.477993\n",
      "Validation loss decreased (1.477995 --> 1.477993).         Saving model ...\n",
      "Epoch: 4697 \tTraining Loss: 1.075829 \tValidation Loss: 1.477991\n",
      "Validation loss decreased (1.477993 --> 1.477991).         Saving model ...\n",
      "Epoch: 4698 \tTraining Loss: 1.075827 \tValidation Loss: 1.477989\n",
      "Validation loss decreased (1.477991 --> 1.477989).         Saving model ...\n",
      "Epoch: 4699 \tTraining Loss: 1.075826 \tValidation Loss: 1.477988\n",
      "Validation loss decreased (1.477989 --> 1.477988).         Saving model ...\n",
      "Epoch: 4700 \tTraining Loss: 1.075825 \tValidation Loss: 1.477986\n",
      "Validation loss decreased (1.477988 --> 1.477986).         Saving model ...\n",
      "Epoch: 4701 \tTraining Loss: 1.075824 \tValidation Loss: 1.477984\n",
      "Validation loss decreased (1.477986 --> 1.477984).         Saving model ...\n",
      "Epoch: 4702 \tTraining Loss: 1.075823 \tValidation Loss: 1.477983\n",
      "Validation loss decreased (1.477984 --> 1.477983).         Saving model ...\n",
      "Epoch: 4703 \tTraining Loss: 1.075821 \tValidation Loss: 1.477981\n",
      "Validation loss decreased (1.477983 --> 1.477981).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4704 \tTraining Loss: 1.075820 \tValidation Loss: 1.477979\n",
      "Validation loss decreased (1.477981 --> 1.477979).         Saving model ...\n",
      "Epoch: 4705 \tTraining Loss: 1.075819 \tValidation Loss: 1.477978\n",
      "Validation loss decreased (1.477979 --> 1.477978).         Saving model ...\n",
      "Epoch: 4706 \tTraining Loss: 1.075818 \tValidation Loss: 1.477977\n",
      "Validation loss decreased (1.477978 --> 1.477977).         Saving model ...\n",
      "Epoch: 4707 \tTraining Loss: 1.075817 \tValidation Loss: 1.477975\n",
      "Validation loss decreased (1.477977 --> 1.477975).         Saving model ...\n",
      "Epoch: 4708 \tTraining Loss: 1.075815 \tValidation Loss: 1.477973\n",
      "Validation loss decreased (1.477975 --> 1.477973).         Saving model ...\n",
      "Epoch: 4709 \tTraining Loss: 1.075814 \tValidation Loss: 1.477972\n",
      "Validation loss decreased (1.477973 --> 1.477972).         Saving model ...\n",
      "Epoch: 4710 \tTraining Loss: 1.075813 \tValidation Loss: 1.477970\n",
      "Validation loss decreased (1.477972 --> 1.477970).         Saving model ...\n",
      "Epoch: 4711 \tTraining Loss: 1.075812 \tValidation Loss: 1.477969\n",
      "Validation loss decreased (1.477970 --> 1.477969).         Saving model ...\n",
      "Epoch: 4712 \tTraining Loss: 1.075811 \tValidation Loss: 1.477968\n",
      "Validation loss decreased (1.477969 --> 1.477968).         Saving model ...\n",
      "Epoch: 4713 \tTraining Loss: 1.075810 \tValidation Loss: 1.477967\n",
      "Validation loss decreased (1.477968 --> 1.477967).         Saving model ...\n",
      "Epoch: 4714 \tTraining Loss: 1.075808 \tValidation Loss: 1.477965\n",
      "Validation loss decreased (1.477967 --> 1.477965).         Saving model ...\n",
      "Epoch: 4715 \tTraining Loss: 1.075807 \tValidation Loss: 1.477964\n",
      "Validation loss decreased (1.477965 --> 1.477964).         Saving model ...\n",
      "Epoch: 4716 \tTraining Loss: 1.075806 \tValidation Loss: 1.477963\n",
      "Validation loss decreased (1.477964 --> 1.477963).         Saving model ...\n",
      "Epoch: 4717 \tTraining Loss: 1.075805 \tValidation Loss: 1.477962\n",
      "Validation loss decreased (1.477963 --> 1.477962).         Saving model ...\n",
      "Epoch: 4718 \tTraining Loss: 1.075804 \tValidation Loss: 1.477960\n",
      "Validation loss decreased (1.477962 --> 1.477960).         Saving model ...\n",
      "Epoch: 4719 \tTraining Loss: 1.075802 \tValidation Loss: 1.477959\n",
      "Validation loss decreased (1.477960 --> 1.477959).         Saving model ...\n",
      "Epoch: 4720 \tTraining Loss: 1.075801 \tValidation Loss: 1.477957\n",
      "Validation loss decreased (1.477959 --> 1.477957).         Saving model ...\n",
      "Epoch: 4721 \tTraining Loss: 1.075800 \tValidation Loss: 1.477956\n",
      "Validation loss decreased (1.477957 --> 1.477956).         Saving model ...\n",
      "Epoch: 4722 \tTraining Loss: 1.075799 \tValidation Loss: 1.477955\n",
      "Validation loss decreased (1.477956 --> 1.477955).         Saving model ...\n",
      "Epoch: 4723 \tTraining Loss: 1.075798 \tValidation Loss: 1.477954\n",
      "Validation loss decreased (1.477955 --> 1.477954).         Saving model ...\n",
      "Epoch: 4724 \tTraining Loss: 1.075797 \tValidation Loss: 1.477953\n",
      "Validation loss decreased (1.477954 --> 1.477953).         Saving model ...\n",
      "Epoch: 4725 \tTraining Loss: 1.075795 \tValidation Loss: 1.477952\n",
      "Validation loss decreased (1.477953 --> 1.477952).         Saving model ...\n",
      "Epoch: 4726 \tTraining Loss: 1.075794 \tValidation Loss: 1.477951\n",
      "Validation loss decreased (1.477952 --> 1.477951).         Saving model ...\n",
      "Epoch: 4727 \tTraining Loss: 1.075793 \tValidation Loss: 1.477950\n",
      "Validation loss decreased (1.477951 --> 1.477950).         Saving model ...\n",
      "Epoch: 4728 \tTraining Loss: 1.075792 \tValidation Loss: 1.477949\n",
      "Validation loss decreased (1.477950 --> 1.477949).         Saving model ...\n",
      "Epoch: 4729 \tTraining Loss: 1.075791 \tValidation Loss: 1.477948\n",
      "Validation loss decreased (1.477949 --> 1.477948).         Saving model ...\n",
      "Epoch: 4730 \tTraining Loss: 1.075790 \tValidation Loss: 1.477948\n",
      "Validation loss decreased (1.477948 --> 1.477948).         Saving model ...\n",
      "Epoch: 4731 \tTraining Loss: 1.075788 \tValidation Loss: 1.477947\n",
      "Validation loss decreased (1.477948 --> 1.477947).         Saving model ...\n",
      "Epoch: 4732 \tTraining Loss: 1.075787 \tValidation Loss: 1.477946\n",
      "Validation loss decreased (1.477947 --> 1.477946).         Saving model ...\n",
      "Epoch: 4733 \tTraining Loss: 1.075786 \tValidation Loss: 1.477946\n",
      "Validation loss decreased (1.477946 --> 1.477946).         Saving model ...\n",
      "Epoch: 4734 \tTraining Loss: 1.075785 \tValidation Loss: 1.477945\n",
      "Validation loss decreased (1.477946 --> 1.477945).         Saving model ...\n",
      "Epoch: 4735 \tTraining Loss: 1.075784 \tValidation Loss: 1.477944\n",
      "Validation loss decreased (1.477945 --> 1.477944).         Saving model ...\n",
      "Epoch: 4736 \tTraining Loss: 1.075782 \tValidation Loss: 1.477943\n",
      "Validation loss decreased (1.477944 --> 1.477943).         Saving model ...\n",
      "Epoch: 4737 \tTraining Loss: 1.075781 \tValidation Loss: 1.477942\n",
      "Validation loss decreased (1.477943 --> 1.477942).         Saving model ...\n",
      "Epoch: 4738 \tTraining Loss: 1.075780 \tValidation Loss: 1.477941\n",
      "Validation loss decreased (1.477942 --> 1.477941).         Saving model ...\n",
      "Epoch: 4739 \tTraining Loss: 1.075779 \tValidation Loss: 1.477940\n",
      "Validation loss decreased (1.477941 --> 1.477940).         Saving model ...\n",
      "Epoch: 4740 \tTraining Loss: 1.075778 \tValidation Loss: 1.477938\n",
      "Validation loss decreased (1.477940 --> 1.477938).         Saving model ...\n",
      "Epoch: 4741 \tTraining Loss: 1.075777 \tValidation Loss: 1.477937\n",
      "Validation loss decreased (1.477938 --> 1.477937).         Saving model ...\n",
      "Epoch: 4742 \tTraining Loss: 1.075775 \tValidation Loss: 1.477936\n",
      "Validation loss decreased (1.477937 --> 1.477936).         Saving model ...\n",
      "Epoch: 4743 \tTraining Loss: 1.075774 \tValidation Loss: 1.477935\n",
      "Validation loss decreased (1.477936 --> 1.477935).         Saving model ...\n",
      "Epoch: 4744 \tTraining Loss: 1.075773 \tValidation Loss: 1.477935\n",
      "Validation loss decreased (1.477935 --> 1.477935).         Saving model ...\n",
      "Epoch: 4745 \tTraining Loss: 1.075772 \tValidation Loss: 1.477934\n",
      "Validation loss decreased (1.477935 --> 1.477934).         Saving model ...\n",
      "Epoch: 4746 \tTraining Loss: 1.075771 \tValidation Loss: 1.477933\n",
      "Validation loss decreased (1.477934 --> 1.477933).         Saving model ...\n",
      "Epoch: 4747 \tTraining Loss: 1.075770 \tValidation Loss: 1.477932\n",
      "Validation loss decreased (1.477933 --> 1.477932).         Saving model ...\n",
      "Epoch: 4748 \tTraining Loss: 1.075768 \tValidation Loss: 1.477931\n",
      "Validation loss decreased (1.477932 --> 1.477931).         Saving model ...\n",
      "Epoch: 4749 \tTraining Loss: 1.075767 \tValidation Loss: 1.477930\n",
      "Validation loss decreased (1.477931 --> 1.477930).         Saving model ...\n",
      "Epoch: 4750 \tTraining Loss: 1.075766 \tValidation Loss: 1.477928\n",
      "Validation loss decreased (1.477930 --> 1.477928).         Saving model ...\n",
      "Epoch: 4751 \tTraining Loss: 1.075765 \tValidation Loss: 1.477928\n",
      "Validation loss decreased (1.477928 --> 1.477928).         Saving model ...\n",
      "Epoch: 4752 \tTraining Loss: 1.075764 \tValidation Loss: 1.477926\n",
      "Validation loss decreased (1.477928 --> 1.477926).         Saving model ...\n",
      "Epoch: 4753 \tTraining Loss: 1.075763 \tValidation Loss: 1.477924\n",
      "Validation loss decreased (1.477926 --> 1.477924).         Saving model ...\n",
      "Epoch: 4754 \tTraining Loss: 1.075761 \tValidation Loss: 1.477923\n",
      "Validation loss decreased (1.477924 --> 1.477923).         Saving model ...\n",
      "Epoch: 4755 \tTraining Loss: 1.075760 \tValidation Loss: 1.477921\n",
      "Validation loss decreased (1.477923 --> 1.477921).         Saving model ...\n",
      "Epoch: 4756 \tTraining Loss: 1.075759 \tValidation Loss: 1.477919\n",
      "Validation loss decreased (1.477921 --> 1.477919).         Saving model ...\n",
      "Epoch: 4757 \tTraining Loss: 1.075758 \tValidation Loss: 1.477919\n",
      "Validation loss decreased (1.477919 --> 1.477919).         Saving model ...\n",
      "Epoch: 4758 \tTraining Loss: 1.075757 \tValidation Loss: 1.477918\n",
      "Validation loss decreased (1.477919 --> 1.477918).         Saving model ...\n",
      "Epoch: 4759 \tTraining Loss: 1.075756 \tValidation Loss: 1.477917\n",
      "Validation loss decreased (1.477918 --> 1.477917).         Saving model ...\n",
      "Epoch: 4760 \tTraining Loss: 1.075754 \tValidation Loss: 1.477915\n",
      "Validation loss decreased (1.477917 --> 1.477915).         Saving model ...\n",
      "Epoch: 4761 \tTraining Loss: 1.075753 \tValidation Loss: 1.477914\n",
      "Validation loss decreased (1.477915 --> 1.477914).         Saving model ...\n",
      "Epoch: 4762 \tTraining Loss: 1.075752 \tValidation Loss: 1.477913\n",
      "Validation loss decreased (1.477914 --> 1.477913).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4763 \tTraining Loss: 1.075751 \tValidation Loss: 1.477912\n",
      "Validation loss decreased (1.477913 --> 1.477912).         Saving model ...\n",
      "Epoch: 4764 \tTraining Loss: 1.075750 \tValidation Loss: 1.477911\n",
      "Validation loss decreased (1.477912 --> 1.477911).         Saving model ...\n",
      "Epoch: 4765 \tTraining Loss: 1.075749 \tValidation Loss: 1.477910\n",
      "Validation loss decreased (1.477911 --> 1.477910).         Saving model ...\n",
      "Epoch: 4766 \tTraining Loss: 1.075747 \tValidation Loss: 1.477909\n",
      "Validation loss decreased (1.477910 --> 1.477909).         Saving model ...\n",
      "Epoch: 4767 \tTraining Loss: 1.075746 \tValidation Loss: 1.477908\n",
      "Validation loss decreased (1.477909 --> 1.477908).         Saving model ...\n",
      "Epoch: 4768 \tTraining Loss: 1.075745 \tValidation Loss: 1.477908\n",
      "Validation loss decreased (1.477908 --> 1.477908).         Saving model ...\n",
      "Epoch: 4769 \tTraining Loss: 1.075744 \tValidation Loss: 1.477907\n",
      "Validation loss decreased (1.477908 --> 1.477907).         Saving model ...\n",
      "Epoch: 4770 \tTraining Loss: 1.075743 \tValidation Loss: 1.477906\n",
      "Validation loss decreased (1.477907 --> 1.477906).         Saving model ...\n",
      "Epoch: 4771 \tTraining Loss: 1.075742 \tValidation Loss: 1.477906\n",
      "Validation loss decreased (1.477906 --> 1.477906).         Saving model ...\n",
      "Epoch: 4772 \tTraining Loss: 1.075741 \tValidation Loss: 1.477905\n",
      "Validation loss decreased (1.477906 --> 1.477905).         Saving model ...\n",
      "Epoch: 4773 \tTraining Loss: 1.075739 \tValidation Loss: 1.477904\n",
      "Validation loss decreased (1.477905 --> 1.477904).         Saving model ...\n",
      "Epoch: 4774 \tTraining Loss: 1.075738 \tValidation Loss: 1.477903\n",
      "Validation loss decreased (1.477904 --> 1.477903).         Saving model ...\n",
      "Epoch: 4775 \tTraining Loss: 1.075737 \tValidation Loss: 1.477903\n",
      "Validation loss decreased (1.477903 --> 1.477903).         Saving model ...\n",
      "Epoch: 4776 \tTraining Loss: 1.075736 \tValidation Loss: 1.477902\n",
      "Validation loss decreased (1.477903 --> 1.477902).         Saving model ...\n",
      "Epoch: 4777 \tTraining Loss: 1.075735 \tValidation Loss: 1.477901\n",
      "Validation loss decreased (1.477902 --> 1.477901).         Saving model ...\n",
      "Epoch: 4778 \tTraining Loss: 1.075734 \tValidation Loss: 1.477900\n",
      "Validation loss decreased (1.477901 --> 1.477900).         Saving model ...\n",
      "Epoch: 4779 \tTraining Loss: 1.075732 \tValidation Loss: 1.477899\n",
      "Validation loss decreased (1.477900 --> 1.477899).         Saving model ...\n",
      "Epoch: 4780 \tTraining Loss: 1.075731 \tValidation Loss: 1.477898\n",
      "Validation loss decreased (1.477899 --> 1.477898).         Saving model ...\n",
      "Epoch: 4781 \tTraining Loss: 1.075730 \tValidation Loss: 1.477897\n",
      "Validation loss decreased (1.477898 --> 1.477897).         Saving model ...\n",
      "Epoch: 4782 \tTraining Loss: 1.075729 \tValidation Loss: 1.477896\n",
      "Validation loss decreased (1.477897 --> 1.477896).         Saving model ...\n",
      "Epoch: 4783 \tTraining Loss: 1.075728 \tValidation Loss: 1.477895\n",
      "Validation loss decreased (1.477896 --> 1.477895).         Saving model ...\n",
      "Epoch: 4784 \tTraining Loss: 1.075727 \tValidation Loss: 1.477894\n",
      "Validation loss decreased (1.477895 --> 1.477894).         Saving model ...\n",
      "Epoch: 4785 \tTraining Loss: 1.075725 \tValidation Loss: 1.477893\n",
      "Validation loss decreased (1.477894 --> 1.477893).         Saving model ...\n",
      "Epoch: 4786 \tTraining Loss: 1.075724 \tValidation Loss: 1.477891\n",
      "Validation loss decreased (1.477893 --> 1.477891).         Saving model ...\n",
      "Epoch: 4787 \tTraining Loss: 1.075723 \tValidation Loss: 1.477889\n",
      "Validation loss decreased (1.477891 --> 1.477889).         Saving model ...\n",
      "Epoch: 4788 \tTraining Loss: 1.075722 \tValidation Loss: 1.477888\n",
      "Validation loss decreased (1.477889 --> 1.477888).         Saving model ...\n",
      "Epoch: 4789 \tTraining Loss: 1.075721 \tValidation Loss: 1.477886\n",
      "Validation loss decreased (1.477888 --> 1.477886).         Saving model ...\n",
      "Epoch: 4790 \tTraining Loss: 1.075720 \tValidation Loss: 1.477885\n",
      "Validation loss decreased (1.477886 --> 1.477885).         Saving model ...\n",
      "Epoch: 4791 \tTraining Loss: 1.075719 \tValidation Loss: 1.477883\n",
      "Validation loss decreased (1.477885 --> 1.477883).         Saving model ...\n",
      "Epoch: 4792 \tTraining Loss: 1.075717 \tValidation Loss: 1.477882\n",
      "Validation loss decreased (1.477883 --> 1.477882).         Saving model ...\n",
      "Epoch: 4793 \tTraining Loss: 1.075716 \tValidation Loss: 1.477880\n",
      "Validation loss decreased (1.477882 --> 1.477880).         Saving model ...\n",
      "Epoch: 4794 \tTraining Loss: 1.075715 \tValidation Loss: 1.477879\n",
      "Validation loss decreased (1.477880 --> 1.477879).         Saving model ...\n",
      "Epoch: 4795 \tTraining Loss: 1.075714 \tValidation Loss: 1.477878\n",
      "Validation loss decreased (1.477879 --> 1.477878).         Saving model ...\n",
      "Epoch: 4796 \tTraining Loss: 1.075713 \tValidation Loss: 1.477876\n",
      "Validation loss decreased (1.477878 --> 1.477876).         Saving model ...\n",
      "Epoch: 4797 \tTraining Loss: 1.075712 \tValidation Loss: 1.477875\n",
      "Validation loss decreased (1.477876 --> 1.477875).         Saving model ...\n",
      "Epoch: 4798 \tTraining Loss: 1.075710 \tValidation Loss: 1.477874\n",
      "Validation loss decreased (1.477875 --> 1.477874).         Saving model ...\n",
      "Epoch: 4799 \tTraining Loss: 1.075709 \tValidation Loss: 1.477873\n",
      "Validation loss decreased (1.477874 --> 1.477873).         Saving model ...\n",
      "Epoch: 4800 \tTraining Loss: 1.075708 \tValidation Loss: 1.477871\n",
      "Validation loss decreased (1.477873 --> 1.477871).         Saving model ...\n",
      "Epoch: 4801 \tTraining Loss: 1.075707 \tValidation Loss: 1.477869\n",
      "Validation loss decreased (1.477871 --> 1.477869).         Saving model ...\n",
      "Epoch: 4802 \tTraining Loss: 1.075706 \tValidation Loss: 1.477867\n",
      "Validation loss decreased (1.477869 --> 1.477867).         Saving model ...\n",
      "Epoch: 4803 \tTraining Loss: 1.075705 \tValidation Loss: 1.477866\n",
      "Validation loss decreased (1.477867 --> 1.477866).         Saving model ...\n",
      "Epoch: 4804 \tTraining Loss: 1.075704 \tValidation Loss: 1.477864\n",
      "Validation loss decreased (1.477866 --> 1.477864).         Saving model ...\n",
      "Epoch: 4805 \tTraining Loss: 1.075702 \tValidation Loss: 1.477862\n",
      "Validation loss decreased (1.477864 --> 1.477862).         Saving model ...\n",
      "Epoch: 4806 \tTraining Loss: 1.075701 \tValidation Loss: 1.477860\n",
      "Validation loss decreased (1.477862 --> 1.477860).         Saving model ...\n",
      "Epoch: 4807 \tTraining Loss: 1.075700 \tValidation Loss: 1.477859\n",
      "Validation loss decreased (1.477860 --> 1.477859).         Saving model ...\n",
      "Epoch: 4808 \tTraining Loss: 1.075699 \tValidation Loss: 1.477857\n",
      "Validation loss decreased (1.477859 --> 1.477857).         Saving model ...\n",
      "Epoch: 4809 \tTraining Loss: 1.075698 \tValidation Loss: 1.477856\n",
      "Validation loss decreased (1.477857 --> 1.477856).         Saving model ...\n",
      "Epoch: 4810 \tTraining Loss: 1.075697 \tValidation Loss: 1.477854\n",
      "Validation loss decreased (1.477856 --> 1.477854).         Saving model ...\n",
      "Epoch: 4811 \tTraining Loss: 1.075696 \tValidation Loss: 1.477852\n",
      "Validation loss decreased (1.477854 --> 1.477852).         Saving model ...\n",
      "Epoch: 4812 \tTraining Loss: 1.075694 \tValidation Loss: 1.477851\n",
      "Validation loss decreased (1.477852 --> 1.477851).         Saving model ...\n",
      "Epoch: 4813 \tTraining Loss: 1.075693 \tValidation Loss: 1.477850\n",
      "Validation loss decreased (1.477851 --> 1.477850).         Saving model ...\n",
      "Epoch: 4814 \tTraining Loss: 1.075692 \tValidation Loss: 1.477849\n",
      "Validation loss decreased (1.477850 --> 1.477849).         Saving model ...\n",
      "Epoch: 4815 \tTraining Loss: 1.075691 \tValidation Loss: 1.477847\n",
      "Validation loss decreased (1.477849 --> 1.477847).         Saving model ...\n",
      "Epoch: 4816 \tTraining Loss: 1.075690 \tValidation Loss: 1.477846\n",
      "Validation loss decreased (1.477847 --> 1.477846).         Saving model ...\n",
      "Epoch: 4817 \tTraining Loss: 1.075689 \tValidation Loss: 1.477845\n",
      "Validation loss decreased (1.477846 --> 1.477845).         Saving model ...\n",
      "Epoch: 4818 \tTraining Loss: 1.075688 \tValidation Loss: 1.477843\n",
      "Validation loss decreased (1.477845 --> 1.477843).         Saving model ...\n",
      "Epoch: 4819 \tTraining Loss: 1.075686 \tValidation Loss: 1.477841\n",
      "Validation loss decreased (1.477843 --> 1.477841).         Saving model ...\n",
      "Epoch: 4820 \tTraining Loss: 1.075685 \tValidation Loss: 1.477839\n",
      "Validation loss decreased (1.477841 --> 1.477839).         Saving model ...\n",
      "Epoch: 4821 \tTraining Loss: 1.075684 \tValidation Loss: 1.477838\n",
      "Validation loss decreased (1.477839 --> 1.477838).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4822 \tTraining Loss: 1.075683 \tValidation Loss: 1.477835\n",
      "Validation loss decreased (1.477838 --> 1.477835).         Saving model ...\n",
      "Epoch: 4823 \tTraining Loss: 1.075682 \tValidation Loss: 1.477834\n",
      "Validation loss decreased (1.477835 --> 1.477834).         Saving model ...\n",
      "Epoch: 4824 \tTraining Loss: 1.075681 \tValidation Loss: 1.477832\n",
      "Validation loss decreased (1.477834 --> 1.477832).         Saving model ...\n",
      "Epoch: 4825 \tTraining Loss: 1.075680 \tValidation Loss: 1.477830\n",
      "Validation loss decreased (1.477832 --> 1.477830).         Saving model ...\n",
      "Epoch: 4826 \tTraining Loss: 1.075678 \tValidation Loss: 1.477829\n",
      "Validation loss decreased (1.477830 --> 1.477829).         Saving model ...\n",
      "Epoch: 4827 \tTraining Loss: 1.075677 \tValidation Loss: 1.477826\n",
      "Validation loss decreased (1.477829 --> 1.477826).         Saving model ...\n",
      "Epoch: 4828 \tTraining Loss: 1.075676 \tValidation Loss: 1.477825\n",
      "Validation loss decreased (1.477826 --> 1.477825).         Saving model ...\n",
      "Epoch: 4829 \tTraining Loss: 1.075675 \tValidation Loss: 1.477824\n",
      "Validation loss decreased (1.477825 --> 1.477824).         Saving model ...\n",
      "Epoch: 4830 \tTraining Loss: 1.075674 \tValidation Loss: 1.477822\n",
      "Validation loss decreased (1.477824 --> 1.477822).         Saving model ...\n",
      "Epoch: 4831 \tTraining Loss: 1.075673 \tValidation Loss: 1.477820\n",
      "Validation loss decreased (1.477822 --> 1.477820).         Saving model ...\n",
      "Epoch: 4832 \tTraining Loss: 1.075672 \tValidation Loss: 1.477819\n",
      "Validation loss decreased (1.477820 --> 1.477819).         Saving model ...\n",
      "Epoch: 4833 \tTraining Loss: 1.075670 \tValidation Loss: 1.477817\n",
      "Validation loss decreased (1.477819 --> 1.477817).         Saving model ...\n",
      "Epoch: 4834 \tTraining Loss: 1.075669 \tValidation Loss: 1.477815\n",
      "Validation loss decreased (1.477817 --> 1.477815).         Saving model ...\n",
      "Epoch: 4835 \tTraining Loss: 1.075668 \tValidation Loss: 1.477814\n",
      "Validation loss decreased (1.477815 --> 1.477814).         Saving model ...\n",
      "Epoch: 4836 \tTraining Loss: 1.075667 \tValidation Loss: 1.477812\n",
      "Validation loss decreased (1.477814 --> 1.477812).         Saving model ...\n",
      "Epoch: 4837 \tTraining Loss: 1.075666 \tValidation Loss: 1.477810\n",
      "Validation loss decreased (1.477812 --> 1.477810).         Saving model ...\n",
      "Epoch: 4838 \tTraining Loss: 1.075665 \tValidation Loss: 1.477808\n",
      "Validation loss decreased (1.477810 --> 1.477808).         Saving model ...\n",
      "Epoch: 4839 \tTraining Loss: 1.075664 \tValidation Loss: 1.477806\n",
      "Validation loss decreased (1.477808 --> 1.477806).         Saving model ...\n",
      "Epoch: 4840 \tTraining Loss: 1.075663 \tValidation Loss: 1.477804\n",
      "Validation loss decreased (1.477806 --> 1.477804).         Saving model ...\n",
      "Epoch: 4841 \tTraining Loss: 1.075661 \tValidation Loss: 1.477803\n",
      "Validation loss decreased (1.477804 --> 1.477803).         Saving model ...\n",
      "Epoch: 4842 \tTraining Loss: 1.075660 \tValidation Loss: 1.477801\n",
      "Validation loss decreased (1.477803 --> 1.477801).         Saving model ...\n",
      "Epoch: 4843 \tTraining Loss: 1.075659 \tValidation Loss: 1.477799\n",
      "Validation loss decreased (1.477801 --> 1.477799).         Saving model ...\n",
      "Epoch: 4844 \tTraining Loss: 1.075658 \tValidation Loss: 1.477798\n",
      "Validation loss decreased (1.477799 --> 1.477798).         Saving model ...\n",
      "Epoch: 4845 \tTraining Loss: 1.075657 \tValidation Loss: 1.477796\n",
      "Validation loss decreased (1.477798 --> 1.477796).         Saving model ...\n",
      "Epoch: 4846 \tTraining Loss: 1.075656 \tValidation Loss: 1.477794\n",
      "Validation loss decreased (1.477796 --> 1.477794).         Saving model ...\n",
      "Epoch: 4847 \tTraining Loss: 1.075655 \tValidation Loss: 1.477792\n",
      "Validation loss decreased (1.477794 --> 1.477792).         Saving model ...\n",
      "Epoch: 4848 \tTraining Loss: 1.075653 \tValidation Loss: 1.477790\n",
      "Validation loss decreased (1.477792 --> 1.477790).         Saving model ...\n",
      "Epoch: 4849 \tTraining Loss: 1.075652 \tValidation Loss: 1.477789\n",
      "Validation loss decreased (1.477790 --> 1.477789).         Saving model ...\n",
      "Epoch: 4850 \tTraining Loss: 1.075651 \tValidation Loss: 1.477787\n",
      "Validation loss decreased (1.477789 --> 1.477787).         Saving model ...\n",
      "Epoch: 4851 \tTraining Loss: 1.075650 \tValidation Loss: 1.477786\n",
      "Validation loss decreased (1.477787 --> 1.477786).         Saving model ...\n",
      "Epoch: 4852 \tTraining Loss: 1.075649 \tValidation Loss: 1.477785\n",
      "Validation loss decreased (1.477786 --> 1.477785).         Saving model ...\n",
      "Epoch: 4853 \tTraining Loss: 1.075648 \tValidation Loss: 1.477784\n",
      "Validation loss decreased (1.477785 --> 1.477784).         Saving model ...\n",
      "Epoch: 4854 \tTraining Loss: 1.075647 \tValidation Loss: 1.477782\n",
      "Validation loss decreased (1.477784 --> 1.477782).         Saving model ...\n",
      "Epoch: 4855 \tTraining Loss: 1.075646 \tValidation Loss: 1.477780\n",
      "Validation loss decreased (1.477782 --> 1.477780).         Saving model ...\n",
      "Epoch: 4856 \tTraining Loss: 1.075644 \tValidation Loss: 1.477779\n",
      "Validation loss decreased (1.477780 --> 1.477779).         Saving model ...\n",
      "Epoch: 4857 \tTraining Loss: 1.075643 \tValidation Loss: 1.477777\n",
      "Validation loss decreased (1.477779 --> 1.477777).         Saving model ...\n",
      "Epoch: 4858 \tTraining Loss: 1.075642 \tValidation Loss: 1.477776\n",
      "Validation loss decreased (1.477777 --> 1.477776).         Saving model ...\n",
      "Epoch: 4859 \tTraining Loss: 1.075641 \tValidation Loss: 1.477775\n",
      "Validation loss decreased (1.477776 --> 1.477775).         Saving model ...\n",
      "Epoch: 4860 \tTraining Loss: 1.075640 \tValidation Loss: 1.477774\n",
      "Validation loss decreased (1.477775 --> 1.477774).         Saving model ...\n",
      "Epoch: 4861 \tTraining Loss: 1.075639 \tValidation Loss: 1.477772\n",
      "Validation loss decreased (1.477774 --> 1.477772).         Saving model ...\n",
      "Epoch: 4862 \tTraining Loss: 1.075638 \tValidation Loss: 1.477771\n",
      "Validation loss decreased (1.477772 --> 1.477771).         Saving model ...\n",
      "Epoch: 4863 \tTraining Loss: 1.075637 \tValidation Loss: 1.477769\n",
      "Validation loss decreased (1.477771 --> 1.477769).         Saving model ...\n",
      "Epoch: 4864 \tTraining Loss: 1.075635 \tValidation Loss: 1.477768\n",
      "Validation loss decreased (1.477769 --> 1.477768).         Saving model ...\n",
      "Epoch: 4865 \tTraining Loss: 1.075634 \tValidation Loss: 1.477767\n",
      "Validation loss decreased (1.477768 --> 1.477767).         Saving model ...\n",
      "Epoch: 4866 \tTraining Loss: 1.075633 \tValidation Loss: 1.477766\n",
      "Validation loss decreased (1.477767 --> 1.477766).         Saving model ...\n",
      "Epoch: 4867 \tTraining Loss: 1.075632 \tValidation Loss: 1.477764\n",
      "Validation loss decreased (1.477766 --> 1.477764).         Saving model ...\n",
      "Epoch: 4868 \tTraining Loss: 1.075631 \tValidation Loss: 1.477762\n",
      "Validation loss decreased (1.477764 --> 1.477762).         Saving model ...\n",
      "Epoch: 4869 \tTraining Loss: 1.075630 \tValidation Loss: 1.477761\n",
      "Validation loss decreased (1.477762 --> 1.477761).         Saving model ...\n",
      "Epoch: 4870 \tTraining Loss: 1.075629 \tValidation Loss: 1.477759\n",
      "Validation loss decreased (1.477761 --> 1.477759).         Saving model ...\n",
      "Epoch: 4871 \tTraining Loss: 1.075628 \tValidation Loss: 1.477758\n",
      "Validation loss decreased (1.477759 --> 1.477758).         Saving model ...\n",
      "Epoch: 4872 \tTraining Loss: 1.075626 \tValidation Loss: 1.477757\n",
      "Validation loss decreased (1.477758 --> 1.477757).         Saving model ...\n",
      "Epoch: 4873 \tTraining Loss: 1.075625 \tValidation Loss: 1.477756\n",
      "Validation loss decreased (1.477757 --> 1.477756).         Saving model ...\n",
      "Epoch: 4874 \tTraining Loss: 1.075624 \tValidation Loss: 1.477755\n",
      "Validation loss decreased (1.477756 --> 1.477755).         Saving model ...\n",
      "Epoch: 4875 \tTraining Loss: 1.075623 \tValidation Loss: 1.477754\n",
      "Validation loss decreased (1.477755 --> 1.477754).         Saving model ...\n",
      "Epoch: 4876 \tTraining Loss: 1.075622 \tValidation Loss: 1.477753\n",
      "Validation loss decreased (1.477754 --> 1.477753).         Saving model ...\n",
      "Epoch: 4877 \tTraining Loss: 1.075621 \tValidation Loss: 1.477752\n",
      "Validation loss decreased (1.477753 --> 1.477752).         Saving model ...\n",
      "Epoch: 4878 \tTraining Loss: 1.075620 \tValidation Loss: 1.477751\n",
      "Validation loss decreased (1.477752 --> 1.477751).         Saving model ...\n",
      "Epoch: 4879 \tTraining Loss: 1.075619 \tValidation Loss: 1.477750\n",
      "Validation loss decreased (1.477751 --> 1.477750).         Saving model ...\n",
      "Epoch: 4880 \tTraining Loss: 1.075617 \tValidation Loss: 1.477749\n",
      "Validation loss decreased (1.477750 --> 1.477749).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4881 \tTraining Loss: 1.075616 \tValidation Loss: 1.477748\n",
      "Validation loss decreased (1.477749 --> 1.477748).         Saving model ...\n",
      "Epoch: 4882 \tTraining Loss: 1.075615 \tValidation Loss: 1.477746\n",
      "Validation loss decreased (1.477748 --> 1.477746).         Saving model ...\n",
      "Epoch: 4883 \tTraining Loss: 1.075614 \tValidation Loss: 1.477746\n",
      "Validation loss decreased (1.477746 --> 1.477746).         Saving model ...\n",
      "Epoch: 4884 \tTraining Loss: 1.075613 \tValidation Loss: 1.477744\n",
      "Validation loss decreased (1.477746 --> 1.477744).         Saving model ...\n",
      "Epoch: 4885 \tTraining Loss: 1.075612 \tValidation Loss: 1.477743\n",
      "Validation loss decreased (1.477744 --> 1.477743).         Saving model ...\n",
      "Epoch: 4886 \tTraining Loss: 1.075611 \tValidation Loss: 1.477741\n",
      "Validation loss decreased (1.477743 --> 1.477741).         Saving model ...\n",
      "Epoch: 4887 \tTraining Loss: 1.075610 \tValidation Loss: 1.477740\n",
      "Validation loss decreased (1.477741 --> 1.477740).         Saving model ...\n",
      "Epoch: 4888 \tTraining Loss: 1.075609 \tValidation Loss: 1.477738\n",
      "Validation loss decreased (1.477740 --> 1.477738).         Saving model ...\n",
      "Epoch: 4889 \tTraining Loss: 1.075607 \tValidation Loss: 1.477737\n",
      "Validation loss decreased (1.477738 --> 1.477737).         Saving model ...\n",
      "Epoch: 4890 \tTraining Loss: 1.075606 \tValidation Loss: 1.477736\n",
      "Validation loss decreased (1.477737 --> 1.477736).         Saving model ...\n",
      "Epoch: 4891 \tTraining Loss: 1.075605 \tValidation Loss: 1.477734\n",
      "Validation loss decreased (1.477736 --> 1.477734).         Saving model ...\n",
      "Epoch: 4892 \tTraining Loss: 1.075604 \tValidation Loss: 1.477732\n",
      "Validation loss decreased (1.477734 --> 1.477732).         Saving model ...\n",
      "Epoch: 4893 \tTraining Loss: 1.075603 \tValidation Loss: 1.477731\n",
      "Validation loss decreased (1.477732 --> 1.477731).         Saving model ...\n",
      "Epoch: 4894 \tTraining Loss: 1.075602 \tValidation Loss: 1.477729\n",
      "Validation loss decreased (1.477731 --> 1.477729).         Saving model ...\n",
      "Epoch: 4895 \tTraining Loss: 1.075601 \tValidation Loss: 1.477728\n",
      "Validation loss decreased (1.477729 --> 1.477728).         Saving model ...\n",
      "Epoch: 4896 \tTraining Loss: 1.075600 \tValidation Loss: 1.477726\n",
      "Validation loss decreased (1.477728 --> 1.477726).         Saving model ...\n",
      "Epoch: 4897 \tTraining Loss: 1.075599 \tValidation Loss: 1.477724\n",
      "Validation loss decreased (1.477726 --> 1.477724).         Saving model ...\n",
      "Epoch: 4898 \tTraining Loss: 1.075597 \tValidation Loss: 1.477724\n",
      "Validation loss decreased (1.477724 --> 1.477724).         Saving model ...\n",
      "Epoch: 4899 \tTraining Loss: 1.075596 \tValidation Loss: 1.477722\n",
      "Validation loss decreased (1.477724 --> 1.477722).         Saving model ...\n",
      "Epoch: 4900 \tTraining Loss: 1.075595 \tValidation Loss: 1.477721\n",
      "Validation loss decreased (1.477722 --> 1.477721).         Saving model ...\n",
      "Epoch: 4901 \tTraining Loss: 1.075594 \tValidation Loss: 1.477719\n",
      "Validation loss decreased (1.477721 --> 1.477719).         Saving model ...\n",
      "Epoch: 4902 \tTraining Loss: 1.075593 \tValidation Loss: 1.477717\n",
      "Validation loss decreased (1.477719 --> 1.477717).         Saving model ...\n",
      "Epoch: 4903 \tTraining Loss: 1.075592 \tValidation Loss: 1.477716\n",
      "Validation loss decreased (1.477717 --> 1.477716).         Saving model ...\n",
      "Epoch: 4904 \tTraining Loss: 1.075591 \tValidation Loss: 1.477714\n",
      "Validation loss decreased (1.477716 --> 1.477714).         Saving model ...\n",
      "Epoch: 4905 \tTraining Loss: 1.075590 \tValidation Loss: 1.477714\n",
      "Validation loss decreased (1.477714 --> 1.477714).         Saving model ...\n",
      "Epoch: 4906 \tTraining Loss: 1.075589 \tValidation Loss: 1.477712\n",
      "Validation loss decreased (1.477714 --> 1.477712).         Saving model ...\n",
      "Epoch: 4907 \tTraining Loss: 1.075587 \tValidation Loss: 1.477711\n",
      "Validation loss decreased (1.477712 --> 1.477711).         Saving model ...\n",
      "Epoch: 4908 \tTraining Loss: 1.075586 \tValidation Loss: 1.477709\n",
      "Validation loss decreased (1.477711 --> 1.477709).         Saving model ...\n",
      "Epoch: 4909 \tTraining Loss: 1.075585 \tValidation Loss: 1.477708\n",
      "Validation loss decreased (1.477709 --> 1.477708).         Saving model ...\n",
      "Epoch: 4910 \tTraining Loss: 1.075584 \tValidation Loss: 1.477706\n",
      "Validation loss decreased (1.477708 --> 1.477706).         Saving model ...\n",
      "Epoch: 4911 \tTraining Loss: 1.075583 \tValidation Loss: 1.477705\n",
      "Validation loss decreased (1.477706 --> 1.477705).         Saving model ...\n",
      "Epoch: 4912 \tTraining Loss: 1.075582 \tValidation Loss: 1.477703\n",
      "Validation loss decreased (1.477705 --> 1.477703).         Saving model ...\n",
      "Epoch: 4913 \tTraining Loss: 1.075581 \tValidation Loss: 1.477702\n",
      "Validation loss decreased (1.477703 --> 1.477702).         Saving model ...\n",
      "Epoch: 4914 \tTraining Loss: 1.075580 \tValidation Loss: 1.477700\n",
      "Validation loss decreased (1.477702 --> 1.477700).         Saving model ...\n",
      "Epoch: 4915 \tTraining Loss: 1.075579 \tValidation Loss: 1.477699\n",
      "Validation loss decreased (1.477700 --> 1.477699).         Saving model ...\n",
      "Epoch: 4916 \tTraining Loss: 1.075577 \tValidation Loss: 1.477698\n",
      "Validation loss decreased (1.477699 --> 1.477698).         Saving model ...\n",
      "Epoch: 4917 \tTraining Loss: 1.075576 \tValidation Loss: 1.477696\n",
      "Validation loss decreased (1.477698 --> 1.477696).         Saving model ...\n",
      "Epoch: 4918 \tTraining Loss: 1.075575 \tValidation Loss: 1.477695\n",
      "Validation loss decreased (1.477696 --> 1.477695).         Saving model ...\n",
      "Epoch: 4919 \tTraining Loss: 1.075574 \tValidation Loss: 1.477693\n",
      "Validation loss decreased (1.477695 --> 1.477693).         Saving model ...\n",
      "Epoch: 4920 \tTraining Loss: 1.075573 \tValidation Loss: 1.477693\n",
      "Validation loss decreased (1.477693 --> 1.477693).         Saving model ...\n",
      "Epoch: 4921 \tTraining Loss: 1.075572 \tValidation Loss: 1.477691\n",
      "Validation loss decreased (1.477693 --> 1.477691).         Saving model ...\n",
      "Epoch: 4922 \tTraining Loss: 1.075571 \tValidation Loss: 1.477690\n",
      "Validation loss decreased (1.477691 --> 1.477690).         Saving model ...\n",
      "Epoch: 4923 \tTraining Loss: 1.075570 \tValidation Loss: 1.477689\n",
      "Validation loss decreased (1.477690 --> 1.477689).         Saving model ...\n",
      "Epoch: 4924 \tTraining Loss: 1.075569 \tValidation Loss: 1.477687\n",
      "Validation loss decreased (1.477689 --> 1.477687).         Saving model ...\n",
      "Epoch: 4925 \tTraining Loss: 1.075568 \tValidation Loss: 1.477687\n",
      "Validation loss decreased (1.477687 --> 1.477687).         Saving model ...\n",
      "Epoch: 4926 \tTraining Loss: 1.075566 \tValidation Loss: 1.477686\n",
      "Validation loss decreased (1.477687 --> 1.477686).         Saving model ...\n",
      "Epoch: 4927 \tTraining Loss: 1.075565 \tValidation Loss: 1.477684\n",
      "Validation loss decreased (1.477686 --> 1.477684).         Saving model ...\n",
      "Epoch: 4928 \tTraining Loss: 1.075564 \tValidation Loss: 1.477683\n",
      "Validation loss decreased (1.477684 --> 1.477683).         Saving model ...\n",
      "Epoch: 4929 \tTraining Loss: 1.075563 \tValidation Loss: 1.477682\n",
      "Validation loss decreased (1.477683 --> 1.477682).         Saving model ...\n",
      "Epoch: 4930 \tTraining Loss: 1.075562 \tValidation Loss: 1.477680\n",
      "Validation loss decreased (1.477682 --> 1.477680).         Saving model ...\n",
      "Epoch: 4931 \tTraining Loss: 1.075561 \tValidation Loss: 1.477678\n",
      "Validation loss decreased (1.477680 --> 1.477678).         Saving model ...\n",
      "Epoch: 4932 \tTraining Loss: 1.075560 \tValidation Loss: 1.477677\n",
      "Validation loss decreased (1.477678 --> 1.477677).         Saving model ...\n",
      "Epoch: 4933 \tTraining Loss: 1.075559 \tValidation Loss: 1.477676\n",
      "Validation loss decreased (1.477677 --> 1.477676).         Saving model ...\n",
      "Epoch: 4934 \tTraining Loss: 1.075558 \tValidation Loss: 1.477674\n",
      "Validation loss decreased (1.477676 --> 1.477674).         Saving model ...\n",
      "Epoch: 4935 \tTraining Loss: 1.075557 \tValidation Loss: 1.477673\n",
      "Validation loss decreased (1.477674 --> 1.477673).         Saving model ...\n",
      "Epoch: 4936 \tTraining Loss: 1.075555 \tValidation Loss: 1.477672\n",
      "Validation loss decreased (1.477673 --> 1.477672).         Saving model ...\n",
      "Epoch: 4937 \tTraining Loss: 1.075554 \tValidation Loss: 1.477669\n",
      "Validation loss decreased (1.477672 --> 1.477669).         Saving model ...\n",
      "Epoch: 4938 \tTraining Loss: 1.075553 \tValidation Loss: 1.477669\n",
      "Validation loss decreased (1.477669 --> 1.477669).         Saving model ...\n",
      "Epoch: 4939 \tTraining Loss: 1.075552 \tValidation Loss: 1.477666\n",
      "Validation loss decreased (1.477669 --> 1.477666).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4940 \tTraining Loss: 1.075551 \tValidation Loss: 1.477665\n",
      "Validation loss decreased (1.477666 --> 1.477665).         Saving model ...\n",
      "Epoch: 4941 \tTraining Loss: 1.075550 \tValidation Loss: 1.477663\n",
      "Validation loss decreased (1.477665 --> 1.477663).         Saving model ...\n",
      "Epoch: 4942 \tTraining Loss: 1.075549 \tValidation Loss: 1.477661\n",
      "Validation loss decreased (1.477663 --> 1.477661).         Saving model ...\n",
      "Epoch: 4943 \tTraining Loss: 1.075548 \tValidation Loss: 1.477659\n",
      "Validation loss decreased (1.477661 --> 1.477659).         Saving model ...\n",
      "Epoch: 4944 \tTraining Loss: 1.075547 \tValidation Loss: 1.477658\n",
      "Validation loss decreased (1.477659 --> 1.477658).         Saving model ...\n",
      "Epoch: 4945 \tTraining Loss: 1.075546 \tValidation Loss: 1.477657\n",
      "Validation loss decreased (1.477658 --> 1.477657).         Saving model ...\n",
      "Epoch: 4946 \tTraining Loss: 1.075544 \tValidation Loss: 1.477655\n",
      "Validation loss decreased (1.477657 --> 1.477655).         Saving model ...\n",
      "Epoch: 4947 \tTraining Loss: 1.075543 \tValidation Loss: 1.477653\n",
      "Validation loss decreased (1.477655 --> 1.477653).         Saving model ...\n",
      "Epoch: 4948 \tTraining Loss: 1.075542 \tValidation Loss: 1.477652\n",
      "Validation loss decreased (1.477653 --> 1.477652).         Saving model ...\n",
      "Epoch: 4949 \tTraining Loss: 1.075541 \tValidation Loss: 1.477651\n",
      "Validation loss decreased (1.477652 --> 1.477651).         Saving model ...\n",
      "Epoch: 4950 \tTraining Loss: 1.075540 \tValidation Loss: 1.477649\n",
      "Validation loss decreased (1.477651 --> 1.477649).         Saving model ...\n",
      "Epoch: 4951 \tTraining Loss: 1.075539 \tValidation Loss: 1.477648\n",
      "Validation loss decreased (1.477649 --> 1.477648).         Saving model ...\n",
      "Epoch: 4952 \tTraining Loss: 1.075538 \tValidation Loss: 1.477647\n",
      "Validation loss decreased (1.477648 --> 1.477647).         Saving model ...\n",
      "Epoch: 4953 \tTraining Loss: 1.075537 \tValidation Loss: 1.477646\n",
      "Validation loss decreased (1.477647 --> 1.477646).         Saving model ...\n",
      "Epoch: 4954 \tTraining Loss: 1.075536 \tValidation Loss: 1.477645\n",
      "Validation loss decreased (1.477646 --> 1.477645).         Saving model ...\n",
      "Epoch: 4955 \tTraining Loss: 1.075535 \tValidation Loss: 1.477643\n",
      "Validation loss decreased (1.477645 --> 1.477643).         Saving model ...\n",
      "Epoch: 4956 \tTraining Loss: 1.075534 \tValidation Loss: 1.477642\n",
      "Validation loss decreased (1.477643 --> 1.477642).         Saving model ...\n",
      "Epoch: 4957 \tTraining Loss: 1.075532 \tValidation Loss: 1.477640\n",
      "Validation loss decreased (1.477642 --> 1.477640).         Saving model ...\n",
      "Epoch: 4958 \tTraining Loss: 1.075531 \tValidation Loss: 1.477639\n",
      "Validation loss decreased (1.477640 --> 1.477639).         Saving model ...\n",
      "Epoch: 4959 \tTraining Loss: 1.075530 \tValidation Loss: 1.477638\n",
      "Validation loss decreased (1.477639 --> 1.477638).         Saving model ...\n",
      "Epoch: 4960 \tTraining Loss: 1.075529 \tValidation Loss: 1.477638\n",
      "Validation loss decreased (1.477638 --> 1.477638).         Saving model ...\n",
      "Epoch: 4961 \tTraining Loss: 1.075528 \tValidation Loss: 1.477636\n",
      "Validation loss decreased (1.477638 --> 1.477636).         Saving model ...\n",
      "Epoch: 4962 \tTraining Loss: 1.075527 \tValidation Loss: 1.477636\n",
      "Validation loss decreased (1.477636 --> 1.477636).         Saving model ...\n",
      "Epoch: 4963 \tTraining Loss: 1.075526 \tValidation Loss: 1.477635\n",
      "Validation loss decreased (1.477636 --> 1.477635).         Saving model ...\n",
      "Epoch: 4964 \tTraining Loss: 1.075525 \tValidation Loss: 1.477634\n",
      "Validation loss decreased (1.477635 --> 1.477634).         Saving model ...\n",
      "Epoch: 4965 \tTraining Loss: 1.075524 \tValidation Loss: 1.477633\n",
      "Validation loss decreased (1.477634 --> 1.477633).         Saving model ...\n",
      "Epoch: 4966 \tTraining Loss: 1.075523 \tValidation Loss: 1.477632\n",
      "Validation loss decreased (1.477633 --> 1.477632).         Saving model ...\n",
      "Epoch: 4967 \tTraining Loss: 1.075522 \tValidation Loss: 1.477630\n",
      "Validation loss decreased (1.477632 --> 1.477630).         Saving model ...\n",
      "Epoch: 4968 \tTraining Loss: 1.075520 \tValidation Loss: 1.477629\n",
      "Validation loss decreased (1.477630 --> 1.477629).         Saving model ...\n",
      "Epoch: 4969 \tTraining Loss: 1.075519 \tValidation Loss: 1.477627\n",
      "Validation loss decreased (1.477629 --> 1.477627).         Saving model ...\n",
      "Epoch: 4970 \tTraining Loss: 1.075518 \tValidation Loss: 1.477626\n",
      "Validation loss decreased (1.477627 --> 1.477626).         Saving model ...\n",
      "Epoch: 4971 \tTraining Loss: 1.075517 \tValidation Loss: 1.477625\n",
      "Validation loss decreased (1.477626 --> 1.477625).         Saving model ...\n",
      "Epoch: 4972 \tTraining Loss: 1.075516 \tValidation Loss: 1.477624\n",
      "Validation loss decreased (1.477625 --> 1.477624).         Saving model ...\n",
      "Epoch: 4973 \tTraining Loss: 1.075515 \tValidation Loss: 1.477622\n",
      "Validation loss decreased (1.477624 --> 1.477622).         Saving model ...\n",
      "Epoch: 4974 \tTraining Loss: 1.075514 \tValidation Loss: 1.477621\n",
      "Validation loss decreased (1.477622 --> 1.477621).         Saving model ...\n",
      "Epoch: 4975 \tTraining Loss: 1.075513 \tValidation Loss: 1.477618\n",
      "Validation loss decreased (1.477621 --> 1.477618).         Saving model ...\n",
      "Epoch: 4976 \tTraining Loss: 1.075512 \tValidation Loss: 1.477617\n",
      "Validation loss decreased (1.477618 --> 1.477617).         Saving model ...\n",
      "Epoch: 4977 \tTraining Loss: 1.075511 \tValidation Loss: 1.477615\n",
      "Validation loss decreased (1.477617 --> 1.477615).         Saving model ...\n",
      "Epoch: 4978 \tTraining Loss: 1.075510 \tValidation Loss: 1.477613\n",
      "Validation loss decreased (1.477615 --> 1.477613).         Saving model ...\n",
      "Epoch: 4979 \tTraining Loss: 1.075508 \tValidation Loss: 1.477611\n",
      "Validation loss decreased (1.477613 --> 1.477611).         Saving model ...\n",
      "Epoch: 4980 \tTraining Loss: 1.075507 \tValidation Loss: 1.477609\n",
      "Validation loss decreased (1.477611 --> 1.477609).         Saving model ...\n",
      "Epoch: 4981 \tTraining Loss: 1.075506 \tValidation Loss: 1.477608\n",
      "Validation loss decreased (1.477609 --> 1.477608).         Saving model ...\n",
      "Epoch: 4982 \tTraining Loss: 1.075505 \tValidation Loss: 1.477606\n",
      "Validation loss decreased (1.477608 --> 1.477606).         Saving model ...\n",
      "Epoch: 4983 \tTraining Loss: 1.075504 \tValidation Loss: 1.477604\n",
      "Validation loss decreased (1.477606 --> 1.477604).         Saving model ...\n",
      "Epoch: 4984 \tTraining Loss: 1.075503 \tValidation Loss: 1.477602\n",
      "Validation loss decreased (1.477604 --> 1.477602).         Saving model ...\n",
      "Epoch: 4985 \tTraining Loss: 1.075502 \tValidation Loss: 1.477601\n",
      "Validation loss decreased (1.477602 --> 1.477601).         Saving model ...\n",
      "Epoch: 4986 \tTraining Loss: 1.075501 \tValidation Loss: 1.477600\n",
      "Validation loss decreased (1.477601 --> 1.477600).         Saving model ...\n",
      "Epoch: 4987 \tTraining Loss: 1.075500 \tValidation Loss: 1.477598\n",
      "Validation loss decreased (1.477600 --> 1.477598).         Saving model ...\n",
      "Epoch: 4988 \tTraining Loss: 1.075499 \tValidation Loss: 1.477597\n",
      "Validation loss decreased (1.477598 --> 1.477597).         Saving model ...\n",
      "Epoch: 4989 \tTraining Loss: 1.075498 \tValidation Loss: 1.477595\n",
      "Validation loss decreased (1.477597 --> 1.477595).         Saving model ...\n",
      "Epoch: 4990 \tTraining Loss: 1.075497 \tValidation Loss: 1.477595\n",
      "Validation loss decreased (1.477595 --> 1.477595).         Saving model ...\n",
      "Epoch: 4991 \tTraining Loss: 1.075496 \tValidation Loss: 1.477593\n",
      "Validation loss decreased (1.477595 --> 1.477593).         Saving model ...\n",
      "Epoch: 4992 \tTraining Loss: 1.075494 \tValidation Loss: 1.477592\n",
      "Validation loss decreased (1.477593 --> 1.477592).         Saving model ...\n",
      "Epoch: 4993 \tTraining Loss: 1.075493 \tValidation Loss: 1.477592\n",
      "Validation loss decreased (1.477592 --> 1.477592).         Saving model ...\n",
      "Epoch: 4994 \tTraining Loss: 1.075492 \tValidation Loss: 1.477591\n",
      "Validation loss decreased (1.477592 --> 1.477591).         Saving model ...\n",
      "Epoch: 4995 \tTraining Loss: 1.075491 \tValidation Loss: 1.477590\n",
      "Validation loss decreased (1.477591 --> 1.477590).         Saving model ...\n",
      "Epoch: 4996 \tTraining Loss: 1.075490 \tValidation Loss: 1.477589\n",
      "Validation loss decreased (1.477590 --> 1.477589).         Saving model ...\n",
      "Epoch: 4997 \tTraining Loss: 1.075489 \tValidation Loss: 1.477588\n",
      "Validation loss decreased (1.477589 --> 1.477588).         Saving model ...\n",
      "Epoch: 4998 \tTraining Loss: 1.075488 \tValidation Loss: 1.477588\n",
      "Validation loss decreased (1.477588 --> 1.477588).         Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4999 \tTraining Loss: 1.075487 \tValidation Loss: 1.477586\n",
      "Validation loss decreased (1.477588 --> 1.477586).         Saving model ...\n",
      "Epoch: 5000 \tTraining Loss: 1.075486 \tValidation Loss: 1.477586\n",
      "Validation loss decreased (1.477586 --> 1.477586).         Saving model ...\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 5000\n",
    "\n",
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    linear_model.train() # prep model for training\n",
    "    for data, target in train_loader:\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = linear_model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    linear_model.eval() # prep model for evaluation\n",
    "    for data, target in test_loader:\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = linear_model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update running validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(test_loader.dataset)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}' \\\n",
    "          .format(epoch+1, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}). \\\n",
    "        Saving model ...'.format(valid_loss_min, valid_loss))\n",
    "        \n",
    "        torch.save(linear_model.state_dict(), 'xlm_model_linear.pt')\n",
    "        valid_loss_min = valid_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb3124d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.34      0.50     79752\n",
      "           1       0.02      0.57      0.03       736\n",
      "           2       0.01      0.58      0.03       605\n",
      "\n",
      "    accuracy                           0.34     81093\n",
      "   macro avg       0.34      0.50      0.19     81093\n",
      "weighted avg       0.98      0.34      0.50     81093\n",
      "\n",
      "Testing Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.34      0.50     19943\n",
      "           1       0.01      0.52      0.03       169\n",
      "           2       0.01      0.51      0.02       162\n",
      "\n",
      "    accuracy                           0.34     20274\n",
      "   macro avg       0.34      0.45      0.18     20274\n",
      "weighted avg       0.97      0.34      0.49     20274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_model = Net()\n",
    "linear_model.load_state_dict(torch.load(\"xlm_model_linear.pt\"))\n",
    "linear_model.eval()\n",
    "\n",
    "pred_list = torch.zeros(0, dtype=torch.long)\n",
    "target_list = torch.zeros(0, dtype=torch.long)\n",
    "train_count = 0\n",
    "count = 0\n",
    "\n",
    "train_pred_list = torch.zeros(0, dtype=torch.long)\n",
    "train_target_list = torch.zeros(0, dtype=torch.long)\n",
    "\n",
    "for data, target in train_loader:\n",
    "    output = linear_model(data)\n",
    "    _, preds = torch.max(output, 1) \n",
    "    train_pred_list = torch.cat([train_pred_list, preds.view(-1)])\n",
    "    train_target_list = torch.cat([train_target_list, target.view(-1)])\n",
    "#     for x in range(16):\n",
    "#         if preds[x] == target[x]: \n",
    "#             train_count+=1\n",
    "            \n",
    "# print(\"Training Accuracy =\", train_count / len(train_loader.dataset))\n",
    "train_result = classification_report(train_pred_list.numpy(), \n",
    "                                     train_target_list.numpy())\n",
    "print(\"Training Classification report: \\n\", train_result)\n",
    "            \n",
    "for data, target in test_loader:\n",
    "    output = linear_model(data)\n",
    "    _, preds = torch.max(output, 1) \n",
    "    pred_list = torch.cat([pred_list, preds.view(-1)])\n",
    "    target_list = torch.cat([target_list, target.view(-1)])\n",
    "#     for x in range(16):\n",
    "#         if preds[x] == target[x]: \n",
    "#             count+=1\n",
    "\n",
    "# print(\"Testing Accuracy =\", count / len(test_loader.dataset))\n",
    "\n",
    "result = classification_report(pred_list.numpy(), target_list.numpy())\n",
    "print(\"Testing Classification report: \\n\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e23212c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
